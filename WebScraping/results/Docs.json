[
    {
        "id": 1,
        "title": "Sector Rotation by Factor Model and Fundamental Analysis",
        "abstract": "",
        "corpus": "HTML conversions sometimes display errors due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on. Authors: achieve the best HTML results from your LaTeX submissions by selecting from this list of supported packages. This study presents an analytical approach to sector rotation, leveraging both factor models and fundamental metrics. We initiate with a systematic classification of sectors, followed by an empirical investigation into their returns. Through factor analysis, the paper underscores the significance of momentum and short-term reversion in dictating sectoral shifts. A subsequent in-depth fundamental analysis evaluates metrics such as PE, PB, EV-to-EBITDA, Dividend Yield, among others. Our primary contribution lies in developing a predictive framework based on these fundamental indicators. The constructed models, post rigorous training, exhibit noteworthy predictive capabilities. The findings furnish a nuanced understanding of sector rotation strategies, with implications for asset management and portfolio construction in the financial domain. Keywords: US Industrial Sectors, Factor Analysis, Fundamental Analysis, Trading Strategy. Sector is composed by a basket of stocks that representing companies in certain business class, which has unique features according to the business. Under certain conditions, such as economic cycles, sectors may behave accordingly due to the different characteristics of businesses. In this report, we are exploring how to capture returns by finding the hidden features behind different sectors and determining the leading sectors in some particular market conditions or social environments. Generally, this report covers a brief exploration of market and fundamental factors, explaining the meaning of each factors and how they are related to some sectors.Then we applied a neural network model to do a classification and prediction using the fundamental factors as inputs. At the end of the report, we also covers how sectors behaved under global events. There are many different ways to divide sectors. For the purpose of common acceptance and convenience for future data acquirement, we used the MSCI Global Industry Classification Standard, which includes 11 level one sectors, 24 level two industry groups, 69 level three industries, and 158 sub-industries. We use the 11 level one sectors as our main target. They are Energy, Materials, Industrials, Consumer Discretionary, Consumer Staples, Health Care, Financials, Information Technology, Communication Services, Utilities, and Real Estate. In order to track the performance of each sector, we use the S& GICS Indices which are constructed exactly as the MSCI classification.Before working on any strategies further, we need to determine if there are actually possible profits. In our case, we need to check how big the differences between sectors\u00e2\u20ac\u2122 returns are. For each observation time period, Define: Return Difference =(\u00e2\u02c6\u2018top 3subscripttop 3 3}}\u00e2\u02c6\u2018 start_POSTSUBSCRIPT top 3 end_POSTSUBSCRIPT Sector Return - \u00e2\u02c6\u2018bottom 3subscriptbottom 3 3}}\u00e2\u02c6\u2018 start_POSTSUBSCRIPT bottom 3 end_POSTSUBSCRIPT Sector Return )/3 Based on a monthly frequency, we calculate the return difference and get the following plot. Also, by calculation, the quarterly return difference has a mean of 0.1306, median of 0.1185, standard deviation of 0.0523. We can reach to a result that half of the quarterly return difference is more than 11.85%percent It is easy to see that there does exist potential investment opportunity by capturing the return differences between sectors. Momentum premium was first recognized by UCLA scholars Narasimhan Jegadeesh and Sheridan Titman in 1993. The momentum premium is established on the observation that assets that have performed well in the past have the trend to persist good performance in the future. Though the momentum effect is considered to be a market anomaly, it has been recognized widely among many asset classes. We will explore the momentum effect based on the sector indices introduced above. First of all, we need to construct the momentum factor. Typically, the momentum factor is constructed by the past 6 or 12 months cumulative return and excludes the most recent month\u00e2\u20ac\u2122s return, considering that there are also short-term reversion effects based on the mean-reversion effects. However, without a clear idea of how the sector indices carry the momentum effect, we need to explore through time intervals to find the best possible momentum factor. Then we constructed 12 different momentum factors using the past 1 to 12 month\u00e2\u20ac\u2122s return and excluding the most recent 0.1 portion trading days of each time period to avoid short-term reversion. For each of the factors with the period of n months where Rdsubscript\u00f0\ufffd\u2018\u2026\u00f0\ufffd\u2018\u2018R_{d}italic_R start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT is the daily return. For the 12 factors we got, we normalized them cross sections. Then we rank the factor exposures for each sector and take long positions of sectors with the highest two factor exposures, take short position of sectors with the lowest two factor exposures. Then we trade our portfolio under a monthly frequency. Here are the results from 2002 to 2022 February: Since there are several market crashes where the momentum factor led to negative returns, we also take a look at the most recent five years from 2017 to 2022 February: From this table, we can tell that by using the MOM__ factor, we can reach a maximum annual return rate of 21.19%percent and a maximum Sharpe ratio of 0.62. It is also interesting that we find the momentum factor with a short time period, for example, MOM__ and MOM__ have a very small even negative return rate. However, it exactly conforms to the short term reversion effect that the typical momentum factor would exclude. Short term reversion factor follows the simple principle that asset\u00e2\u20ac\u2122s price will have the trend to stay on an average level. Since we can see from the previous results of the momentum factor that there does exist short term reversion effect, we can try different reversion factors and find out what would be the best short term reversion observation period. Similarly, we can define several reversion factors with different time periods. And we take the negative number of the past n days cumulative return as the factor exposures. For the purpose of exploring the optimal time period, we take 5-day time interval and create 12 reversion factors from 5 trade days to 55 trade days. By using the same method, we compute the rank of each sector\u00e2\u20ac\u2122s factor exposure, and long the top two sectors, short the last two sectors on a monthly observation frequency. Between 2002 and 2022 February, the results are: From this table, we can tell that for the time between 2002 to recent time, the short term reversion effect is optimal for taking the past 30 days cumulative return. It has an optimal annual return rate of 8.77%percent on average and leads to a sharp ratio of 0.8735. Fundamental Analysis are always a good aspect to look at for investing. We collected quarterly data for all 11 indices from Bloomberg, including their P/E ratio, EV/EBIT, Profit Margin, etc. Our fundamental analysis would start from discovering features for each of the fundamental ratio,then we are trying to predict the sector performance by constructing using some of the features we found. The P/E is one of the most widely used tools to determine a stock\u00e2\u20ac\u2122s relative valuation. The purpose of analyzing the ratio is to show whether certain sector is worth to be invested because P/E ratio can reflect the investment risk in this sector. The figure below shows distribution of P/E ratios in different sectors. By comparing cross-sectional data, it is obvious that P/E of Real Estate Sector and Consumer Discretionary Sector are higher than others. The reason is that earning growth in the future is expected to grow fast in the two sectors or these sectors have some special advantages that guarantee long-term profitability with low risk. On the other hand, Financials Sector\u00e2\u20ac\u2122s ratio is relatively low compared with other sectors, which may result from its high volatility so investors are reluctant to pay for it. We also notice that the ratio in Energy Sector surged in 2015, which is related to some changes in the sector. The end of the oil age and emergence of alternative energy have reduced the earnings of the original sector. As a result, its relative price becomes higher than before. The change in EV/EBIT and EV/EBITDA is also due to this reason. The P/B ratio provides a valuable reality check for investors who are seeking growth at a reasonable price. For those sectors with more assets, their book value and market value are close, so P/B ratio is more useful when we analyze Real Estate sector and Financials sector. The figure below shows distribution of P/B ratio in different sectors. As the picture shows, Consumer Discretionary sector and IT sector have higher P/B ratio while Financials sector and Energy sector have relatively low ratios. What\u00e2\u20ac\u2122s more, Real Estate sector with high P/E ratio has relatively lower P/B ratio. EV/Sales can help investors better understand cost relative to unit sales and whether the company is overvalued or undervalued. If EV/Sales is relatively high, the company or sector is less attractive to investors. The figure below shows distribution of EV/Sales in different sectors. The result shows that Real Estate sector\u00e2\u20ac\u2122s ratio is higher than others\u00e2\u20ac\u2122, which means that index in this sector is overvalued. On the other hand, ratio in Energy sector is low, which can attract more investors. EV/EBIT and EV/EBITDA are independent of the capital structure of the company, whereas multiples like P/E ratio are impacted by financing decisions. Because of this reason, the two are the most commonly relied-upon multiples in relative valuation. However, one obvious distinction is that EV/EBIT considers depreciation and amortization. In some capital-intensive industries which have significant differences in D& EV/EBIT may make it a more accurate measure of value. But in our analysis, there is no such difference in the comparison of these two ratios under different sectors. The results can show that Real Estate sector has a higher ratio. The three ratio EV/Sales, EV/EBIT and EV/EBITDA can give a consensus conclusion that Real Estate sector is overvalued in the market. Dividend Yield is used to measure the amount of cash flow investors are getting back for each dollar. It is essentially the return on investment for a stock without any capital gains. The figure below shows distribution of Dividend yield in different sectors. The ratio in Communication Services sector is higher before 2018 while Energy sector\u00e2\u20ac\u2122s ratio is higher after that time. This is because communication services sector took place a reorganization of S& index in 2018. It now includes at least eighteen companies from IT and Consumer Discretionary sectors. Due to this reshuffling, dividend yield of this sector is impacted. Gross margin equals net sales less the cost of goods sold (COGS). Net sales are equivalent to the total revenue from sales, and COGS is the direct cost associated with producing goods. By calculating gross margin, we could measure one company\u00e2\u20ac\u2122s retain revenue after subtracting the production cost. The higher the gross margin, the more capital a company retains, which it can then use to pay other costs or satisfy debt obligations. Generally, companies with good gross margins would have a relatively sustainable competitive advantage. By analyzing gross margin data across sectors, we may observe some sectors that have more stable development in the long run. For our 11 sectors\u00e2\u20ac\u2122 gross margin data, the line chart above shows significant differences between the sectors. Overall, each industry index is relatively flat on its own, and have gaps between each others. Utilities, Communication Services and Information Technology(IT) have been among the top spears for last 10 years, occupying the first, second and third positions respectively, all above 40%percent On the contrary, the energy sector has been an under-performer for the past decade, ranking at the bottom, with gross margins consistently below 20%percent Gross margins in the rest industries are concentrated in the 25%percent range and have not fluctuate much. At the same time, by observing the comparison of fluctuations between industries, it is not difficult to see that the gross margin fluctuations of the energy industry and the utilities industry maybe relatively high in the past decade, and their peaks correspond to each other. During 2016, the utilities industry grew significantly, while energy declined comparatively. The trend was even more pronounced in 2020, with utilities reaching its highest level and the energy industry fell to the bottom. Generally, the gross margin feature maybe a significant indicator for Utilities, Communication Services and IT sectors. And our conjecture about the correlation between utilities and energy sectors will need further observation and verification. Operating margin equals operating income divided by revenue, it is a profitability ratio measuring revenue after covering operating and non-operating expenses of a business. And profit margin measures the profit ratio after paying for variable costs of production. It is calculated by the formula: Both operating margin and profit margin are used to gauge the degree of the company\u00e2\u20ac\u2122s activity makes money. Higher ratios are generally better, illustrating the company is efficient in its operations and is good at turning sales into profits. In our analysis, there is not a very big difference in the comparison of these two ratios under different sectors, which is determined by their definition. For these two ratios, Real Estate sector, IT sector and Financial sector have the top three high ratios.And Energy sector has the relatively lowest ratio. Also, both operating margin and profit margin for almost all sectors have similar trends in the last decade curves. This is attributed to the definition difference between the two features, and that\u00e2\u20ac\u2122s why the operating margin was slightly higher than the profit margin. Another thing that is worth to mentioning is that for Energy Sector, not just operating margin and profit margin, but also the gross margin, it always has the relatively lowest ratios and similar curve fluctuation, with sharp declines in 2016 and 2020. The two time nodes may consistent with some big revolution in the energy industry, which we will analyze later. Return on equity (ROE) and return on assets (ROA) are two of the most important measures for evaluating how effectively a company\u00e2\u20ac\u2122s management team is doing its job of managing the capital entrusted to it. ROE equals to generally net income divided by equity, while Return on Assets (ROA) is net income divided by average assets. So the primary differentiator between ROE and ROA is financial leverage or debt. ROE measures profitability and ROA is an efficiency measure of how well a company is using its assets. Investors may prefer to observe ROE, since equity represents the owner\u00e2\u20ac\u2122s interest in the business. Compared to other sources of fund, equity capital tends to be the most expensive source of funding and carries the largest risk premium of all financing options. Therefore, in our analysis, ROE may be a better feature that it could reflect the trend of market investment. As shown in the picture, IT sector has the highest ROA, the Consumer Staples sector and Consumer Discretionary sector also have a relatively higher ratio. In contrast, Financial sector has a lower ROA. The past ten years, or even twenty years, has been an era of rapid development of information technology. And compared with traditional industry and commerce, information technology is more flexible in the time and form of investment assets, that\u00e2\u20ac\u2122s the reason why IT will have the highest ratio. Also for the the Consumer Staples sector and Consumer Discretionary sector,they are all industries with fast innovation and short production cycle. Generally, these three will have constantly higher ratio for the long run. Therefore, for these three industries, if the ROA indicator fluctuates significantly, it may have an impact on the investment trend. For ROE ratio, similarly, IT, Consumer Staples stay high, and Consumer Discretionary sectors is also at a slightly higher level, except that the IT sector lost its prominence in ROA ratio. By comparing cross-sectional data, the Consumer Discretionary Sector and Industrials Sector have similar patterns in the last decade for both ROA and ROE ratios. They both have a low peak in 2020. It is conceivable that this is affected by the general environment of the epidemic. And as we mentioned before, the ROE and ROA curves of the energy sector still have a similar pattern, falling sharply in 2016 and 2020. In 2016, it was affected by changes in energy policy since 2015, reducing oil production while encouraging the development of clean and new energy. For 2020, we attribute this decline to the outbreak of the COVID-19 pandemic. Having these fundamental data, next step is to find out what quantitative relationships they have to futures sector returns. For fundamental factors, they are usually exposed in the company report with annual, semi-annual, or quarterly frequency. Our fundamental factors for each sector are reported quarterly, leading to a problem that the sample size for each individual sector is very small. To have a better performance of the prediction model, we need to combine all the sectors together and make a uniformed and comparable large sample. We neutralized each factor cross-sectional for the factor to have a mean of 0 and standard deviation of 1. If Xi,tsubscript\u00f0\ufffd\u2018\u2039\u00f0\ufffd\u2018\u2013\u00f0\ufffd\u2018\u00a1X_{i,t}italic_X start_POSTSUBSCRIPT italic_i , italic_t end_POSTSUBSCRIPT denotes one specific factor exposure for i\u00f0\ufffd\u2018\u2013iitalic_i-th sector at time t\u00f0\ufffd\u2018\u00a1titalic_t, in this case would be at t\u00f0\ufffd\u2018\u00a1titalic_t-th quarter, then for each individual t\u00f0\ufffd\u2018\u00a1titalic_t we have the neutralized exposure to be: Then we used the next quarter\u00e2\u20ac\u2122s cross-sectional normalized return as the corresponding return. First, we want to have a general view of the relations. The scatter plots between neutralized factors and future returns are as following: From the scatter plots, the relations between all factors and their future returns cannot be well interpreted by simple linear models. However, it is very common in the financial field that the sample will have a very low signal-noise ratio. As we observed before, the relations between each factor and its future return cannot be interpreted very well by linear models. Also, we have no idea what model would exactly best fit the data. Therefore, converting prediction of future returns to a classification problem and fitting the training sample with a neural network model which has comparably good performance with non-linear relations would be a great start point. [height=10] bias=false, title=Input layer, text=x start_POSTSUBSCRIPT end_POSTSUBSCRIPT[count=5, bias=false, title=Hidden layer 1, text=h start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT end_POSTSUBSCRIPT bias=false, title=Hidden layer 2, text=h start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT end_POSTSUBSCRIPT title=Output layer, text=y^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT end_POSTSUBSCRIPT Neural network takes a vector as the input, and goes to each of the neuron in the first hidden layer and gains new activation vectors which act as the input for next hidden layer. After the last hidden layer, neural network model would pass out the probability for each of the prediction class and we choose the one with the highest probability as the prediction. This process is called front propagation. After comparing the prediction to the actual results, we adjust the weights of the nodes by using back propagation for each training pair in the training samples. Also, we use the rectified linear unit function as the activation function for hidden layers and sigmoid function as the activation function for final output. Since we only have a sample of size 200, choosing quasi-Newton methods as the solver has better performance for small sample training. Then we need to construct the training, validation, and test sets. Since the fundamental factors are already neutralized (normalized) within each sector, we divide the sample data to 60%percent 20%percent 20%percent by convention. Without shuffling, we will have the historical data divided where test set contains the most recent data. For the corresponding output value, we assign 1 to samples with positive future return and 0 with negative returns. The complexity of neural network directly related to the number and sizes of hidden layers. For the purpose of avoiding overfitting or under-fitting, we need to find proper hyper parameters for neural network model. We start from a simple model with two layers. Let N\u00f0\ufffd\u2018\ufffdNitalic_N denote the number of nodes in each hidden layer, alpha is the hyper parameter for L2 regularization penalty function. With larger N\u00f0\ufffd\u2018\ufffdNitalic_N, the model is more complex. If alpha increases, the penalty for large weights increases, which makes the model tend to be more simple. Considering our sample size is small, intuitively we need to focus more on the overfitting problem. For a range of alpha and N\u00f0\ufffd\u2018\ufffdNitalic_N, we train the model using the training set data, and get the score for prediction on validation set. The score represents the probability of making a right prediction. Here are the results: To better understand how the hyperparameters influence model performance, we visualize the data by using N\u00f0\ufffd\u2018\ufffdNitalic_N and alpha as the bottom coordinates, and use the corresponding probability as the height. From the figure, we can tell that the model have several local optimal pairs. And the scores at the optimal points with relative large N values are also combined with small alpha values. For example, the combination of 14 nodes and alpha equals 0.01 has a local optimal score of 0.6. Since we are training with a small sample, using such a complex model with a high score is highly likely overfitting. Therefore, we start from the simple model by looking at models with 5 nodes model and check how the score varies with alpha. For model with 5 nodes, we see there are two local peaks with alpha equal to 1 and 0.25, then we pick the middle value 0.5 as the value of alpha considering the trade-off between variance and bias. Constructed and trained the model, next we would test the model by feeding a new data set to the model. On the test set, the score of the model is 0.64, which means the model predicts 64%percent of the results correctly. More detailed results are showed in the following table: On the test set, we have a 0.59 winning rates on the positive predictions and 0.72 on the negative predictions, which gives an overall winning rate of 0.64. By using the predictions from the trained model, we used the data from validation set to get trade signals. Instead of having signals of 1 or 0 as the model\u00e2\u20ac\u2122s output, we choose the probability of the prediction output being 1, which is given by the activation sigmoid function. Then we will have a time series of the probability for each sector, and rank the probability from highest to lowest where the highest probability will have a rank 1. For each cross-sectional ranking, we equally-weighted long sectors with rank 1 to 3 and short sectors with rank 9 to 11 to construct a dollar-neutral portfolio. On the test set, which is from September in 2020 to September in 2021, we have a Sharpe ratio of 2.21. The cumulative return plot is following: There are still issues that need to be considered carefully in the future. First is the factor neutralization. In previous model, we neutralized the factor exposure cross-sectionally, where the exposures reflect the relative level of factor exposure for one sector compared to other sectors at a given time. However, different sectors may have inner trends of higher exposures than others for some factors, especially for fundamental factor. What\u00e2\u20ac\u2122s more, we only have quarterly fundamental data available from 2017 and it is hard to implement time series normalization for each sector. Therefore, how to modify the factor exposures to make them comparable is a difficult problem. Secondly, as the sample size is small, the model might not be applicable on a wider range of time since we only trained and tested on the most recent five years. One possible way to improve this model is to use daily factors such as volume, close price as input, and convert fundamental factors to daily frequency by the corresponding quarter. Then we would have a sample size of approximately 1250 for each sector and over 13000 samples for training. However, the model might depends more on the daily factors rather than fundamental factors since their exposures would be the same value for each quarter. 1. Returns to Buying Winners and Selling Losers: Implications for Stock Market Efficiency Narasimhan Jegadeesh; Sheridan Titman The Journal of Finance, Vol. 48, No. 1. (Mar., 1993), pp. 65-91. 2.The Global Industry Classification Standard, MSCI (1999)",
        "keywords": ""
    },
    {
        "id": 2,
        "title": "Prompt emission of relativistic protons up to GeV energies from M6.4-class solar flare on July 17, 2023",
        "abstract": "AbstractWe show evidence of particle acceleration at GEV energies associated directly with protons from the prompt emission of a long-duration M6-class solar flare on July 17, 2023, rather than from protons acceleration by shocks from its associated Coronal Mass Ejection (CME), which erupted with a speed of 1342 km/s. Solar Energetic Particles (SEP) accelerated by the blast have reached Earth, up to an almost S3 (strong) category of a radiation storm on the NOAA scale.\nAlso, we show a temporal correlation between the fast rising of GOES-16 proton and muon excess at ground level in the count rate of the New-Tupi muon detector at the central SAA region.\nA Monte Carlo spectral analysis based on muon excess at New-Tupi is consistent with the acceleration of electrons and protons (ions) up to relativistic energies (GeV energy range) in the impulsive phase of the flare. In addition, we present another two marginal particle excesses (with low confidence) at ground-level detectors in correlation with the solar flare prompt emission.",
        "corpus": "We show evidence of particle acceleration at GEV energies associated directly with protons from the prompt emission of a long-duration M6-class solar flare on July 17, 2023, rather than from protons acceleration by shocks from its associated Coronal Mass Ejection (CME), which erupted with a speed of 1342 km/s. Solar Energetic Particles (SEP) accelerated by the blast have reached Earth, up to an almost S3 (strong) category of a radiation storm on the NOAA scale. Also, we show a temporal correlation between the fast rising of GOES-16 proton and muon excess at ground level in the count rate of the New-Tupi muon detector at the central SAA region. A Monte Carlo spectral analysis based on muon excess at New-Tupi is consistent with the acceleration of electrons and protons (ions) up to relativistic energies (GeV energy range) in the impulsive phase of the flare. In addition, we present another two marginal particle excesses (with low confidence) at ground-level detectors in correlation with the solar flare prompt emission. Since 1950 the observation of solar energetic particles from the solar flares and coronal mass ejections (CMEs) have been done with ground-level experiments, such as the neutron monitors (NMs) (Meyer et\u00c2 al., 1956; Simpson, 2000; Moraal et\u00c2 al., 2000) as well as the solar neutron telescope network (Hu & Semones, 2022; Vald\u00c3\u00a9s-Galicia et\u00c2 al., 2009), all around the world. These observations have yielded a lot of new information. For instance, the existence of a prompt and gradual emission of solar energetic particles (SEP) in flares and CMEs, respectively, the correlations of the cosmic ray intensity with CMEs and other solar disturbances crossing the Earth, etc. (Chupp et\u00c2 al., 1987; Moraal et\u00c2 al., 2000) Also, the solar modulation of galactic cosmic rays is inversely correlated with solar activity, inferred through the number of sunspots, which can be the key to understanding more about space weather (Cade\u00c2 III & Chan-Park, 2015). Nowadays, particles accelerated to near the Sun can be detected by space-borne instruments such as the High-Energy Proton and Alpha Detector (HEPAD) on the Geostationary Operations Environmental Satellite (GOES) and the Advanced Composition Explorer (ACE) spacecraft at Lagrange L1 point, through the Electron Proton Alpha Monitor (EPAM) and the Solar Isotope Spectrometer (SIS), among others. Not all of the solar energetic particles can be measured at ground level. Even those SEPs from solar events with a good geoeffectiveness can be dissipated by the IMF, or deflected or captured by the Earth\u00e2\u20ac\u2122s magnetic field or until absorbed by atmosphere. On the other hand, ground-level enhancements (GLEs), typically in the MeV-GeV energy range, are sudden increases in cosmic ray intensities registered in most cases by NMs. GLEs are quite rare events, and fewer than 100 GLEs have been observed by NMs in the last 70 years. In most cases, the NMs that observed GLEs are located at regions with small geomagnetic rigidity cutoff, that is, at high latitudes (Shea & Smart, 2012). The GLEs follow the solar radiation storms, solar energetic particles (mostly protons) observed by GOES. They occur when a large-scale magnetic eruption, a coronal mass ejection and associated solar flare, accelerates charged particles in the solar atmosphere to high energies. However, in the present case, despite a radiation storm reaching above the S2-class on the NOAA scale on July 18, 2023, it did not generate a GLE, only a prompt emission of relativistic protons (ions) above GeV energies, during the phase eruptive, and observed by ground-level detectors strategically located, within the SAA central region (New-Tupi muon detector) and by the (Yangbagin muon telescope) at the Yangbajing Cosmic Ray Observatory (Tibet 4440 m a.s.l) (Zhang et\u00c2 al., 2010). Also, we looked for any signal in the counting rate at the Neutron Monitor\u00e2\u20ac\u2122s (NM) network around the world from Neutron Monitor Data Base (NMDB) https://www.nmdb.eu/nest/, with negative results. However, we found a low confidence signal only at Kerguelen NM, at geographical coordinates (49.3S, 70.3E), altitude of 33 m a.s.l, and an effective vertical cutoff rigidity of 1.14 GV. We present details of these observations. The New-Tupi muon detector is completely unmoderated (without no surrounding lead or other material). The muon detection energy threshold is about 200 MeV (see Appendix A). That contrasts with other muon detectors that have, in most cases, a surrounding lead material with a thickness of up to 5 cm. The shielding effect of the Earth\u00e2\u20ac\u2122s magnetic field on cosmic ray particles is quantified by the magnetic rigidity cutoff from a specific location (Smart & Shea, 2009). The smaller the rigidity cutoff, the lower the energy cosmic ray particles penetrate the magnetosphere. On the other hand, a restricted area between latitudes 20 and 40 of the southern hemisphere, over South America and the Atlantic Ocean poses a geomagnetic field with an anomalously lower intensity (around 22,000 nT). The region is known as the South Atlantic Anomaly (SAA) (Pav\u00c3\u00b3n-Carrasco & De\u00c2 Santis, 2016). According to Swarm\u00e2\u20ac\u2122s satellite observations (Finlay et\u00c2 al., 2020), the SAA appears splitting into two, a smaller area over the Atlantic Ocean in southwest Africa and a larger area over eastern South America. Fig.\u00c2 1 (top panel) summarizes the situation. We would like to point out that the location of the New-Tupi telescope coincides with the central part of the SAA indicated by the arrow on the left of Fig.\u00c2 1 (top panel). The main effect of the SAA is on the satellites since the \u00e2\u20ac\u212270s. We know the frequent failures when they pass through the SAA region. A large amount of charged particles precipitation in this region damages and perturbates the satellites\u00e2\u20ac\u2122 electronics. Also, according to the results from the PAMELA detector at satellite\u00e2\u20ac\u2122s altitudes (Casolino et\u00c2 al., 2009), the effect of geomagnetic cutoff on low-energy particles is present in high latitudes close to the poles and also in the SAA region, composed mostly of low energy cosmic protons (E <<< 200 MeV ). In other words, the Pamella satellite has shown that the SAA introduces a sub-cutoff in the magnetic rigidity, below the Stormer\u00e2\u20ac\u2122s magnetic rigidity cutoff. We show that the SAA also affects secondary cosmic rays detected at ground level. As the horizontal magnetic component on Earth\u00e2\u20ac\u2122s surface is smaller on the SAA, the magnetic lateral dispersion of the secondary particles forming an air shower is smaller too. The effect increases the number of particles reaching a detector. In other words, this behavior mimics a magnetic rigidity sub-cutoff below the Stormer\u00e2\u20ac\u2122s rigidity cutoff. We show that effect through a Monte Carlo simulation based on CORSIKA-Fluka code (Heck et\u00c2 al., 2012; Battistoni et\u00c2 al., 2008), where 1.0\u00c3\u20141061.0superscript1061.0 10^{6}1.0 \u00c3\u2014 10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT proton air-showers are simulated, taking into account the magnetic coordinates (latitude, longitude) and height of several places where detectors are installed (mostly neutron monitors). Fig.\u00c2 1 bottom left panel shows the lateral particle distribution in air-showers of cosmic rays, as detected from several ground-level detectors. In all cases, there is a fast rise of particles with the shower lateral development until reach um maximum value that happens for different values of R, called hereafter as Rm\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2xsubscript\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5R_{max}italic_R start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT We can see that the number of shower particles at Rm\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2xsubscript\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5R_{max}italic_R start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT in the SAA central region (SAA-CR) rigidity 9.6 GV is higher than at Rome and Athens, both with the rigidity of 6.3 GV, and 8.5 GV, respectively, i.e., minors than the SAA-CR. Already Fig. 1 bottom right panel, shows a correlation between Rm\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2xsubscript\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5R_{max}italic_R start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT versus the geomagnetic Stormer rigidity cutoff of six different places (black circles), including the SAA-CR (blue square). The solid red line is a linear fit, and the two dotted red lines delimit the region with significance of \u00c2\u00b11\u00e2\ufffd\u00a2\u00cf\u0192plus-or-minus1\u011f\ufffd\u0153\ufffd 1 1 italic_\u00cf\u0192. Only two places are out from the \u00c2\u00b11.0\u00e2\ufffd\u00a2\u00cf\u0192plus-or-minus1.0\u011f\ufffd\u0153\ufffd 1.0 1.0 italic_\u00cf\u0192 significance region, the Thule (Groenlandia) in the lowest rigidity region and SAA-CR in the highest rigidity region. The high Stormer\u00e2\u20ac\u2122s rigidity of SAA-CR does not correspond to the high value of Rm\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2xsubscript\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5R_{max}italic_R start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT expected by the correlation. From an interpolation, it is possible to see that the small value of Rm\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2xsubscript\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5R_{max}italic_R start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT at SAA-CR correspond to the rigidity of only 3.1\u00e2\u02c6\u20191.7+3.0subscriptsuperscript3.13.01.73.1^{+3.0}_{-1.7}3.1 start_POSTSUPERSCRIPT + 3.0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT - 1.7 end_POSTSUBSCRIPT GV, within a confidence of \u00c2\u00b11.0\u00e2\ufffd\u00a2\u00cf\u0192plus-or-minus1.0\u011f\ufffd\u0153\ufffd 1.0 1.0 italic_\u00cf\u0192. This behavior of having a location close to the Equator, with a nominal lower magnetic rigidity cutoff, favors the observation of phenomena such as the SEPs. On July 17, 2023, at \u00e2\u02c6\u00bcsimilar-to UT, the active region AR 13363 had an explosion, reaching an M6-class solar flare followed by a resplendent coronal mass ejection. Fig.\u00c2 2 left panel shows the image from the Solar Dynamo observatory of the blaze of fire responsible for the X-ray flux reaching M6-class flare. Already the right panel shows the LASCO-C2 coronograph image of its associated CME on July 18, 2023, at 00:42 UT. NOAA prediction models confirmed that a CME originated in the powerful M6-class flare from sunspot AR3363 would pass through the magnetosphere on July 20, triggering at least a G1-class (minor) geomagnetic storm. However, no magnetic storms were observed. Fig.\u00c2 3 shows the GOES-18 X-ray flux (upper panel) and the GOES-16 proton flux (bottom panel). The X-ray flux peaks at 18:00 UT, while the proton flux has two peaks. The first (in orange) is due to the acceleration of protons during the impulsive fast-rising phase of the flare peaking at 18:09 UT. The delay between the X-ray and proton flux peaks is because the proton velocity is slightly less than c, and the proton path is longer. The second peak are the protons accelerated by CME shocks, peaking at 18:14 UT, and it\u00e2\u20ac\u2122s the so-called gradual phase and is characterized by its long duration, up to several days. Fig.\u00c2 4 shows the temporal coincidence between the GOES proton flux in the impulsive phase and New-Tupi muon excess. Particles (mostly proton) are accelerated in this phase exclusively by the flare, during the fast-rising until to reach the first peak (orange sector) in Fig.\u00c2 4. However, in the so-called gradual phase, protons accelerated by CME\u00e2\u20ac\u2122s shocks, the proton flux does not reach the GeV energy range because there are no excess muons at ground level. We perform a Monte Carlo simulation of air showers initiated by SEP (protons) using the CORSIKA code (Heck et\u00c2 al., 2012), together with the FLUKA interaction model (Battistoni et\u00c2 al., 2008), that works well at GeV and sub-GeV energies, including secondary particle decay. The surviving particles are tracked through the atmosphere until they reach ground level (sea level). Most particles are muons with a small contribution of electrons and nucleons. The aim is to obtain the yield function, S\u00ce\u00bc\u00e2\ufffd\u00a2(EP)subscript\u011f\ufffd\u2018\u2020\u011f\ufffd\u0153\u2021subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u0192S_{ start_POSTSUBSCRIPT italic_\u00ce\u00bc end_POSTSUBSCRIPT ( italic_E start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT ), that is, the number of muons at sea level per primary proton, for an estimate of the upper limit of the integral proton flux in the GeV energy range, associated with the impulsive phase of M-6-class flare with onset on July 17, 2023, at \u00e2\u02c6\u00bcsimilar-to 18 UT. Fig.\u00c2 6 (black squares) shows the Monte Carlo output under the New-Tupi geomagnetic conditions and vertical proton incidence, and fitting as where A\u00ce\u00bc=(6.8\u00c2\u00b11.4)\u00c3\u201410\u00e2\u02c6\u20193subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u0153\u2021plus-or-minus6.81.4superscript103A_{ 1.4) 10^{-3}italic_A start_POSTSUBSCRIPT italic_\u00ce\u00bc end_POSTSUBSCRIPT = ( 6.8 \u00c2\u00b1 1.4 ) \u00c3\u2014 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT, \u00ce\u00bd=1.18\u00c2\u00b10.24\u011f\ufffd\u0153\u02c6plus-or-minus1.180.24 0.24italic_\u00ce\u00bd = 1.18 \u00c2\u00b1 0.24, and E0=10.2\u00c2\u00b12.1subscript\u011f\ufffd\ufffd\u00b80plus-or-minus10.22.1E_{0}=10.2 2.1italic_E start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = 10.2 \u00c2\u00b1 2.1 GeV. Fig.\u00c2 6 shows the fits (red dot line). In addition, we assume here that the energy spectrum of solar protons in the GeV energy range, which is in the high-energy tail of the SEP spectrum, can be fitted by a single power-law function. There are two unknown quantities in the above power-law function: the coefficient APsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u0192A_{P}italic_A start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT and the spectral index \u00ce\u00b2\u011f\ufffd\u203a\u00bd A convolution between the yield function S\u00ce\u00bc\u00e2\ufffd\u00a2(EP)subscript\u011f\ufffd\u2018\u2020\u011f\ufffd\u0153\u2021subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u0192S_{ start_POSTSUBSCRIPT italic_\u00ce\u00bc end_POSTSUBSCRIPT ( italic_E start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT ) and the proton spectrum JP\u00e2\ufffd\u00a2(EP)subscript\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u2018\u0192subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u0192J_{P}(E_{P})italic_J start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT ( italic_E start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT ) gives the response function (Augusto et\u00c2 al., 2016b), which is the number of muons in the excess signal at New-Tupi detector generated by the SEP during the period T. We express this convolution as where F\u00e2\ufffd\u00a2(\u00ce\u00b8)\u00e2\u02c6\u00bcexp\u00e2\ufffd\u00a1(\u00ce\u00b8/C)similar-to\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u0153\u0192\u011f\ufffd\u0153\u0192\u011f\ufffd\ufffd\u00b6F( ( italic_\u00ce\u00b8 ) \u00e2\u02c6\u00bc roman_exp ( italic_\u00ce\u00b8 / italic_C ) is the pitch angle distribution (Shea & Smart, 1982; Miroshnichenko et\u00c2 al., 2005). In the central region of SAA (New-Tupi), the transverse geomagnetic component is only B\u00e2\u0178\u201a=18.3subscript\u011f\ufffd\ufffd\u00b5perpendicular-to18.3B_{ start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT = 18.3 mT, that is, almost 80% smaller than the transverse component, at the same latitude, but outside from the SAA region, favoring the focusing factor of the geomagnetic parallel geomagnetic on the incident solar protons (small pitch angles). For the present event, we found exp\u00e2\ufffd\u00a1(\u00ce\u00b8/C)\u00e2\u02c6\u00bc1similar-to\u011f\ufffd\u0153\u0192\u011f\ufffd\ufffd\u00b61 1roman_exp ( italic_\u00ce\u00b8 / italic_C ) \u00e2\u02c6\u00bc 1. The muon excess associated with protons emitted during the impulsive phase (see Fig.\u00c2 4), and considering an effective angular aperture of 60 degrees around the zenith of the New-Tupi detector, the counting rate excess is Furthermore, we also obtain the integrated time primary fluence as For the present case, the GOES-proton fluence in the high-energy region (Ep\u00e2\u2030\u00a5 MeV is The terms on the left side of Eq.\u00c2 1 and Eq.\u00c2 5 are known. Thus, we can consider all possible values of \u00ce\u00b2\u011f\ufffd\u203a\u00bd and APsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u0192A_{P}italic_A start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT compatible with the observed muon counting rate excess, J\u00ce\u00bcsubscript\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u0153\u2021J_{ start_POSTSUBSCRIPT italic_\u00ce\u00bc end_POSTSUBSCRIPT, and the integrated GOES-proton fluence F\u011f\ufffd\ufffd\u00b9Fitalic_F. Fig.\u00c2 7 summarizes the situation. Giving: A\u00e2\ufffd\u00a2p=(1.20\u00c2\u00b10.96)\u00c3\u201410\u00e2\u02c6\u20193/(c\u00e2\ufffd\u00a2m2\u00e2\ufffd\u00a2s\u00e2\ufffd\u00a2s\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2G\u00e2\ufffd\u00a2e\u00e2\ufffd\u00a2V)\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\ufffdplus-or-minus1.200.96superscript103\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u01612\u011f\ufffd\u2018 \u011f\ufffd\u2018 \u011f\ufffd\u2018\u0178\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u2030Ap=(1.20 0.96) 10^{-3}/(cm^{2}s italic_p = ( 1.20 \u00c2\u00b1 0.96 ) \u00c3\u2014 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT / ( italic_c italic_m start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_s italic_s italic_r italic_G italic_e italic_V ) and \u00ce\u00b2=1.89\u00c2\u00b11.10\u011f\ufffd\u203a\u00bdplus-or-minus1.891.10 1.10italic_\u00ce\u00b2 = 1.89 \u00c2\u00b1 1.10. To make a comparison with satellite GOES data, we obtain the integral proton flux in the GeV energy range as Fig.\u00c2 8 shows the results of the integral proton flux obtained from the New-Tupi muon excess observed in coincidence with the radiation. The red circles represent the GOES-16 data, and the black squares represent the expected proton flux in the GeV energy range obtained from Monte Carlo, muon excess at the New-Tupi detector, and the GOES-proton fluence. The origin of this transient event was the solar eruption, an M6-class flare (prompt emission), accelerating protons (ions) up to relativistic energies, GeV energy range. We have reported evidence of SEPs accelerated up to GeV energies during the eruptive phase of the M6-class solar flare on July 17, 2023. The result comes from a timing analysis of a muon excess from the New-Tupi detector at the SAA central region. Muons at New-Tupi are produced by protons (ions) interaction in the upper atmosphere reaching the Earth with a magnetic rigidity above 3 GV (\u00e2\u02c6\u00bcsimilar-to 3 GeV for protons). In most cases, SEP (mostly protons) detected by the GOES-16 spacecraft shows two steps. An impulsive phase, where the acceleration of protons (ions) is by the prompt emission of flare, followed by a gradual phase of long duration, where the acceleration of protons (ions) is by the associated CME shock waves. We want to point out that the muon excess produced by SEPs with an effective rigidity above the cutoff (\u00e2\u02c6\u00bcsimilar-to 3 GV) at the New-Tupi muon detector is in temporal coincidence only with the GOES proton flux from the impulsive phase (see Fig.\u00c2 4) . Consequently, in the gradual phase, the protons accelerated by CME\u00e2\u20ac\u2122s shocks do not reach the GeV energy range because a muon excess is absent at ground level. A marginal muon excess also appears on the Yan ba Jing S-21(pointing 21 degrees south) muon telescope (in Tibet). Also, a marginal particle excess is seen only in the French Kerguel NM (close to the South polar region). In both cases, the excesses are in (temporal) coincidence with the GOES proton flux (impulsive phase). However, it is hard to verify whether these excesses are genuine due to low confidence or simply fluctuations in the detectors\u00e2\u20ac\u2122 count rate. From a Monte Carlo analysis, we show that the SAA central region is favourable to the observation of transient solar events, especially SEP, because the magnetosphere has a \u00e2\u20ac\ufffddip\u00c2\u00b4\u00c2\u00b4 in this region, weakening the geomagnetic field strength and allowing the entrance of charged particles at large deeps in a region not far from the geographic Equator, giving a rigidity sub-cutoff around 3.1 GV in a place where the conventional Stormer geomagnetic rigidity cutoff is around 10 GV. This work is supported by the Rio de Janeiro Research Foundation (FAPERJ) under Grant E-26/010.101128/2018. We thank to NMDB Database (www.nmdb.eu), founded under the European Union FP7 Program (Contract No. 213007) by provide NMs data and the Space Weather Prediction Center from NOAA for its open data policy. The New-Tupi telescope is built with four identical particle detectors, forming two telescopes, as shown in Fig. 8 from Augusto et\u00c2 al. (2016a). Each detector consisting of an Eljen EJ-208 plastic scintillator slab of 150 cm x 75 cm x 5 cm and a Hamamatsu R877 photomultiplier of 127 millimeters in diameter, packaged in a pyramidal box. The PMT high voltage divider, amplifier, and high voltage power supplier are in the ORTEC ScintiPackTM Photomultiplier Base 296. From February 6, 2023, we have implemented a data acquisition system using a VERTILON high-speed pulse counting system (MCPC618-8 Channel). allowing for direct connection with the PMTs without the need for external preamplifiers, with a 250 MHz count rate per channel. Now the detector is working only in scaler mode or single particle technique (Aglietta et\u00c2 al., 1996), where the single hit rates of all four PMTs, are recorded once a second. However, so far, only two detectors are working. The coincidences among these detectors of each telescope will be implanted. Also, the barometric coefficients for cosmic muon fluxes at the Earth\u00e2\u20ac\u2122s surface can be obtained using the CORSICA code in Kovylyaeva et\u00c2 al. (2013). For New-Tupi detector conditions and at sea level, the barometric coefficient is about -0.14% per mb, about eight to nine times less than the typical barometric coefficient in NMs.",
        "keywords": "sun:activity, high-speed stream, cosmic rays modulation"
    },
    {
        "id": 3,
        "title": "Generative Inverse Design of Metamaterials with Functional Responses by Interpretable Learning",
        "abstract": "AbstractMetamaterials with functional responses, such as wave-based responses or deformation-induced property variation under external stimuli, can exhibit varying properties or functionalities under different conditions. Herein, we aim at rapid inverse design of these metamaterials to meet target qualitative functional behaviors. This inverse problem is challenging due to its intractability and the existence of non-unique solutions. Past works mainly focus on deep-learning-based methods that are data-demanding, require time-consuming training and hyperparameter tuning, and are non-interpretable. To overcome these limitations, we propose the Random-forest-based Interpretable Generative Inverse Design (RIGID), a single-shot inverse design method to achieve the fast generation of metamaterial designs with on-demand functional behaviors. Unlike most existing methods, by exploiting the interpretability of the random forest, we eliminate the need to train an inverse model mapping responses to designs. Based on the likelihood of target satisfaction derived from the trained forward model, one can sample design solutions using Markov chain Monte Carlo methods. The RIGID method therefore functions as a generative model that captures the conditional distribution of satisfying solutions given a design target. We demonstrate the effectiveness and efficiency of RIGID on both acoustic and optical metamaterial design problems where only small datasets (less than 250 training samples) are available. Synthetic design problems are created to further illustrate and validate the mechanism of likelihood estimation in RIGID. This work offers a new perspective on solving on-demand inverse design problems, showcasing the potential for incorporating interpretable machine learning into generative design and eliminating its large data requirement.",
        "corpus": "Metamaterials with functional responses, such as wave-based responses or deformation-induced property variation under external stimuli, can exhibit varying properties or functionalities under different conditions. Herein, we aim at rapid inverse design of these metamaterials to meet target qualitative functional behaviors. This inverse problem is challenging due to its intractability and the existence of non-unique solutions. Past works mainly focus on deep-learning-based methods that are data-demanding, require time-consuming training and hyperparameter tuning, and are non-interpretable. To overcome these limitations, we propose the Random-forest-based Interpretable Generative Inverse Design (RIGID), a single-shot inverse design method to achieve the fast generation of metamaterial designs with on-demand functional behaviors. Unlike most existing methods, by exploiting the interpretability of the random forest, we eliminate the need to train an inverse model mapping responses to designs. Based on the likelihood of target satisfaction derived from the trained forward model, one can sample design solutions using Markov chain Monte Carlo methods. The RIGID method therefore functions as a generative model that captures the conditional distribution of satisfying solutions given a design target. We demonstrate the effectiveness and efficiency of RIGID on both acoustic and optical metamaterial design problems where only small datasets (less than 250 training samples) are available. Synthetic design problems are created to further illustrate and validate the mechanism of likelihood estimation in RIGID. This work offers a new perspective on solving on-demand inverse design problems, showcasing the potential for incorporating interpretable machine learning into generative design and eliminating its large data requirement. Metamaterials with functional responses are engineered materials that exhibit varying properties or behaviors under different conditions. One example is metamaterials whose electromagnetic, acoustic, or elastic wave propagation behaviors change with wavelengths or frequencies\u00c2 [1]. Another example is metamaterials that exhibit changing properties or functionalities due to deformation in response to external stimuli like temperature\u00c2 [2] and magnetic fields\u00c2 [3]. Tailoring functional responses of these metamaterials is of interest to applications such as sound and vibration control, analog computing, medical imaging, sensing, communication, and soft robotics. In many use cases, rather than precisely controlling the complete functional responses, we only care about qualitative behaviors under certain conditions. For example, acoustic metamaterials were usually designed to have bandgaps at specified frequencies to achieve functionalities like wave-guiding\u00c2 [4, 5], focusing\u00c2 [6, 7], and vibration mitigation\u00c2 [8, 9, 10]. However, it is unnecessary and computationally expensive to design for the whole dispersion relation\u00c2 [11, 12, 13, 14, 15]. Similarly, we may design optical metamaterials to qualitatively manipulate optical properties (e.g., high or low absorption/reflection/transmission) under certain wavelengths, without requiring the entire spectral response to match an exact target\u00c2 [16, 17]. Identifying metamaterial designs from a given target forms an inverse design problem. Unlike many forward problems where one can obtain solutions (e.g., spectral responses or material properties under external stimuli) by modeling the physics or conducting experiments, inverse design problems are usually intractable. Traditionally, these problems are solved by iterative optimization (i.e., minimizing the difference between the actual quantity of interest and the target)\u00c2 [11, 12, 14]. This, however, requires repeatedly updating the design solution and solving forward problems. When the design target changes, one needs to rerun the entire optimization process. Thus, inverse design by iterative optimization becomes impractical if solving the forward problem (by simulations or experiments) is time-consuming or if the design target needs to change frequently. To accelerate the optimization approach, prior works replaced simulations or experiments with machine learning models\u00c2 [18, 19]. However, the efficiency and quality of final solutions are highly dependent on both the machine learning model and the optimization algorithm. On the other hand, a single run of optimization usually only returns one final solution, although multiple designs might satisfy a given target (i.e., the non-uniqueness of solutions). For example, multiple acoustic metamaterial designs may have bandgaps within the same target frequency range. This non-uniqueness nature of inverse design problems was also shown for optical metasurfaces\u00c2 [20, 21, 22]. The optimization approach eliminates the opportunity to explore diverse alternative solutions. To avoid iterative optimization and enable fast on-demand inverse design, prior research attempted to realize single-shot (iteration-free) inverse design using machine learning. There are three mainstream models (their schematic diagrams are shown in Appendix, Fig.\u00c2 7). The most straightforward approach is to learn a direct inverse mapping from the response to design variables. Neural networks are the most commonly used machine learning model for this purpose, due to their high flexibility in approximating arbitrary nonlinear input-output relationships\u00c2 [23, 13]. Despite the simplicity of the direct inverse mapping, its underlying assumption of the response-design mapping being one-to-one does not hold in many cases due to the non-uniqueness of solutions, as mentioned earlier. Such non-uniqueness will cause conflicting training instances where the same input (response) is associated with distinct outputs (designs), which will destabilize the convergence during neural network training\u00c2 [20, 24]. To avoid this issue, past work proposed the Tandem Neural Network (T-NN) that cascades an inverse-design network with a forward-modeling network\u00c2 [20, 25, 26, 27, 28]. Its training is split into two steps: (1)\u00c2 pretraining the forward-modeling network to approximate the design-response mapping and (2)\u00c2 training the cascaded network by freezing the weights of the pretrained forward-modeling network. There is no loss function that forces designs at the intermediate layer to match data (which contains conflicting instances), hence the training convergence issue is avoided. Nonetheless, the original T-NNs still learn a one-to-one response-design mapping and cannot account for the non-uniqueness of design solutions. To fundamentally solve this problem, one needs to learn a one-to-many mapping. Bastek et al.\u00c2 [28] integrated stochastic sampling into the inverse-design network to allow the generation of multiple feasible solutions. A large body of recent works achieved the goal of learning one-to-many mapping by using conditional generative models, typically conditional generative adversarial networks (cGANs)\u00c2 [29, 30, 31, 32, 22], conditional variational autoencoders (cVAEs)\u00c2 [21], and conditional diffusion models\u00c2 [33]. These models can generate multiple designs given a target response by learning the distribution of designs conditioned on the response. Different generative models have distinct ways of learning conditional distributions. In general, this is realized by training neural networks to transform responses and random noise (or latent variables) into designs, so that the trained network can generate a non-deterministic design solution from a given target response and randomly sampled noise, which is equivalent to sampling from a conditional distribution. Although conditional generative models have demonstrated success in solving inverse design problems, they still have issues, such as high data demand, exhaustive hyperparameter tuning, slow training, and low interpretability, especially compared to traditional machine learning models like decision trees and random forests. On the other hand, Elzouka et al.\u00c2 [34] proposed to use the decision tree as a more interpretable model to solve both the forward prediction and inverse design problem. After training a decision tree for forward prediction, one can identify explicit design rules (i.e., feasible regions in the design space) by tracing from target leaf nodes to the root node. This approach also captures the one-to-many mapping nature of inverse design problems since it gives feasible design variable ranges rather than a single solution. However, there remain some limitations. Firstly, for solutions identified by the design rules, the method does not differentiate their likelihood of target satisfaction. Yet in reality, solutions always have different likelihoods due to the uncertainty of model estimation. Secondly, the method has to train two models: a random forest was trained first to ensure model accuracy and robustness, and then a large decision tree was trained to emulate the performance of the random forest and provide design rules. This is due to the challenge of deriving explicit design rules from an ensemble model like the random forest. Finally, the method was demonstrated on a problem with more than 104superscript10410^{4}10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT training data, while the effectiveness on smaller datasets (i.e., data with orders of magnitude smaller sample sizes) was not studied. This work aims to address the aforementioned problems by proposing a method called Random-forest-based Interpretable Generative Inverse Design (RIGID). Figure\u00c2 1 shows an overview of this method. Specifically, we first train a forward prediction random forest. Then given a design target, we can probe the trained random forest to infer the likelihood of any design satisfying the target. To generate new designs tailored to the target, we can sample from the design space according to the likelihood. Compared to the most widely studied neural-network-based methods, RIGID has a much lower cost in training and hyperparameter tuning, and works more robustly on small-size datasets (as random forests are less prone to overfitting). Similar to deep generative models, it can generate a desired number of solutions, allowing one to explore alternative solutions that might have desired properties or functionalities beyond the ones considered as the target. The explicit likelihood estimation also offers an interpretable characterization of a design\u00e2\u20ac\u2122s target satisfaction probability and allows an exploitation-exploration trade-off when selecting generated designs. We validate the RIGID method on two metamaterial design examples\u00c2 \u00e2\u20ac\u201d\u00c2 an acoustic metamaterial design example, where the target is to generate metamaterials with specific bandgaps, and an optical metasurface design example, where the target is to generate metasurfaces with high absorbance at specified wavelengths. Our contributions are three-fold. First, we propose a single-shot inverse design method that is fast, generative, interpretable, and small-data-compatible. Secondly, we demonstrate the effectiveness of the proposed method on acoustic and optical metamaterial design examples, and propose both qualitative and quantitative ways of assessing our method. Finally, we create two synthetic test cases for fast examination and validation of model performance. These test cases can be used for future benchmarking studies of related methods. The functional response of metamaterials can be modeled as y=f\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1,s)\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u201c\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018 y=f( = italic_f ( bold_x , italic_s ), where \u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b1 denotes metamaterial design variables (e.g., materials and geometry parameters), s\u011f\ufffd\u2018 sitalic_s is an auxiliary variable representing the independent variable (or the \u00e2\u20ac\u0153x\u011f\ufffd\u2018\u00a5xitalic_x-axis\u00e2\u20ac\ufffd) of the response (e.g., the frequency/wavelength or the external stimuli such as temperature), and y\u011f\ufffd\u2018\u00a6yitalic_y indicates the value of the response associated with our design target. In this paper, we assume y\u00e2\u02c6\u02c6{0,1}\u011f\ufffd\u2018\u00a601y \u00e2\u02c6\u02c6 { 0 , 1 } since we only focus on qualitative behaviors at specified frequencies (e.g., for an acoustic metamaterial or an optical metamaterial design, whether a bandgap exists or whether the energy absorbance is higher than a threshold within a range of frequencies). We leave the more challenging problem of tailoring quantitative behaviors as future work. We use a random forest to approximate the function f\u011f\ufffd\u2018\u201cfitalic_f. A random forest is an ensemble learning method that combines the predictions of multiple decision trees to improve accuracy and reduce overfitting\u00c2 [35]. The trained random forest serves as a forward prediction model that predicts the outcome y\u011f\ufffd\u2018\u00a6yitalic_y given design variables \u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b1 and the auxiliary variable s\u011f\ufffd\u2018 sitalic_s. Compared to the widely used neural networks, the random forest as a forward prediction model offers (1)\u00c2 significantly faster training, (2)\u00c2 less hyperparameters to tune, (3)\u00c2 less susceptible to overfitting on small data, and (4)\u00c2 interpretability (i.e., the decision-making of each tree in the random forest is transparent). More importantly, this interpretability also allows us to realize inverse design without training a separate inverse model. Figure\u00c2 2 shows how, by probing the trained random forest, one can estimate a likelihood distribution for target satisfaction of solutions over the entire design space and sample (generate) new designs based on this likelihood distribution. Since we target qualitative (binary) behaviors at specified s\u011f\ufffd\u2018 sitalic_s (e.g., a bandgap in 3-4 MHz frequency or high absorption at a wavelength of 400-500 nm), we first identify the leaf nodes (on each decision tree in the random forest) that are relevant to the s\u011f\ufffd\u2018 sitalic_s in the target (Fig.\u00c2 2, Step 1). We do this by tracing down each tree, checking only the nodes that use s\u011f\ufffd\u2018 sitalic_s as the splitting feature, and pruning the branches that are irrelevant to the s\u011f\ufffd\u2018 sitalic_s in the target. For example, as shown in Fig.\u00c2 2, there are two tree nodes using s\u011f\ufffd\u2018 sitalic_s as the splitting feature, with splitting criteria at s\u00e2\u2030\u00a45\u011f\ufffd\u2018 5s 5italic_s \u00e2\u2030\u00a4 5 and s\u00e2\u2030\u00a47\u011f\ufffd\u2018 7s 7italic_s \u00e2\u2030\u00a4 7. Given the target frequency range of 3\u00e2\u2030\u00a4s\u00e2\u2030\u00a443\u011f\ufffd\u2018 43 s 43 \u00e2\u2030\u00a4 italic_s \u00e2\u2030\u00a4 4, we can remove the right branches of both nodes as these branches are only relevant to s>5\u011f\ufffd\u2018 5s>5italic_s > 5 and s>7\u011f\ufffd\u2018 7s>7italic_s > 7, respectively, which conflicts with the target range of 3\u00e2\u2030\u00a4s\u00e2\u2030\u00a443\u011f\ufffd\u2018 43 s 43 \u00e2\u2030\u00a4 italic_s \u00e2\u2030\u00a4 4. After pruning these branches, we end up with a set of leaves relevant to the target (highlighted in Fig.\u00c2 2, Step 1). When we have a combined target (e.g., bandgaps in both 3-4 MHz and 6-7 MHz, as shown in Fig.\u00c2 2), we need to get the intersection of all the sets of relevant leaves and use that as the final set of relevant leaves (highlighted in Fig.\u00c2 2, Step 2). Note that a combined target includes cases where there are multiple nonadjacent target ranges (e.g., 3-4 MHz and 6-7 MHz) or when a target range is split by a tree node (e.g., a target range of 4-6 MHz can be split by the node \u00e2\u20ac\u0153s\u00e2\u2030\u00a45\u011f\ufffd\u2018 5s 5italic_s \u00e2\u2030\u00a4 5\u00e2\u20ac\ufffd, thus we need to consider it as the combination of two target ranges\u00c2 \u00e2\u20ac\u201d\u00c2 4-5 MHz and 5-6 MHz). A more detailed discussion of this step is in Appendix, Sec.\u00c2 B. The next step is to trace up the tree from the N\u011f\ufffd\u2018\ufffdNitalic_N relevant leaves, obtained by Step 2, to the root node (Fig.\u00c2 2, Step 3). This will result in N\u011f\ufffd\u2018\ufffdNitalic_N decision paths, along which are nodes indicating splitting criteria for design variables \u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b1 Thus, each decision path represents a set of design variable ranges, or in other words, a region in the design space. We assign each region a score equal to the predicted probability at each corresponding leaf. This probability is learned from the training data and equals the proportion of positive data in a leaf. It indicates the tree\u00e2\u20ac\u2122s belief in the probability of a design \u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b1 satisfying the target \u011f\ufffd\u2019\u00af\u011f\ufffd\u2019\u00af if the design falls in the design space region corresponding to the leaf. Therefore, with a single decision tree i\u011f\ufffd\u2018\u2013iitalic_i, we already have the map of likelihood \u00e2\u201e\u2019m\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1|\u011f\ufffd\u2019\u00af)=\u00e2\u201e\u2122m\u00e2\ufffd\u00a2(\u011f\ufffd\u2019\u00af|\u011f\ufffd\ufffd\u00b1)subscript\u00e2\u201e\u2019\u011f\ufffd\u2018\u0161conditional\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2019\u00afsubscript\u00e2\u201e\u2122\u011f\ufffd\u2018\u0161conditional\u011f\ufffd\u2019\u00af\u011f\ufffd\ufffd\u00b1 start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ( bold_x | caligraphic_T ) = blackboard_P start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ( caligraphic_T | bold_x ) for target satisfaction: each of the N\u011f\ufffd\u2018\ufffdNitalic_N regions has a uniformly distributed likelihood equal to the predicted probability at the corresponding leaf, and the rest of the design space has a likelihood of 0 (Fig.\u00c2 2, Step 3). Since a single decision tree usually lacks accuracy, robustness, and a way to quantify estimation uncertainty, we still want to take advantage of the random forest as an ensemble model for inverse design. We use Steps 1-3 to derive the likelihood distribution for each of the M\u011f\ufffd\u2018\u20acMitalic_M trees in the random forest, and simply use the average of these M\u011f\ufffd\u2018\u20acMitalic_M likelihood distributions as the final likelihood for target satisfaction, \u00e2\u201e\u2019\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1|\u011f\ufffd\u2019\u00af)=\u00e2\u02c6\u2018mM\u00e2\u201e\u2019m\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1|\u011f\ufffd\u2019\u00af)/M\u00e2\u201e\u2019conditional\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2019\u00afsuperscriptsubscript\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u20acsubscript\u00e2\u201e\u2019\u011f\ufffd\u2018\u0161conditional\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2019\u00af\u011f\ufffd\u2018\u20ac ( bold_x | caligraphic_T ) = \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT caligraphic_L start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ( bold_x | caligraphic_T ) / italic_M, which is a more complex and smooth function (Fig.\u00c2 2, Step 4). If more trees believe a design \u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b1 has a higher likelihood of satisfying the target, then the design will have a higher likelihood \u00e2\u201e\u2019\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1|\u011f\ufffd\u2019\u00af)\u00e2\u201e\u2019conditional\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2019\u00af ( bold_x | caligraphic_T ). Finally, to generate new designs, we can sample from \u00e2\u201e\u2019\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1|\u011f\ufffd\u2019\u00af)\u00e2\u201e\u2019conditional\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2019\u00af ( bold_x | caligraphic_T ) using Markov chain Monte Carlo (MCMC) methods such as Metropolis-Hastings\u00c2 [36] (Fig.\u00c2 2, Step 5). Compared to prior works, RIGID provides the following unique benefits: It is effective on small data problems as the random forest is less susceptible to overfitting. The training is fast (in seconds of wall time) and does not require computationally-demanding hyperparameter tuning. Once the training is done, no further training or iterative optimization is required to generate designs for different targets. The model is interpretable as one can easily probe the trained model to understand its reasoning behind any decision-making. It estimates the explicit likelihood of target satisfaction for every possible solution in the design space. Given a design target of specific functional behavior, we can generate an unlimited number of solutions based on the likelihood, allowing us to explore alternative solutions that might have desired properties or functionalities beyond the ones considered as the target. When generating design solutions, one can use a single parameter\u00c2 \u00e2\u20ac\u201d\u00c2 the sampling threshold\u00c2 \u00e2\u20ac\u201d\u00c2 to easily tune the trade-off between exploitation (i.e., generated designs have higher chances of satisfying the target) and exploration (i.e., generated designs cover a broader area of the design space), as we will demonstrate in Results. We demonstrate our RIGID method on an acoustic metamaterial design problem, an optical metasurface design problem, and two synthetic design problems. Based on a recent review article by Lee et al.\u00c2 [24] and other related works (e.g., [28]), existing single-shot inverse design methods were demonstrated on training data size ranging from 103superscript10310^{3}10 start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT to 106superscript10610^{6}10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT in scale. Here we show that our method can work with much smaller-scale datasets (less than 250 training samples). For all the test problems, we used the same random forest hyperparameter settings and did not perform hyperparameter tuning. Specifically, each random forest contains 1,000 trees with a minimum of 2 samples required to split an internal node and a minimum of 1 sample required to be at a leaf node. Gini impurity\u00c2 [37] was used as the splitting criterion at tree nodes. The train-test split ratio was 4:1. Since the positive/negative training data can be highly imbalanced (e.g., the frequency ranges with bandgaps are much narrower than those without), we used the Synthetic Minority Over-sampling TEchnique (SMOTE)\u00c2 [38] to over-sample the positive class. For all the case studies, the random forest training took less than 10 seconds on an Intel Core i5-9300H CPU 2.4GHz and 8GB memory. After training, we generate new designs by sampling from the resulting likelihood distribution using Metropolis-Hastings. In practice, Metropolis-Hastings can generate identical samples, which provides no benefits for design purposes. Thus in this work, we reject the designs identical to previous ones during sampling. Here we consider acoustic metamaterials that can control elastic wave propagation at ultrasound (MHz) frequencies. Varying the microscale geometries of acoustic metamaterials changes the dynamic properties of a material, such as bandgaps\u00c2 [10] (i.e., forbidden frequency ranges of a material) and wave propagation direction\u00c2 [4]. These materials promise applications in waveguides\u00c2 [4, 5], lenses\u00c2 [6, 7], and vibration mitigation\u00c2 [9]. We present the braced cubic design framework (Fig. 3A-B) as a method to tune the size and location of bandgaps (Fig.\u00c2 3C). In particular, spherical micro-inertia are added to the center and corner of a braced cubic unit cell with strut radius rstrutsubscript\u011f\ufffd\u2018\u0178strutr_{ start_POSTSUBSCRIPT strut end_POSTSUBSCRIPT. Micro-inertia placed at the center of the brace has radius rcentersubscript\u011f\ufffd\u2018\u0178centerr_{ start_POSTSUBSCRIPT center end_POSTSUBSCRIPT while micro-inertia placed at the corner of the cubic unit cell has radius rcornersubscript\u011f\ufffd\u2018\u0178cornerr_{ start_POSTSUBSCRIPT corner end_POSTSUBSCRIPT. We randomly created 284 sets of geometric parameters \u011f\ufffd\ufffd\u00b1=(rstrut,rcenter,rcorner)\u011f\ufffd\ufffd\u00b1subscript\u011f\ufffd\u2018\u0178strutsubscript\u011f\ufffd\u2018\u0178centersubscript\u011f\ufffd\u2018\u0178corner = ( italic_r start_POSTSUBSCRIPT strut end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT center end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT corner end_POSTSUBSCRIPT ) with 4 \u00e2\u2030\u00a4rstrut\u00e2\u2030\u00a4absentsubscript\u011f\ufffd\u2018\u0178strutabsent r_{ italic_r start_POSTSUBSCRIPT strut end_POSTSUBSCRIPT \u00e2\u2030\u00a4 6.41, 0 \u00e2\u2030\u00a4rcenter\u00e2\u2030\u00a4absentsubscript\u011f\ufffd\u2018\u0178centerabsent r_{ italic_r start_POSTSUBSCRIPT center end_POSTSUBSCRIPT \u00e2\u2030\u00a4 20, and 0 \u00e2\u2030\u00a4rcorner\u00e2\u2030\u00a4absentsubscript\u011f\ufffd\u2018\u0178cornerabsent r_{ italic_r start_POSTSUBSCRIPT corner end_POSTSUBSCRIPT \u00e2\u2030\u00a4 20 (unit: \u00c2\u00b5m). The unit cell size was set at a=60\u011f\ufffd\u2018\ufffd60a=60italic_a = 60 \u00c2\u00b5m. For each of these designs, we performed Bloch-wave analysis to compute its acoustic dispersion relation. Bandgap location and width were extracted for each design based on its dispersion relation. Out of the 284 sets of design variables and bandgap data, we used 227 samples as training data. We first discretized the entire frequency range into 100 intervals, and trained a random forest to predict bandgap existence y\u00e2\u02c6\u02c6{0,1}\u011f\ufffd\u2018\u00a601y \u00e2\u02c6\u02c6 { 0 , 1 } at a specific interval s\u011f\ufffd\u2018 sitalic_s for a given design \u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b1 The trained model has a test F1 score of 0.82. The resulting confusion matrix on test data is shown in Appendix, Tab.\u00c2 1. To test the inverse design capability of RIGID, we randomly created 10 targets, each containing 1-2 frequency ranges in which bandgap(s) should exist. We generated 30 designs for each target by sampling from the resulting likelihood distribution over the design space111Note that it is possible for the likelihood to be zero everywhere in the design space when the model believes the target is unachievable. We ignore these cases as it is meaningless and impossible to sample designs from such likelihood distribution.. Bandgaps were identified from dispersion relations computed using Bloch-wave analysis. Figure\u00c2 3D shows the kernel density estimation (KDE) for the likelihood of the 300 generated designs, conditioned on their target satisfaction. We use \u011f\ufffd\u2019\u0178\u011f\ufffd\u2019\u0178 and \u011f\ufffd\u2019\u0178feassubscript\u011f\ufffd\u2019\u0178feas start_POSTSUBSCRIPT feas end_POSTSUBSCRIPT to represent the complete set of generated designs and the set of generated designs that actually satisfy the target, respectively. Then \u011f\ufffd\u2019\u0178 caligraphic_D start_POSTSUBSCRIPT feas end_POSTSUBSCRIPT denotes the set of generated designs that cannot fulfill the target in reality. In an ideal scenario, all solutions in \u011f\ufffd\u2019\u0178\u011f\ufffd\u2019\u0178 would satisfy the target, which means \u011f\ufffd\u2019\u0178=\u011f\ufffd\u2019\u0178feas\u011f\ufffd\u2019\u0178subscript\u011f\ufffd\u2019\u0178feas = caligraphic_D start_POSTSUBSCRIPT feas end_POSTSUBSCRIPT, and their density profiles should coincide. However, this ideal scenario is not possible due to limited model accuracy. Conveniently, the estimation of target satisfaction likelihood offers us an indicator of what solution is more likely to violate the target. For a reasonable model, most designs in \u011f\ufffd\u2019\u0178 caligraphic_D start_POSTSUBSCRIPT feas end_POSTSUBSCRIPT should have low estimated likelihood values. Consequently, the density of \u011f\ufffd\u2019\u0178feassubscript\u011f\ufffd\u2019\u0178feas start_POSTSUBSCRIPT feas end_POSTSUBSCRIPT\u00e2\u20ac\u2122s likelihood is a result of shifting some of \u011f\ufffd\u2019\u0178\u011f\ufffd\u2019\u0178 density from left (low likelihood) to right (high likelihood). This expectation aligns with the observation in Fig.\u00c2 3D. When sampling new designs or selecting solutions from generated designs, we can put a sampling threshold \u00cf\u201e\u00e2\u02c6\u02c6(0,1)\u011f\ufffd\u0153\ufffd01 \u00e2\u02c6\u02c6 ( 0 , 1 ) on the likelihood values to filter out \u00e2\u20ac\u0153less promising\u00e2\u20ac\ufffd solutions. To further examine model behavior and quantify how \u00cf\u201e\u011f\ufffd\u0153\ufffd affects the inverse design outcome, we define the following metrics: where \u011f\ufffd\u2019\u0178\u00cf\u2022\u00e2\u2030\u00a5\u00cf\u201esubscript\u011f\ufffd\u2019\u0178italic-\u00cf\u2022\u011f\ufffd\u0153\ufffd start_POSTSUBSCRIPT italic_\u00cf\u2022 \u00e2\u2030\u00a5 italic_\u00cf\u201e end_POSTSUBSCRIPT is the set of generated designs with the likelihood of at least \u00cf\u201e\u011f\ufffd\u0153\ufffd (i.e., the selected designs) and qisubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013q_{i}italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT denotes the percentage overlap between the target and the actual behavior of selected designs. The satisfaction rate evaluates how many selected designs satisfy the target based on a binary criterion (i.e., whether or not a design satisfies the complete target), whereas the average score provides a soft measure where partial satisfaction is also counted. The average score is lower-bounded by the satisfaction rate. As shown in Fig.\u00c2 3E, the selection rate decreases when \u00cf\u201e\u011f\ufffd\u0153\ufffd increases since more solutions are filtered out. On the other hand, both the satisfaction rate and the average score increase with \u00cf\u201e\u011f\ufffd\u0153\ufffd which indicates a high correlation between the estimated likelihood of a solution and its probability of actually achieving the target. As \u00cf\u201e\u011f\ufffd\u0153\ufffd reaches 0.6, the satisfaction rate and the average score reach 1, indicating that all generated designs satisfy their targets. When sampling or selecting new solutions, we can use the sample threshold \u00cf\u201e\u011f\ufffd\u0153\ufffd to tune the trade-off between exploitation and exploration\u00c2 \u00e2\u20ac\u201d\u00c2 a low \u00cf\u201e\u011f\ufffd\u0153\ufffd favors exploration as sampled solutions will cover a larger area of the design space, while a high \u00cf\u201e\u011f\ufffd\u0153\ufffd favors exploitation as sampled solutions will have a higher chance of satisfying the target. Figure\u00c2 3F visualizes the geometries and dispersion relations of designs generated based on a randomly created bandgap target. Only the top five designs with the highest likelihood values are shown. In this example, our method generates geometrically different designs that have a high probability of achieving target bandgaps, each yielding a slightly different dispersion relation. This is promising in design applications requiring other material properties, such as dynamic wave velocity or quasi-static stiffness, in which the user can select from a menu of designs with the same target bandgap but other varying properties. Generated designs based on the other nine bandgap targets can be found in Appendix, Figs.\u00c2 8-10. Optical metasurfaces are artificially engineered systems that can support exotic light propagation building on subwavelength inclusions\u00c2 [39, 40, 41, 42, 43, 44]. Among a diverse array of devices, metamaterial absorbers\u00c2 [45, 46, 47, 48, 49, 50, 51] have been intensely studied for medical imaging, sensing, and wireless communications. In this case study, we consider four types of cross-sections (c\u00e2\u02c6\u02c6{1,2,3,4}\u011f\ufffd\u2018\ufffd1234c \u00e2\u02c6\u02c6 { 1 , 2 , 3 , 4 }) chosen from the literature (Fig.\u00c2 4B). It is assumed that a 3D geometric instance is composed of a stack of three layers of prismatic unit cells, each of which is vertically extruded and stacked (Fig.\u00c2 4A). The geometries constructed in this way can be regarded as an instantiation of multilayered metasurfaces\u00c2 [52, 53, 54, 55, 56], which offer richer design freedom than the single-layer counterpart. The height of each layer (hl,l=1,2,3formulae-sequencesubscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u2122123h_{l},l=1,2,3italic_h start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT , italic_l = 1 , 2 , 3) is allowed to continuously vary between 50 and 150 nm. Herein we do not consider parametric variations of a given type of unit cell cross-section; yet those can be trivially incorporated in the proposed design framework if necessary. We also design the material of each layer (ml,l=1,2,3formulae-sequencesubscript\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u2122123m_{l},l=1,2,3italic_m start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT , italic_l = 1 , 2 , 3). Three dielectric materials of interest, each of which is assigned to a different color in Fig.\u00c2 4A, are Ti (red), Si (blue), and Ge (yellow). In general, a dielectric material is characterized through a complex refractive index n~\u00e2\u02c6\u02c6\u00e2\u201e\u201a~\u011f\ufffd\u2018\u203a\u00e2\u201e\u201a start_ARG italic_n end_ARG \u00e2\u02c6\u02c6 blackboard_C defined as n~=n+j\u00e2\ufffd\u00a2k~\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u02dc start_ARG italic_n end_ARG = italic_n + italic_j italic_k, where j=\u00e2\u02c6\u20191\u011f\ufffd\u2018\u20141j= = square-root start_ARG - 1 end_ARG is the imaginary unit, n\u00e2\u02c6\u02c6\u00e2\u201e\ufffd\u011f\ufffd\u2018\u203a\u00e2\u201e\ufffdn \u00e2\u02c6\u02c6 blackboard_R involves the speed at which the light propagates through the material, and k\u00e2\u02c6\u02c6\u00e2\u201e\ufffd\u011f\ufffd\u2018\u02dc\u00e2\u201e\ufffdk \u00e2\u02c6\u02c6 blackboard_R is the extinction coefficient that dictates the energy loss due to the material. Within the frequency regime of interest, those exhibit nonlinear dispersion; both the real and imaginary terms in general are a non-analytic function of excitation wavelength s\u011f\ufffd\u2018 sitalic_s, i.e., n\u00e2\ufffd\u00a2(s)\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018 n(s)italic_n ( italic_s ) and k\u00e2\ufffd\u00a2(s)\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018 k(s)italic_k ( italic_s ). In addition, the impact of the same material choice on the spectral response A\u00e2\ufffd\u00a2(s)\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018 A(s)italic_A ( italic_s ) varies depending on the layer location at which the material is placed. Thus the highlight of this case study is the combinatorial nature of design, whose spectral responses are affected by the joint contributions of geometry and material. Based on the above configuration, we randomly sampled 258 sets of design variables \u011f\ufffd\ufffd\u00b1=(c,h1,h2,h3,m1,m2,m3)\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\ufffdsubscript\u00e2\u201e\ufffd1subscript\u00e2\u201e\ufffd2subscript\u00e2\u201e\ufffd3subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01613 = ( italic_c , italic_h start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_h start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_h start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_m start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) and computed their corresponding absorbance spectra using wave analysis. We set t=0.9\u011f\ufffd\u2018\u00a10.9t=0.9italic_t = 0.9 as the absorbance threshold, so that \u00e2\u20ac\u0153high\u00e2\u20ac\ufffd absorbance means the absorbance A\u00e2\ufffd\u00a2(s)\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018 A(s)italic_A ( italic_s ) is no less than 0.9. We trained a random forest on 206 training data (i.e., 80% of the 258 designs and corresponding absorbance spectra) to predict whether \u00e2\u20ac\u0153high\u00e2\u20ac\ufffd absorbance is presented (i.e., the binary indicator y=1\u011f\ufffd\u2018\u00a61y=1italic_y = 1) at a wavelength s\u011f\ufffd\u2018 sitalic_s for a given design \u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b1 The trained random forest has a test F1 score of 0.83. The confusion matrix on test data is shown in Appendix, Tab.\u00c2 2. Note that this problem involves inverse design with both continuous and categorical variables, which common optimization and generative modeling-based inverse design cannot handle well without special treatment\u00c2 [57, 58, 59]. On the other hand, our random forest-based method can naturally address such mixed-variable problems without any issues. Similar to the acoustic metamaterial design problem, we use 10 randomly created targets to evaluate the inverse design performance of RIGID, except that here a target is represented as the wavelength range(s) within which absorbance should be at least 0.9. We generated 100 designs for each target by sampling from the estimated likelihood distribution. Among the 1,000 generated solutions, we successfully conducted wave analysis for 911 designs and obtained their absorbance spectra. Figure\u00c2 4D shows the KDE for the likelihood of these 911 designs, conditioned on their target satisfaction. The densities share similar behavior as in the acoustic problem (Fig.\u00c2 3D)\u00c2 \u00e2\u20ac\u201dunsatisfied/infeasible designs \u011f\ufffd\u2019\u0178 caligraphic_D start_POSTSUBSCRIPT feas end_POSTSUBSCRIPT are concentrated at low likelihood regions, which causes the likelihood density of satisfied/feasible designs \u011f\ufffd\u2019\u0178feassubscript\u011f\ufffd\u2019\u0178feas start_POSTSUBSCRIPT feas end_POSTSUBSCRIPT to be a result of shifting some of \u011f\ufffd\u2019\u0178\u011f\ufffd\u2019\u0178 density from left (low likelihood) to right (high likelihood). The sampling threshold and metrics relation shown in Fig.\u00c2 4E also follow the same trend as in the acoustic problem (Fig.\u00c2 3E), which again demonstrates a strong positive correlation between the estimated likelihood and the probability of generated designs actually achieving their targets. Figure\u00c2 4F shows generated optical metasurface designs with the top five likelihood estimations for a randomly created target. While the materials, cross-section geometries, and layer heights of generated designs can be different, all the designs satisfy the target (Fig.\u00c2 4F, right panel). To further enhance the diversity of final solutions, we can use sampling strategies such as the one proposed in Ref.\u00c2 [60, 61] to identify a subset (of generated solutions) that simultaneously exhibits high likelihood and high diversity. Generated designs based on the other nine targets can be found in Appendix, Figs.\u00c2 11-12. While the above metamaterial design problems represent practical use cases, the validation study is time-consuming due to the expensive computation of metamaterials\u00e2\u20ac\u2122 responses such as dispersion relations and absorbance spectra. To allow fast validation of the proposed method and easier inspection of the estimated likelihood in the design space, we create two synthetic case studies. Both problems have 2-dimensional \u00e2\u20ac\u0153design spaces\u00e2\u20ac\ufffd that allow easy visualization. To construct the first synthetic problem, we used a squared exponential function with tunable parameters a\u011f\ufffd\u2018\ufffdaitalic_a and b\u011f\ufffd\u2018\ufffdbitalic_b to mimic the quantitative functional response of metamaterials. The qualitative response (e.g., \u00e2\u20ac\u0153high\u00e2\u20ac\ufffd or \u00e2\u20ac\u0153low\u00e2\u20ac\ufffd energy absorption at a wavelength) is defined as: where z\u011f\ufffd\u2018\u00a7zitalic_z represents quantitative response and t\u011f\ufffd\u2018\u00a1titalic_t is a threshold that converts z\u011f\ufffd\u2018\u00a7zitalic_z into a qualitative response I\u00e2\ufffd\u00a2(a,b;s)\u011f\ufffd\ufffd\u00bc\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018 I(a,b;s)italic_I ( italic_a , italic_b ; italic_s ). Specifically, I\u00e2\ufffd\u00a2(a,b;s)=1\u011f\ufffd\ufffd\u00bc\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018 1I(a,b;s)=1italic_I ( italic_a , italic_b ; italic_s ) = 1 can mean the existence of a bandgap or high absorbance at a frequency s\u011f\ufffd\u2018 sitalic_s. Then {s|I\u00e2\ufffd\u00a2(a,b;s)=1}conditional-set\u011f\ufffd\u2018 \u011f\ufffd\ufffd\u00bc\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018 1 italic_s | italic_I ( italic_a , italic_b ; italic_s ) = 1 } represents a range of s\u011f\ufffd\u2018 sitalic_s that mimics our design targets, such as the bandgap or the frequency range of high absorbance. By varying a\u011f\ufffd\u2018\ufffdaitalic_a and b\u011f\ufffd\u2018\ufffdbitalic_b, we can produce different synthetic responses and ranges. Therefore, we can use a\u011f\ufffd\u2018\ufffdaitalic_a and b\u011f\ufffd\u2018\ufffdbitalic_b as synthetic design variables. There is a clear relation between these design variables and the range that Eq.\u00c2 2 creates\u00c2 \u00e2\u20ac\u201d\u00c2 a\u011f\ufffd\u2018\ufffdaitalic_a and b\u011f\ufffd\u2018\ufffdbitalic_b control the center location and the width of the range, respectively. In this design problem, we sampled 100 sets of a\u011f\ufffd\u2018\ufffdaitalic_a and b\u011f\ufffd\u2018\ufffdbitalic_b uniformly at random. We set t\u011f\ufffd\u2018\u00a1titalic_t as 0.9. Based on Eq.\u00c2 2, we obtained the corresponding responses (Fig.\u00c2 5A). These sets of a\u011f\ufffd\u2018\ufffdaitalic_a, b\u011f\ufffd\u2018\ufffdbitalic_b, and responses constitute a dataset for training and testing our model. Another synthetic design problem was constructed by replacing the squared exponential function in the SqExp problem with a superposed sine function. Given synthetic design variables a\u011f\ufffd\u2018\ufffdaitalic_a and b\u011f\ufffd\u2018\ufffdbitalic_b, we can produce qualitative responses using the following equation: Same as in the SqExp problem, we set t=0.9\u011f\ufffd\u2018\u00a10.9t=0.9italic_t = 0.9 and created a dataset with 100 sets of synthetic design variables and corresponding ranges derived from synthetic responses (Fig.\u00c2 5B). Unlike the squared exponential function, the superposed sine function can be multimodal, which means it can result in multiple synthetic ranges to mimic, for example, multiple bandgaps. The bandgap locations are controlled by a\u011f\ufffd\u2018\ufffdaitalic_a and b\u011f\ufffd\u2018\ufffdbitalic_b. For each synthetic example, we split the data into 80 training data and 20 test data, and trained a random forest, with the same hyperparameter settings as the other problems, to predict the binary indicators I\u00e2\ufffd\u00a2(a,b;s)\u011f\ufffd\ufffd\u00bc\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018 I(a,b;s)italic_I ( italic_a , italic_b ; italic_s ). The F1 scores are 0.85 and 0.86 for the SqExp and the SupSin problems, respectively. The resulting confusion matrices are shown in Appendix, Tables\u00c2 3-4. We evaluated the inverse design performance with the trained models. Due to the fast evaluation of Equations\u00c2 2 and 3, we can exhaust all the possible solutions in the design space to obtain the ground-truth feasible region(s) for a target. Figure\u00c2 6A shows the estimated likelihood values and the ground-truth feasible regions under randomly created targets. In general, high-likelihood regions match actual feasible regions well, which further demonstrates the effectiveness of RIGID. We can also observe that feasible regions in the SqExp and the SupSin problems follow distinct patterns. In the SqExp problem, a\u011f\ufffd\u2018\ufffdaitalic_a and b\u011f\ufffd\u2018\ufffdbitalic_b control the center location and the width of the output range, respectively. Therefore, the position of the feasible region along the a\u011f\ufffd\u2018\ufffdaitalic_a-axis moves with the location of the target range, while the feasible region gradually shrinks as b\u011f\ufffd\u2018\ufffdbitalic_b decreases since the decrease of b\u011f\ufffd\u2018\ufffdbitalic_b (i.e., output range width) causes the choice of a\u011f\ufffd\u2018\ufffdaitalic_a (i.e., output range center location) to be more restricted to fit the target range. In the SupSin problem, there might be multiple bandgaps appearing at the peaks of the superposed sine function in Eq.\u00c2 3. Design variables a\u011f\ufffd\u2018\ufffdaitalic_a and b\u011f\ufffd\u2018\ufffdbitalic_b control bandgap locations by translating each sine function. Due to the sine function\u00e2\u20ac\u2122s periodicity, we can obtain multiple feasible regions along both a\u011f\ufffd\u2018\ufffdaitalic_a- and b\u011f\ufffd\u2018\ufffdbitalic_b-axes. Figure\u00c2 6A shows that the likelihood estimation by RIGID successfully captured the above-mentioned patterns of feasible regions. Figure\u00c2 6B demonstrates how the estimated likelihood varies when increasing the number of trees in a random forest. With a single decision tree, the estimated likelihood function is almost a binary function and highly inaccurate. The likelihood in the SqExp case is even zero everywhere, which makes it impossible to sample designs based on the likelihood. As the number of trees increases, the likelihood function becomes smoother and eventually converges. Besides these qualitative visual inspections, we also calculated the metrics proposed in Eq.\u00c2 1, as shown in Fig.\u00c2 6C. For each of the two synthetic problems, these metrics were computed on 500 designs generated by giving five random target ranges. Again, the satisfaction rate and the average score increase with the sampling threshold, indicating a strong correlation between the sampling threshold and the probability of generated designs actually achieving their targets. In both problems, all the selected designs satisfy their targets (i.e., the satisfaction rates and average scores reach 1) when the sampling threshold reaches 0.8. We proposed RIGID, a single-shot inverse design method that generates metamaterials to satisfy qualitative behaviors of functional responses. Such qualitative behaviors are important design targets in many applications such as tailoring bandgaps of acoustic metamaterials for wave-guiding, focusing, and vibration mitigation, or tailoring the absorption level of optical metasurfaces at certain wavelengths for medical sensing, imaging, and communication applications. Unlike most existing inverse design methods that require training an inverse model to map targets to designs, the RIGID method takes advantage of the random forest\u00e2\u20ac\u2122s interpretability and derives the likelihood of target satisfaction by probing the trained forward model. Incorporated with MCMC, one can sample a desired number of new designs based on the estimated likelihood. Therefore, RIGID functions as a generative model that can capture the conditional distribution of satisfying designs given a target, or in other words, the one-to-many mapping from the target to satisfying designs. Using both real-world and synthetic design problems, we demonstrated that RIGID is efficient and effective on datasets with training sample sizes smaller than 250. Thus, RIGID is particularly useful when data collection is expensive, as in many cases where high-fidelity simulation or experimental data are needed. We used both qualitative and quantitative approaches to validate the proposed method. The quantitative results revealed a strong correlation between the estimated likelihood of a solution and its probability of actually achieving the target, which demonstrated the effectiveness of the likelihood estimation. Due to the fast evaluation of output responses and the transparency of ground-truth solutions, the proposed synthetic problems can be used for future benchmarking studies of metamaterial design problems. While we address qualitative design targets in this study, the idea of using random forest-based models for inverse design has the potential to generalize to quantitative targets. Such problems can be, for example, generating optical metasurface designs with specific optical spectra\u00c2 [62, 21], generating functional materials with target nonlinear constitutive relations\u00c2 [33, 63], or generating programmable metamaterials with prescribed functional responses\u00c2 [64, 65]. It is also straightforward to adjust the target to achieve multifunctionality (e.g., negative/positive Poisson\u00e2\u20ac\u2122s ratio under low/high compression rate\u00c2 [66]). Although this study only demonstrates the RIGID method on parametric design (i.e., designs are represented by geometric and/or material parameters), the method also applies to shape or topological design problems where the shape or topology of designs can vary without being restricted to a limited number of geometric parameters\u00c2 [62, 29, 21, 31, 67]. In those cases, as valid designs only lie on a lower-dimensional manifold of the design space, the likelihood of target satisfaction will be zero almost everywhere in the original design space. Thus before applying RIGID, we need to obtain a latent representation that compactly captures the manifold of valid designs\u00c2 [68, 69], and use the latent representation as design variables for inverse design. This work was supported by the startup funds from the J. Mike Walker \u00e2\u20ac\u212266 Department of Mechanical Engineering at Texas A&M University, the National Science Foundation (NSF) BRITE Fellow program (CMMI 2227641), the NSF CSSI program (OAC 1835782), the Kansas City National Security Campus (PDRD #705288), and NSF CAREER Award (CMMI-2142460). R.S. acknowledges financial support from the NSF Graduate Research Fellowship Program. Figure\u00c2 7 shows the schematic diagrams of three mainstream machine learning models for single-shot inverse design of metamaterials. The purpose of Step 2 is to obtain the intersection of relevant design space regions for all the ranges of s\u011f\ufffd\u2018 sitalic_s in a target. We are approximating this goal by simply obtaining the intersection of relevant leaves. However, some non-intersecting leaves may still have intersecting design space regions. When assigning the probability to the intersecting region of two non-intersecting leaves A\u011f\ufffd\ufffd\u00b4Aitalic_A and B\u011f\ufffd\ufffd\u00b5Bitalic_B, we need to consider the predicted probabilities at both leaves (PAsubscript\u011f\ufffd\u2018\u0192\u011f\ufffd\ufffd\u00b4P_{A}italic_P start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT and PBsubscript\u011f\ufffd\u2018\u0192\u011f\ufffd\ufffd\u00b5P_{B}italic_P start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT). Specifically, the assigned probability at this intersecting region should be PA\u00e2\ufffd\u00a2PBsubscript\u011f\ufffd\u2018\u0192\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\u2018\u0192\u011f\ufffd\ufffd\u00b5P_{A}P_{B}italic_P start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT italic_P start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT, which can be small. Therefore, we adopt the simplification of only considering the intersection of relevant leaves and ignoring the intersecting regions associated with non-intersecting leaves. The results also demonstrate that this is a reasonable approximation. We performed Bloch-wave analysis in COMSOL Multiphysics to compute the dispersion relations of acoustic metamaterials. Poisson\u00e2\u20ac\u2122s ratio of 0.49, Young\u00e2\u20ac\u2122s modulus of 2.7 GPa, and density of 1170 kg/m33{{}^{3}}start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT were set as material properties with \u00e2\u02c6\u00bc1.5\u00c3\u2014104similar-toabsent1.5superscript104 1.5 10^{4}\u00e2\u02c6\u00bc 1.5 \u00c3\u2014 10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT mesh elements per unit cell. We used Floquet-Bloch periodic boundary conditions to obtain the first 60 eigenfrequencies along all symmetry domains of the cubic irreducible Brillouin zone (Fig. 3B) for all lattices, thus generating a dispersion relation. We computed the absorbance spectra for optical metasurfaces using wave analysis inspired by Zhang et al.\u00c2 [56]. The RF Module of COMSOL Multiphysics\u00c2\u00ae\u00c2 [70] was used to evaluate the spectral response of concern, which is the energy absorbance A\u00e2\ufffd\u00a2(s)\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018 A(s)italic_A ( italic_s ) in the visible regime (380-700 nm). An absorbance spectrum is computed with respect to 33 wavelength components sksubscript\u011f\ufffd\u2018 \u011f\ufffd\u2018\u02dcs_{k}italic_s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT that are uniformly discretized over the specified range. An incident plane wave is assumed to be given from the port, located at the top face of the analysis domain. We set the periodicity of the analysis domain as 400 nm. The periodic boundary condition on electromagnetic fields is imposed on the lateral faces of the analysis domain. A substrate made of SiO22{}_{2}start_FLOATSUBSCRIPT 2 end_FLOATSUBSCRIPT is placed right below a given unit cell instance (the black layers in Fig.\u00c2 4A-B). With full electric fields computed through the wave analysis, the energy absorbance at a single wavelength s\u011f\ufffd\u2018 sitalic_s is quantified as A\u00e2\ufffd\u00a2(s)=1\u00e2\u02c6\u2019|S11\u00e2\ufffd\u00a2(s)|2\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018 1superscriptsubscript\u011f\ufffd\u2018\u202011\u011f\ufffd\u2018 2A(s)=1-|S_{11}(s)|^{2}italic_A ( italic_s ) = 1 - | italic_S start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT ( italic_s ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, where Si\u00e2\ufffd\u00a2jsubscript\u011f\ufffd\u2018\u2020\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014S_{ij}italic_S start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT is the component of the S\u011f\ufffd\u2018\u2020Sitalic_S-parameter matrix that specifies energy transfer between ports. We use the data presented in Ref.\u00c2 [71] to set the material dispersion of the dielectric. Test data for all the design problems are designs \u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b1 (that the random forests have never seen during training) and their corresponding qualitative behaviors y\u00e2\u02c6\u02c6{0,1}\u011f\ufffd\u2018\u00a601y \u00e2\u02c6\u02c6 { 0 , 1 } based on functional responses. In the acoustic metamaterial design problem, we have 57 test designs, yielding 5,700 test points as the entire frequency range of dispersion relations is discretized into 100 intervals for each design. In the optical metasurface design problem, we have 52 test designs, with each functional response discretized into 33 points, which yields 1,716 test points in total. In each of the synthetic design problems, we have 20 synthetic test designs, with each synthetic response discretized into 100 points. This results in 2,000 test data points in total. Confusion matrices showing test performances are in Tables\u00c2 1-4. Figures\u00c2 8-12 show the rest of generated designs and their corresponding responses in addition to those in Figures\u00c2 3F and 4F.",
        "keywords": ""
    },
    {
        "id": 4,
        "title": "Metabolic scaling in small life forms",
        "abstract": "AbstractMetabolic scaling is one of the most important patterns in biology. Theory explaining the 3/4-power size-scaling of biological metabolic rate does not predict the non-linear scaling observed for smaller life forms. Here we present a new model for cells<10\u00e2\u02c6\u20198absentsuperscript108<10^{-8}< 10 start_POSTSUPERSCRIPT - 8 end_POSTSUPERSCRIPTm33{}^{3}start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPTthat maximizes power from the reaction-displacement dynamics of enzyme-catalyzed reactions. Maximum metabolic rate is achieved through an allocation of cell volume to optimize a ratio of reaction velocity to molecular movement. Small cells<10\u00e2\u02c6\u201917absentsuperscript1017<10^{-17}< 10 start_POSTSUPERSCRIPT - 17 end_POSTSUPERSCRIPTm33{}^{3}start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPTgenerate power under diffusion by diluting enzyme concentration as cell volume increases. Larger cells require bulk flow of cytoplasm generated by molecular motors. These outcomes predict curves with literature-reported parameters that match the observed scaling of metabolic rates for unicells, and predicts the volume at which Prokaryotes transition to Eukaryotes. We thus reveal multiple size-dependent physical constraints for microbes in a model that extends prior work to provide a parsimonious hypothesis for how metabolism scales across small life.",
        "corpus": "Metabolic scaling is one of the most important patterns in biology. Theory explaining the 3/4-power size-scaling of biological metabolic rate does not predict the non-linear scaling observed for smaller life forms. Here we present a new model for cells <10\u00e2\u02c6\u20198absentsuperscript108<10^{-8}< 10 start_POSTSUPERSCRIPT - 8 end_POSTSUPERSCRIPT m33{}^{3}start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT that maximizes power from the reaction-displacement dynamics of enzyme-catalyzed reactions. Maximum metabolic rate is achieved through an allocation of cell volume to optimize a ratio of reaction velocity to molecular movement. Small cells <10\u00e2\u02c6\u201917absentsuperscript1017<10^{-17}< 10 start_POSTSUPERSCRIPT - 17 end_POSTSUPERSCRIPT m33{}^{3}start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT generate power under diffusion by diluting enzyme concentration as cell volume increases. Larger cells require bulk flow of cytoplasm generated by molecular motors. These outcomes predict curves with literature-reported parameters that match the observed scaling of metabolic rates for unicells, and predicts the volume at which Prokaryotes transition to Eukaryotes. We thus reveal multiple size-dependent physical constraints for microbes in a model that extends prior work to provide a parsimonious hypothesis for how metabolism scales across small life. Understanding how and why organisms differ in their demand for and use of resources is a key objective of biologists [1, 2, 3] and critical to understanding the response of biodiversity and ecosystem function to global changes [4, 5]. A fundamental and often-debated pattern is how metabolic rate, B\u011f\ufffd\ufffd\u00b5Bitalic_B, scales with body mass, M\u011f\ufffd\u2018\u20acMitalic_M [1, 6, 7], followng the form Data for vertebrates and vascular plants [8, 9, 10, 11, 12]show an average interspecific scaling exponent of 3/4. This relationship has inspired diverse theories [10, 11, 13, 14, 15], including the network model, which derives 3/4 from the need for organisms to supply the entire body volume with resources from vascular resource distribution networks that minimize energy dissipation. More recent analyses [16, 1, 17, 18, 19, 20] that include organisms from the smallest 11 orders of magnitude in size that largely lack vascular distribution networks, show a variable metabolic scaling exponent that changes across size ranges from scaling exponents as high as 2 \u00e2\u20ac\u201c super-linear scaling \u00e2\u20ac\u201c for the smallest range and near 3/4 for the largest organisms. Understanding the basis for this variation is important, as many different organism features can be derived from this metabolic scaling, including how maximum growth rates and ribosomal abundances scale with cell size along with key tradeoffs between features [21, 22]. However, there is no general, parsimonious theory derived from physical and chemical principles that addresses this size-dependent scaling for these smallest organisms [16]. Here we propose a combined thermodynamic and reaction description of metabolic rate for a cell. We assume that natural selection will favor organisms that can perform more work per time (power) for material synthesis, replication, repair, locomotion, and other cellular functions [23]. While often co-limited by materials in the environment, optimizing this power faces cellular trade-offs concerning both environmental and intra-cellular physical constraints. Consequently, we optimize cellular features to maximize the free energy produced by the conversion of chemical substrates to products, where heat and products may inhibit metabolism if not moved away from reaction sites. This thermodynamic approach provides a framework for considering the two processes, conversion and displacement, simultaneously. We assume that work is proportional to the volume of reactive surface, where macromolecular catalytic enzymes are freely dispersed in the cytoplasm or attached to the membranes, cytoskeleton, and/or other organelles within the entity [24]. However, a portion of cell volume is needed to allow substrates from the environment to reach reaction surfaces and to allow displacement of reaction products away from reaction structures. This sets up a conflict between the volume devoted to metabolic processes and that devoted to transport. Here we derive a physical and chemical principles-based theory for metabolic scaling for metabolic rate across the roughly 11 orders of magnitude in volume of organisms that lack branching vascular systems. We describe metabolism from a reaction-displacement thermodynamic system centered on or near reaction surfaces and its generation of free energy within a spherical space otherwise obstructed by surfaces at which reactions occur. Our framework applies to unicellular Prokaryotes, Archaea, and Eukaryotes along with eukaryotic organelles. Our basic model, which we expand on in stages, is to consider metabolism in a sphere described by the following reaction-diffusion model where the product, P\u00e2\ufffd\u00a2(r)\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u0178P ( italic_r ), substrate, A\u00e2\ufffd\u00a2(r)\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u0178A ( italic_r ), and enzyme, Z\u00e2\ufffd\u00a2(r)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178Z ( italic_r ), concentrations (mol m\u00e2\u02c6\u201933{}^{-3}start_FLOATSUPERSCRIPT - 3 end_FLOATSUPERSCRIPT) are all a function of radius, r\u011f\ufffd\u2018\u0178ritalic_r, inside a sphere, and where the dynamics are one dimensional in spherical coordinates with spherical symmetry. Additionally, k=kc\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t/KM\u011f\ufffd\u2018\u02dcsubscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\ufffd\u00be\u011f\ufffd\u2018\u20ack=k_{cat}/K_{M}italic_k = italic_k start_POSTSUBSCRIPT italic_c italic_a italic_t end_POSTSUBSCRIPT / italic_K start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT is the reaction constant ((m33{}^{3}start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT mol \u00e2\u02c6\u201911{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT s\u00e2\u02c6\u201911{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT)) and D\u011f\ufffd\ufffd\u00b7Ditalic_D is a displacement coefficient (e.g. molecular diffusivity in some cases) and has units of (m22{}^{2}start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT s\u00e2\u02c6\u201911{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT) so that each rate is a change in concentration (mol m\u00e2\u02c6\u201933{}^{-3}start_FLOATSUPERSCRIPT - 3 end_FLOATSUPERSCRIPT s\u00e2\u02c6\u201911{}^{-1}start_FLOATSUPERSCRIPT - 1 end_FLOATSUPERSCRIPT). We consider the steady-state dynamics, representing a persistent entity and its metabolism in a fixed environment over time, allowing us to solve for closed-form solutions of P\u00e2\ufffd\u00a2(r)\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u0178P(r)italic_P ( italic_r ) and A\u00e2\ufffd\u00a2(r)\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u0178A(r)italic_A ( italic_r ) under a given concentration of Z\u011f\ufffd\u2018\ufffdZitalic_Z (see SI). The steady-state free energy production at any location in the cell is given by where Ke\u00e2\ufffd\u00a2qsubscript\u011f\ufffd\ufffd\u00be\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\ufffdK_{eq}italic_K start_POSTSUBSCRIPT italic_e italic_q end_POSTSUBSCRIPT is the equilibrium constant of the energy producing reaction (which can be interrelated with \u00ce\u201d\u00e2\ufffd\u00a2G0\u00ce\u201dsubscript\u011f\ufffd\ufffd\u00ba0 G_{0}roman_\u00ce\u201d italic_G start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT), T\u011f\ufffd\u2018\u2021Titalic_T is temperature, and R\u011f\ufffd\u2018\u2026Ritalic_R is the ideal gas constant. The entire metabolism (given as a power in watts) of the entire cell is then described by where rcsubscript\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdr_{c}italic_r start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT is the radius of the cell and Vesubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2019V_{e}italic_V start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT is the essential volume required for other for other cellular materials, such as DNA, and is unavailable for energy generation. In this system, we can maximize power (free energy/time), B\u011f\ufffd\ufffd\u00b5Bitalic_B (Watts), as a function of Z\u011f\ufffd\u2018\ufffdZitalic_Z. If there were no tradeoffs, then B\u011f\ufffd\ufffd\u00b5Bitalic_B would be maximized by the largest feasible Z\u011f\ufffd\u2018\ufffdZitalic_Z at a given size (a cell full of enzymes). However, the need to move substrate into different regions of the cell and to displace products away from reaction sites introduces a trade-off between the effective diffusion coefficient, D\u011f\ufffd\ufffd\u00b7Ditalic_D, and enzyme concentration, Z\u011f\ufffd\u2018\ufffdZitalic_Z. An increase in Z\u011f\ufffd\u2018\ufffdZitalic_Z corresponds to a decrease in diffusivity [25, 26], and this leads to an optimal enzyme concentration corresponding to a maximal metabolic rate (see SI). Maximizing power over the whole cell, at a given cell size rcsubscript\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdr_{c}italic_r start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT subject to variation in the concentration of enzymes, Z\u011f\ufffd\u2018\ufffdZitalic_Z, we find that the optimal enzyme concentration Z*superscript\u011f\ufffd\u2018\ufffdZ^{*}italic_Z start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT follows where \u00ce\u00b3\u011f\ufffd\u203a\u00be is the scaling between diffusivity and enzyme concentration at high enzyme concentrations, and D0subscript\u011f\ufffd\ufffd\u00b70D_{0}italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT is the normalization constant for that scaling relationship (see SI). Remarkably, this relationship shows that the optimal enzyme concentration in cells can be predicted from a few fundamental thermodynamic, Ke\u00e2\ufffd\u00a2qsubscript\u011f\ufffd\ufffd\u00be\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\ufffdK_{eq}italic_K start_POSTSUBSCRIPT italic_e italic_q end_POSTSUBSCRIPT, and kinetic, k\u011f\ufffd\u2018\u02dckitalic_k, constants (Figure 1). Note that Z*superscript\u011f\ufffd\u2018\ufffdZ^{*}italic_Z start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT depends on a ratio of reaction rate, k\u011f\ufffd\u2018\u02dckitalic_k, to a diffusivity normalization for small molecules in the cytoplasm, D0subscript\u011f\ufffd\ufffd\u00b70D_{0}italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. Using the known relationship for diffusivity with enzyme concentration, where \u00ce\u00b3\u00e2\u2030\u02c6\u00e2\u02c6\u20193/2\u011f\ufffd\u203a\u00be32 \u00e2\u2030\u02c6 - 3 / 2 for sufficiently high concentrations [26], we obtain Previous studies have shown that total protein count scales with cell size following a power law with an exponent <1absent1<1< 1 [22], but these relationships have no fundamental explanation. Our optimization predicts that protein concentration should become more dilute as cells become larger following an exponent of \u00e2\u02c6\u20194/15\u00e2\u2030\u02c6\u00e2\u02c6\u20190.274150.27-4/15 4 / 15 \u00e2\u2030\u02c6 - 0.27, which is indistinguishable from the best fit exponent to data of \u00e2\u02c6\u20190.30\u00c2\u00b10.06plus-or-minus0.300.06-0.30 0.06- 0.30 \u00c2\u00b1 0.06 (Figure 1). The prediction for Z\u011f\ufffd\u2018\ufffdZitalic_Z was determined by optimizing metabolic rate and so we also predict the relationship for maximum metabolic rate: Here B0subscript\u011f\ufffd\ufffd\u00b50B_{0}italic_B start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT is a constant that is a complicated function of diffusivity, kinetic and thermodynamic parameters (see SI), and Vesubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2019V_{e}italic_V start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT is the volume of other essential macromolecules which follows Ve=v0\u00e2\ufffd\u00a2Vc\u00ce\u00b1subscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2019subscript\u011f\ufffd\u2018\u00a30superscriptsubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\ufffd\u011f\ufffd\u203a\u00bcV_{e}=v_{0}V_{c}^{ start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT = italic_v start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u00ce\u00b1 end_POSTSUPERSCRIPT with \u00ce\u00b1=0.83\u011f\ufffd\u203a\u00bc0.83 = 0.83 [22]. Equation 7 provides excellent agreement with observed metabolic rates for prokaryotes (Fig. 2). Metabolic rate has strong, non-power law curvature for small cell sizes driven by the volume V\u00e2\ufffd\u00a2e\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2019V{e}italic_V italic_e required for macromolecules not involved in reactions, such as DNA, and this is what leads to the apparent super-linear (\u00ce\u00b2>1\u011f\ufffd\u203a\u00bd1 > 1) scaling previously observed for prokaryotes [16]. This curvature quickly relaxes for larger cells due to the sublinear (\u00ce\u00b2<1\u011f\ufffd\u203a\u00bd1 < 1) scaling of Vesubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2019V_{e}italic_V start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT. For cell sizes up to about the volume of E. coli (\u00e2\u2030\u02c610\u00e2\u02c6\u201918absentsuperscript1018 10^{-18}\u00e2\u2030\u02c6 10 start_POSTSUPERSCRIPT - 18 end_POSTSUPERSCRIPT m33{}^{3}start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT) the power law approximation is superlinear (SI Figure 4) with an approximate exponent of 1.681.681.681.68 which agrees well with the previous estimates of 1.751.751.751.75 [16]. For larger bacteria, the scaling of B\u011f\ufffd\ufffd\u00b5Bitalic_B converges on the sublinear scaling of 11/15=0.7311150.7311/15=0.7311 / 15 = 0.73. For intermediate prokaryote cell sizes, binning the data to remove oversampling of certain cell volumes and scatter, shows exceptionally good agreement between our model and the data (SI Figure 5). These results are not in conflict with the overall superlinear fit to all of the prokaryotic data [16], but show that this is a consequence of a complicated set of scale transitions and shifting constraints. Thus, downstream models that derive results from the scaling exponent of metabolic rate (e.g. [21, 22]) will gain accuracy and predictive power by starting from our more complex model. For example, models of growth which assume a power law for metabolism [21] should incorporate the curvature described in Equation 7. The trade-off between decreasing enzyme concentration and increased diffusivity applies only for high concentrations of the enzyme. Eventually, for large enough cells, sufficiently low enzyme concentrations are reached such that D=Dm\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2x\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5D=D_{max}italic_D = italic_D start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT, the maximum diffusivity of small molecules in water (see SI). Once diffusivity saturates, the optimal concentration follows Z\u00e2\u02c6\ufffdVc\u00e2\u02c6\u20192/3proportional-to\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\ufffd23Z V_{c}^{-2/3}italic_Z \u00e2\u02c6\ufffd italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 2 / 3 end_POSTSUPERSCRIPT (see SI) yielding B\u00e2\u02c6\ufffdVc1/3proportional-to\u011f\ufffd\ufffd\u00b5superscriptsubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\ufffd13B V_{c}^{1/3}italic_B \u00e2\u02c6\ufffd italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 / 3 end_POSTSUPERSCRIPT (Fig. 2, dashed red curve) and a metabolic rate controlled by diffusion across the cell membrane. Such scaling also avoids thermodynamic shutdown (power = 0) that can occur in the center of larger cells. Shutdown can occur when Dm\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2xsubscript\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5D_{max}italic_D start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT is not fast enough to sufficiently displace reaction products and avoid reaction reversal. These changes may result in body designs, such as large central vacuoles, filamented rods, membrane bound organelles, and extreme polyploidy [28, 29, 22, 30] that minimize the potential for interior thermodynamic shutdown, but yield a relatively slow metabolic rate for prokaryotes larger than 10\u00e2\u02c6\u201917superscript101710^{-17}10 start_POSTSUPERSCRIPT - 17 end_POSTSUPERSCRIPT m33{}^{3}start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT [22]. With further increases in cell volume, metabolic rate can only be increased by increasing the rate of molecular displacement, as Z\u011f\ufffd\u2018\ufffdZitalic_Z is well below the concentration that influences diffusivity. A variety of means for increasing transport in cells exist (e.g. [31, 32, 33, 34, 35, 36, 37, 38, 39, 40]) with most attributable to the addition of structures, such as molecular motors or transport proteins, that each generate active transport of molecules or viscous bulk flow of cytoplasm over at least some local region within the cell. We model this as an enhanced effective diffusivity of Dt\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2n\u00e2\ufffd\u00a2ssubscript\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018 D_{trans}italic_D start_POSTSUBSCRIPT italic_t italic_r italic_a italic_n italic_s end_POSTSUBSCRIPT. For example, the movement of molecules along a cytoskeletal network and randomly arranged regions of bulk flow with a random flow direction can each be thought of as random walks with long single steps, and so displacement in the simplest summary model for all of these processes can be described as an enhanced diffusion (e.g. [31, 41, 42, 35, 36, 34, 39, 40]). A new trade-off is introduced between the space occupied by dedicated transport structures versus the space devoted to catalyzing reactions (enzymes and supporting structures). This effective diffusivity and volume tradeoffs are captured by and where Dt\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2n\u00e2\ufffd\u00a2ssubscript\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018 D_{trans}italic_D start_POSTSUBSCRIPT italic_t italic_r italic_a italic_n italic_s end_POSTSUBSCRIPT is the enhanced diffusivity in the region affected by the active transport or bulk flow, \u00cf\ufffd\u011f\ufffd\u0153\u0152 is the fraction of the average cellular volume that is associated with active transport or bulk flow, and \u00cf\u00b5italic-\u00cf\u00b5 is the ratio of the effective volume of active transport to the volume of the structures generating that transport (e.g. the ratio of the volume of a region of enhanced transport to a molecular motor or transport protein\u00e2\u20ac\u2122s volume). We optimize total metabolic rate (see SI) at a given cell volume as a function of \u00cf\ufffd\u011f\ufffd\u0153\u0152 and find that \u00cf\ufffd\u011f\ufffd\u0153\u0152 grows with cell size following a complicated function (see SI) that scales like \u00e2\u2030\u02c6Vc0.10absentsuperscriptsubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\ufffd0.10 V_{c}^{0.10}\u00e2\u2030\u02c6 italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0.10 end_POSTSUPERSCRIPT for small cell sizes and \u00e2\u2030\u02c6Vc2/3absentsuperscriptsubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\ufffd23 V_{c}^{2/3}\u00e2\u2030\u02c6 italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 / 3 end_POSTSUPERSCRIPT in the limit of large cell sizes. This density scaling implies that the volume dedicated to transport structures scales super-linearly with overall cell size (\u00e2\u2030\u02c6Vc1.1absentsuperscriptsubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\ufffd1.1 V_{c}^{1.1}\u00e2\u2030\u02c6 italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1.1 end_POSTSUPERSCRIPT to \u00e2\u2030\u02c6Vc5/3absentsuperscriptsubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\ufffd53 V_{c}^{5/3}\u00e2\u2030\u02c6 italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 5 / 3 end_POSTSUPERSCRIPT).Thus, for cell sizes larger than 10\u00e2\u02c6\u201917superscript101710^{-17}10 start_POSTSUPERSCRIPT - 17 end_POSTSUPERSCRIPT m33{}^{3}start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT, the effective diffusivity parameter can increase with cell volume but at the expense of an ever-increasing proportion of cell volume devoted to transport. This yields a size-dependent curve for maximum metabolic power in logarithmic space (blue curve in Fig. 3) that fits the available data for metabolic rate of Eukaryotes (again with average transport and reaction kinetic parameters). Over the middle size range of the single cell Eukaryotes, metabolic rate should approximate a power law with an exponent of 0.900.900.900.90 which agrees very well with the power law fit to data of 0.90\u00c2\u00b10.17plus-or-minus0.900.170.90 0.170.90 \u00c2\u00b1 0.17 [16, 21]. However, the super-linear scaling of the required volume of transport molecules means that motors and transport proteins begin to substantially reduce the volume for reaction structures. This transport volume requirement ultimately may limit metabolic rate, and impose a theoretical upper limit to Eukaryote size of 10\u00e2\u02c6\u20199superscript10910^{-9}10 start_POSTSUPERSCRIPT - 9 end_POSTSUPERSCRIPT m33{}^{3}start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT which compares well to the size of the largest unicellular organisms in the metabolic database (Fig. 2). These analyses produce a series of metabolic scaling curves (Fig. 2) across a succession of cell (or organism) volume ranges. Each curve is associated with a particular mode of reaction volume and molecular displacement mechanisms, with molecular diffusion at the smallest sizes then with an enhanced diffusion within devoted transport regions at the largest sizes (Fig. 3). Across the size spectrum, optimal metabolic rate is set by the tradeoff between volume for transport and volume for metabolic reactions. For prokaryotes, the smallest cells require space for other macromolecules such as DNA, which limit the space available for catalytic reaction enzymes. The largest unstructured prokaryotes face the slow scaling of metabolism set by the maximum diffusivity of small molecules in water. For unicellular eukaryotes, transport molecules provide the needed increase in molecular movement and metabolism scales almost linearly with cell volume. At the largest sizes, unicellular eukaryotes reach a sharp decrease dictated by the required overpacking of transport structures to assure the necessary effective diffusivity throughout the cell. Collectively, these curves merge to form an overall nonlinear relationship between metabolic rate and size that fit observed data very strongly (Fig. 2) and predict the scaling of protein and other material concentrations and the size at which major transitions in body plans occur. These curves clearly depart from the prediction of a single scaling exponent of 3/4343/43 / 4 predicted by the theory for the optimal organization of vascular networks, and support the general hypothesis that the smallest forms of life face different physical constraints, with different accompanying solutions, for maximizing metabolic power. However, the derived mechanisms here tend, as a first approximation, to a sublinear scaling not far from 3/4343/43 / 4. For example, the mid range bacteria are predicted to scale like 11/15=0.7311150.7311/15=0.7311 / 15 = 0.73, and the largest eukaryotes scale like \u00e2\u2030\u02c6.80absent.80 .80 as curvature sets in. These scalings for both small life and for organisms with vascular systems occur for very different mechanistic reasons, but are linked by the fundamental need for life to allocate and organize space to achieve sufficiently high rates of molecular displacement. Our results thus support more general arguments for why metabolic scaling should not be either surface area to volume scaling (\u00ce\u00b2=2/3\u011f\ufffd\u203a\u00bd23 = 2 / 3) or strictly proportional to volume (isometric, \u00ce\u00b2=1\u011f\ufffd\u203a\u00bd1 = 1). Our work suggests that previous analyses of prokaryote metabolic scaling with all of the data [16], which found super-linear scaling, requires size-dependent shifts in physical constraints that accompany shifts in scaling to approximate a super-linear power law. Our results demonstrate that the overall super-linear pattern is driven by strong curvature away from a power law at the smallest cell sizes. Downstream extension of the fits using all data have been used to derive other features such as the increase in growth rate with cell size and the total abundance of ribosomes [21, 22]. Such models may gain accuracy and improved resolution in size ranges by incorporating the more complicated metabolic scaling derived here. In addition, other cellular constraint perspectives have been proposed for explaining scaling in bacteria such as biosynthetic costs of the membrane [44], ribosome and protein abundances and costs [45, 22], the spatial location and number of organelles and genomes [16, 29], the increasing number of genes and their cost [16, 29, 45, 46], and transporter optimizations associated with the environment (e.g. [23] for a review). In addition, the deployment of phase separation as another means for enhancing reaction rates [47, 48] and the spatial architecture of macromolecules [49, 50] may also be important for cellular scaling. These are all important biophysical, physiological, and evolutionary considerations, and it will be important to integrate these additional constraints with cellular scaling in a more complicated optimization approach [23] that combines these costs with the diffusive tradeoffs employed here. Large prokaryotes also deploy active molecular transport and so the two models presented here represent bounding cases where large prokaryotes (E. coli and bigger) and small unicellular eukaryotes. Multicellular organisms overcome the limit faced by the largest single cells by evolving mechanisms of bulk flow among cells. At its extreme, optimizing such bulk flow through tubular vascular systems to minimize energy dissipation (friction) produces the well-known B\u00e2\u02c6\ufffdM3/4proportional-to\u011f\ufffd\ufffd\u00b5superscript\u011f\ufffd\u2018\u20ac34B M^{3/4}italic_B \u00e2\u02c6\ufffd italic_M start_POSTSUPERSCRIPT 3 / 4 end_POSTSUPERSCRIPT [10, 11, 51, 13, 52, 53]. Taken together, our results and vascular network models show that, organisms across the tree of life may face universal tradeoffs between biochemical reactions and the space devoted to transport, where larger organisms must employ increasingly energy-requiring methods to increase molecular transport velocities. Our results also predict the scaling of materials within the cell. For small entities relying on diffusion, we predict the total mass of enzymes (protein) to scale as Vc11/15superscriptsubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\ufffd1115V_{c}^{11/15}italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 11 / 15 end_POSTSUPERSCRIPT, which closely agrees with observed scaling proportional to Vc0.70superscriptsubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\ufffd0.70V_{c}^{0.70}italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0.70 end_POSTSUPERSCRIPT [22]. We also predict the minimum size and volume scaling at which cells should produce molecular motors, microtubules and other cytoskeletal material and other mechanisms to enhance diffusivity (Fig. 2). These scaling predictions cannot yet be tested, as they predate the measurement of such volumes or masses for diverse species and cell sizes, with just recently-developed microscopy techniques. However, the largest prokaryotes are known for unusual storage capacity [28, 22], many copies of the genome [29], and surprising amount of cytoskeleton [54]. All of these characteristics may give hints to the eukaryotic transition, and indeed Asgard archaea, which are suggested to be the eukaryotic ancestor, have several atypical cellular morphological characteristics [54, 55, 56]. Our results suggest that active transport in and/or bulk flow of the cytoplasm is likely required to generate free energy even in single cell organisms such as larger Prokaryotes and single-cell Eukaryotes. Extrapolation of the required molecular movement in our models further suggests that smaller multicellular organisms may require mechanisms such as contraction of tissues and/or locomotion to generate bulk transport of intercellular fluids without an organized single source vascular system. Extending further, branching pressurized circulatory networks may be required to sustain metabolism for organisms >1absent1>1> 1 g, a hypothesis supported by evidence that smallest mechanical pumping circulatory systems are limited by damping of pulsatile flow [10]. Our results now provide a physical and chemical explanation for the unique metabolic scaling exhibited by the smallest 11111111 orders of magnitude in organism size. We demonstrate that these life forms face significant design constraints, set by limited space for macromolecules and diffusive molecular movement, and the continuing need for faster molecular displacement mechanisms for the largest unicellulars. The predicted scaling relationships as organisms shift across the different transport limitation domains suggest that natural selection has addressed this sequence of problems during the evolution of larger cell body sizes. Such evolution has led to cells with clustered reaction surfaces, channels of cytoplasm for transporting molecules, molecular motors and cytoskeletal structures to enhance diffusion and then finally by mechanical pumping mechanisms that preview the evolution of powered branched circulatory systems. Our work now extends prior theory to provide a parsimonious hypothesis for how metabolism and the materials that support such activity scale across all life. The coupled diffusion equations to be solved for steady state are with the boundary conditions The solution to these equations is Following a similar derivation, the corresponding equation for P\u011f\ufffd\u2018\u0192Pitalic_P is Returning to the integral which represents the full metabolic rate of the cell, can can use these solutions for A\u011f\ufffd\ufffd\u00b4Aitalic_A and P\u011f\ufffd\u2018\u0192Pitalic_P set constraints on Z\u011f\ufffd\u2018\ufffdZitalic_Z. To avoid thermodynamic shutdown we need Ke\u00e2\ufffd\u00a2q\u00e2\ufffd\u00a2A\u00e2\ufffd\u00a2(r)P\u00e2\ufffd\u00a2(r)>1subscript\u011f\ufffd\ufffd\u00be\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u01781 start_ARG italic_K start_POSTSUBSCRIPT italic_e italic_q end_POSTSUBSCRIPT italic_A ( italic_r ) end_ARG start_ARG italic_P ( italic_r ) end_ARG > 1 which, given the solutions above, leads to the condition Thermodynamic shutdown is a problem for the interior of the cell and so we are interested in checking this condition for r=0\u011f\ufffd\u2018\u01780r=0italic_r = 0. Evaluating the above inequality at r=0\u011f\ufffd\u2018\u01780r=0italic_r = 0 and expanding in small rcsubscript\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdr_{c}italic_r start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT leads to This equation isn\u00e2\u20ac\u2122t fully solved because the diffusivity, D\u011f\ufffd\ufffd\u00b7Ditalic_D, depends on Z\u011f\ufffd\u2018\ufffdZitalic_Z. Previous work has shown that for large enough Z\u011f\ufffd\u2018\ufffdZitalic_Z changes in diffusivity will approximately follow a power law [26], and so we can consider D\u00e2\ufffd\u00a2(Z)=D0\u00e2\ufffd\u00a2Z\u00ce\u00b3\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\ufffd\u00b70superscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u203a\u00beD ( italic_Z ) = italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_Z start_POSTSUPERSCRIPT italic_\u00ce\u00b3 end_POSTSUPERSCRIPT which yields which for P\u00e2\u2030\u02c60\u011f\ufffd\u2018\u01920P 0italic_P \u00e2\u2030\u02c6 0 is This equation states how the concentration of enzyme should either concentrate or dilute with cell size to avoid thermodynamic limitations. Given that \u00ce\u00b3\u00e2\u2030\u02c6\u00e2\u02c6\u20193/2\u011f\ufffd\u203a\u00be32 \u00e2\u2030\u02c6 - 3 / 2 [26] we have that Z\u00e2\u02c6\ufffdrc\u00e2\u02c6\u20194/5proportional-to\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffd45Z r_{c}^{-4/5}italic_Z \u00e2\u02c6\ufffd italic_r start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 4 / 5 end_POSTSUPERSCRIPT or It should be noted that given Equation 20, Z\u011f\ufffd\u2018\ufffdZitalic_Z is bounded by a concentration that is diluting out as cells increase in size. This should set a hard upper bound where the cellular concentrations start to reach discrete numbers of enzymes. Thus, under a fixed tradeoff for diffusivity an upper bound on cell volume is predicted by the dilution of enzyme concentrations required to avoid thermodynamic shutdown. It should be noted that once Z\u011f\ufffd\u2018\ufffdZitalic_Z reaches sufficiently low concentrations diffusivity saturates to a maximum value set by molecular motion in the fluid [26]. At this point D\u00e2\ufffd\u00a2(Z)=Dm\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2x\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5D ( italic_Z ) = italic_D start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT and we have In this limit Z\u011f\ufffd\u2018\ufffdZitalic_Z will scale like Vc\u00e2\u02c6\u20192/3superscriptsubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\ufffd23V_{c}^{-2/3}italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 2 / 3 end_POSTSUPERSCRIPT to avoid thermodynamic shutdown. More generally, we are interested in the concentrations of enzymes that would optimize cellular metabolic rate. The above arguments give us a bounding expectation for the scaling of enzyme concentration, but we can replace these with the complete optimization of cellular metabolic rate, B\u011f\ufffd\ufffd\u00b5Bitalic_B. Specifically, we are interested in where the total metabolism integrated over a cell is Considering cases where the environmental concentration of the product is low, P0\u00e2\u2030\u02c60subscript\u011f\ufffd\u2018\u019200P_{0} 0italic_P start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u00e2\u2030\u02c6 0, the integrand is given by We approximate this integral considering small rcsubscript\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdr_{c}italic_r start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT and with, D\u00e2\ufffd\u00a2(Z)=D0\u00e2\ufffd\u00a2Z\u00ce\u00b3\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\ufffd\u00b70superscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u203a\u00beD ( italic_Z ) = italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_Z start_POSTSUPERSCRIPT italic_\u00ce\u00b3 end_POSTSUPERSCRIPT, the dependence of diffusivity on Z\u011f\ufffd\u2018\ufffdZitalic_Z . Given these assumptions integrand is well approximated by leading to the solution of the integral as In the small radius limit the derivative, \u00e2\u02c6\u201aB/\u00e2\u02c6\u201aZ\u011f\ufffd\ufffd\u00b5\u011f\ufffd\u2018\ufffd B/ Z\u00e2\u02c6\u201a italic_B / \u00e2\u02c6\u201a italic_Z, is then well approximated by Setting this to zero leads to This optimal solution of Zo\u00e2\ufffd\u00a2p\u00e2\ufffd\u00a2tsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0153\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1Z_{opt}italic_Z start_POSTSUBSCRIPT italic_o italic_p italic_t end_POSTSUBSCRIPT can be substituted back into the approximate solution for total metabolic rate, B\u011f\ufffd\ufffd\u00b5Bitalic_B, which we find does a good job of approximating the full numerical integral. If we take \u00ce\u00b3=\u00e2\u02c6\u20193/2\u011f\ufffd\u203a\u00be32 = - 3 / 2 this gives This solution shows that the optimal Z\u011f\ufffd\u2018\ufffdZitalic_Z scales like in agreement with our considerations above for thermodynamic shutdown. The corresponding solution for metabolic rate is given by which scales like predicting that metabolic rate will scale slightly sublinearly for sufficiently large size. It should be note that this is the approximate scaling of B\u011f\ufffd\ufffd\u00b5Bitalic_B over a range of larger cell sizes, but the full form of B\u011f\ufffd\ufffd\u00b5Bitalic_B is more complicated a small cells sizes, especially considering the factor of (1\u00e2\u02c6\u2019Ve\u00e2\ufffd\u00a2(rc)/Vc)1subscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2019subscript\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\ufffd(1-V_{e} 1 - italic_V start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_r start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ) / italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ) multiplying the entire scaling where Ve=v0\u00e2\ufffd\u00a2Vc\u00ce\u00b1subscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2019subscript\u011f\ufffd\u2018\u00a30superscriptsubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\ufffd\u011f\ufffd\u203a\u00bcV_{e}=v_{0}V_{c}^{ start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT = italic_v start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u00ce\u00b1 end_POSTSUPERSCRIPT with \u00ce\u00b1=0.83\u011f\ufffd\u203a\u00bc0.83 = 0.83 [22]. Figure 4 shows the full solution of B\u011f\ufffd\ufffd\u00b5Bitalic_B with more strongly superlinear scaling because of the small-size curvature. It should be noted that at very low Z\u011f\ufffd\u2018\ufffdZitalic_Z the diffusivity saturates to a constant maximum behavior and stops following a power law. In this case diffusivity reaches the maximum molecular diffusivity, D=Dm\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2x\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5D=D_{max}italic_D = italic_D start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT, and the above equations lead a optimal enzyme concentration of and corresponding metabolic rate of Here enzyme concentration will scale like Z\u00e2\u02c6\ufffdVc\u00e2\u02c6\u20192/3proportional-to\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\ufffd23Z V_{c}^{-2/3}italic_Z \u00e2\u02c6\ufffd italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 2 / 3 end_POSTSUPERSCRIPT and B\u00e2\u02c6\ufffdVc1/3proportional-to\u011f\ufffd\ufffd\u00b5superscriptsubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\ufffd13B V_{c}^{1/3}italic_B \u00e2\u02c6\ufffd italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 / 3 end_POSTSUPERSCRIPT. However, these scalings are unlikely to be observed because of the shift to employing active transport, and these results are only shown to illustrate the extreme limitation faced by large cells if they only used molecular diffusion. Our model for active transport treats diffusion in the cell as with a modified effective diffusivity, D\u00e2\u20ac\u00b2superscript\u011f\ufffd\ufffd\u00b7\u00e2\u20ac\u00b2D^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT, that follows where \u00cf\ufffd\u011f\ufffd\u0153\u0152 is the fraction of cell volume occupied by transport structures. Here we define an effective volume (region with enhanced transport) of a transport structure, and \u00cf\ufffd\u011f\ufffd\u0153\u0152 is the ratio of the total of these effective volumes to the total cell volume. The optimization of metabolism now depends on tradeoffs between the adjusted diffusivity and the space occupied by the transport structures, where total metabolism follows where \u00cf\u00b5italic-\u00cf\u00b5 is the ratio of the volume of a transport structure to the effective volume of enhanced transport that structure creates. The solutions for A\u00e2\ufffd\u00a2(r)\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u0178A ( italic_r ) and P\u00e2\ufffd\u00a2(r)\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u0178P ( italic_r ) are the same as in Equations 15 and 16. We are again interested in optimizing cellular metabolic rate, B\u011f\ufffd\ufffd\u00b5Bitalic_B, where now we are looking for solutions to The integration of B\u011f\ufffd\ufffd\u00b5Bitalic_B is well approximated by for small values of rcsubscript\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdr_{c}italic_r start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. Again we are considering the regime where transport, now represented by the adjusted diffusivity D\u00e2\u20ac\u00b2superscript\u011f\ufffd\ufffd\u00b7\u00e2\u20ac\u00b2D^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT, is large relative to the scale of the cell. Taking the derivative of this this solution and again approximating it for small rcsubscript\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdr_{c}italic_r start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT and also for small Dm\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2xsubscript\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5D_{max}italic_D start_POSTSUBSCRIPT italic_m italic_a italic_x end_POSTSUBSCRIPT (the maximum molecular diffusivity) we have which gives the optimal fraction of transport structures as where W\u011f\ufffd\u2018\u0160Witalic_W is the Lambert W\u011f\ufffd\u2018\u0160Witalic_W function (the product logarithm). For small rcsubscript\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdr_{c}italic_r start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT this is well approximated by Similar to our solutions above for the enzyme concentration tradeoffs in bacteria, this function again highlights that optimal metabolic values depend on D\u00e2\ufffd\u00a2Ke\u00e2\ufffd\u00a2qk\u00e2\ufffd\u00a2rc2\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\ufffd\u00be\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02dcsuperscriptsubscript\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffd2 start_ARG italic_D italic_K start_POSTSUBSCRIPT italic_e italic_q end_POSTSUBSCRIPT end_ARG start_ARG italic_k italic_r start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG. Taking all of this together we have that the optimal metabolic rate follows This scales like B\u00e2\u02c6\ufffdrc3\u00e2\u02c6\ufffdVcproportional-to\u011f\ufffd\ufffd\u00b5superscriptsubscript\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffd3proportional-tosubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\ufffdB r_{c}^{3} V_{c}italic_B \u00e2\u02c6\ufffd italic_r start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT \u00e2\u02c6\ufffd italic_V start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT with a logarithmic correction term. This explains why the scaling of metabolism in Eukaryotes is close to linear with cell volume but actually sublinear due to the logarithmic terms. Figure 6 gives the approximate local exponent of B\u011f\ufffd\ufffd\u00b5Bitalic_B with cell size. The full range of Eukaryotes is well approximated by \u00ce\u00b2=0.90\u011f\ufffd\u203a\u00bd0.90 = 0.90 which agrees with data as discussed in the maintext. This function also comes with an asymptotic limit that occurs because transportors begin to overpack the cell. This limit occurs when which corresponds to an maximum single cell eukaryote of This solution mirrors the molecular diffusion limit but with an altered diffusivity.",
        "keywords": ""
    },
    {
        "id": 5,
        "title": "Gradient Estimate for Fisher-KPP Equation on Finsler metric measure spaces",
        "abstract": "AbstractIn this manuscript, we study the positive solutions of the Finslerian Fisher-KPP equationut=\u00ce\u201d\u00e2\u02c6\u2021u\u00e2\ufffd\u00a2u+c\u00e2\ufffd\u00a2u\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019u).subscript\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a1superscript\u00ce\u201d\u00e2\u02c6\u2021\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a21\u011f\ufffd\u2018\u00a2u_{t}=\\Delta^{\\nabla u}u+cu(1-u).italic_u start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = roman_\u00ce\u201d start_POSTSUPERSCRIPT \u00e2\u02c6\u2021 italic_u end_POSTSUPERSCRIPT italic_u + italic_c italic_u ( 1 - italic_u ) .The Fisher-KPP equation is widely applied and connected to many mathematical branches. We establish the global gradient estimates on compact Finsler metric measure manifold with the traditionalC\u00e2\ufffd\u00a2D\u00e2\ufffd\u00a2(K,N)\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00be\u011f\ufffd\u2018\ufffdCD(K,N)italic_C italic_D ( italic_K , italic_N )condition, which is developed by S. Ohta and K.-T. Sturm in Finsler geometry. Furthermore, With the assistance of a new comparison theorem developed by the first author, we also give the gradient estimate on forward complete noncompact locally finite misalignment Finsler metric measure spaces with the mixed weighted curvature bounded below and some non-Riemannian curvatures norm-bounded.",
        "corpus": "HTML conversions sometimes display errors due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on. Authors: achieve the best HTML results from your LaTeX submissions by following these best practices. In this manuscript, we study the positive solutions of the Finslerian Fisher-KPP equation The Fisher-KPP equation is widely applied and connected to many mathematical branches. We establish the global gradient estimates on compact Finsler metric measure manifold with the traditional C\u00e2\ufffd\u00a2D\u00e2\ufffd\u00a2(K,N)\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00be\u011f\ufffd\u2018\ufffdCD(K,N)italic_C italic_D ( italic_K , italic_N ) condition, which is developed by S. Ohta and K.-T. Sturm in Finsler geometry. Furthermore, With the assistance of a new comparison theorem developed by the first author, we also give the gradient estimate on forward complete noncompact locally finite misalignment Finsler metric measure spaces with the mixed weighted curvature bounded below and some non-Riemannian curvatures norm-bounded. MSC Classification]35K55, 53C60, 58J35 . The Fisher-KPP equation on a complete Riemannian manifold M\u011f\ufffd\u2018\u20acMitalic_M is given by where u\u011f\ufffd\u2018\u00a2uitalic_u is a real-valued function on M\u00c3\u2014[0,\u00e2\u02c6\ufffd)\u011f\ufffd\u2018\u20ac0M \u00c3\u2014 [ 0 , \u00e2\u02c6\ufffd ) and c\u011f\ufffd\u2018\ufffdcitalic_c is a positive constant. The equation was proposed by R. A. Fisher in 1937 to describe the propagation of an evolutionarily advantageous gene in a population, and was also independently described in a seminal paper by A. N. Kolmogorov, I. G. Petrovskii, and N. S. Piskunov in the same year; for this reason, it is often referred to in the literature as the name of Fisher\u00e2\u20ac\u201cKPP equation. Since the two papers in 1937, there have been extensive investigations on traveling wave solutions and asymptotic behavior in terms of spreading speeds for various evolution systems. Traveling waves were adopted to study the nonlinear PDEs, such as the nonlinear reaction-diffusion equations modeling physical and biological phenomena (cf. [22][23]), the integral and integrodifferential population models (cf. [2][7][15][16][30]), the lattice differential systems (cf. [6][11][12][14][21][40]), and the time-delayed reaction-diffusion equations (cf. [29][38]). In 2017, Cao et al. [10] derived differential Harnack estimates for positive solutions to (1.1) on Riemannian manifolds with nonnegative Ricci curvature. The idea comes from [8][9], in which a systematic method was developed to find a Harnack inequality for geometric evolution equations. Actually, they obtained the following theorem. Theorem A. [10] Let (M,g)\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u201d(M,g)( italic_M , italic_g ) be an n\u011f\ufffd\u2018\u203anitalic_n-dimensional complete noncompact Riemannian manifold with nonnegative Ricci curvature, and let u\u00e2\ufffd\u00a2(x,t):M\u00c3\u2014[0,\u00e2\u02c6\ufffd)\u00e2\u2020\u2019Rnormal-:\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a1normal-\u00e2\u2020\u2019\u011f\ufffd\u2018\u20ac0\u011f\ufffd\u2018\u2026u(x,t):M Ritalic_u ( italic_x , italic_t ) : italic_M \u00c3\u2014 [ 0 , \u00e2\u02c6\ufffd ) \u00e2\u2020\u2019 italic_R be a positive solution to (1.1), where u\u011f\ufffd\u2018\u00a2uitalic_u is C2superscript\u011f\ufffd\ufffd\u00b62C^{2}italic_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT in x\u011f\ufffd\u2018\u00a5xitalic_x and C1superscript\u011f\ufffd\ufffd\u00b61C^{1}italic_C start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT in t\u011f\ufffd\u2018\u00a1titalic_t. let f=l\u00e2\ufffd\u00a2o\u00e2\ufffd\u00a2g\u00e2\ufffd\u00a2u\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u0153\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u00a2f=loguitalic_f = italic_l italic_o italic_g italic_u, then we have for all x\u011f\ufffd\u2018\u00a5xitalic_x and t\u011f\ufffd\u2018\u00a1titalic_t, provided that 0<\u00ce\u00b1<10\u011f\ufffd\u203a\u00bc10< < italic_\u00ce\u00b1 < 1 as well as \u00e2\u02c6\u2019c\u00e2\ufffd\u00a2n\u00e2\ufffd\u00a2(2+2)4\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019\u00ce\u00b1)<\u00ce\u00b2<min\u00e2\ufffd\u00a1{\u00e2\u02c6\u2019c\u00e2\ufffd\u00a2n\u00e2\ufffd\u00a2(1+\u00ce\u00b1)4\u00e2\ufffd\u00a2\u00ce\u00b12\u00e2\u02c6\u20194\u00e2\ufffd\u00a2\u00ce\u00b1+2\u00e2\ufffd\u00a2n,\u00e2\u02c6\u2019c\u00e2\ufffd\u00a2n\u00e2\ufffd\u00a2(2\u00e2\u02c6\u20192)4\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019\u00ce\u00b1)}<0\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a2241\u011f\ufffd\u203a\u00bc\u011f\ufffd\u203a\u00bd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a1\u011f\ufffd\u203a\u00bc4superscript\u011f\ufffd\u203a\u00bc24\u011f\ufffd\u203a\u00bc2\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a2241\u011f\ufffd\u203a\u00bc0 2}-4 start_ARG - italic_c italic_n ( 2 + square-root start_ARG 2 end_ARG ) end_ARG start_ARG 4 ( 1 - italic_\u00ce\u00b1 ) end_ARG < italic_\u00ce\u00b2 < roman_min { divide start_ARG - italic_c italic_n ( 1 + italic_\u00ce\u00b1 ) end_ARG start_ARG 4 italic_\u00ce\u00b1 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - 4 italic_\u00ce\u00b1 + 2 italic_n end_ARG , divide start_ARG - italic_c italic_n ( 2 - square-root start_ARG 2 end_ARG ) end_ARG start_ARG 4 ( 1 - italic_\u00ce\u00b1 ) end_ARG } < 0, where \u00cf\u2022\u00e2\ufffd\u00a2(t)=u\u00e2\ufffd\u00a2(e2\u00e2\ufffd\u00a2\u00ce\u00bc\u00e2\ufffd\u00a2w\u00e2\ufffd\u00a2tv\u00e2\u02c6\u2019w\u00e2\u02c6\u20191\u00ce\u00bc+w)1\u00e2\u02c6\u2019e2\u00e2\ufffd\u00a2\u00ce\u00bc\u00e2\ufffd\u00a2w\u00e2\ufffd\u00a2t,italic-\u00cf\u2022\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a2superscript\u011f\ufffd\u2018\u20192\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u00a4\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u00a41\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u00a41superscript\u011f\ufffd\u2018\u20192\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u00a4\u011f\ufffd\u2018\u00a1 wt}}{v-w}- wt}},italic_\u00cf\u2022 ( italic_t ) = divide start_ARG italic_u ( divide start_ARG italic_e start_POSTSUPERSCRIPT 2 italic_\u00ce\u00bc italic_w italic_t end_POSTSUPERSCRIPT end_ARG start_ARG italic_v - italic_w end_ARG - divide start_ARG 1 end_ARG start_ARG italic_\u00ce\u00bc + italic_w end_ARG ) end_ARG start_ARG 1 - italic_e start_POSTSUPERSCRIPT 2 italic_\u00ce\u00bc italic_w italic_t end_POSTSUPERSCRIPT end_ARG , with \u00ce\u00bc=\u00ce\u00b2\u00e2\ufffd\u00a2c\u00e2\ufffd\u00a22\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019\u00ce\u00b1)c\u00e2\ufffd\u00a2(\u00e2\u02c6\u2019c\u00e2\ufffd\u00a2n\u00e2\u02c6\u20198\u00e2\ufffd\u00a2\u00ce\u00b2\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019\u00ce\u00b1)),\u011f\ufffd\u0153\u2021\u011f\ufffd\u203a\u00bd\u011f\ufffd\u2018\ufffd21\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a8\u011f\ufffd\u203a\u00bd1\u011f\ufffd\u203a\u00bc c = italic_\u00ce\u00b2 italic_c square-root start_ARG divide start_ARG 2 ( 1 - italic_\u00ce\u00b1 ) end_ARG start_ARG italic_c ( - italic_c italic_n - 8 italic_\u00ce\u00b2 ( 1 - italic_\u00ce\u00b1 ) ) end_ARG end_ARG , v=(4\u00e2\ufffd\u00a2\u00ce\u00b2\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019\u00ce\u00b1)n+c)\u00e2\u2039\u20262\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019\u00ce\u00b1)c\u00e2\ufffd\u00a2(\u00e2\u02c6\u2019c\u00e2\ufffd\u00a2n\u00e2\u02c6\u20198\u00e2\ufffd\u00a2\u00ce\u00b2\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019\u00ce\u00b1))\u011f\ufffd\u2018\u00a3normal-\u00e2\u2039\u20264\u011f\ufffd\u203a\u00bd1\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\ufffd21\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a8\u011f\ufffd\u203a\u00bd1\u011f\ufffd\u203a\u00bcv= cn-8 = ( divide start_ARG 4 italic_\u00ce\u00b2 ( 1 - italic_\u00ce\u00b1 ) end_ARG start_ARG italic_n end_ARG + italic_c ) \u00e2\u2039\u2026 square-root start_ARG divide start_ARG 2 ( 1 - italic_\u00ce\u00b1 ) end_ARG start_ARG italic_c ( - italic_c italic_n - 8 italic_\u00ce\u00b2 ( 1 - italic_\u00ce\u00b1 ) ) end_ARG end_ARG and w=2\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019\u00ce\u00b1)n.\u011f\ufffd\u2018\u00a421\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u203aw= = square-root start_ARG divide start_ARG 2 ( 1 - italic_\u00ce\u00b1 ) end_ARG start_ARG italic_n end_ARG end_ARG . Utilizing Theorem A, one can integrate along space-time curves to get a Harnack inequality. However, it is different from the classical Li\u00e2\u20ac\u201cYau Harnack inequality [20] in form. Gradient estimates play an important role in studying elliptic and parabolic operators. The method originated first in [44] and [13], and was further developed by Li and Yau [20], Li [19], Negrin [24], P. Souplet and Q. Zhang [37], Y. Yang [43], etc.. Recent gradient estimates under the geometric flow include [4] and [3]. For more results on the nonlinear PDEs, one may refer to [1][18]. In 2018, following the line in [19], X. Geng and S. Hou [17] proved the positive solutions to the Fisher\u00e2\u20ac\u201cKPP equation on complete Riemannian manifolds. They derived a gradient estimate, and got the classic Harnack inequality by using it, which extended the recent result of Cao, Liu, Pendleton and Ward [10]. In 2009, upon the foundational investigations of gradient estimation on Riemannian manifolds, S. Ohta initially put forward a sophisticated framework for gradient estimation applicable to the heat equation on compact Finsler manifolds [25]. Subsequently, in the year 2014, C. Xia [41] undertook a comprehensive analysis of harmonic functions within the context of both compact and non-compact (specifically, forward complete) Finsler structures by utilizing an advanced form of Moser\u00e2\u20ac\u2122s iterative technique. Progressing further, Q. Xia [42] delivered intricate gradient estimates for positive solutions to the heat equation on forward complete Finsler spaces, employing methodologies analogous to those documented in [41]. The first author [32] proposed a method for global and local gradient estimates on Finsler metric measure spaces, which was also used to solve the Finslerian Schr\u00c3\u00b6dinger equation. Later, the first author [31] gives the gradient estimates of bounded solutions to the Finslerian Allen-Cahn equation. In this paper, we study the Fisher-KPP equation (1.1) on a Finsler metric measure manifold (M,F,\u00ce\u00bc)\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u0153\u2021(M,F, italic_M , italic_F , italic_\u00ce\u00bc ), where c\u011f\ufffd\u2018\ufffdcitalic_c is a positive constant, the solution of (1.1) is a function u\u00e2\ufffd\u00a2(x)\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a5u(x)italic_u ( italic_x ) on M\u00c3\u2014[0,\u00e2\u02c6\ufffd)\u011f\ufffd\u2018\u20ac0M \u00c3\u2014 [ 0 , \u00e2\u02c6\ufffd ). Our main theorems in this paper are as follows Let (M,F,\u00ce\u00bc)\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u0153\u2021(M,F, italic_M , italic_F , italic_\u00ce\u00bc ) be a compact Finsler metric measure space with dimensional n\u00e2\u2030\u00a52\u011f\ufffd\u2018\u203a2n 2italic_n \u00e2\u2030\u00a5 2, whose weighted Ricci curvature satisfies R\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2cN\u00e2\u2030\u00a5\u00e2\u02c6\u2019K\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u2013superscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00beRic^{N} italic_i italic_c start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \u00e2\u2030\u00a5 - italic_K, for some positive constant K\u011f\ufffd\ufffd\u00beKitalic_K. Assume the reversibility of M\u011f\ufffd\u2018\u20acMitalic_M has upper bound \u00cf\ufffd0subscript\u011f\ufffd\u0153\u01520 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. Suppose u\u011f\ufffd\u2018\u00a2uitalic_u is a bounded positive smooth solution of the Fisher-KPP parabolic equation (1.1) on M\u00c3\u2014[0,\u00e2\u02c6\ufffd)\u011f\ufffd\u2018\u20ac0M \u00c3\u2014 [ 0 , \u00e2\u02c6\ufffd ), then we have where, M1=supu\u00e2\ufffd\u00a2(x,t)subscript\u011f\ufffd\u2018\u20ac1supremum\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a1M_{1}= u(x,t)italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = roman_sup italic_u ( italic_x , italic_t ). Similarily, on a noncompact forward complete Finsler manifold, the following local gradient estimates is obtained. Let (M,F,\u00ce\u00bc)\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u0153\u2021(M,F, italic_M , italic_F , italic_\u00ce\u00bc ) be a complete noncompact Finsler metric measure space. Denote by B\u00e2\ufffd\u00a2(p,2\u00e2\ufffd\u00a2R)\u011f\ufffd\ufffd\u00b5\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\u2026B(p,2R)italic_B ( italic_p , 2 italic_R ) the forward geodesic ball centered at p\u011f\ufffd\u2018\ufffdpitalic_p with forward radius 2R\u011f\ufffd\u2018\u2026Ritalic_R. Suppose the mixed weighted Ricci curvature Rm\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2cN\u00e2\u2030\u00a5\u00e2\u02c6\u2019K\u00e2\ufffd\u00a2(2\u00e2\ufffd\u00a2R)superscript\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2013superscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00be2\u011f\ufffd\u2018\u2026{}^{m}Ric^{N} italic_m end_FLOATSUPERSCRIPT italic_R italic_i italic_c start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \u00e2\u2030\u00a5 - italic_K ( 2 italic_R ) in B\u00e2\ufffd\u00a2(p,2\u00e2\ufffd\u00a2R)\u011f\ufffd\ufffd\u00b5\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\u2026B(p,2R)italic_B ( italic_p , 2 italic_R ) with K\u00e2\ufffd\u00a2(2\u00e2\ufffd\u00a2R)\u00e2\u2030\u00a50\u011f\ufffd\ufffd\u00be2\u011f\ufffd\u2018\u20260K(2R) 0italic_K ( 2 italic_R ) \u00e2\u2030\u00a5 0, and the misalignment \u00ce\u00b1\u011f\ufffd\u203a\u00bc satisfies \u00ce\u00b1\u00e2\u2030\u00a4A\u00e2\ufffd\u00a2(2\u00e2\ufffd\u00a2R)\u011f\ufffd\u203a\u00bc\u011f\ufffd\ufffd\u00b42\u011f\ufffd\u2018\u2026 A(2R)italic_\u00ce\u00b1 \u00e2\u2030\u00a4 italic_A ( 2 italic_R ) in B\u00e2\ufffd\u00a2(p,2\u00e2\ufffd\u00a2R)\u011f\ufffd\ufffd\u00b5\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\u2026B(p,2R)italic_B ( italic_p , 2 italic_R ). Moreover, the non-Riemannian tensors satisfy F\u00e2\ufffd\u00a2(U)+F*\u00e2\ufffd\u00a2(\u011f\ufffd\u2019\u00af)+F\u00e2\ufffd\u00a2(d\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2v\u00e2\ufffd\u00a2C\u00e2\ufffd\u00a2(V))\u00e2\u2030\u00a4K0\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u02c6superscript\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2019\u00af\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a3\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\u2030subscript\u011f\ufffd\ufffd\u00be0F(U)+F^{*}( K_{0}italic_F ( italic_U ) + italic_F start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT ( caligraphic_T ) + italic_F ( italic_d italic_i italic_v italic_C ( italic_V ) ) \u00e2\u2030\u00a4 italic_K start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. Assume u\u00e2\ufffd\u00a2(x,t)\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a1u(x,t)italic_u ( italic_x , italic_t ) is a bounded positive smooth solution of the Fisher-KPP parabolic equation (1.1) on M\u00c3\u2014[0,\u00e2\u02c6\ufffd)\u011f\ufffd\u2018\u20ac0M \u00c3\u2014 [ 0 , \u00e2\u02c6\ufffd ), then we have on B\u00e2\ufffd\u00a2(p,R)\u011f\ufffd\ufffd\u00b5\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2026B(p,R)italic_B ( italic_p , italic_R ) for 0<\u00ce\u00b5<10\u011f\ufffd\u0153\u20ac10< < italic_\u00ce\u00b5 < 1 , s>1\u011f\ufffd\u2018 1s>1italic_s > 1 , q>0\u011f\ufffd\u2018\ufffd0q>0italic_q > 0, such that 2\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019\u00ce\u00b5)N\u00e2\u02c6\u2019\u00ce\u00b5\u00e2\ufffd\u00a2(N\u00e2\u02c6\u2019n)\u00e2\ufffd\u00a2s\u00e2\u02c6\u20191s\u00e2\ufffd\u00a2q\u00e2\u2030\u00a51\u00ce\u00b5\u00e2\u02c6\u20191+(2\u00e2\ufffd\u00a2s\u00e2\u02c6\u20191)2821\u011f\ufffd\u0153\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018 1\u011f\ufffd\u2018 \u011f\ufffd\u2018\ufffd1\u011f\ufffd\u0153\u20ac1superscript2\u011f\ufffd\u2018 128 start_ARG 2 ( 1 - italic_\u00ce\u00b5 ) end_ARG start_ARG italic_N - italic_\u00ce\u00b5 ( italic_N - italic_n ) end_ARG divide start_ARG italic_s - 1 end_ARG start_ARG italic_s italic_q end_ARG \u00e2\u2030\u00a5 divide start_ARG 1 end_ARG start_ARG italic_\u00ce\u00b5 end_ARG - 1 + divide start_ARG ( 2 italic_s - 1 ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG 8 end_ARG, where C1subscript\u011f\ufffd\ufffd\u00b61C_{1}italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, C2subscript\u011f\ufffd\ufffd\u00b62C_{2}italic_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT are positive constants. . In this section, we introduce the fundamental principles governing Finsler metric measure spaces (refer to [32] for more details). A Finsler metric space is a triple (M,F,\u00ce\u00bc)\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u0153\u2021(M,F, italic_M , italic_F , italic_\u00ce\u00bc ), which indicates that a differential manifold is equipped with a Finsler metric F\u011f\ufffd\ufffd\u00b9Fitalic_F and a measure \u00ce\u00bc\u011f\ufffd\u0153\u2021 Suppose the local coordinate of the tangent bundle is (x,y)\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a6(x,y)( italic_x , italic_y ), where x\u011f\ufffd\u2018\u00a5xitalic_x is the point on M\u011f\ufffd\u2018\u20acMitalic_M and y\u011f\ufffd\u2018\u00a6yitalic_y is the direction on Tx\u00e2\ufffd\u00a2Msubscript\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u20acT_{x}Mitalic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M. A Finsler metric F\u011f\ufffd\ufffd\u00b9Fitalic_F is a nonnegative function F:T\u00e2\ufffd\u00a2M\u00e2\u2020\u2019[0,+\u00e2\u02c6\ufffd):\u011f\ufffd\ufffd\u00b9\u00e2\u2020\u2019\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u20ac0F:TM : italic_T italic_M \u00e2\u2020\u2019 [ 0 , + \u00e2\u02c6\ufffd ) satisfies that (i) F\u011f\ufffd\ufffd\u00b9Fitalic_F is smooth and positive on T\u00e2\ufffd\u00a2M\u00e2\u02c6\u2013{0}\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u20ac0TM italic_M \u00e2\u02c6\u2013 { 0 }; (ii) F\u011f\ufffd\ufffd\u00b9Fitalic_F is a positive homogenous norm, i.e., F\u00e2\ufffd\u00a2(x,k\u00e2\ufffd\u00a2y)=k\u00e2\ufffd\u00a2F\u00e2\ufffd\u00a2(x,y)\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u02dc\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a6F(x,ky)=kF(x,y)italic_F ( italic_x , italic_k italic_y ) = italic_k italic_F ( italic_x , italic_y ) for any (x,y)\u00e2\u02c6\u02c6T\u00e2\ufffd\u00a2M\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u20ac TM( italic_x , italic_y ) \u00e2\u02c6\u02c6 italic_T italic_M and for any k>0\u011f\ufffd\u2018\u02dc0k>0italic_k > 0; (iii) F\u011f\ufffd\ufffd\u00b9Fitalic_F is strongly pseudo-convex, namely, for any (x,y)\u00e2\u02c6\u02c6T\u00e2\ufffd\u00a2M\u00e2\u02c6\u2013{0}\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u20ac0 TM italic_x , italic_y ) \u00e2\u02c6\u02c6 italic_T italic_M \u00e2\u02c6\u2013 { 0 }, the fundamental tensor is a positive definite matrix defined by Unlike the Riemann metric, the Finsler metric is defined locally as the norm on the tangent space at each point, and globally as a metric on the pull-back bundle, so there are a large number of non-Riemannian geometric quantities on a Finsler metric measure space. The Cartan tensor is defined by for any local vector fields X\u011f\ufffd\u2018\u2039Xitalic_X, Y\u011f\ufffd\u2018\u0152Yitalic_Y, Z\u011f\ufffd\u2018\ufffdZitalic_Z. There is a unique almost g-compatible and torsion-free connection on the pull-back tangent bundle \u00cf\u20ac*\u00e2\ufffd\u00a2T\u00e2\ufffd\u00a2Msuperscript\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u20ac start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT italic_T italic_M of the Finsler manifold (M,F)\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b9(M,F)( italic_M , italic_F ) called the Chern connection. It is determined by for any X,Y,Z\u00e2\u02c6\u02c6T\u00e2\ufffd\u00a2M\u00e2\u02c6\u2013{0}\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u20ac0X,Y,Z TM , italic_Y , italic_Z \u00e2\u02c6\u02c6 italic_T italic_M \u00e2\u02c6\u2013 { 0 }, where Cysubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\u00a6C_{y}italic_C start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT is the Cartan tensor. The Chern connection coefficients are locally denoted by \u00ce\u201cj\u00e2\ufffd\u00a2ki\u00e2\ufffd\u00a2(x,y)subscriptsuperscript\u00ce\u201c\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a6 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT ( italic_x , italic_y ) in a natural coordinate system, which could induce the spray coefficients as Gi=12\u00e2\ufffd\u00a2\u00ce\u201cj\u00e2\ufffd\u00a2ki\u00e2\ufffd\u00a2yj\u00e2\ufffd\u00a2yksuperscript\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u201312subscriptsuperscript\u00ce\u201c\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u02dcsuperscript\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u2014superscript\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u02dcG^{i}= start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT = divide start_ARG 1 end_ARG start_ARG 2 end_ARG roman_\u00ce\u201c start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j italic_k end_POSTSUBSCRIPT italic_y start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT italic_y start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT. The spray is given by in which \u00ce\u00b4\u00ce\u00b4\u00e2\ufffd\u00a2xi=\u00e2\u02c6\u201a\u00ce\u00b4\u00e2\ufffd\u00a2xi\u00e2\u02c6\u2019Nij\u00e2\ufffd\u00a2\u00e2\u02c6\u201a\u00e2\u02c6\u201ayj\u011f\ufffd\u203a\u00bf\u011f\ufffd\u203a\u00bfsuperscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2013\u011f\ufffd\u203a\u00bfsuperscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2013subscriptsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u2013superscript\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u2014 x^{i}}= x^{i}}-N^{j}_{i} y^{j}}divide start_ARG italic_\u00ce\u00b4 end_ARG start_ARG italic_\u00ce\u00b4 italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT end_ARG = divide start_ARG \u00e2\u02c6\u201a end_ARG start_ARG italic_\u00ce\u00b4 italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT end_ARG - italic_N start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT divide start_ARG \u00e2\u02c6\u201a end_ARG start_ARG \u00e2\u02c6\u201a italic_y start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT end_ARG and the nonlinear connection coefficients are locally induced from the spray coefficients by Nji=\u00e2\u02c6\u201aGi\u00e2\u02c6\u201ayjsubscriptsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014superscript\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2013superscript\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u2014N^{i}_{j}= G^{i}}{ y^{j}}italic_N start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = divide start_ARG \u00e2\u02c6\u201a italic_G start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT end_ARG start_ARG \u00e2\u02c6\u201a italic_y start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT end_ARG. The Chern connection can define the Chern Riemannian curvature R\u011f\ufffd\u2018\u2026Ritalic_R and Chern non-Riemannian connection P\u011f\ufffd\u2018\u0192Pitalic_P. Denote by \u00ce\u00a9\u00ce\u00a9 the curvature form of the Chern connection, so that for any X,Y,Z\u00e2\u02c6\u02c6T\u00e2\ufffd\u00a2M\u00e2\u02c6\u2013{0}\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u20ac0X,Y,Z TM , italic_Y , italic_Z \u00e2\u02c6\u02c6 italic_T italic_M \u00e2\u02c6\u2013 { 0 }, where locally Customarily, we denote the horizontal Chern derivative by \"\u00e2\u02c6\u00a3\"conditional\"\"\" \u00e2\u02c6\u00a3 \" and the vertical Chern derivative by \";\"\"\"\";\"\" ; \". For example, for any 1-form v=vi\u00e2\ufffd\u00a2d\u00e2\ufffd\u00a2xi\u011f\ufffd\u2018\u00a3subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2018superscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2013v=v_{i}dx^{i}italic_v = italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_d italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT on the pull-back bundle. The angular metric form hysubscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u00a6h_{y}italic_h start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT is defined by for any y,u,v\u00e2\u02c6\u02c6Tx\u00e2\ufffd\u00a2M\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a3subscript\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u20acy,u,v T_{x}Mitalic_y , italic_u , italic_v \u00e2\u02c6\u02c6 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M with y\u00e2\u2030 0\u011f\ufffd\u2018\u00a60y 0italic_y \u00e2\u2030 0 Thus, for any two linearly independent vectors y,v\u00e2\u02c6\u02c6Tx\u00e2\ufffd\u00a2M\u00e2\u02c6\u2013{0}\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a3subscript\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u20ac0y,v T_{x}M , italic_v \u00e2\u02c6\u02c6 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M \u00e2\u02c6\u2013 { 0 }, which span a tangent plane \u00ce y=s\u00e2\ufffd\u00a2p\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2n\u00e2\ufffd\u00a2{y,v}subscript\u00ce \u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018 \u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a3 start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT = italic_s italic_p italic_a italic_n { italic_y , italic_v }, the flag curvature with pole y\u011f\ufffd\u2018\u00a6yitalic_y is defined by which is locally expressed by The Ricci curvature is defined by where e1,\u00e2\u20ac\u00a6,en\u00e2\u02c6\u20191,vF\u00e2\ufffd\u00a2(v)subscript\u011f\ufffd\u2018\u20191\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u203a1\u011f\ufffd\u2018\u00a3\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u00a3e_{1}, start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_e start_POSTSUBSCRIPT italic_n - 1 end_POSTSUBSCRIPT , divide start_ARG italic_v end_ARG start_ARG italic_F ( italic_v ) end_ARG form an orthonormal basis of Tx\u00e2\ufffd\u00a2Msubscript\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u20acT_{x}Mitalic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M with respect to gysubscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u00a6g_{y}italic_g start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT. The Landsberg curvature of (M,F)\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b9(M,F)( italic_M , italic_F ) is given by By the zero homogeneity, according to the Euler lemma, it easy to see that H.B. Rademacher introduced the concepts of reversibility and reversible manifolds [28], which are also closely related to the analytical assumptions on Finsler manifolds. A Finsler metric is defined to be reversible if F\u00e2\ufffd\u00a2(x,V)=F\u00c2\u00af\u00e2\ufffd\u00a2(x,V)\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2030\u00c2\u00af\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2030F(x,V)= ( italic_x , italic_V ) = over\u00c2\u00af start_ARG italic_F end_ARG ( italic_x , italic_V ) for any point x\u011f\ufffd\u2018\u00a5xitalic_x and any vector field V\u011f\ufffd\u2018\u2030Vitalic_V, where F\u00c2\u00af\u00e2\ufffd\u00a2(x,V):=F\u00e2\ufffd\u00a2(x,\u00e2\u02c6\u2019V)assign\u00c2\u00af\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2030\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2030 start_ARG italic_F end_ARG ( italic_x , italic_V ) := italic_F ( italic_x , - italic_V ) is called the reversed Finsler metric of F\u011f\ufffd\ufffd\u00b9Fitalic_F. Obviously, F\u011f\ufffd\ufffd\u00b9Fitalic_F is reversible if and only if \u00cf\ufffd\u00e2\u2030\u00a11\u011f\ufffd\u0153\u01521 1italic_\u00cf\ufffd \u00e2\u2030\u00a1 1. A Finsler manifold (M,F)\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b9(M,F)( italic_M , italic_F ) is said to have finite reversibility if \u00cf\ufffd<+\u00e2\u02c6\ufffd\u011f\ufffd\u0153\u0152 < + \u00e2\u02c6\ufffd. Later, K. Ball, E. Carlen, and E. Lieb introduced the concepts of uniform smoothness and uniform convexity in Banach space theory [5], whose geometric interpretation in Finsler geometry was provided by S. Ohta [26]. We say F\u011f\ufffd\ufffd\u00b9Fitalic_F satisfies uniform convexity and uniform smoothness if there exist uniform positive constants \u00ce\u00ba*superscript\u011f\ufffd\u0153\u2026 start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT and \u00ce\u00ba\u011f\ufffd\u0153\u2026 called the uniform convexity constant and the uniform smoothness constant, respectively, such that for any x\u00e2\u02c6\u02c6M\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u20acx Mitalic_x \u00e2\u02c6\u02c6 italic_M, V\u00e2\u02c6\u02c6Tx\u00e2\ufffd\u00a2M\u00e2\u02c6\u2013{0}\u011f\ufffd\u2018\u2030subscript\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u20ac0V T_{x}M \u00e2\u02c6\u02c6 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M \u00e2\u02c6\u2013 { 0 }, and W\u00e2\u02c6\u02c6Tx\u00e2\ufffd\u00a2M\u011f\ufffd\u2018\u0160subscript\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u20acW T_{x}Mitalic_W \u00e2\u02c6\u02c6 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M, we have where gV=(gi\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(x,V))subscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u2030subscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2030g_{V}=(g_{ij}(x,V))italic_g start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT = ( italic_g start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ( italic_x , italic_V ) ) is the Riemannian metric on M\u011f\ufffd\u2018\u20acMitalic_M induced from F\u011f\ufffd\ufffd\u00b9Fitalic_F with respect to the reference vector V\u011f\ufffd\u2018\u2030Vitalic_V . In this situation, the reversibility \u00cf\ufffd\u011f\ufffd\u0153\u0152 could be controlled by \u00ce\u00ba\u011f\ufffd\u0153\u2026 and \u00ce\u00ba*superscript\u011f\ufffd\u0153\u2026 start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT as F\u011f\ufffd\ufffd\u00b9Fitalic_F is Riemannian if and only if \u00ce\u00ba=1\u011f\ufffd\u0153\u20261 = 1 if and only if \u00ce\u00ba*=1superscript\u011f\ufffd\u0153\u20261 start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT = 1 [26]. The Riemannian structure is inconsistent when the reference vectors are different. For example, given three different local non-vanishing vector fields around x\u011f\ufffd\u2018\u00a5xitalic_x, namely, V\u011f\ufffd\u2018\u2030Vitalic_V, W\u011f\ufffd\u2018\u0160Witalic_W, Y\u011f\ufffd\u2018\u0152Yitalic_Y , the norm of Y\u011f\ufffd\u2018\u0152Yitalic_Y about gVsubscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u2030g_{V}italic_g start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT and gWsubscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u0160g_{W}italic_g start_POSTSUBSCRIPT italic_W end_POSTSUBSCRIPT maybe not the same in general case. The ratio gV\u00e2\ufffd\u00a2(Y,Y)=gW\u00e2\ufffd\u00a2(Y,Y)subscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u0152subscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u0160\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u0152g_{V}(Y,Y)=g_{W}(Y,Y)italic_g start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT ( italic_Y , italic_Y ) = italic_g start_POSTSUBSCRIPT italic_W end_POSTSUBSCRIPT ( italic_Y , italic_Y ) is a function about V\u011f\ufffd\u2018\u2030Vitalic_V, W\u011f\ufffd\u2018\u0160Witalic_W, Y\u011f\ufffd\u2018\u0152Yitalic_Y . Based on this fact, [32] defined an important constant on a Finsler manifold, called the misalignment. ([32]). For a Finsler manifold (M,F)\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b9(M,F)( italic_M , italic_F ), the misalignment of a Finsler metric at point x\u011f\ufffd\u2018\u00a5xitalic_x is defined by Moreover, the global misalignment of the Finsler metric is defined by it also provided in [32] some characterizations of the misalignment. Especially, a Finsler manifold (M,F)\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b9(M,F)( italic_M , italic_F ) is a Riemannian manifold if and only if \u00ce\u00b1M=1subscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u20ac1 start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT = 1. Moreover, a Finsler manifold (M,F)\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b9(M,F)( italic_M , italic_F ) is uniform convexity and uniform smoothness if and only if it satisfies finite misalignment. Since that, we have gaven an important class of Finsler manifold as the following. We call a Finsler manifold (M,F)\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b9(M,F)( italic_M , italic_F ) has finite misalignment if there is a positive constant A\u011f\ufffd\ufffd\u00b4Aitalic_A such that \u00ce\u00b1\u00e2\u2030\u00a4A\u011f\ufffd\u203a\u00bc\u011f\ufffd\ufffd\u00b4 Aitalic_\u00ce\u00b1 \u00e2\u2030\u00a4 italic_A, and has locally finite misalignment if for any compact subset \u00ce\u00a9\u00e2\u0160\u201aMnormal-\u00ce\u00a9\u011f\ufffd\u2018\u20ac Mroman_\u00ce\u00a9 \u00e2\u0160\u201a italic_M, there is a constant A\u00e2\ufffd\u00a2(\u00ce\u00a9)\u011f\ufffd\ufffd\u00b4normal-\u00ce\u00a9A( ( roman_\u00ce\u00a9 ) depending on \u00ce\u00a9normal-\u00ce\u00a9 such that \u00ce\u00b1\u00e2\ufffd\u00a2(x)\u00e2\u2030\u00a4A\u00e2\ufffd\u00a2(\u00cf\u2030)\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u00a5\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u0153\u201d A( ( italic_x ) \u00e2\u2030\u00a4 italic_A ( italic_\u00cf\u2030 ) for any x\u00e2\u02c6\u02c6\u00ce\u00a9\u011f\ufffd\u2018\u00a5normal-\u00ce\u00a9x \u00e2\u02c6\u02c6 roman_\u00ce\u00a9. So far, we have briefly introduced some Riemannian or non-Riemannian local quantities and tensors in Finsler geometry corresponding to Riemannian geometric quantities. Next, we will introduce more tensors related to the measure d\u00e2\ufffd\u00a2\u00ce\u00bc\u011f\ufffd\u2018\u2018\u011f\ufffd\u0153\u2021d italic_\u00ce\u00bc. For any smooth function f:M\u00e2\u2020\u2019R:\u011f\ufffd\u2018\u201c\u00e2\u2020\u2019\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2026f:M Ritalic_f : italic_M \u00e2\u2020\u2019 italic_R, df denotes its differential 1-form and its gradient \u00e2\u02c6\u2021f\u00e2\u02c6\u2021\u011f\ufffd\u2018\u201c f\u00e2\u02c6\u2021 italic_f is defined as the dual of the 1-form via the Legendre transformation, namely, \u00e2\u02c6\u2021f\u00e2\ufffd\u00a2(x):=l\u00e2\u02c6\u20191\u00e2\ufffd\u00a2(d\u00e2\ufffd\u00a2f\u00e2\ufffd\u00a2(x))\u00e2\u02c6\u02c6Tx\u00e2\ufffd\u00a2Massign\u00e2\u02c6\u2021\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u00a5superscript\u011f\ufffd\u2018\u21221\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u20ac f(x):=l^{-1}(df(x)) T_{x}M\u00e2\u02c6\u2021 italic_f ( italic_x ) := italic_l start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( italic_d italic_f ( italic_x ) ) \u00e2\u02c6\u02c6 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M. Locally it can be written as on Mf:=d\u00e2\ufffd\u00a2f\u00e2\u2030 0assignsubscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u201c0M_{f}:={df 0}italic_M start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT := italic_d italic_f \u00e2\u2030 0. The Hessian of f\u011f\ufffd\u2018\u201cfitalic_f is defined via the Chern connection by It can be shown that \u00e2\u02c6\u20212f\u00e2\ufffd\u00a2(X,Y)superscript\u00e2\u02c6\u20212\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u0152 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_f ( italic_X , italic_Y ) is symmetric [27]. For any two points p\u011f\ufffd\u2018\ufffdpitalic_p, q\u011f\ufffd\u2018\ufffdqitalic_q on M\u011f\ufffd\u2018\u20acMitalic_M, the distance function is defined by where the infimum is taken over all the C1superscript\u011f\ufffd\ufffd\u00b61C^{1}italic_C start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT curves \u00ce\u00b3:[0,1]\u00e2\u2020\u2019M:\u011f\ufffd\u203a\u00be\u00e2\u2020\u201901\u011f\ufffd\u2018\u20ac Mitalic_\u00ce\u00b3 : [ 0 , 1 ] \u00e2\u2020\u2019 italic_M such that \u00ce\u00b3\u00e2\ufffd\u00a2(0)=p\u011f\ufffd\u203a\u00be0\u011f\ufffd\u2018\ufffd ( 0 ) = italic_p and \u00ce\u00b3\u00e2\ufffd\u00a2(1)=q\u011f\ufffd\u203a\u00be1\u011f\ufffd\u2018\ufffd ( 1 ) = italic_q. Fixed a base point p\u011f\ufffd\u2018\ufffdpitalic_p on M\u011f\ufffd\u2018\u20acMitalic_M, we denote the forward distance function by r\u011f\ufffd\u2018\u0178ritalic_r. That is, r\u00e2\ufffd\u00a2(x)=d\u00e2\ufffd\u00a2(p,x)\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5r(x)=d(p,x)italic_r ( italic_x ) = italic_d ( italic_p , italic_x ), with d denotes the forward distance. The forward distance function r\u011f\ufffd\u2018\u0178ritalic_r is a function defined on the Finsler manifold M\u011f\ufffd\u2018\u20acMitalic_M. d\u00e2\ufffd\u00a2r\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u0178dritalic_d italic_r is a 1-form on M\u011f\ufffd\u2018\u20acMitalic_M, whose dual is a gradient vector field, noted by \u00e2\u02c6\u2021r\u00e2\u02c6\u2021\u011f\ufffd\u2018\u0178 r\u00e2\u02c6\u2021 italic_r. Precisely, \u00e2\u02c6\u2021r=gi\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(x,\u00e2\u02c6\u2021r)\u00e2\ufffd\u00a2\u00e2\u02c6\u201ar\u00e2\u02c6\u201axi\u00e2\ufffd\u00a2\u00e2\u02c6\u201a\u00e2\u02c6\u201axj\u00e2\u02c6\u2021\u011f\ufffd\u2018\u0178superscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u00a5\u00e2\u02c6\u2021\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u0178superscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2013superscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2014 r=g^{ij}(x, r) r}{ x^{i}} x^{j}}\u00e2\u02c6\u2021 italic_r = italic_g start_POSTSUPERSCRIPT italic_i italic_j end_POSTSUPERSCRIPT ( italic_x , \u00e2\u02c6\u2021 italic_r ) divide start_ARG \u00e2\u02c6\u201a italic_r end_ARG start_ARG \u00e2\u02c6\u201a italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT end_ARG divide start_ARG \u00e2\u02c6\u201a end_ARG start_ARG \u00e2\u02c6\u201a italic_x start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT end_ARG Taking the Chern horizontal derivative of \u00e2\u02c6\u2021r\u00e2\u02c6\u2021\u011f\ufffd\u2018\u0178 r\u00e2\u02c6\u2021 italic_r yields the Hessian of distance function \u00e2\u02c6\u20212rsuperscript\u00e2\u02c6\u20212\u011f\ufffd\u2018\u0178 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r. Locally, in a natural coordinate system In (2.23), the derivative is taken in the direction \u00e2\u02c6\u2021r\u00e2\u02c6\u2021\u011f\ufffd\u2018\u0178 r\u00e2\u02c6\u2021 italic_r naturally. Generally, we can take the derivative in any direction. Suppose V\u011f\ufffd\u2018\u2030Vitalic_V is a local vector field around x\u011f\ufffd\u2018\u00a5xitalic_x on M\u011f\ufffd\u2018\u20acMitalic_M. Note that the distance function may not be symmetric about p\u011f\ufffd\u2018\ufffdpitalic_p and q\u011f\ufffd\u2018\ufffdqitalic_q unless F\u011f\ufffd\ufffd\u00b9Fitalic_F is reversible. A\u00e2\ufffd\u00a2C2\u011f\ufffd\ufffd\u00b4superscript\u011f\ufffd\ufffd\u00b62AC^{2}italic_A italic_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT curve \u00ce\u00b3\u011f\ufffd\u203a\u00be is called a geodesic if locally where Gi\u00e2\ufffd\u00a2(x,y)superscript\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a6G^{i}(x,y)italic_G start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT ( italic_x , italic_y ) are the spray coefficients. A forward geodesic ball centered at p\u011f\ufffd\u2018\ufffdpitalic_p with radius R\u011f\ufffd\u2018\u2026Ritalic_R can be represented by Adopting the exponential map, a Finsler manifold (M,F)\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b9(M,F)( italic_M , italic_F ) is said to be forward complete or forward geodesically complete if the exponential map is defined on the entire T\u00e2\ufffd\u00a2M\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u20acTMitalic_T italic_M. Thus, any two points in a forward complete manifold M\u011f\ufffd\u2018\u20acMitalic_M can be connected by a minimal forward geodesic. Moreover, the forward closed balls BR+\u00e2\ufffd\u00a2(p)\u00c2\u00af\u00c2\u00afsubscriptsuperscript\u011f\ufffd\ufffd\u00b5\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\ufffd start_ARG italic_B start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_R end_POSTSUBSCRIPT ( italic_p ) end_ARG are compact. A Finsler metric measure space (M,F,d\u00e2\ufffd\u00a2\u00ce\u00bc)\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u2018\u011f\ufffd\u0153\u2021(M,F,d italic_M , italic_F , italic_d italic_\u00ce\u00bc ) is a Finsler manifold equipped with a given measure \u00ce\u00bc\u011f\ufffd\u0153\u2021 In local coordinates {xi}i=1nsuperscriptsubscriptsuperscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\u203a italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, we can express the volume form as d\u00e2\ufffd\u00a2\u00ce\u00bc=\u00cf\u0192\u00e2\ufffd\u00a2(x)\u00e2\ufffd\u00a2d\u00e2\ufffd\u00a2x1\u00e2\ufffd\u00a2\u00e2\u20ac\u00a6\u00e2\ufffd\u00a2d\u00e2\ufffd\u00a2xn\u011f\ufffd\u2018\u2018\u011f\ufffd\u0153\u2021\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2018superscript\u011f\ufffd\u2018\u00a51\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u2018superscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u203ad dx^{n}italic_d italic_\u00ce\u00bc = italic_\u00cf\u0192 ( italic_x ) italic_d italic_x start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT \u00e2\u20ac\u00a6 italic_d italic_x start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. For any y\u00e2\u02c6\u02c6Tx\u00e2\ufffd\u00a2M\u00e2\u02c6\u2013{0}\u011f\ufffd\u2018\u00a6subscript\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u20ac0y T_{x}M \u00e2\u02c6\u02c6 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M \u00e2\u02c6\u2013 { 0 }, define which is called the distortion of (M,F,d\u00e2\ufffd\u00a2\u00ce\u00bc)\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u2018\u011f\ufffd\u0153\u2021(M,F,d italic_M , italic_F , italic_d italic_\u00ce\u00bc ). The definition of the S-curvature is given in the following. ([35][34]). Suppose (M,F,d\u00e2\ufffd\u00a2\u00ce\u00bc)\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u2018\u011f\ufffd\u0153\u2021(M,F,d italic_M , italic_F , italic_d italic_\u00ce\u00bc ) is a Finsler metric measure space. For any point x\u00e2\u02c6\u02c6M\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u20acx Mitalic_x \u00e2\u02c6\u02c6 italic_M, let \u00ce\u00b3=\u00ce\u00b3\u00e2\ufffd\u00a2(t)\u011f\ufffd\u203a\u00be\u011f\ufffd\u203a\u00be\u011f\ufffd\u2018\u00a1 = italic_\u00ce\u00b3 ( italic_t ) be a forward geodesic from x with the initial tangent vector \u00ce\u00b3\u00cb\u2122\u00e2\ufffd\u00a2(0)=ynormal-\u00cb\u2122\u011f\ufffd\u203a\u00be0\u011f\ufffd\u2018\u00a6 start_ARG italic_\u00ce\u00b3 end_ARG ( 0 ) = italic_y. The S-curvature of (M,F,d\u00e2\ufffd\u00a2\u00ce\u00bc)\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u2018\u011f\ufffd\u0153\u2021(M,F,d italic_M , italic_F , italic_d italic_\u00ce\u00bc ) is Definition 2.3 means that the S-curvature is the changing of distortion along the geodesic in direction y. Modeled on the definition of \u011f\ufffd\u2019\u00af\u011f\ufffd\u2019\u00af curvature in [36], [32] defined the difference of \u00e2\u02c6\u2021\u00cf\u201enormal-\u00e2\u02c6\u2021\u011f\ufffd\u0153\ufffd italic_\u00cf\u201e on the tangent sphere, denoted by \u011f\ufffd\u2019\u00af\u011f\ufffd\u2019\u00af ([32]). The difference of \u00e2\u02c6\u2021\u00cf\u201enormal-\u00e2\u02c6\u2021\u011f\ufffd\u0153\ufffd italic_\u00cf\u201e on the tangent bundle is a tensor denoted by \u011f\ufffd\u2019\u00af\u011f\ufffd\u2019\u00af which is given by for vector fields V\u011f\ufffd\u2018\u2030Vitalic_V,W\u011f\ufffd\u2018\u0160Witalic_W on M\u011f\ufffd\u2018\u20acMitalic_M. Locally, it is \u011f\ufffd\u2019\u00af\u00e2\ufffd\u00a2(V,W)=\u011f\ufffd\u2019\u00afi\u00e2\ufffd\u00a2(V,w)\u00e2\ufffd\u00a2d\u00e2\ufffd\u00a2xi\u011f\ufffd\u2019\u00af\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u0160subscript\u011f\ufffd\u2019\u00af\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u00a4\u011f\ufffd\u2018\u2018superscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2013 ( italic_V , italic_W ) = caligraphic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_V , italic_w ) italic_d italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT, with Obviously, \u011f\ufffd\u2019\u00af\u00e2\ufffd\u00a2(V,W)\u011f\ufffd\u2019\u00af\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u0160 ( italic_V , italic_W ) is anti-symmetric about V\u011f\ufffd\u2018\u2030Vitalic_V and W\u011f\ufffd\u2018\u0160Witalic_W, that is, \u011f\ufffd\u2019\u00af\u00e2\ufffd\u00a2(V,W)=\u00e2\u02c6\u2019\u011f\ufffd\u2019\u00af\u00e2\ufffd\u00a2(W,V)\u011f\ufffd\u2019\u00af\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u0160\u011f\ufffd\u2019\u00af\u011f\ufffd\u2018\u0160\u011f\ufffd\u2018\u2030 ( italic_V , italic_W ) = - caligraphic_T ( italic_W , italic_V ) for any nonvanishing V\u011f\ufffd\u2018\u2030Vitalic_V and W\u011f\ufffd\u2018\u0160Witalic_W. If in local coordinates {xi}i=1nsubscriptsuperscriptsuperscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u20131 italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT, expressing d\u00e2\ufffd\u00a2\u00ce\u00bc=e\u00cf\u2022\u00e2\ufffd\u00a2d\u00e2\ufffd\u00a2x1\u00e2\ufffd\u00a2\u00e2\u20ac\u00a6\u00e2\ufffd\u00a2d\u00e2\ufffd\u00a2xn\u011f\ufffd\u2018\u2018\u011f\ufffd\u0153\u2021superscript\u011f\ufffd\u2018\u2019italic-\u00cf\u2022\u011f\ufffd\u2018\u2018superscript\u011f\ufffd\u2018\u00a51\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u2018superscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u203ad dx^{n}italic_d italic_\u00ce\u00bc = italic_e start_POSTSUPERSCRIPT italic_\u00cf\u2022 end_POSTSUPERSCRIPT italic_d italic_x start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT \u00e2\u20ac\u00a6 italic_d italic_x start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, the divergence of a smooth vector field V\u011f\ufffd\u2018\u2030Vitalic_V can be written as The Finsler Laplacian of a function f\u011f\ufffd\u2018\u201cfitalic_f on M\u011f\ufffd\u2018\u20acMitalic_M could now be given by \u00ce\u201dd\u00e2\ufffd\u00a2\u00ce\u00bc\u00e2\ufffd\u00a2f:=d\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2vd\u00e2\ufffd\u00a2\u00ce\u00bc\u00e2\ufffd\u00a2(\u00e2\u02c6\u2021f)assignsubscript\u00ce\u201d\u011f\ufffd\u2018\u2018\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2018\u011f\ufffd\u0153\u2021\u00e2\u02c6\u2021\u011f\ufffd\u2018\u201c f)roman_\u00ce\u201d start_POSTSUBSCRIPT italic_d italic_\u00ce\u00bc end_POSTSUBSCRIPT italic_f := italic_d italic_i italic_v start_POSTSUBSCRIPT italic_d italic_\u00ce\u00bc end_POSTSUBSCRIPT ( \u00e2\u02c6\u2021 italic_f ), noticing that \u00ce\u201dd\u00e2\ufffd\u00a2\u00ce\u00bc=\u00ce\u201d\u00e2\u02c6\u2021f\u00e2\ufffd\u00a2fsubscript\u00ce\u201d\u011f\ufffd\u2018\u2018\u011f\ufffd\u0153\u2021superscript\u00ce\u201d\u00e2\u02c6\u2021\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u201c f}froman_\u00ce\u201d start_POSTSUBSCRIPT italic_d italic_\u00ce\u00bc end_POSTSUBSCRIPT = roman_\u00ce\u201d start_POSTSUPERSCRIPT \u00e2\u02c6\u2021 italic_f end_POSTSUPERSCRIPT italic_f, where \u00ce\u201dd\u00e2\ufffd\u00a2\u00ce\u00bc\u00e2\u02c6\u2021f\u00e2\ufffd\u00a2f:=d\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2vd\u00e2\ufffd\u00a2\u00ce\u00bc\u00e2\ufffd\u00a2(\u00e2\u02c6\u2021\u00e2\u02c6\u2021ff)assignsubscriptsuperscript\u00ce\u201d\u00e2\u02c6\u2021\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2018\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2018\u011f\ufffd\u0153\u2021superscript\u00e2\u02c6\u2021\u00e2\u02c6\u2021\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u201c f}_{d f}f)roman_\u00ce\u201d start_POSTSUPERSCRIPT \u00e2\u02c6\u2021 italic_f end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_d italic_\u00ce\u00bc end_POSTSUBSCRIPT italic_f := italic_d italic_i italic_v start_POSTSUBSCRIPT italic_d italic_\u00ce\u00bc end_POSTSUBSCRIPT ( \u00e2\u02c6\u2021 start_POSTSUPERSCRIPT \u00e2\u02c6\u2021 italic_f end_POSTSUPERSCRIPT italic_f ) is in the view of weighted Laplacian with A Finsler Laplacian is better to be viewed in a weak sense due to the lack of regularity. Concretely, assuming f\u00e2\u02c6\u02c6W1,p\u00e2\ufffd\u00a2(M)\u011f\ufffd\u2018\u201csuperscript\u011f\ufffd\u2018\u01601\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20acf W^{1,p}(M)italic_f \u00e2\u02c6\u02c6 italic_W start_POSTSUPERSCRIPT 1 , italic_p end_POSTSUPERSCRIPT ( italic_M ), for any test function \u00cf\u2022\u00e2\u02c6\u02c6C0\u00e2\u02c6\ufffd\u00e2\ufffd\u00a2(M)italic-\u00cf\u2022superscriptsubscript\u011f\ufffd\ufffd\u00b60\u011f\ufffd\u2018\u20ac C_{0}^{ \u00e2\u02c6\u02c6 italic_C start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\ufffd end_POSTSUPERSCRIPT ( italic_M ). On the other hand, the Laplacian of a function f\u011f\ufffd\u2018\u201cfitalic_f on a Riemannian manifold is the trace of the Hessian of f\u011f\ufffd\u2018\u201cfitalic_f with respect to the Riemannian metric g\u011f\ufffd\u2018\u201dgitalic_g. On a Finsler metric measure space (M,F,d\u00e2\ufffd\u00a2\u00ce\u00bc)\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u2018\u011f\ufffd\u0153\u2021(M,F,d italic_M , italic_F , italic_d italic_\u00ce\u00bc ), the weighted Hessian H~\u00e2\ufffd\u00a2(f)~\u011f\ufffd\ufffd\u00bb\u011f\ufffd\u2018\u201c start_ARG italic_H end_ARG ( italic_f ) of a function f\u011f\ufffd\u2018\u201cfitalic_f on Mf={x\u00e2\u02c6\u02c6M:\u00e2\u02c6\u2021f|x\u00e2\u2030 0}subscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u201cconditional-set\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u20acevaluated-at\u00e2\u02c6\u2021\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u00a50M_{f}= M: f|_{x} 0 start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT = { italic_x \u00e2\u02c6\u02c6 italic_M : \u00e2\u02c6\u2021 italic_f | start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT \u00e2\u2030 0 }is defined in [39] by where h\u00e2\u02c6\u2021fsubscript\u00e2\u201e\ufffd\u00e2\u02c6\u2021\u011f\ufffd\u2018\u201ch_{ f}italic_h start_POSTSUBSCRIPT \u00e2\u02c6\u2021 italic_f end_POSTSUBSCRIPT is the angular metric form in the direction \u00e2\u02c6\u2021f\u00e2\u02c6\u2021\u011f\ufffd\u2018\u201c f\u00e2\u02c6\u2021 italic_f, given in (2.9) It is clear that H~\u00e2\ufffd\u00a2(f)~\u011f\ufffd\ufffd\u00bb\u011f\ufffd\u2018\u201c start_ARG italic_H end_ARG ( italic_f ) is still a symmetric bilinear form with Inspired by this, [32] defined the mixed weighted Hessian where hV,\u00e2\u02c6\u2021fsubscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2030\u00e2\u02c6\u2021\u011f\ufffd\u2018\u201ch_{V, f}italic_h start_POSTSUBSCRIPT italic_V , \u00e2\u02c6\u2021 italic_f end_POSTSUBSCRIPT is the mixed angular metric form in the directions V\u011f\ufffd\u2018\u2030Vitalic_V and \u00e2\u02c6\u2021f\u00e2\u02c6\u2021\u011f\ufffd\u2018\u201c f\u00e2\u02c6\u2021 italic_f, which is defined by for any vector X\u011f\ufffd\u2018\u2039Xitalic_X, Y\u011f\ufffd\u2018\u0152Yitalic_Y. It is necessary to remark that h\u00e2\u02c6\u2021f,\u00e2\u02c6\u2021f=h\u00e2\u02c6\u2021fsubscript\u00e2\u201e\ufffd\u00e2\u02c6\u2021\u011f\ufffd\u2018\u201c\u00e2\u02c6\u2021\u011f\ufffd\u2018\u201csubscript\u00e2\u201e\ufffd\u00e2\u02c6\u2021\u011f\ufffd\u2018\u201ch_{ f, f}=h_{ f}italic_h start_POSTSUBSCRIPT \u00e2\u02c6\u2021 italic_f , \u00e2\u02c6\u2021 italic_f end_POSTSUBSCRIPT = italic_h start_POSTSUBSCRIPT \u00e2\u02c6\u2021 italic_f end_POSTSUBSCRIPT, so that H~\u00e2\u02c6\u2021f\u00e2\ufffd\u00a2(f)=H~\u00e2\ufffd\u00a2(f)superscript~\u011f\ufffd\ufffd\u00bb\u00e2\u02c6\u2021\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u201c~\u011f\ufffd\ufffd\u00bb\u011f\ufffd\u2018\u201c f}(f)= start_ARG italic_H end_ARG start_POSTSUPERSCRIPT \u00e2\u02c6\u2021 italic_f end_POSTSUPERSCRIPT ( italic_f ) = over~ start_ARG italic_H end_ARG ( italic_f ) for any function f\u011f\ufffd\u2018\u201cfitalic_f on M\u011f\ufffd\u2018\u20acMitalic_M. With the assistance of the S-curvature, one can present the definition of the weighted Ricci curvature as the following. ([27][34]). Given a unit vector V\u00e2\u02c6\u02c6Tx\u00e2\ufffd\u00a2M\u011f\ufffd\u2018\u2030subscript\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u20acV T_{x}Mitalic_V \u00e2\u02c6\u02c6 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M and an positive integral number k\u011f\ufffd\u2018\u02dckitalic_k, the weighted Ricci curvature is defined by where the derivative is taken along the geodesic started from x\u011f\ufffd\u2018\u00a5xitalic_x in the direction of V\u011f\ufffd\u2018\u2030Vitalic_V. According to the definition of weighted Ricci curvature, B. Wu defined the weighted flag curvature when k=N\u00e2\u02c6\u02c6(1,n)\u00e2\u02c6\u00aa(n,\u00e2\u02c6\ufffd)\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\ufffd1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u203ak=N = italic_N \u00e2\u02c6\u02c6 ( 1 , italic_n ) \u00e2\u02c6\u00aa ( italic_n , \u00e2\u02c6\ufffd ) in [39]. We have completely introduced this concept for any k\u011f\ufffd\u2018\u02dckitalic_k in [32]. ([32]). Let (M,F,d\u00e2\ufffd\u00a2\u00ce\u00bc)\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u2018\u011f\ufffd\u0153\u2021(M,F,d italic_M , italic_F , italic_d italic_\u00ce\u00bc ) be a Finsler metric measure space, and V,W\u00e2\u02c6\u02c6Tx\u00e2\ufffd\u00a2M\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u0160subscript\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u20acV,W T_{x}Mitalic_V , italic_W \u00e2\u02c6\u02c6 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M be linearly independent vectors. The weighted flag curvature Kk\u00e2\ufffd\u00a2(V,W)superscript\u011f\ufffd\ufffd\u00be\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u0160K^{k}(V,W)italic_K start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( italic_V , italic_W ) is defined by where the derivative is taken along the geodesic started from x\u011f\ufffd\u2018\u00a5xitalic_x in the direction of V\u011f\ufffd\u2018\u2030Vitalic_V. Moreover, it has also been defined the mixed weighted Ricci curvature in [32], denoted by Rm\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2cksuperscript\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2013superscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02dc{}^{m}Ric^{k}start_FLOATSUPERSCRIPT italic_m end_FLOATSUPERSCRIPT italic_R italic_i italic_c start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT. ([32])Given two unit vectors V,W\u00e2\u02c6\u02c6Tx\u00e2\ufffd\u00a2M\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u0160subscript\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u20acV,W T_{x}Mitalic_V , italic_W \u00e2\u02c6\u02c6 italic_T start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_M and an positive integral number k\u011f\ufffd\u2018\u02dckitalic_k, the mixed weighted Ricci curvature Rm\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2ck\u00e2\ufffd\u00a2(V,W)=mR\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2cWk\u00e2\ufffd\u00a2(V)superscript\u011f\ufffd\u2018\u0161superscript\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2013superscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u0160\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u2013subscriptsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u0160\u011f\ufffd\u2018\u2030{}^{m}Ric^{k}(V,W)=^{m}Ric^{k}_{W}(V)start_FLOATSUPERSCRIPT italic_m end_FLOATSUPERSCRIPT italic_R italic_i italic_c start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( italic_V , italic_W ) = start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_R italic_i italic_c start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_W end_POSTSUBSCRIPT ( italic_V )is defined by where the derivative is taken along the geodesic started from x\u011f\ufffd\u2018\u00a5xitalic_x in the direction of V\u011f\ufffd\u2018\u2030Vitalic_V, and t\u00e2\ufffd\u00a2rW\u00e2\ufffd\u00a2RV\u00e2\ufffd\u00a2(V)=gi\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(W)\u00e2\ufffd\u00a2gV\u00e2\ufffd\u00a2(RV\u00e2\ufffd\u00a2(ei,V)\u00e2\ufffd\u00a2V,ej)\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u0160subscript\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2030superscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u0160subscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u2030subscript\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u2030subscript\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2030subscript\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u2014tr_{W}R_{V}(V)=g^{ij}(W)g_{V}(R_{V}(e_{i},V)V,e_{j})italic_t italic_r start_POSTSUBSCRIPT italic_W end_POSTSUBSCRIPT italic_R start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT ( italic_V ) = italic_g start_POSTSUPERSCRIPT italic_i italic_j end_POSTSUPERSCRIPT ( italic_W ) italic_g start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT ( italic_R start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT ( italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_V ) italic_V , italic_e start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) means taking trace of the flag curvature with respect to g\u00e2\ufffd\u00a2(x,W)\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u0160g(x,W)italic_g ( italic_x , italic_W ). The weighted Ricci curvature is a special case of the mixed weighted Ricci curvature, i.e., R\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2ck\u00e2\ufffd\u00a2(V)=mR\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2cVk\u00e2\ufffd\u00a2(V)superscript\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u2013superscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u2013subscriptsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2030Ric^{k}(V)=^{m}Ric^{k}_{V}(V)italic_R italic_i italic_c start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( italic_V ) = start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_R italic_i italic_c start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_V end_POSTSUBSCRIPT ( italic_V ). Defining the function c\u00e2\ufffd\u00a2tc\u00e2\ufffd\u00a2(r)\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178ct_{c}(r)italic_c italic_t start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( italic_r ) as the following weighted Hessian comparison theorem is cited from Theorem 3.3 in [39]. ([32]). Let (M,F,d\u00e2\ufffd\u00a2\u00ce\u00bc)\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u2018\u011f\ufffd\u0153\u2021(M,F,d italic_M , italic_F , italic_d italic_\u00ce\u00bc ) be a forward complete n-dimensional Finsler metric measure space with finite misalignment \u00ce\u00b1\u011f\ufffd\u203a\u00bc Denote the forward distance function by r\u011f\ufffd\u2018\u0178ritalic_r and by V\u011f\ufffd\u2018\u2030Vitalic_V a fixed vector field on M\u011f\ufffd\u2018\u20acMitalic_M. Suppose the mixed weighted Ricci curvature R\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2cN\u00e2\ufffd\u00a2(V,\u00e2\u02c6\u2021r)\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u2013superscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2030normal-\u00e2\u02c6\u2021\u011f\ufffd\u2018\u0178Ric^{N}(V, r)italic_R italic_i italic_c start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT ( italic_V , \u00e2\u02c6\u2021 italic_r ) of M\u011f\ufffd\u2018\u20acMitalic_M is bounded from below by \u00e2\u02c6\u2019K\u011f\ufffd\ufffd\u00be-K- italic_K with K>0\u011f\ufffd\ufffd\u00be0K>0italic_K > 0, for some N>n\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203aN>nitalic_N > italic_n, as well as the non-Riemannian curvatures U\u011f\ufffd\u2018\u02c6Uitalic_U, \u011f\ufffd\u2019\u00af\u011f\ufffd\u2019\u00af and d\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2v\u00e2\ufffd\u00a2C\u00e2\ufffd\u00a2(V)=Ck|ii\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(V)\u00e2\ufffd\u00a2Vk\u00e2\ufffd\u00a2\u00ce\u00b4\u00ce\u00b4\u00e2\ufffd\u00a2xj\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a3\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\u2030subscriptsuperscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014conditional\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2030superscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u02dc\u011f\ufffd\u203a\u00bf\u011f\ufffd\u203a\u00bfsuperscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2014divC(V)=C^{ij}_{k|i}(V)V^{k} x^{j}}italic_d italic_i italic_v italic_C ( italic_V ) = italic_C start_POSTSUPERSCRIPT italic_i italic_j end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k | italic_i end_POSTSUBSCRIPT ( italic_V ) italic_V start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT divide start_ARG italic_\u00ce\u00b4 end_ARG start_ARG italic_\u00ce\u00b4 italic_x start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT end_ARG satisfy the norm bounds by F\u00e2\ufffd\u00a2(U)+F\u00e2\ufffd\u00a2(\u011f\ufffd\u2019\u00af)+F*\u00e2\ufffd\u00a2(d\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2v\u00e2\ufffd\u00a2C\u00e2\ufffd\u00a2(V))\u00e2\u2030\u00a4K0\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2019\u00afsuperscript\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a3\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\u2030subscript\u011f\ufffd\ufffd\u00be0F(U)+F( K_{0}italic_F ( italic_U ) + italic_F ( caligraphic_T ) + italic_F start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT ( italic_d italic_i italic_v italic_C ( italic_V ) ) \u00e2\u2030\u00a4 italic_K start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. Then, by setting l=K/C\u00e2\ufffd\u00a2(N,\u00ce\u00b1)\u011f\ufffd\u2018\u2122\u011f\ufffd\ufffd\u00be\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffd\u011f\ufffd\u203a\u00bcl=K/C(N, = italic_K / italic_C ( italic_N , italic_\u00ce\u00b1 ) with C\u00e2\ufffd\u00a2(N,\u00ce\u00b1)=N+(\u00ce\u00b1\u00e2\u02c6\u20191)\u00e2\ufffd\u00a2n\u00e2\u02c6\u2019\u00ce\u00b1\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffd\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\ufffd\u011f\ufffd\u203a\u00bc1\u011f\ufffd\u2018\u203a\u011f\ufffd\u203a\u00bcC(N, ( italic_N , italic_\u00ce\u00b1 ) = italic_N + ( italic_\u00ce\u00b1 - 1 ) italic_n - italic_\u00ce\u00b1, wherever r\u011f\ufffd\u2018\u0178ritalic_r is C2superscript\u011f\ufffd\ufffd\u00b62C^{2}italic_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, the nonlinear Laplacian of r\u011f\ufffd\u2018\u0178ritalic_r with reference vector V\u011f\ufffd\u2018\u2030Vitalic_V satisfies . In this section, we will focus on the global gradient estimates of positive solutions to the Fisher-KPP equation (1.1) on compact Finsler manifolds, with the weighted Ricci curvature bounded from below. This condition of curvature is extensively employed within the realm of Finsler geometric analysis. Suppose that u\u011f\ufffd\u2018\u00a2uitalic_u is a positive solution on M\u00c3\u2014[0,\u00e2\u02c6\ufffd)\u011f\ufffd\u2018\u20ac0M \u00c3\u2014 [ 0 , \u00e2\u02c6\ufffd ) to the Fisher-KPP equation(1.1) . We define the function W\u00e2\ufffd\u00a2(x,t)=u\u00e2\u02c6\u2019q\u011f\ufffd\u2018\u0160\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a1superscript\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\ufffdW(x,t)=u^{-q}italic_W ( italic_x , italic_t ) = italic_u start_POSTSUPERSCRIPT - italic_q end_POSTSUPERSCRIPT, where q\u011f\ufffd\u2018\ufffdqitalic_q is a positive constant to be fixed later. We now have the following lemma. Let u\u011f\ufffd\u2018\u00a2uitalic_u be a positive solution on M\u00c3\u2014[0,\u00e2\u02c6\ufffd)\u011f\ufffd\u2018\u20ac0M \u00c3\u2014 [ 0 , \u00e2\u02c6\ufffd ) to the Fisher-KPP equation (1.1) and W\u00e2\ufffd\u00a2(x,t)=u\u00e2\u02c6\u2019q\u011f\ufffd\u2018\u0160\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a1superscript\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\ufffdW(x,t)=u^{-q}italic_W ( italic_x , italic_t ) = italic_u start_POSTSUPERSCRIPT - italic_q end_POSTSUPERSCRIPT, then W\u011f\ufffd\u2018\u0160Witalic_W satisfies that The gradient of W\u011f\ufffd\u2018\u0160Witalic_W with respect to \u00e2\u02c6\u2021u\u00e2\u02c6\u2021\u011f\ufffd\u2018\u00a2 u\u00e2\u02c6\u2021 italic_u is the dual of dW\u011f\ufffd\u2018\u0160Witalic_W by the pull-back metric g\u00e2\u02c6\u2021usubscript\u011f\ufffd\u2018\u201d\u00e2\u02c6\u2021\u011f\ufffd\u2018\u00a2g_{ u}italic_g start_POSTSUBSCRIPT \u00e2\u02c6\u2021 italic_u end_POSTSUBSCRIPT. Precisely, \u00e2\u02c6\u2021W=\u00e2\u02c6\u2019q\u00e2\ufffd\u00a2u\u00e2\u02c6\u2019q\u00e2\u02c6\u20191\u00e2\ufffd\u00a2\u00e2\u02c6\u2021u\u00e2\u02c6\u2021\u011f\ufffd\u2018\u0160\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\ufffd1\u00e2\u02c6\u2021\u011f\ufffd\u2018\u00a2 W=-qu^{-q-1} u\u00e2\u02c6\u2021 italic_W = - italic_q italic_u start_POSTSUPERSCRIPT - italic_q - 1 end_POSTSUPERSCRIPT \u00e2\u02c6\u2021 italic_u on M\u011f\ufffd\u2018\u20acMitalic_M and Wt=\u00e2\u02c6\u2019q\u00e2\ufffd\u00a2u\u00e2\u02c6\u2019q\u00e2\u02c6\u20191\u00e2\ufffd\u00a2utsubscript\u011f\ufffd\u2018\u0160\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a1W_{t}=-qu^{-q-1}u_{t}italic_W start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = - italic_q italic_u start_POSTSUPERSCRIPT - italic_q - 1 end_POSTSUPERSCRIPT italic_u start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, so we have Then we deduce that in the distributional sense on Musubscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u00a2M_{u}italic_M start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT, wherever \u00e2\u02c6\u2021u\u00e2\u2030 0\u00e2\u02c6\u2021\u011f\ufffd\u2018\u00a20 u 0\u00e2\u02c6\u2021 italic_u \u00e2\u2030 0 Combine with (1.1) and (3.2), we have After the transformation, we obtain the Lemma 3.1. \u00e2\u02c6\ufffd Now, we follow the line in [19]. Define three functions as the follow. where a\u011f\ufffd\u2018\ufffdaitalic_a, \u00ce\u00b2\u011f\ufffd\u203a\u00bd are two positive constants to be determined later. Direct calculations provide that and on Musubscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u00a2M_{u}italic_M start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT, where we have employed the Ricci-type identity in [33]. On the other hand, it satisfies that and Plugging (3.10) and (3.11) into (3.9) yields wherever \u00e2\u02c6\u2021u\u00e2\u2030 0\u00e2\u02c6\u2021\u011f\ufffd\u2018\u00a20 u 0\u00e2\u02c6\u2021 italic_u \u00e2\u2030 0. By a basic computation of Finsler geometry, we could get where we have already employed the fact that C\u00e2\ufffd\u00a2(\u00e2\u02c6\u2021u,\u00e2\u2039\u2026,\u00e2\u2039\u2026)=0\u011f\ufffd\ufffd\u00b6\u00e2\u02c6\u2021\u011f\ufffd\u2018\u00a2\u00e2\u2039\u2026\u00e2\u2039\u20260C( u, ( \u00e2\u02c6\u2021 italic_u , \u00e2\u2039\u2026 , \u00e2\u2039\u2026 ) = 0 and C\u00e2\u02c6\u20212u\u00e2\u02c6\u2021u\u00e2\ufffd\u00a2(\u00e2\u02c6\u2021\u00e2\u02c6\u2021uH0)=u|ik\u00e2\ufffd\u00a2Cki\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(\u00e2\u02c6\u2021u)\u00e2\ufffd\u00a2HjC_{ u}( u}H_{0})=u_{|i}^{k}C_{k}^{ij}( u% )H_{j}italic_C start_POSTSUBSCRIPT \u00e2\u02c6\u2021 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\u2021 italic_u end_POSTSUPERSCRIPT ( \u00e2\u02c6\u2021 start_POSTSUPERSCRIPT \u00e2\u02c6\u2021 italic_u end_POSTSUPERSCRIPT italic_H start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) = italic_u start_POSTSUBSCRIPT | italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT italic_C start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i italic_j end_POSTSUPERSCRIPT ( \u00e2\u02c6\u2021 italic_u ) italic_H start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT. The notation \u00e2\u20ac\u0153||||\u00e2\u20ac\ufffd denotes the horizontal derivative with respect to the Chern connection in the direction \u00e2\u02c6\u2021u\u00e2\u02c6\u2021\u011f\ufffd\u2018\u00a2 u\u00e2\u02c6\u2021 italic_u. It follows from that (3.13) is equal to Combining it with (3.12), we could find that by noticing that Therefore, H0\u00e2\ufffd\u00a2(x,t)subscript\u011f\ufffd\ufffd\u00bb0\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a1H_{0}(x,t)italic_H start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_x , italic_t ) satisfies that Because of \u00e2\u02c6\u2021Wt=(\u00e2\u02c6\u2021W)t\u00e2\u02c6\u2021subscript\u011f\ufffd\u2018\u0160\u011f\ufffd\u2018\u00a1subscript\u00e2\u02c6\u2021\u011f\ufffd\u2018\u0160\u011f\ufffd\u2018\u00a1 W_{t}=( W)_{t}\u00e2\u02c6\u2021 italic_W start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = ( \u00e2\u02c6\u2021 italic_W ) start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, it follows for \u00e2\u02c6\u2021\u00e2\u02c6\u2021uH1superscript\u00e2\u02c6\u2021\u00e2\u02c6\u2021\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\ufffd\u00bb1 u}H_{1}\u00e2\u02c6\u2021 start_POSTSUPERSCRIPT \u00e2\u02c6\u2021 italic_u end_POSTSUPERSCRIPT italic_H start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT that It asserts by direct caiculation that arccording to [32]. Thus, for H1subscript\u011f\ufffd\ufffd\u00bb1H_{1}italic_H start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, one may find that so that Moreover, one could calculate that as well as Plugging (3.22)-(3.24) into (3.16) and (3.17) yields It asserts from the h\u00c3\u00b6lder inequality that Thus, when 0<\u00ce\u00b5<10\u011f\ufffd\u0153\u20ac10< < italic_\u00ce\u00b5 < 1, it satisfies that According to the equality (a+b)2n=a2N\u00e2\u02c6\u2019b2N\u00e2\u02c6\u2019n+N\u00e2\ufffd\u00a2(N\u00e2\u02c6\u2019n)n\u00e2\ufffd\u00a2(aN+bN\u00e2\u02c6\u2019b)2superscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\u203asuperscript\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u203asuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd2 }{N}+ start_ARG ( italic_a + italic_b ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG italic_n end_ARG = divide start_ARG italic_a start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG italic_N end_ARG - divide start_ARG italic_b start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG italic_N - italic_n end_ARG + divide start_ARG italic_N ( italic_N - italic_n ) end_ARG start_ARG italic_n end_ARG ( divide start_ARG italic_a end_ARG start_ARG italic_N end_ARG + divide start_ARG italic_b end_ARG start_ARG italic_N - italic_b end_ARG ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, for any N>n\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203aN>nitalic_N > italic_n, the following inequality holds by substituting a\u011f\ufffd\u2018\ufffdaitalic_a, b\u011f\ufffd\u2018\ufffdbitalic_b and N\u011f\ufffd\u2018\ufffdNitalic_N by \u00ce\u201d\u00e2\u02c6\u2021u\u00e2\ufffd\u00a2Wsuperscript\u00ce\u201d\u00e2\u02c6\u2021\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u0160 u}Wroman_\u00ce\u201d start_POSTSUPERSCRIPT \u00e2\u02c6\u2021 italic_u end_POSTSUPERSCRIPT italic_W, S\u00cb\u2122\u00e2\ufffd\u00a2(\u00e2\u02c6\u2021\u00e2\u02c6\u2021uW)\u00cb\u2122\u011f\ufffd\u2018\u2020superscript\u00e2\u02c6\u2021\u00e2\u02c6\u2021\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u0160 u}W)over\u00cb\u2122 start_ARG italic_S end_ARG ( \u00e2\u02c6\u2021 start_POSTSUPERSCRIPT \u00e2\u02c6\u2021 italic_u end_POSTSUPERSCRIPT italic_W ) and N\u00e2\u02c6\u2019\u00ce\u00b5\u00e2\ufffd\u00a2(N\u00e2\u02c6\u2019n)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203aN- - italic_\u00ce\u00b5 ( italic_N - italic_n ), respectively. Namely, so that Moreover, it\u00e2\u20ac\u2122s easy to infer that It is deduced from (3.25) by combining (3.27)-(3.30) and employing the definition of weighted Ricci curvature that on Musubscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u00a2M_{u}italic_M start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT. Let \u00ce\u00b2=aq\u011f\ufffd\u203a\u00bd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd = divide start_ARG italic_a end_ARG start_ARG italic_q end_ARG, combining with (3.21), we have Noticing \u00ce\u201d\u00e2\u02c6\u2021u\u00e2\ufffd\u00a2WW=qa\u00e2\ufffd\u00a2H+(q+1q\u00e2\u02c6\u2019qa)\u00e2\ufffd\u00a2F\u00e2\u02c6\u2021u2\u00e2\ufffd\u00a2(\u00e2\u02c6\u2021\u00e2\u02c6\u2021uW)W2superscript\u00ce\u201d\u00e2\u02c6\u2021\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u0160\u011f\ufffd\u2018\u0160\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00bb\u011f\ufffd\u2018\ufffd1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsubscriptsuperscript\u011f\ufffd\ufffd\u00b92\u00e2\u02c6\u2021\u011f\ufffd\u2018\u00a2superscript\u00e2\u02c6\u2021\u00e2\u02c6\u2021\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u0160superscript\u011f\ufffd\u2018\u01602 u}W}{W}= ^{2}_{ u}( u}W)}{W^{2}}divide start_ARG roman_\u00ce\u201d start_POSTSUPERSCRIPT \u00e2\u02c6\u2021 italic_u end_POSTSUPERSCRIPT italic_W end_ARG start_ARG italic_W end_ARG = divide start_ARG italic_q end_ARG start_ARG italic_a end_ARG italic_H + ( divide start_ARG italic_q + 1 end_ARG start_ARG italic_q end_ARG - divide start_ARG italic_q end_ARG start_ARG italic_a end_ARG ) divide start_ARG italic_F start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT \u00e2\u02c6\u2021 italic_u end_POSTSUBSCRIPT ( \u00e2\u02c6\u2021 start_POSTSUPERSCRIPT \u00e2\u02c6\u2021 italic_u end_POSTSUPERSCRIPT italic_W ) end_ARG start_ARG italic_W start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG, and setting a=s\u00e2\ufffd\u00a2q2\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018 superscript\u011f\ufffd\u2018\ufffd2a=sq^{2}italic_a = italic_s italic_q start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, we get that Plugging it into (3.32), we arrive at the following lemma. Let (M,F,\u00ce\u00bc)\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u0153\u2021(M,F, italic_M , italic_F , italic_\u00ce\u00bc ) be a forward complete Finsler metric measure space, and denote Mu={x\u00e2\u02c6\u02c6M\u00e2\u02c6\u00a3\u00e2\u02c6\u2021u\u00e2\ufffd\u00a2(x)\u00e2\u2030 0}subscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u00a2conditional-set\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u20acnormal-\u00e2\u02c6\u2021\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a50M_{u}= M u(x) 0 start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT = { italic_x \u00e2\u02c6\u02c6 italic_M \u00e2\u02c6\u00a3 \u00e2\u02c6\u2021 italic_u ( italic_x ) \u00e2\u2030 0 }. For H=F\u00e2\u02c6\u2021u2\u00e2\ufffd\u00a2(\u00e2\u02c6\u2021\u00e2\u02c6\u2021uW)W2+a\u00e2\ufffd\u00a2c\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019W\u00e2\u02c6\u20191q)+\u00ce\u00b2\u00e2\ufffd\u00a2WtW\u011f\ufffd\ufffd\u00bbsubscriptsuperscript\u011f\ufffd\ufffd\u00b92normal-\u00e2\u02c6\u2021\u011f\ufffd\u2018\u00a2superscriptnormal-\u00e2\u02c6\u2021normal-\u00e2\u02c6\u2021\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u0160superscript\u011f\ufffd\u2018\u01602\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd1superscript\u011f\ufffd\u2018\u01601\u011f\ufffd\u2018\ufffd\u011f\ufffd\u203a\u00bdsubscript\u011f\ufffd\u2018\u0160\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u0160H= u}( u}W)}{W^{2}}+ac(1-W^{- = divide start_ARG italic_F start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT \u00e2\u02c6\u2021 italic_u end_POSTSUBSCRIPT ( \u00e2\u02c6\u2021 start_POSTSUPERSCRIPT \u00e2\u02c6\u2021 italic_u end_POSTSUPERSCRIPT italic_W ) end_ARG start_ARG italic_W start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG + italic_a italic_c ( 1 - italic_W start_POSTSUPERSCRIPT - divide start_ARG 1 end_ARG start_ARG italic_q end_ARG end_POSTSUPERSCRIPT ) + italic_\u00ce\u00b2 divide start_ARG italic_W start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG start_ARG italic_W end_ARG with a=s\u00e2\ufffd\u00a2q2\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018 superscript\u011f\ufffd\u2018\ufffd2a=sq^{2}italic_a = italic_s italic_q start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, \u00ce\u00b2=aq\u011f\ufffd\u203a\u00bd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd = divide start_ARG italic_a end_ARG start_ARG italic_q end_ARG, it satisfies on Musubscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u00a2M_{u}italic_M start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT that Employing Lemma 3.2, the following global gradient estimate theorem could be obtained by utilizing the maximum principle argument, which was first adopted in [27] and was applied also in [32][31]. Let (M,F,\u00ce\u00bc)\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u0153\u2021(M,F, italic_M , italic_F , italic_\u00ce\u00bc ) be a compact Finsler metric measure manifold whose weighted Ricci curvature satisfies R\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2cN\u00e2\u2030\u00a5\u00e2\u02c6\u2019K\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u2013superscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00beRic^{N} italic_i italic_c start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \u00e2\u2030\u00a5 - italic_K, for some positive constant K\u011f\ufffd\ufffd\u00beKitalic_K. Assume the bound of the reversibility on M\u011f\ufffd\u2018\u20acMitalic_M is \u00cf\ufffd0subscript\u011f\ufffd\u0153\u01520 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. Suppose u\u00e2\ufffd\u00a2(x,t)\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a1u(x,t)italic_u ( italic_x , italic_t ) is a bounded positive smooth solution of the Fisher-KPP parabolic equation (1.1) on M\u00c3\u2014[0,\u00e2\u02c6\ufffd)\u011f\ufffd\u2018\u20ac0M \u00c3\u2014 [ 0 , \u00e2\u02c6\ufffd ), then we have where, 0<\u00ce\u00b5<10\u011f\ufffd\u0153\u20ac10< < italic_\u00ce\u00b5 < 1, s>1\u011f\ufffd\u2018 1s>1italic_s > 1, q>0\u011f\ufffd\u2018\ufffd0q>0italic_q > 0, such that 2\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019\u00ce\u00b5)N\u00e2\u02c6\u2019\u00ce\u00b5\u00e2\ufffd\u00a2(N\u00e2\u02c6\u2019n)\u00e2\ufffd\u00a2s\u00e2\u02c6\u20191s\u00e2\ufffd\u00a2q\u00e2\u2030\u00a51\u00ce\u00b5\u00e2\u02c6\u20191+(2\u00e2\ufffd\u00a2s\u00e2\u02c6\u20191)2821\u011f\ufffd\u0153\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018 1\u011f\ufffd\u2018 \u011f\ufffd\u2018\ufffd1\u011f\ufffd\u0153\u20ac1superscript2\u011f\ufffd\u2018 128 start_ARG 2 ( 1 - italic_\u00ce\u00b5 ) end_ARG start_ARG italic_N - italic_\u00ce\u00b5 ( italic_N - italic_n ) end_ARG divide start_ARG italic_s - 1 end_ARG start_ARG italic_s italic_q end_ARG \u00e2\u2030\u00a5 divide start_ARG 1 end_ARG start_ARG italic_\u00ce\u00b5 end_ARG - 1 + divide start_ARG ( 2 italic_s - 1 ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG 8 end_ARG, and M1=supu\u00e2\ufffd\u00a2(x,t)subscript\u011f\ufffd\u2018\u20ac1supremum\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a1M_{1}= u(x,t)italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = roman_sup italic_u ( italic_x , italic_t ). Lemma 3.34 implies that (3.34) holds in the distributional sense on M\u011f\ufffd\u2018\u20acMitalic_M. For any nonnegative test function \u00cf\u2020\u011f\ufffd\u0153\u2018 we have where \u00ce\u00b2\u011f\ufffd\u203a\u00bd denotes the RHS of (3.34). Assume y0=(x0,t0)\u00e2\u02c6\u02c6B\u00e2\ufffd\u00a2(p,2\u00e2\ufffd\u00a2R)\u00c3\u2014[0,\u00e2\u02c6\ufffd)subscript\u011f\ufffd\u2018\u00a60subscript\u011f\ufffd\u2018\u00a50subscript\u011f\ufffd\u2018\u00a10\u011f\ufffd\ufffd\u00b5\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\u20260y_{0}=(x_{0},t_{0}) B(p,2R) start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = ( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) \u00e2\u02c6\u02c6 italic_B ( italic_p , 2 italic_R ) \u00c3\u2014 [ 0 , \u00e2\u02c6\ufffd ) be the point where H\u011f\ufffd\ufffd\u00bbHitalic_H achieves its maximum. Without loss of generality, we could assume H\u00e2\ufffd\u00a2(x0,t0)\u00e2\u2030\u00a50\u011f\ufffd\ufffd\u00bbsubscript\u011f\ufffd\u2018\u00a50subscript\u011f\ufffd\u2018\u00a100H(x_{0},t_{0}) 0italic_H ( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) \u00e2\u2030\u00a5 0, otherwise the result will be satisfied trivially. We claim that \u00ce\u00b2\u00e2\ufffd\u00a2(x0,t0)\u00e2\u2030\u00a40\u011f\ufffd\u203a\u00bdsubscript\u011f\ufffd\u2018\u00a50subscript\u011f\ufffd\u2018\u00a100 0italic_\u00ce\u00b2 ( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) \u00e2\u2030\u00a4 0. Otherwise, \u00ce\u00b2\u011f\ufffd\u203a\u00bd is strictly positive at (x0,t0)subscript\u011f\ufffd\u2018\u00a50subscript\u011f\ufffd\u2018\u00a10(x_{0},t_{0})( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ), so that \u00ce\u00b2\u00e2\ufffd\u00a2(x0,t0)\u011f\ufffd\u203a\u00bdsubscript\u011f\ufffd\u2018\u00a50subscript\u011f\ufffd\u2018\u00a10 ( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) is positive in a small neighborhood of (x0,t0)subscript\u011f\ufffd\u2018\u00a50subscript\u011f\ufffd\u2018\u00a10(x_{0},t_{0})( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) on M\u011f\ufffd\u2018\u20acMitalic_M, which may be denoted by U\u011f\ufffd\u2018\u02c6Uitalic_U. Chosen a test function \u00cf\u2020\u011f\ufffd\u0153\u2018 whose compact support V\u011f\ufffd\u2018\u2030Vitalic_V is contained in U\u011f\ufffd\u2018\u02c6Uitalic_U, we know from (3.36) that H\u011f\ufffd\ufffd\u00bbHitalic_H is a weak, local subharmonic function in a neighborhood V\u00e2\u0160\u201aU\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u02c6V Uitalic_V \u00e2\u0160\u201a italic_U. It is a contradiction because (x0,t0)subscript\u011f\ufffd\u2018\u00a50subscript\u011f\ufffd\u2018\u00a10(x_{0},t_{0})( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) is a inner point of V\u011f\ufffd\u2018\u2030Vitalic_V. Because of \u00ce\u00b2\u00e2\ufffd\u00a2(x0,t0)\u00e2\u2030\u00a40\u011f\ufffd\u203a\u00bdsubscript\u011f\ufffd\u2018\u00a50subscript\u011f\ufffd\u2018\u00a100 0italic_\u00ce\u00b2 ( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) \u00e2\u2030\u00a4 0 and \u00e2\u02c6\u2021\u00e2\u02c6\u2021uH\u00e2\ufffd\u00a2(y0)=0superscript\u00e2\u02c6\u2021\u00e2\u02c6\u2021\u011f\ufffd\u2018\u00a2\u011f\ufffd\ufffd\u00bbsubscript\u011f\ufffd\u2018\u00a600 u}H(y_{0})=0\u00e2\u02c6\u2021 start_POSTSUPERSCRIPT \u00e2\u02c6\u2021 italic_u end_POSTSUPERSCRIPT italic_H ( italic_y start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) = 0, we arrive at It follows from the h\u00c3\u00b6lder inequality that and where M1=supu\u00e2\ufffd\u00a2(x)subscript\u011f\ufffd\u2018\u20ac1supremum\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a5M_{1}= u(x)italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = roman_sup italic_u ( italic_x ). Now, let q>0\u011f\ufffd\u2018\ufffd0q>0italic_q > 0 such that 2\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019\u00ce\u00b5)N\u00e2\u02c6\u2019\u00ce\u00b5\u00e2\ufffd\u00a2(N\u00e2\u02c6\u2019n)\u00e2\ufffd\u00a2s\u00e2\u02c6\u20191s\u00e2\ufffd\u00a2q\u00e2\u2030\u00a51\u00ce\u00b5\u00e2\u02c6\u20191+(2\u00e2\ufffd\u00a2s\u00e2\u02c6\u20191)2821\u011f\ufffd\u0153\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018 1\u011f\ufffd\u2018 \u011f\ufffd\u2018\ufffd1\u011f\ufffd\u0153\u20ac1superscript2\u011f\ufffd\u2018 128 start_ARG 2 ( 1 - italic_\u00ce\u00b5 ) end_ARG start_ARG italic_N - italic_\u00ce\u00b5 ( italic_N - italic_n ) end_ARG divide start_ARG italic_s - 1 end_ARG start_ARG italic_s italic_q end_ARG \u00e2\u2030\u00a5 divide start_ARG 1 end_ARG start_ARG italic_\u00ce\u00b5 end_ARG - 1 + divide start_ARG ( 2 italic_s - 1 ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG 8 end_ARG. Combining with (3.37), we get Hence we achieve the global gradient estimates on compact Finsler manifolds. \u00e2\u02c6\ufffd Theorem 1.1 follows by taking \u00ce\u00b5=12\u011f\ufffd\u0153\u20ac12 = divide start_ARG 1 end_ARG start_ARG 2 end_ARG , s=2\u011f\ufffd\u2018 2s=2italic_s = 2, q=227\u00e2\ufffd\u00a2(N+n)\u011f\ufffd\u2018\ufffd227\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203aq= = divide start_ARG 2 end_ARG start_ARG 27 ( italic_N + italic_n ) end_ARG in Theorem 3.1 . In this section, we prove the local gradient estimates on forward complete Finsler metric measure spaces with the assistance of Lemma 3.34 and the Comparison theorem (cf. Theorem 2.1). Let (M,F,\u00ce\u00bc)\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u0153\u2021(M,F, italic_M , italic_F , italic_\u00ce\u00bc ) be a complete noncompact Finsler metric measure space. Denote by B\u00e2\ufffd\u00a2(p,2\u00e2\ufffd\u00a2R)\u011f\ufffd\ufffd\u00b5\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\u2026B(p,2R)italic_B ( italic_p , 2 italic_R ) the forward geodesic ball centered at p\u011f\ufffd\u2018\ufffdpitalic_p with forward radius 2\u00e2\ufffd\u00a2R2\u011f\ufffd\u2018\u20262R2 italic_R. Suppose the mixed weighted Ricci curvature Rm\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2cN\u00e2\u2030\u00a5\u00e2\u02c6\u2019K\u00e2\ufffd\u00a2(2\u00e2\ufffd\u00a2R)superscript\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2013superscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00be2\u011f\ufffd\u2018\u2026{}^{m}Ric^{N} italic_m end_FLOATSUPERSCRIPT italic_R italic_i italic_c start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT \u00e2\u2030\u00a5 - italic_K ( 2 italic_R ) in B\u00e2\ufffd\u00a2(p,2\u00e2\ufffd\u00a2R)\u011f\ufffd\ufffd\u00b5\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\u2026B(p,2R)italic_B ( italic_p , 2 italic_R ) with K\u00e2\ufffd\u00a2(2\u00e2\ufffd\u00a2R)\u00e2\u2030\u00a50\u011f\ufffd\ufffd\u00be2\u011f\ufffd\u2018\u20260K(2R) 0italic_K ( 2 italic_R ) \u00e2\u2030\u00a5 0, and the misalignment \u00ce\u00b1\u011f\ufffd\u203a\u00bc satisfies \u00ce\u00b1\u00e2\u2030\u00a4A\u00e2\ufffd\u00a2(2\u00e2\ufffd\u00a2R)\u011f\ufffd\u203a\u00bc\u011f\ufffd\ufffd\u00b42\u011f\ufffd\u2018\u2026 A(2R)italic_\u00ce\u00b1 \u00e2\u2030\u00a4 italic_A ( 2 italic_R ) in B\u00e2\ufffd\u00a2(p,2\u00e2\ufffd\u00a2R)\u011f\ufffd\ufffd\u00b5\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\u2026B(p,2R)italic_B ( italic_p , 2 italic_R ). Moreover, the non-Riemannian tensors satisfy F\u00e2\ufffd\u00a2(U)+F*\u00e2\ufffd\u00a2(\u011f\ufffd\u2019\u00af)+F\u00e2\ufffd\u00a2(d\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2v\u00e2\ufffd\u00a2C\u00e2\ufffd\u00a2(V))\u00e2\u2030\u00a4K0\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u02c6superscript\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2019\u00af\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a3\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\u2030subscript\u011f\ufffd\ufffd\u00be0F(U)+F^{*}( K_{0}italic_F ( italic_U ) + italic_F start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT ( caligraphic_T ) + italic_F ( italic_d italic_i italic_v italic_C ( italic_V ) ) \u00e2\u2030\u00a4 italic_K start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. Assume u\u00e2\ufffd\u00a2(x,t)\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a1u(x,t)italic_u ( italic_x , italic_t ) is a bounded positive smooth solution of the Fisher-KPP parabolic equation (1.1) on M\u00c3\u2014[0,\u00e2\u02c6\ufffd)\u011f\ufffd\u2018\u20ac0M \u00c3\u2014 [ 0 , \u00e2\u02c6\ufffd ), then we have on B\u00e2\ufffd\u00a2(p,R)\u011f\ufffd\ufffd\u00b5\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2026B(p,R)italic_B ( italic_p , italic_R ) for 0<\u00ce\u00b5<10\u011f\ufffd\u0153\u20ac10< < italic_\u00ce\u00b5 < 1, s>1\u011f\ufffd\u2018 1s>1italic_s > 1, q>0\u011f\ufffd\u2018\ufffd0q>0italic_q > 0, such that 2\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019\u00ce\u00b5)N\u00e2\u02c6\u2019\u00ce\u00b5\u00e2\ufffd\u00a2(N\u00e2\u02c6\u2019n)\u00e2\ufffd\u00a2s\u00e2\u02c6\u20191s\u00e2\ufffd\u00a2q\u00e2\u2030\u00a51\u00ce\u00b5\u00e2\u02c6\u20191+(2\u00e2\ufffd\u00a2s\u00e2\u02c6\u20191)2821\u011f\ufffd\u0153\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018 1\u011f\ufffd\u2018 \u011f\ufffd\u2018\ufffd1\u011f\ufffd\u0153\u20ac1superscript2\u011f\ufffd\u2018 128 start_ARG 2 ( 1 - italic_\u00ce\u00b5 ) end_ARG start_ARG italic_N - italic_\u00ce\u00b5 ( italic_N - italic_n ) end_ARG divide start_ARG italic_s - 1 end_ARG start_ARG italic_s italic_q end_ARG \u00e2\u2030\u00a5 divide start_ARG 1 end_ARG start_ARG italic_\u00ce\u00b5 end_ARG - 1 + divide start_ARG ( 2 italic_s - 1 ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG 8 end_ARG, where C1subscript\u011f\ufffd\ufffd\u00b61C_{1}italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, C2subscript\u011f\ufffd\ufffd\u00b62C_{2}italic_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT are positive constants. In noncompact situation, we choose the cut-off function \u00cf\u2020~\u00e2\u02c6\u02c6C2\u00e2\ufffd\u00a2[0,+\u00e2\u02c6\ufffd)~\u011f\ufffd\u0153\u2018superscript\u011f\ufffd\ufffd\u00b620 C^{2}[0,+ start_ARG italic_\u00cf\u2020 end_ARG \u00e2\u02c6\u02c6 italic_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT [ 0 , + \u00e2\u02c6\ufffd ), such that So \u00cf\u2020~\u00e2\ufffd\u00a2(r)\u00e2\u02c6\u02c6[0,1]~\u011f\ufffd\u0153\u2018\u011f\ufffd\u2018\u017801 start_ARG italic_\u00cf\u2020 end_ARG ( italic_r ) \u00e2\u02c6\u02c6 [ 0 , 1 ]. In addition, we supposed that where C1,C2subscript\u011f\ufffd\ufffd\u00b61subscript\u011f\ufffd\ufffd\u00b62C_{1},C_{2}italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT are positive constants. For a fixed point p\u011f\ufffd\u2018\ufffdpitalic_p, denote by r\u00e2\ufffd\u00a2(x)\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u00a5r(x)italic_r ( italic_x ) the forward distance function from p\u011f\ufffd\u2018\ufffdpitalic_p to any point x\u011f\ufffd\u2018\u00a5xitalic_x. We define the cut-off function by \u00cf\u2020\u00e2\ufffd\u00a2(x)=\u00cf\u2020~\u00e2\ufffd\u00a2(r\u00e2\ufffd\u00a2(x)R)\u011f\ufffd\u0153\u2018\u011f\ufffd\u2018\u00a5~\u011f\ufffd\u0153\u2018\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2026 ( italic_x ) = over~ start_ARG italic_\u00cf\u2020 end_ARG ( divide start_ARG italic_r ( italic_x ) end_ARG start_ARG italic_R end_ARG ). So that According to the curvature conditions and the Laplacian comparison theorem on forward complete Finsler manifolds, it satisfies the Laplacian estimation [32] that where C3=C3\u00e2\ufffd\u00a2(N,A,K0)subscript\u011f\ufffd\ufffd\u00b63subscript\u011f\ufffd\ufffd\u00b63\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\ufffd\u00be0C_{3}=C_{3}(N,A,K_{0})italic_C start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = italic_C start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_N , italic_A , italic_K start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) is a constant depending on K0subscript\u011f\ufffd\ufffd\u00be0K_{0}italic_K start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, N\u011f\ufffd\u2018\ufffdNitalic_N and A\u011f\ufffd\ufffd\u00b4Aitalic_A. Defining Z=t\u00e2\ufffd\u00a2H\u00e2\ufffd\u00a2(x,t)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u011f\ufffd\ufffd\u00bb\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a1Z=tH(x,t)italic_Z = italic_t italic_H ( italic_x , italic_t ), we suppose that the support of function \u00cf\u2020\u00e2\ufffd\u00a2(x)\u00e2\ufffd\u00a2Z\u00e2\ufffd\u00a2(x,t)\u011f\ufffd\u0153\u2018\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a1 ( italic_x ) italic_Z ( italic_x , italic_t ) is contained in Bp\u00e2\ufffd\u00a2(2\u00e2\ufffd\u00a2R)subscript\u011f\ufffd\ufffd\u00b5\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\u2026B_{p}(2R)italic_B start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( 2 italic_R ). For any fixed T>0\u011f\ufffd\u2018\u20210T>0italic_T > 0, let (x0,t0)subscript\u011f\ufffd\u2018\u00a50subscript\u011f\ufffd\u2018\u00a10(x_{0},t_{0})( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) be the point where \u00cf\u2020\u00e2\ufffd\u00a2(x)\u00e2\ufffd\u00a2Z\u00e2\ufffd\u00a2(x,t)\u011f\ufffd\u0153\u2018\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a1 ( italic_x ) italic_Z ( italic_x , italic_t ) achieves its positive maximum, at which it satisfies that (4.6) implies that and at the maximum point (x0,t0)subscript\u011f\ufffd\u2018\u00a50subscript\u011f\ufffd\u2018\u00a10(x_{0},t_{0})( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ). Let \u00ce\u00b2=aq\u011f\ufffd\u203a\u00bd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd = divide start_ARG italic_a end_ARG start_ARG italic_q end_ARG, a=s\u00e2\ufffd\u00a2q2\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018 superscript\u011f\ufffd\u2018\ufffd2a=sq^{2}italic_a = italic_s italic_q start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, employing Lemma 3.34, we have It follows from the h\u00c3\u00b6lder inequality that and Substituting (4.10) and (4.11) into (4.9), and choosing s>1\u011f\ufffd\u2018 1s>1italic_s > 1, q>0\u011f\ufffd\u2018\ufffd0q>0italic_q > 0, such that 2\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019\u00ce\u00b5)n\u00e2\ufffd\u00a2s\u00e2\u02c6\u20191s\u00e2\ufffd\u00a2q\u00e2\u2030\u00a51\u00ce\u00b5\u00e2\u02c6\u20191+(2\u00e2\ufffd\u00a2s\u00e2\u02c6\u20191)2821\u011f\ufffd\u0153\u20ac\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018 1\u011f\ufffd\u2018 \u011f\ufffd\u2018\ufffd1\u011f\ufffd\u0153\u20ac1superscript2\u011f\ufffd\u2018 128 1)^{2}}{8}divide start_ARG 2 ( 1 - italic_\u00ce\u00b5 ) end_ARG start_ARG italic_n end_ARG divide start_ARG italic_s - 1 end_ARG start_ARG italic_s italic_q end_ARG \u00e2\u2030\u00a5 divide start_ARG 1 end_ARG start_ARG italic_\u00ce\u00b5 end_ARG - 1 + divide start_ARG ( 2 italic_s - 1 ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG 8 end_ARG, one may find that Substituting (4.12) into (4.8) and noticing (4.7), we have It\u00e2\u20ac\u2122s easy to know that Multiplying through by t\u00e2\ufffd\u00a2\u00cf\u2020\u011f\ufffd\u2018\u00a1\u011f\ufffd\u0153\u2018t italic_\u00cf\u2020 at (4.13) and utilizing (4.14), we get that which implies that is satisfied at (x0,t0)subscript\u011f\ufffd\u2018\u00a50subscript\u011f\ufffd\u2018\u00a10(x_{0},t_{0})( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ). Clearly, corresponding to the assumption of (x0,t0)subscript\u011f\ufffd\u2018\u00a50subscript\u011f\ufffd\u2018\u00a10(x_{0},t_{0})( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ), one can deduce that Recall a result that, if a1,a2,a3\u00e2\u2030\u00a50subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd30a_{1},a_{2},a_{3} 0italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT \u00e2\u2030\u00a5 0 then a1\u00e2\ufffd\u00a2a2+a3\u00e2\u2030\u00a4a1\u00e2\ufffd\u00a2a2+a1\u00e2\ufffd\u00a2a3subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd3subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd3 start_ARG italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG square-root start_ARG italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + italic_a start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG \u00e2\u2030\u00a4 square-root start_ARG italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG + square-root start_ARG italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG. Thus, on B\u00e2\ufffd\u00a2(p,2\u00e2\ufffd\u00a2R)\u011f\ufffd\ufffd\u00b5\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\u2026B(p,2R)italic_B ( italic_p , 2 italic_R ), which is the desired inequality. \u00e2\u02c6\ufffd Theorem 1.2 follows from Theorem 4.1 directly.",
        "keywords": "keywords: gradient estimate, Fisher-KPP equation, Finsler metric measure space, weighted Ricci curvature, mixed weighted Ricci curvature"
    },
    {
        "id": 6,
        "title": "Radical Pair Mechanism and the Role of Chirality-Induced Spin Selectivity during Planaria Regeneration: Effect of Weak Magnetic Field on ROS levels",
        "abstract": "AbstractPlanarian is an intriguing model system wherein the effect of electric and magnetic fields can be studied on various biochemical pathways during cell morphogenesis. Recent experimental observations have demonstrated the non-trivial modulation of reactive oxygen species (ROS) levels by weak magnetic field during planaria regeneration. However, the underlying biophysical mechanism behind this remains elusive.\nIn this paper, we study the radical pair mechanism to explain the effect of weak magnetic fields on ROS modulation during planaria regeneration to explain the experimental results. We also investigate the effect of chirality-induced spin selectivity (CISS) on ROS levels by including it in the framework of the radical pair mechanism. We conclude that the inclusion of CISS not only explains the experimental results better but also allows for the radical pair model to have more parametric space to satisfy the experimental constraints. This study explains the crucial process of ROS modulation by the weak magnetic field with and without CISS thereby paving the way to unravel the vast domain of ROS modulation for desired outcomes.",
        "corpus": "HTML conversions sometimes display errors due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on. Authors: achieve the best HTML results from your LaTeX submissions by following these best practices. Planarian is an intriguing model system wherein the effect of electric and magnetic fields can be studied on various biochemical pathways during cell morphogenesis. Recent experimental observations have demonstrated the non-trivial modulation of reactive oxygen species (ROS) levels by weak magnetic field during planaria regeneration. However, the underlying biophysical mechanism behind this remains elusive. In this paper, we study the radical pair mechanism to explain the effect of weak magnetic fields on ROS modulation during planaria regeneration to explain the experimental results. We also investigate the effect of chirality-induced spin selectivity (CISS) on ROS levels by including it in the framework of the radical pair mechanism. We conclude that the inclusion of CISS not only explains the experimental results better but also allows for the radical pair model to have more parametric space to satisfy the experimental constraints. This study explains the crucial process of ROS modulation by the weak magnetic field with and without CISS thereby paving the way to unravel the vast domain of ROS modulation for desired outcomes. Several research studies emphasize the significant impact of electromagnetic fields on diverse biological processes and systems [1, 2, 3]. Morphogenesis, a biological process, is affected by electromagnetic fields, with planarians serving as a notable model for comprehending morphogenesis and cell communication. Planarians, recognized for their exceptional regenerative abilities, are often studied in this context \u00c2 [4, 5, 6, 7, 8, 9]. Planaria\u00e2\u20ac\u2122s impressive regenerative ability is due to the presence of a set of robust adult stem cells known as neoblasts. Once injured, these cells migrate to the injured site and form a specialized structure known as a blastema. The blastema subsequently undergoes multiplication and transformation, regenerating the lost body parts like the head, trunk, or tail [10, 11, 12, 13, 14]. The formation of the blastema is influenced by specific signaling molecules known as reactive oxygen species (ROS). Blocking and activation of these molecules contribute to the change in the formation of blastema. Consequently, this impacts the growth of new tissues and affects the process of planarian regeneration [15, 16, 17]. Recent insights into how living organisms interact with electromagnetic radiation indicate the possibility of discovering novel techniques for controlling ROS within the body using weak magnetic fields (WMFs)\u00c2 [17]. However, the exact biophysical mechanism behind the effect of weak magnetic fields on ROS levels is not fully known. Radical pair mechanism has been proposed to elucidate the impact of weak magnetic fields on modulation of ROS levels\u00c2 [18, 19, 20, 21, 22, 23, 24, 25]. More generally, the radical pair mechanism (RPM) has emerged as a prominent theory explaining the effect of magnetic field on various biological and chemical systems\u00c2 [23, 26, 27, 28, 29] In particular, it has been studied in detail for the cryptochrome protein present in bird\u00e2\u20ac\u2122s retina and is considered a potential explanation for the avian magnetoreception [30, 31, 32, 33, 34]. Moreover, it has recently been reported that CISS might play a role in conjunction with radical pairs in birds for the navigational compass [35, 36, 37]. The radical pair mechanism involves electron transport steps during the formation and recombination\u00c2 [32, 38, 39]. This involves the movement of electrons through protein molecules. Owing to the chirality of protein molecules, the chiral-induced spin selectivity (CISS) effect could play an essential role in the electron transport part of the reaction. Although the exact role of CISS in the avian magnetoreception has been debated, there are strong evidence in support of its presence in various biochemical reactions involving electron transfer or rearrangement in chiral molecules\u00c2 [40, 41, 42, 43, 44]. The origin of CISS is attributed to the spin-orbit interaction and the electrostatic potential provided by the chiral molecules\u00c2 [45, 46, 47, 48, 49, 50, 51, 52]. In this work, we examine the radical pair mechanism in light of recent experimental work pertaining to ROS level modulation by the weak magnetic field\u00c2 [53]. Furthermore, we also investigate the effect of chirality-induced spin selectivity (CISS) in the modulation of Reactive Oxygen Species (ROS) in the planarian system. To achieve this, we establish a theoretical model of the CISS-assisted radical pair mechanism, aligning our simulated results with experimental data [17]. Our investigation of the CISS-assisted radical pair mechanism is structured around three key considerations: 1) the absolute yield of the reaction, 2) the ratio of yield values at the experimental point of interest, and 3) the number of nuclei configurations that adhere to the experimental trend. Additionally, we explore two scenarios: 1) CISS presence exclusively during the formation of radicals and 2) CISS presence during both the formation and recombination of radical pairs. The manuscript has been organized as follows: Section\u00c2 II discusses the simulation methodology followed for analysis. Section \u00c2 III discusses the results, where subsection\u00c2 III.1 discusses the RP model with no CISS subsection\u00c2 III.2 discusses the RP model with CISS, subsection\u00c2 III.3 explores the impact of singlet and triplet recombination rate on planaria regeneration and \u00c2 III.4 discuss a system with higher number of nuclei. Finally, we discuss the shortcomings and conclusions of the study. In the radical pair model of the planaria regeneration, an electron is excited in the acceptor molecule, creating a vacancy in the ground state. Another electron from a neighboring donor molecule travels in the chiral medium to fill this vacancy. It results in the formation of a radical pair. The spin operator of the electron on the donor molecule is S^D\u00e2\ufffd\u00a2zsubscript^\u011f\ufffd\u2018\u2020\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u00a7 start_ARG italic_S end_ARG start_POSTSUBSCRIPT italic_D italic_z end_POSTSUBSCRIPT and on the acceptor molecule is S^A\u00e2\ufffd\u00a2zsubscript^\u011f\ufffd\u2018\u2020\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u00a7 start_ARG italic_S end_ARG start_POSTSUBSCRIPT italic_A italic_z end_POSTSUBSCRIPT. Therefore, the spin state of the above-formed radical pair is governed by the following Hamiltonian\u00c2 [54, 31, 37] where \u00cf\u2030=g\u00e2\ufffd\u00a2\u00ce\u00bcB\u00c2\u00af\u00e2\ufffd\u00a2B\u00c2\u00af\u011f\ufffd\u0153\u201d\u011f\ufffd\u2018\u201d\u00c2\u00afsubscript\u011f\ufffd\u0153\u2021\u011f\ufffd\ufffd\u00b5\u00c2\u00af\u011f\ufffd\ufffd\u00b5 = italic_g over\u00c2\u00af start_ARG italic_\u00ce\u00bc start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT end_ARG over\u00c2\u00af start_ARG italic_B end_ARG, B\u00c2\u00af=B0\u00e2\ufffd\u00a2z\u00c2\u00af\u00c2\u00af\u011f\ufffd\ufffd\u00b5subscript\u011f\ufffd\ufffd\u00b50\u00c2\u00af\u011f\ufffd\u2018\u00a7 start_ARG italic_B end_ARG = italic_B start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT over\u00c2\u00af start_ARG italic_z end_ARG where B0subscript\u011f\ufffd\ufffd\u00b50B_{0}italic_B start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT corresponds to the applied magnetic field. J\u011f\ufffd\ufffd\u00bdJitalic_J and D\u011f\ufffd\ufffd\u00b7Ditalic_D are the exchange and dipolar interactions. A\u011f\ufffd\ufffd\u00b4Aitalic_A is the hyperfine tensor depicting interactions between electrons and neighboring nuclear spins. The spin state of the radical pair evolves under the zeeman and hyperfine interactions. Along with this evolution, the radical pair also recombines back to the singlet yield and triplet yield shown in Fig.\u00c2 1. The singlet yield corresponds to the ground state while the triplet state corresponds to reactive oxygen species(ROS) concentrationFig.\u00c2 1). The radical pair formation begins with the donor molecule (D) and the acceptor molecule (A) in their ground states. The reaction initiates with the excitation of the acceptor molecule, causing an electron to transition to a higher energy state and leaving a vacancy in the ground state of the acceptor molecule. Electron transfer occurs from the ground state of the donor molecule to fill the vacancy in the ground state of the acceptor molecule. This leads to the formation of the radical pair on donor ion D.+D^{.+}italic_D start_POSTSUPERSCRIPT . + end_POSTSUPERSCRIPT and acceptor ion A.\u00e2\u02c6\u2019A^{.-}italic_A start_POSTSUPERSCRIPT . - end_POSTSUPERSCRIPT. Fig,2 illustrates the formation of the radical pair in a chiral medium where the spin state of the electron |\u00e2\u2020\u201c\u00e2\u0178\u00a9ket\u00e2\u2020\u201c start_ARG \u00e2\u2020\u201c end_ARG \u00e2\u0178\u00a9 is allowed in the forward propagation of the electron. In a non-chiral case, both |\u00e2\u2020\u201c\u00e2\u0178\u00a9ket\u00e2\u2020\u201c start_ARG \u00e2\u2020\u201c end_ARG \u00e2\u0178\u00a9 and |\u00e2\u2020\u2018\u00e2\u0178\u00a9ket\u00e2\u2020\u2018 start_ARG \u00e2\u2020\u2018 end_ARG \u00e2\u0178\u00a9 will be allowed in the formation of the radical pair. The recombination of the radical pair involves the transition from the donor ion D.+D^{.+}italic_D start_POSTSUPERSCRIPT . + end_POSTSUPERSCRIPT and acceptor ion A.\u00e2\u02c6\u2019A^{.-}italic_A start_POSTSUPERSCRIPT . - end_POSTSUPERSCRIPT to their respective ground states, as well as the generation of regenerative oxygen species. This process occurs in three stages. Stage 1 is the initial stage where the radical pair is formed. The chirality of the medium allows only the |\u00e2\u2020\u201c\u00e2\u0178\u00a9ket\u00e2\u2020\u201c start_ARG \u00e2\u2020\u201c end_ARG \u00e2\u0178\u00a9 state to move from the donor ion D.+D^{.+}italic_D start_POSTSUPERSCRIPT . + end_POSTSUPERSCRIPT to the acceptor ion A.\u00e2\u02c6\u2019A^{.-}italic_A start_POSTSUPERSCRIPT . - end_POSTSUPERSCRIPT as illustrated in Fig.2. In Stage 2, the system exists in a superposition of singlet and triplet states. The spins of the isolated electrons on D.+D^{.+}italic_D start_POSTSUPERSCRIPT . + end_POSTSUPERSCRIPT and A.\u00e2\u02c6\u2019A^{.-}italic_A start_POSTSUPERSCRIPT . - end_POSTSUPERSCRIPT change due to their interaction with the nuclei (hyperfine interaction). This stage is affected by the system Hamiltonian (Eq.1). In stage 3, because the forward movement allowed the |\u00e2\u2020\u201c\u00e2\u0178\u00a9ket\u00e2\u2020\u201c start_ARG \u00e2\u2020\u201c end_ARG \u00e2\u0178\u00a9 state, the |\u00e2\u2020\u2018\u00e2\u0178\u00a9ket\u00e2\u2020\u2018 start_ARG \u00e2\u2020\u2018 end_ARG \u00e2\u0178\u00a9 state will move in the opposite (backward) direction for recombination. This recombination yield leads to the formation of the respective singlet and triplet yield. The triplet yield would contribute towards the ROS signaling, whereas the singlet yield would contribute towards the ground state of the donor and acceptor molecule. In Fig.3, we have illustrated it for a fully chiral medium and how chirality affects the formation of the yield. Due to chirality, since only |\u00e2\u2020\u2018\u00e2\u0178\u00a9ket\u00e2\u2020\u2018 start_ARG \u00e2\u2020\u2018 end_ARG \u00e2\u0178\u00a9 is allowed, we observe that yield formation of the yield of triplet state |\u00e2\u2020\u201c\u00e2\u2020\u201c\u00e2\u0178\u00a9ket\u00e2\u2020\u201cabsent\u00e2\u2020\u201c start_ARG \u00e2\u2020\u201c \u00e2\u2020\u201c end_ARG \u00e2\u0178\u00a9 is inhibited. The CISS effect plays a role in forming (Fig.2) and recombining (Fig.3) the radical pair as it involves electron transport through the chiral protein molecule. Therefore, the action of CISS is captured by the initial state PIsubscript\u011f\ufffd\u2018\u0192\u011f\ufffd\ufffd\u00bcP_{I}italic_P start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT and recombination state PSsubscript\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2020P_{S}italic_P start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT and PTsubscript\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2021P_{T}italic_P start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT, shown with red arrows in Fig.\u00c2 1. Then the initial state density matrix is given as: PI\u00e2\ufffd\u00a2n\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2l=PI\u00e2\ufffd\u00a2n\u00e2\u0160\u2014IZsubscript\u011f\ufffd\u2018\u0192\u011f\ufffd\ufffd\u00bc\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2122tensor-productsubscript\u011f\ufffd\u2018\u0192\u011f\ufffd\ufffd\u00bc\u011f\ufffd\u2018\u203a\u011f\ufffd\ufffd\u00bc\u011f\ufffd\u2018\ufffdP_{Initial}=P_{In} start_POSTSUBSCRIPT italic_I italic_n italic_i italic_t italic_i italic_a italic_l end_POSTSUBSCRIPT = italic_P start_POSTSUBSCRIPT italic_I italic_n end_POSTSUBSCRIPT \u00e2\u0160\u2014 divide start_ARG italic_I end_ARG start_ARG italic_Z end_ARG, where IZ\u011f\ufffd\ufffd\u00bc\u011f\ufffd\u2018\ufffd start_ARG italic_I end_ARG start_ARG italic_Z end_ARG corresponds to the mixed state of nuclei, and Z\u011f\ufffd\u2018\ufffdZitalic_Z is the size of the nuclear Hilbert space. The singlet recombination operator PS=|\u00cf\u02c6S\u00e2\u0178\u00a9\u00e2\ufffd\u00a2\u00e2\u0178\u00a8\u00cf\u02c6S|subscript\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2020ketsubscript\u011f\ufffd\u0153\u201c\u011f\ufffd\u2018\u2020brasubscript\u011f\ufffd\u0153\u201c\u011f\ufffd\u2018\u2020P_{S}={ start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT = | start_ARG italic_\u00cf\u02c6 start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT end_ARG \u00e2\u0178\u00a9 \u00e2\u0178\u00a8 start_ARG italic_\u00cf\u02c6 start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT end_ARG | accounts for recombination to the ground state where: The triplet recombination operator PT=PT++PT\u00e2\u02c6\u2019+PT\u00e2\ufffd\u00a20subscript\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2021subscript\u011f\ufffd\u2018\u0192limit-from\u011f\ufffd\u2018\u2021subscript\u011f\ufffd\u2018\u0192limit-from\u011f\ufffd\u2018\u2021subscript\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u20210P_{T}=P_{T+}+P_{T-}+P_{T0}italic_P start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT = italic_P start_POSTSUBSCRIPT italic_T + end_POSTSUBSCRIPT + italic_P start_POSTSUBSCRIPT italic_T - end_POSTSUBSCRIPT + italic_P start_POSTSUBSCRIPT italic_T 0 end_POSTSUBSCRIPT accounts for recombination to the reactive oxygen species concentration. PT+subscript\u011f\ufffd\u2018\u0192limit-from\u011f\ufffd\u2018\u2021P_{T+}italic_P start_POSTSUBSCRIPT italic_T + end_POSTSUBSCRIPT correspond to triplet state when net magnetic moment mS=1subscript\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u20201m_{S}=1italic_m start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT = 1. PT\u00e2\u02c6\u2019subscript\u011f\ufffd\u2018\u0192limit-from\u011f\ufffd\u2018\u2021P_{T-}italic_P start_POSTSUBSCRIPT italic_T - end_POSTSUBSCRIPT correspond to triplet state when net magnetic moment mS=\u00e2\u02c6\u20191subscript\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u20201m_{S}=-1italic_m start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT = - 1 and PT\u00e2\ufffd\u00a20subscript\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u20210P_{T0}italic_P start_POSTSUBSCRIPT italic_T 0 end_POSTSUBSCRIPT correspond to triplet state when net magnetic moment mS=0subscript\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u20200m_{S}=0italic_m start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT = 0 The CISS parameter \u00cf\u2021\u00e2\u02c6\u02c6[0,\u00cf\u20ac2]\u011f\ufffd\u0153\u20190\u011f\ufffd\u0153\u20392 \u00e2\u02c6\u02c6 [ 0 , divide start_ARG italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG ] depends on the spin selectivity of the protein medium; \u00cf\u2021=0\u011f\ufffd\u0153\u20190 = 0 corresponding to no CISS and \u00cf\u2021=\u00cf\u20ac/2\u011f\ufffd\u0153\u2019\u011f\ufffd\u0153\u20392 = italic_\u00cf\u20ac / 2 corresponding to the full CISS. The master equation governing the state evolution of the system is given as: Where kSsubscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2020k_{S}italic_k start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT is the singlet recombination rate, and kTsubscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2021k_{T}italic_k start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT is the triplet recombination rate. [A,B]=A\u00e2\ufffd\u00a2B\u00e2\u02c6\u2019B\u00e2\ufffd\u00a2A\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b5\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b5\u011f\ufffd\ufffd\u00b5\u011f\ufffd\ufffd\u00b4[A,B]=AB-BA[ italic_A , italic_B ] = italic_A italic_B - italic_B italic_A correspond to the commutator whereas, {A,B}=A\u00e2\ufffd\u00a2B+B\u00e2\ufffd\u00a2A\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b5\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b5\u011f\ufffd\ufffd\u00b5\u011f\ufffd\ufffd\u00b4 italic_A , italic_B } = italic_A italic_B + italic_B italic_A is the anti-commutator. As the literature states, the triplet yield is directly related to reactive oxygen species (ROS) concentration [17, 53]. Consequently, it is crucial to determine how the distribution of triplet yield varies concerning the external magnetic field. Defining the yield product of the triplet state (\u00cf\u2022Tsubscriptitalic-\u00cf\u2022\u011f\ufffd\u2018\u2021 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT) is imperative; therefore, it is defined according to Eq.10. \u00cf\ufffd\u00e2\ufffd\u00a2(t)^^\u011f\ufffd\u0153\u0152\u011f\ufffd\u2018\u00a1 start_ARG italic_\u00cf\ufffd ( italic_t ) end_ARG is the solution of the master equation Eq.\u00c2 9, T\u00e2\ufffd\u00a2r\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u0178Tritalic_T italic_r is the trace over the state density matrix \u00cf\ufffd\u011f\ufffd\u0153\u0152 As reported in [17, 53], the ROS yield follows the following distribution Hence, if RPM dictates the generation of reactive oxygen species (ROS), a plot of triplet yield (\u00cf\u2022Tsubscriptitalic-\u00cf\u2022\u011f\ufffd\u2018\u2021 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT) against the external magnetic field (B0subscript\u011f\ufffd\ufffd\u00b50B_{0}italic_B start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT) should exhibit a strong correlation with the aforementioned experimental findings. In [17, 53], it is documented that the two nuclei involved may be an oxide (O2\u00e2\u02c6\u2019\u00cb\u2122superscriptsubscript\u011f\ufffd\u2018\u201a2\u00cb\u2122O_{2}^{ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT over\u00cb\u2122 start_ARG - end_ARG end_POSTSUPERSCRIPT) and tryptophan (T\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2p+\u00cb\u2122\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u0178superscript\u011f\ufffd\u2018\ufffd\u00cb\u2122Trp^{ italic_r italic_p start_POSTSUPERSCRIPT over\u00cb\u2122 start_ARG + end_ARG end_POSTSUPERSCRIPT). The oxygen nucleus in O2\u00e2\u02c6\u2019\u00cb\u2122superscriptsubscript\u011f\ufffd\u2018\u201a2\u00cb\u2122O_{2}^{ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT over\u00cb\u2122 start_ARG - end_ARG end_POSTSUPERSCRIPT is nonmagnetic and, thus, does not contribute to the hyperfine interaction. Conversely, tryptophan contains multiple magnetic nuclei of nitrogen and hydrogen. Considering the biological context where distances between nuclei and electrons are variable, a parametric approach has been adopted, specifically addressing the hyperfine interaction of tryptophan with an electron. In our initial investigation into the feasibility of the radical pair mechanism, we have defined three quantities that will assist us in our investigation. Based on the experimental results reported in [17, 53], we expect parameters L1,L2,L3subscript\u011f\ufffd\ufffd\u00bf1subscript\u011f\ufffd\ufffd\u00bf2subscript\u011f\ufffd\ufffd\u00bf3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT to have values at least greater than 1. We initially perform analysis considering there is no CISS (\u00cf\u2021=0\u011f\ufffd\u0153\u20190 = 0) in the system and try to ascertain the planaria response to the external magnetic field. In Figure 4, the triplet yield (\u00cf\u2022Tsubscriptitalic-\u00cf\u2022\u011f\ufffd\u2018\u2021 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT) is plotted against the external magnetic field (B0subscript\u011f\ufffd\ufffd\u00b50B_{0}italic_B start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT) for \u00cf\u2021=0\u011f\ufffd\u0153\u20190 = 0 (no CISS) at kS=108subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2020superscript108k_{S}=10^{8}italic_k start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 8 end_POSTSUPERSCRIPT and kT=106subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2021superscript106k_{T}=10^{6}italic_k start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT, with D=0\u011f\ufffd\ufffd\u00b70D=0italic_D = 0 and J=0\u011f\ufffd\ufffd\u00bd0J=0italic_J = 0, under the hyperfine configuration [ax\u00e2\ufffd\u00a2x,ay\u00e2\ufffd\u00a2y,az\u00e2\ufffd\u00a2z]=[0.54,0.06,0.24]\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2Tsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u00a70.540.060.24\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2021[a_{xx},a_{yy},a_{zz}]=[0.54,0.06,0.24]mT[ italic_a start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_z italic_z end_POSTSUBSCRIPT ] = [ 0.54 , 0.06 , 0.24 ] italic_m italic_T. The figure highlights points of interest corresponding to experimental conditions in planaria: A\u011f\ufffd\ufffd\u00b4Aitalic_A for \u00cf\u2022Tsubscriptitalic-\u00cf\u2022\u011f\ufffd\u2018\u2021 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT at 45\u00e2\ufffd\u00a2\u00ce\u00bc\u00e2\ufffd\u00a2T45\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u202145 T45 italic_\u00ce\u00bc italic_T, B\u011f\ufffd\ufffd\u00b5Bitalic_B for \u00cf\u2022Tsubscriptitalic-\u00cf\u2022\u011f\ufffd\u2018\u2021 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT at 200\u00e2\ufffd\u00a2\u00ce\u00bc\u00e2\ufffd\u00a2T200\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u2021200 T200 italic_\u00ce\u00bc italic_T, and C\u011f\ufffd\ufffd\u00b6Citalic_C for \u00cf\u2022Tsubscriptitalic-\u00cf\u2022\u011f\ufffd\u2018\u2021 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT at 500\u00e2\ufffd\u00a2\u00ce\u00bc\u00e2\ufffd\u00a2T500\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u2021500 T500 italic_\u00ce\u00bc italic_T. The experimental plot from references [17, 53] is displayed at the bottom of Figure 4, demonstrating the concentration of reactive oxygen species (ROC) in the experimental outcome. A parametric analysis was conducted for all values of [ax\u00e2\ufffd\u00a2x,ay\u00e2\ufffd\u00a2y,az\u00e2\ufffd\u00a2z]subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u00a7[a_{xx},a_{yy},a_{zz}][ italic_a start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_z italic_z end_POSTSUBSCRIPT ], with each component ranging from 0 to 3 m\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2021mTitalic_m italic_T (step size 0.06 m\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2021mTitalic_m italic_T), ensuring that all three parameters (L1,L2,L3subscript\u011f\ufffd\ufffd\u00bf1subscript\u011f\ufffd\ufffd\u00bf2subscript\u011f\ufffd\ufffd\u00bf3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT) yield values greater than unity. Out of 132,651 possible hyperfine tensors, approximately 39 values met the desired condition. From Figure 4, the observed values were L1=1.132,L2=1.131,L3=1.001formulae-sequencesubscript\u011f\ufffd\ufffd\u00bf11.132formulae-sequencesubscript\u011f\ufffd\ufffd\u00bf21.131subscript\u011f\ufffd\ufffd\u00bf31.001L_{1}=1.132,L_{2}=1.131,L_{3}=1.001italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1.132 , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1.131 , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1.001. Although ideally, a higher value of these ratios is preferred, the range of these ratios for all 39 possible hyperfine tensors was between 1-1.25. The maximum values of hyperfine tensor [ax\u00e2\ufffd\u00a2x,ay\u00e2\ufffd\u00a2y,az\u00e2\ufffd\u00a2z]subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u00a7[a_{xx},a_{yy},a_{zz}][ italic_a start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_z italic_z end_POSTSUBSCRIPT ], where L1,L2,L3subscript\u011f\ufffd\ufffd\u00bf1subscript\u011f\ufffd\ufffd\u00bf2subscript\u011f\ufffd\ufffd\u00bf3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT are greater than unity, were found to be [0.54,0.06,0.24]\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2T0.540.060.24\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2021[0.54,0.06,0.24]mT[ 0.54 , 0.06 , 0.24 ] italic_m italic_T . Consequently, the desired trend was only observed for low hyperfine values. Additionally, it was noted that the absolute value of \u00cf\u2022Tsubscriptitalic-\u00cf\u2022\u011f\ufffd\u2018\u2021 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT was relatively low. In the next section, chirality will be introduced to investigate whether spin selectivity provides a more accurate model that closely aligns with the experimental outcome. This section introduces spin selectivity arising from chirality, taking into account the nonzero value of \u00cf\u2021\u011f\ufffd\u0153\u2019 Initially, we focus on spin selectivity during the formation of the radical pair from the acceptor and donor molecules. Consequently, the initial density matrix, denoted as P^I\u00e2\ufffd\u00a2nsubscript^\u011f\ufffd\u2018\u0192\u011f\ufffd\ufffd\u00bc\u011f\ufffd\u2018\u203a start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_I italic_n end_POSTSUBSCRIPT, is influenced by variations in the CISS parameter \u00cf\u2021\u011f\ufffd\u0153\u2019 However, the recombination operators are observed under the no CISS case (\u00cf\u2021=0\u011f\ufffd\u0153\u20190 = 0), representing the standard singlet and triplet projection operators. In the subsequent part, we explore the role of CISS in both the formation and recombination of the radical. Thus, \u00cf\u2021\u011f\ufffd\u0153\u2019 will impact not only the initial density matrix P^I\u00e2\ufffd\u00a2nsubscript^\u011f\ufffd\u2018\u0192\u011f\ufffd\ufffd\u00bc\u011f\ufffd\u2018\u203a start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_I italic_n end_POSTSUBSCRIPT but also recombination operators P^Ssubscript^\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2020 start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT and P^Tsubscript^\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2021 start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT. This work calculates the result for the fixed orientation of the CISS axis to the hyperfine z-axis [37]. In Figure 5, the triplet yield (\u00cf\u2022Tsubscriptitalic-\u00cf\u2022\u011f\ufffd\u2018\u2021 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT) is graphed against the external magnetic field for five different values of \u00cf\u2021=0,\u00cf\u20ac6,\u00cf\u20ac4,\u00cf\u20ac3,\u00cf\u20ac2\u011f\ufffd\u0153\u20190\u011f\ufffd\u0153\u20396\u011f\ufffd\u0153\u20394\u011f\ufffd\u0153\u20393\u011f\ufffd\u0153\u20392 = 0 , divide start_ARG italic_\u00cf\u20ac end_ARG start_ARG 6 end_ARG , divide start_ARG italic_\u00cf\u20ac end_ARG start_ARG 4 end_ARG , divide start_ARG italic_\u00cf\u20ac end_ARG start_ARG 3 end_ARG , divide start_ARG italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG. This analysis is conducted at kS=108subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2020superscript108k_{S}=10^{8}italic_k start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 8 end_POSTSUPERSCRIPT and kT=106subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2021superscript106k_{T}=10^{6}italic_k start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT, with D=0\u011f\ufffd\ufffd\u00b70D=0italic_D = 0 and J=0\u011f\ufffd\ufffd\u00bd0J=0italic_J = 0, and under the hyperfine configuration [ax\u00e2\ufffd\u00a2x,ay\u00e2\ufffd\u00a2y,az\u00e2\ufffd\u00a2z]=[0,0.78,0.84]\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2Tsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u00a700.780.84\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2021[a_{xx},a_{yy},a_{zz}]=[0,0.78,0.84]mT[ italic_a start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_z italic_z end_POSTSUBSCRIPT ] = [ 0 , 0.78 , 0.84 ] italic_m italic_T. Notably, CISS is present only during the formation of the radical in this scenario. We list the values of L1,L2,L3subscript\u011f\ufffd\ufffd\u00bf1subscript\u011f\ufffd\ufffd\u00bf2subscript\u011f\ufffd\ufffd\u00bf3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT in Tab.1 for Fig 5. It is noteworthy that when CISS exclusively influences the formation of the radical, the observed trend aligns with the experimental findings. A distinctive peak is evident at 500\u00e2\ufffd\u00a2\u00ce\u00bc\u00e2\ufffd\u00a2T500\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u2021500 T500 italic_\u00ce\u00bc italic_T when CISS is considered. Specifically, when \u00cf\u2021=\u00cf\u20ac2\u011f\ufffd\u0153\u2019\u011f\ufffd\u0153\u20392 = divide start_ARG italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG, there is a notable increase in the ratio L1subscript\u011f\ufffd\ufffd\u00bf1L_{1}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT by at least four times. Tab. 2 provides the count of hyperfine tensors corresponding to the five \u00cf\u2021\u011f\ufffd\u0153\u2019 values that meet the criteria 11 at kS=108subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2020superscript108k_{S}=10^{8}italic_k start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 8 end_POSTSUPERSCRIPT and kT=106subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2021superscript106k_{T}=10^{6}italic_k start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT, considering CISS solely in the formation of the radical pair. In Fig.6, we plotted triplet yield \u00cf\u2022Tsubscriptitalic-\u00cf\u2022\u011f\ufffd\u2018\u2021 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT with respect to external magnetic field for five values of \u00cf\u2021=0,\u00cf\u20ac6,\u00cf\u20ac4,\u00cf\u20ac3,\u00cf\u20ac2\u011f\ufffd\u0153\u20190\u011f\ufffd\u0153\u20396\u011f\ufffd\u0153\u20394\u011f\ufffd\u0153\u20393\u011f\ufffd\u0153\u20392 = 0 , divide start_ARG italic_\u00cf\u20ac end_ARG start_ARG 6 end_ARG , divide start_ARG italic_\u00cf\u20ac end_ARG start_ARG 4 end_ARG , divide start_ARG italic_\u00cf\u20ac end_ARG start_ARG 3 end_ARG , divide start_ARG italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG at kS=108subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2020superscript108k_{S}=10^{8}italic_k start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 8 end_POSTSUPERSCRIPT and kT=106subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2021superscript106k_{T}=10^{6}italic_k start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT with D=0\u011f\ufffd\ufffd\u00b70D=0italic_D = 0 and J=0\u011f\ufffd\ufffd\u00bd0J=0italic_J = 0 at two different hyperfine configuration. (a) [ax\u00e2\ufffd\u00a2x,ay\u00e2\ufffd\u00a2y,az\u00e2\ufffd\u00a2z]=[0.12,0.12,0]\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2Tsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u00a70.120.120\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2021[a_{xx},a_{yy},a_{zz}]=[0.12,0.12,0]mT[ italic_a start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_z italic_z end_POSTSUBSCRIPT ] = [ 0.12 , 0.12 , 0 ] italic_m italic_T and (b) [ax\u00e2\ufffd\u00a2x,ay\u00e2\ufffd\u00a2y,az\u00e2\ufffd\u00a2z]=[0,0.72,0.9]\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2Tsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u00a700.720.9\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2021[a_{xx},a_{yy},a_{zz}]=[0,0.72,0.9]mT[ italic_a start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_z italic_z end_POSTSUBSCRIPT ] = [ 0 , 0.72 , 0.9 ] italic_m italic_T. We list the values of L1,L2,L3subscript\u011f\ufffd\ufffd\u00bf1subscript\u011f\ufffd\ufffd\u00bf2subscript\u011f\ufffd\ufffd\u00bf3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT in Tab.3 and Tab.4 for all five values of \u00cf\u2021\u011f\ufffd\u0153\u2019 Our parametric analysis found no single combination of hyperfine values for which L1,L2,L3subscript\u011f\ufffd\ufffd\u00bf1subscript\u011f\ufffd\ufffd\u00bf2subscript\u011f\ufffd\ufffd\u00bf3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT are greater than one for all five values of \u00cf\u2021\u011f\ufffd\u0153\u2019 at kS=108subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2020superscript108k_{S}=10^{8}italic_k start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 8 end_POSTSUPERSCRIPT and kT=106subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2021superscript106k_{T}=10^{6}italic_k start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT. The closest result observed was when [ax\u00e2\ufffd\u00a2x,ay\u00e2\ufffd\u00a2y,az\u00e2\ufffd\u00a2z]=[0.12,0.12,0]\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2Tsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u00a70.120.120\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2021[a_{xx},a_{yy},a_{zz}]=[0.12,0.12,0]mT[ italic_a start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_z italic_z end_POSTSUBSCRIPT ] = [ 0.12 , 0.12 , 0 ] italic_m italic_T when \u00cf\u2021=\u00cf\u20ac6,\u00cf\u20ac4,\u00cf\u20ac3,\u00cf\u20ac2\u011f\ufffd\u0153\u2019\u011f\ufffd\u0153\u20396\u011f\ufffd\u0153\u20394\u011f\ufffd\u0153\u20393\u011f\ufffd\u0153\u20392 = divide start_ARG italic_\u00cf\u20ac end_ARG start_ARG 6 end_ARG , divide start_ARG italic_\u00cf\u20ac end_ARG start_ARG 4 end_ARG , divide start_ARG italic_\u00cf\u20ac end_ARG start_ARG 3 end_ARG , divide start_ARG italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG all reported a value of L1,L2,L3subscript\u011f\ufffd\ufffd\u00bf1subscript\u011f\ufffd\ufffd\u00bf2subscript\u011f\ufffd\ufffd\u00bf3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT greater than 1 however this was not observed for \u00cf\u2021=0\u011f\ufffd\u0153\u20190 = 0. It was observed that the values of \u00cf\u2022Tsubscriptitalic-\u00cf\u2022\u011f\ufffd\u2018\u2021 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT at \u00cf\u2021=\u00cf\u20ac2\u011f\ufffd\u0153\u2019\u011f\ufffd\u0153\u20392 = divide start_ARG italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG are at least ten times larger than that for the case when \u00cf\u2021=0\u011f\ufffd\u0153\u20190 = 0. However, the values of the ratio L1,L2,L3subscript\u011f\ufffd\ufffd\u00bf1subscript\u011f\ufffd\ufffd\u00bf2subscript\u011f\ufffd\ufffd\u00bf3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT remain almost the same. Moreover, the number of hyperfine tensors corresponding to five values of \u00cf\u2021\u011f\ufffd\u0153\u2019 which satisfy criteria 11 at kS=108subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2020superscript108k_{S}=10^{8}italic_k start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 8 end_POSTSUPERSCRIPT and kT=106subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2021superscript106k_{T}=10^{6}italic_k start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT is given in 5 when CISS acts both in formation and recombination of radical pair. Hence, we summarize the difference in the cases when CISS is only present at the formation of the radical (Case A) and when CISS is present both in the formation and recombination of radicals (Case B). Case A has a lower value of triplet yield at 45,200,500\u00e2\ufffd\u00a2\u00ce\u00bc\u00e2\ufffd\u00a2T45200500\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u202145,200,500 T45 , 200 , 500 italic_\u00ce\u00bc italic_T compared to Case B; hence, case B seems more favorable. Case A shows an improved increase in the ratio of L1,L2,L3subscript\u011f\ufffd\ufffd\u00bf1subscript\u011f\ufffd\ufffd\u00bf2subscript\u011f\ufffd\ufffd\u00bf3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT due to CISS compared to Case B at around the same hyperfine tensor; hence, case A seems more favorable. Case A has more number of hyperfine tensor for \u00cf\u2021\u00e2\u2030 0\u011f\ufffd\u0153\u20190 0italic_\u00cf\u2021 \u00e2\u2030 0 compared to case B. Since this reaction occurs in a biological system, this property gives the system more degree of freedom and reaction and is not bounded by strict values of hyperfine tensors. Therefore, case A is more promising if we consider this property. In this section, our aim was to investigate the impact of singlet and triplet recombination rates on the yield of the triplet product, \u00cf\u2022Tsubscriptitalic-\u00cf\u2022\u011f\ufffd\u2018\u2021 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT. The goal is to discern a trend that aligns with experimental findings, as articulated in Eq.11, across the maximum number of hyperfine tensors. Recognizing that the planaria reaction transpires in a biological medium, we have exercised the discretion to consider hyperfine tensors. Tabulated in Tab6 are the counts of hyperfine configurations, out of the 132,651 possible configurations, that adhere to the observed experimental trend when \u00cf\u2021=0\u011f\ufffd\u0153\u20190 = 0. Our observation indicates that when \u00cf\u2021=0\u011f\ufffd\u0153\u20190 = 0, rate combinations with kS=108subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2020superscript108k_{S}=10^{8}italic_k start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 8 end_POSTSUPERSCRIPT and kT=105subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2021superscript105k_{T}=10^{5}italic_k start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT = 10 start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT exhibit the maximum number of hyperfine configurations satisfying the experimental conditions. However, the absolute value of triplet yield is low due to the diminished triplet recombination rate. Consequently, a higher triplet rate leads to an increased triplet yield value; nevertheless, the rapid recombination rate renders the yield less sensitive to the external magnetic field. This results in a limited number of hyperfine tensor values that meet the specified criteria. Additionally, it was observed that no rate combination resulted in L1,L2,L3\u00e2\u2030\u00a52subscript\u011f\ufffd\ufffd\u00bf1subscript\u011f\ufffd\ufffd\u00bf2subscript\u011f\ufffd\ufffd\u00bf32L_{1},L_{2},L_{3} 2italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT \u00e2\u2030\u00a5 2 (table not shown). When \u00cf\u2021=\u00cf\u20ac2\u011f\ufffd\u0153\u2019\u011f\ufffd\u0153\u20392 = divide start_ARG italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG, we have calculated the number of combinations of hyperfine tensors for which L1,L2,L3subscript\u011f\ufffd\ufffd\u00bf1subscript\u011f\ufffd\ufffd\u00bf2subscript\u011f\ufffd\ufffd\u00bf3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT is greater than unity. This has been done for case A (Tab.7) and case B (Tab.8) at \u00cf\u2021=\u00cf\u20ac2\u011f\ufffd\u0153\u2019\u011f\ufffd\u0153\u20392 = divide start_ARG italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG. We generally observe an increase in the number of hyperfine tensors for either case when compared to when \u00cf\u2021=0\u011f\ufffd\u0153\u20190 = 0. However, in case A, the number of hyperfine tensors for which L1,L2,L3subscript\u011f\ufffd\ufffd\u00bf1subscript\u011f\ufffd\ufffd\u00bf2subscript\u011f\ufffd\ufffd\u00bf3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT is greater than unity is much greater compared to case B for most values of kSsubscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2020k_{S}italic_k start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT and kTsubscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2021k_{T}italic_k start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT. We have also computed the maximum values of L1,L2,L3subscript\u011f\ufffd\ufffd\u00bf1subscript\u011f\ufffd\ufffd\u00bf2subscript\u011f\ufffd\ufffd\u00bf3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT when each component of the hyperfine tensor [ax\u00e2\ufffd\u00a2x,ay\u00e2\ufffd\u00a2y,az\u00e2\ufffd\u00a2z]subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u00a7[a_{xx},a_{yy},a_{zz}][ italic_a start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_z italic_z end_POSTSUBSCRIPT ] varies from 0 to 3 mT, covering a total of 132,651 tensor values at \u00cf\u2021=\u00cf\u20ac2\u011f\ufffd\u0153\u2019\u011f\ufffd\u0153\u20392 = divide start_ARG italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG for case A (Tab.13) and case B (Tab.14). Notably, significant values of L1,L2,L3subscript\u011f\ufffd\ufffd\u00bf1subscript\u011f\ufffd\ufffd\u00bf2subscript\u011f\ufffd\ufffd\u00bf3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT are observed when kTsubscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2021k_{T}italic_k start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT is in the range of 104superscript10410^{4}10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT and 105superscript10510^{5}10 start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT, with the singlet recombination rate being at least a hundred times (107superscript10710^{7}10 start_POSTSUPERSCRIPT 7 end_POSTSUPERSCRIPT and 108superscript10810^{8}10 start_POSTSUPERSCRIPT 8 end_POSTSUPERSCRIPT) for both the cases.We also observe that L1,L2,L3subscript\u011f\ufffd\ufffd\u00bf1subscript\u011f\ufffd\ufffd\u00bf2subscript\u011f\ufffd\ufffd\u00bf3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT values are higher for case A compared to case B. We have also calculated the maximum absolute value of triplet yield (ROS level) at 45\u00e2\ufffd\u00a2\u00ce\u00bc\u00e2\ufffd\u00a2T,200\u00e2\ufffd\u00a2\u00ce\u00bc\u00e2\ufffd\u00a2T,500\u00e2\ufffd\u00a2\u00ce\u00bc\u00e2\ufffd\u00a2T45\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u2021200\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u2021500\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u202145 T,~{}200 T,~{}500 T45 italic_\u00ce\u00bc italic_T , 200 italic_\u00ce\u00bc italic_T , 500 italic_\u00ce\u00bc italic_T for case A (Tab.16) and case B (Tab.15) It is essential to acknowledge that the rate combination resulting in the maximum value of L1,L2,L3subscript\u011f\ufffd\ufffd\u00bf1subscript\u011f\ufffd\ufffd\u00bf2subscript\u011f\ufffd\ufffd\u00bf3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT tends to yield lower values of triplet yield compared to yields observed at other rates. This implies that at \u00cf\u2021=\u00cf\u20ac2\u011f\ufffd\u0153\u2019\u011f\ufffd\u0153\u20392 = divide start_ARG italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG, one can either achieve the maximum value of the ratio L1,L2,L3subscript\u011f\ufffd\ufffd\u00bf1subscript\u011f\ufffd\ufffd\u00bf2subscript\u011f\ufffd\ufffd\u00bf3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT or attain the absolute yield value by adjusting the recombination rates. This section examines whether the intended experimental outcomes are observed for higher nuclei or if the trend diverges. Given in \u00c2 [17, 53], indicating that the second nucleus might be tryptophan, we assume the second nucleus to be spin-half, akin to hydrogen. We vary it similarly to a single-nuclei system, but with two nuclei, the number of parameters increases to six. We sampled 51 points from 0 to 3 mT for each component of the hyperfine tensor for a single nuclei system, resulting in 132,651 combinations. This number is 516superscript51651^{6}51 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT tensors for two nuclei systems a very large value. Consequently, we selected values for the hyperfine tensor of the first nucleus that satisfy the conditions outlined in the criteria 11 as given in the preceding section of one nucleus study and varied the hyperfine tensor for the second nucleus. We observe in Fig.7 that for a two nuclei system, we observe the desired trend for \u00cf\u2021=\u00cf\u20ac2\u011f\ufffd\u0153\u2019\u011f\ufffd\u0153\u20392 = divide start_ARG italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG. The L1,L2,L3subscript\u011f\ufffd\ufffd\u00bf1subscript\u011f\ufffd\ufffd\u00bf2subscript\u011f\ufffd\ufffd\u00bf3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT are listed in Tab.9 for five values of \u00cf\u2021\u011f\ufffd\u0153\u2019 We observe that compared to single nucleus case with hyperfine tensor [ax\u00e2\ufffd\u00a2x,ay\u00e2\ufffd\u00a2y,az\u00e2\ufffd\u00a2z]=[0.12,0.12,0]\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2Tsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u00a70.120.120\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2021[a_{xx},a_{yy},a_{zz}]=[0.12,0.12,0]mT[ italic_a start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_z italic_z end_POSTSUBSCRIPT ] = [ 0.12 , 0.12 , 0 ] italic_m italic_T Fig.(6.a), we observe that L1,L2,L3subscript\u011f\ufffd\ufffd\u00bf1subscript\u011f\ufffd\ufffd\u00bf2subscript\u011f\ufffd\ufffd\u00bf3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT is greater for \u00cf\u2021=\u00cf\u20ac2\u011f\ufffd\u0153\u2019\u011f\ufffd\u0153\u20392 = divide start_ARG italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG for two nuclei case. Hence, we also observe an experimental trend for two nuclei cases. However, due to scaling issues, it might not be possible to give maximum values of L1,L2,L3subscript\u011f\ufffd\ufffd\u00bf1subscript\u011f\ufffd\ufffd\u00bf2subscript\u011f\ufffd\ufffd\u00bf3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT. Keeping the value of hyperfine tensor fixed [ax\u00e2\ufffd\u00a2x,ay\u00e2\ufffd\u00a2y,az\u00e2\ufffd\u00a2z]=[0.12,0.12,0]\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2Tsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u00a70.120.120\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2021[a_{xx},a_{yy},a_{zz}]=[0.12,0.12,0]mT[ italic_a start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_z italic_z end_POSTSUBSCRIPT ] = [ 0.12 , 0.12 , 0 ] italic_m italic_T, we have done a parametric analysis for the second nucleus and found a number of hyperfine tensors satisfying the criteria for various value of \u00cf\u2021\u011f\ufffd\u0153\u2019 (Tab.10). A similar analysis for hyperfine tensor is[ax\u00e2\ufffd\u00a2x,ay\u00e2\ufffd\u00a2y,az\u00e2\ufffd\u00a2z]=[0,0.72,0.9]\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2Tsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u00a700.720.9\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2021[a_{xx},a_{yy},a_{zz}]=[0,0.72,0.9]mT[ italic_a start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_z italic_z end_POSTSUBSCRIPT ] = [ 0 , 0.72 , 0.9 ] italic_m italic_T of spin 1 nucleus give us very different results in Tab.11. Here, we obtain no hyperfine tensor for second nuclei, which might satisfy the criteria for \u00cf\u2021=\u00cf\u20ac2\u011f\ufffd\u0153\u2019\u011f\ufffd\u0153\u20392 = divide start_ARG italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG. Hence, we cannot reach any conclusive result by this brute-force method. We also simulated the case when CISS is only present in the formation of the radical pair when the spin one nucleus has hyperfine tensor [ax\u00e2\ufffd\u00a2x,ay\u00e2\ufffd\u00a2y,az\u00e2\ufffd\u00a2z]=[0,0.78,0.84]\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2Tsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u00a700.780.84\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2021[a_{xx},a_{yy},a_{zz}]=[0,0.78,0.84]mT[ italic_a start_POSTSUBSCRIPT italic_x italic_x end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_y italic_y end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_z italic_z end_POSTSUBSCRIPT ] = [ 0 , 0.78 , 0.84 ] italic_m italic_T. We found, in general, that more hyperfine tensors satisfied the criteria (Tab.12). This hints more towards the involvement of CISS only in forming the radical pair. However, a more rigorous approach is required to achieve a more conclusive outcome. The process of blastema formation, crucial for planarian regeneration, seems to be correlated with the level of Reactive Oxygen Species (ROS). Interestingly, the experiments suggest that exposure to Weak Magnetic Fields (WMF) should be continued until the blastema is fully formed. It\u00e2\u20ac\u2122s worth noting that the radical pair mechanism, which involves the spin dynamics of electrons and is influenced by magnetic fields, typically has a very short lifetime, on the order of microseconds. This short lifetime raises questions about whether the radical pair mechanism directly participates in the planarian regeneration process or if there\u00e2\u20ac\u2122s another mechanism at play. The observed correlation between WMF exposure duration and blastema formation could imply a more complex interplay between magnetic field effects and biological processes. It\u00e2\u20ac\u2122s possible that the radical pair mechanism, despite its short-lived nature, triggers or influences other biochemical pathways or mechanisms that lead to blastema formation over a longer timescale. Further research is needed to unravel the specifics of these interactions and mechanisms in planarian regeneration. The issue of radical pair formation in the context of planarian regeneration, especially in the absence of an external excitation source, raises intriguing questions. In avian magnetoreception, radical pairs are typically formed through the photoexcitation of neutral acceptor molecules. In the experiments conducted on planaria regeneration, where Weak Magnetic Fields (WMF) are applied [17, 53], there is no apparent external excitation source. The absence of a known external stimulus for radical pair formation prompts the question of what initiates this reaction in the absence of an external excitation source. One plausible explanation could be related to the cut or segment of the planaria body. The external cut might release some reactive chemical or signaling molecule, which could act as an internal stimulus, leading to the generation of excitation and the subsequent formation of radical pairs in the system. However, the specific identity and nature of this chemical or excitation remain unclear and would require further investigation. Understanding the underlying biochemical processes triggered by the external cut in planaria regeneration, especially in the context of magnetic field effects, could provide valuable insights into the role of radical pair mechanisms and other potential signaling pathways in this intriguing biological phenomenoa. In summary, our analysis suggests that the Radical Pair Mechanism (RPM) provides an explanation for the influence of a weak magnetic field on planaria regeneration. However, our findings indicate that the effect is more robustly explained when considering the Chirality-Induced Spin Selectivity (CISS) in conjunction with the radical pair mechanism. Specifically, when chirality is involved solely in the formation of the radical pair, it yields even more consistent and fitting results based on the experimental findings. This underscores the potential significance of CISS in understanding the magnetic field effects on planaria regeneration with radical pair mechanism. In this section, we have listed the L1,L2,L3subscript\u011f\ufffd\ufffd\u00bf1subscript\u011f\ufffd\ufffd\u00bf2subscript\u011f\ufffd\ufffd\u00bf3L_{1},L_{2},L_{3}italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_L start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT at all possible recombination rates of kS,kTsubscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2020subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2021k_{S},k_{T}italic_k start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT , italic_k start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT when CISS is involved in the formation and recombination of radical pair as well as when it is involved only in the formation of the radical. We have also listed the absolute values of the yield at 45\u00e2\ufffd\u00a2\u00ce\u00bc\u00e2\ufffd\u00a2T,200\u00e2\ufffd\u00a2\u00ce\u00bc\u00e2\ufffd\u00a2T,500\u00e2\ufffd\u00a2\u00ce\u00bc\u00e2\ufffd\u00a2T45\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u2021200\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u2021500\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u202145 T,200 T,500 T45 italic_\u00ce\u00bc italic_T , 200 italic_\u00ce\u00bc italic_T , 500 italic_\u00ce\u00bc italic_T for both of the mentioned cases. All the results are for the case when \u00cf\u2021=\u00cf\u20ac2\u011f\ufffd\u0153\u2019\u011f\ufffd\u0153\u20392 = divide start_ARG italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG.",
        "keywords": ""
    },
    {
        "id": 7,
        "title": "Uso de herramientas digitales matem\u00c3\u00a1ticas en la Educaci\u00c3\u00b3n Secundaria",
        "abstract": "ResumenLas Tecnolog\u00c3\u00adas de la Informaci\u00c3\u00b3n y la Comunicaci\u00c3\u00b3n (TIC) est\u00c3\u00a1n cada d\u00c3\u00ada m\u00c3\u00a1s presentes en nuestra sociedad y por tanto en el \u00c3\u00a1mbito educativo. En apenas dos d\u00c3\u00a9cadas hemos pasado de una ense\u00c3\u00b1anza basada, en muchos casos, en las clases magistrales a una ense\u00c3\u00b1anza en la que metodolog\u00c3\u00adas como el aula invertida o la gamificaci\u00c3\u00b3n tienen m\u00c3\u00a1s fuerza que nunca.A lo largo del trabajo hemos realizado una encuesta a docentes y alumnado con el objetivo de comparar los conocimientos en herramientas digitales, su uso y su aceptaci\u00c3\u00b3n. Hemos utilizado WxMaxima y Geogebra como herramientas did\u00c3\u00a1cticas. Para ello propondremos un ejercicio de laEvaluaci\u00c3\u00b3n de Bachillerato para el Acceso a la Universidad(EBAU) relacionado con la geometr\u00c3\u00ada, analizando sus puntos fuertes y d\u00c3\u00a9biles en comparaci\u00c3\u00b3n con la resoluci\u00c3\u00b3n manual. Por \u00c3\u00batlimo, expondremos algunas conclusiones y posibles l\u00c3\u00adneas de investigaci\u00c3\u00b3n acerca de las herramientas digitales, as\u00c3\u00ad como una propuesta de curso introductorio a WxMaxima y Geogebra con el que formar al docente de secundaria.",
        "corpus": "Las Tecnolog\u00c3as de la Informaci\u00c3\u00b3n y la Comunicaci\u00c3\u00b3n (TIC) est\u00c3\u00a1n cada d\u00c3a m\u00c3\u00a1s presentes en nuestra sociedad y por tanto en el \u00c3\u00a1mbito educativo. En apenas dos d\u00c3\u00a9cadas hemos pasado de una ense\u00c3\u00b1anza basada, en muchos casos, en las clases magistrales a una ense\u00c3\u00b1anza en la que metodolog\u00c3as como el aula invertida o la gamificaci\u00c3\u00b3n tienen m\u00c3\u00a1s fuerza que nunca. A lo largo del trabajo hemos realizado una encuesta a docentes y alumnado con el objetivo de comparar los conocimientos en herramientas digitales, su uso y su aceptaci\u00c3\u00b3n. Hemos utilizado WxMaxima y Geogebra como herramientas did\u00c3\u00a1cticas. Para ello propondremos un ejercicio de la Evaluaci\u00c3\u00b3n de Bachillerato para el Acceso a la Universidad (EBAU) relacionado con la geometr\u00c3a, analizando sus puntos fuertes y d\u00c3\u00a9biles en comparaci\u00c3\u00b3n con la resoluci\u00c3\u00b3n manual. Por \u00c3\u00batlimo, expondremos algunas conclusiones y posibles l\u00c3neas de investigaci\u00c3\u00b3n acerca de las herramientas digitales, as\u00c3 como una propuesta de curso introductorio a WxMaxima y Geogebra con el que formar al docente de secundaria. Abstract Information and Community Technologies (ICT) are very present in our society nowadays and particularly in the educative field. In just two decades, we have passed from a learning based, in many cases, on the master lessons to one such that methodologies like the flipped classroom or the gamification are stronger than ever. Along this work, we have done a study to teachers and students with the main objective to compare the knowledge on digital tools, their use and their acceptation. We use WxMaxima and Geogebra in order to solve an exercise of Evaluaci\u00c3\u00b3n de Bachillerato para el Acceso a la Universidad (EBAU) related with Geometry, comparing their ins and outs with the manual solution. Finally, we expose some conclusions and some possible research lines about digital tools, as well as a proposition of an introductory course on WxMaxima and Geogebra in order to teach the teachers. Keywords: TIC; Geogebra; WxMaxima; Herramientas digitales; Educaci\u00c3\u00b3n Matem\u00c3\u00a1tica; Competencia Digital. MSC2020: 97D10; 97N80; 97U10. La Ley Org\u00c3\u00a1nica 2/2006, de 3 de mayo, de Educaci\u00c3\u00b3n, LOE en adelante, define las competencias como \u00e2\u20ac\u0153las capacidades para aplicar de forma integrada los contenidos propios de cada ense\u00c3\u00b1anza y etapa educativa, con el fin de lograr la realizaci\u00c3\u00b3n adecuada de actividades y la resoluci\u00c3\u00b3n eficaz de problemas complejos\u00e2\u20ac\ufffd. Todas las leyes que han sucedido a esta, han apostado por un car\u00c3\u00a1cter competencial y cada vez tienen m\u00c3\u00a1s fuerza dentro de la ense\u00c3\u00b1anza. En la vigente Ley Org\u00c3\u00a1nica 3/2020, de 29 de diciembre, por la que se modifica la Ley Org\u00c3\u00a1nica 2/2006, de 3 de mayo, de Educaci\u00c3\u00b3n (LOMLOE en adelante), podemos encontrar la \u00e2\u20ac\u0153Competencia Matem\u00c3\u00a1tica y de ciencias, tecnolog\u00c3a e ingenier\u00c3a\u00e2\u20ac\ufffd (STEM) y la \u00e2\u20ac\u0153Competencia digital\u00e2\u20ac\ufffd. Seg\u00c3\u00ban el Ministerio de Educaci\u00c3\u00b3n y Formaci\u00c3\u00b3n Profesional, la competencia matem\u00c3\u00a1tica \u00e2\u20ac\u0153implica la capacidad de aplicar el razonamiento matem\u00c3\u00a1tico y sus herramientas para describir, interpretar y predecir distintos fen\u00c3\u00b3menos en su contexto\u00e2\u20ac\ufffd, mientras que la competencia digital implica el uso creativo y cr\u00c3tico de las tecnolog\u00c3as de la informaci\u00c3\u00b3n y la comunicaci\u00c3\u00b3n, siempre de manera segura y controlada, por lo que no s\u00c3\u00b3lo implicar\u00c3\u00a1 destrezas en el acceso o procesamiento de la informaci\u00c3\u00b3n, sino tambi\u00c3\u00a9n del filtrado y comprobaci\u00c3\u00b3n de la veracidad de dicha informaci\u00c3\u00b3n. Es evidente la relaci\u00c3\u00b3n directa entre las matem\u00c3\u00a1ticas y el uso de las tecnolog\u00c3as, ya que los nuevos avances cient\u00c3ficos permiten, por ejemplo, el mejor cifrado y encriptado de contrase\u00c3\u00b1as en internet, pero la relaci\u00c3\u00b3n entre inform\u00c3\u00a1tica y matem\u00c3\u00a1ticas parece m\u00c3\u00a1s difusa. Esta relaci\u00c3\u00b3n se propicia cuando, para descubrir nuevos resultados matem\u00c3\u00a1ticos, se hace uso de las herramientas inform\u00c3\u00a1ticas para realizar c\u00c3\u00a1lculos que hacerlos manualmente nos llevar\u00c3an una eternidad. Si echamos la vista atr\u00c3\u00a1s, no hace mucho los logaritmos se calculaban mediante interpolaciones a partir de valores ya calculados en unas tablas. Estas tablas quedaron obsoletas cuando aparecieron las calculadoras. Estamos quiz\u00c3\u00a1s ante la siguiente brecha digital, donde los ordenadores han venido a sustituir a las calculadoras, como estas hicieron con las tablas de logaritmos y otros muchos c\u00c3\u00a1lculos manuales. No podemos dar el siguiente paso tecnol\u00c3\u00b3gico a los ordenadores, tablets o pizarras digitales si el personal docente no tiene suficientes conocimientos sobre su utilizaci\u00c3\u00b3n. Es evidente entonces, que la incorporaci\u00c3\u00b3n de nuevas herramientas digitales a la docencia de las matem\u00c3\u00a1ticas es inevitable y se intensificar\u00c3\u00a1 en los pr\u00c3\u00b3ximos a\u00c3\u00b1os. El uso de los ordenadores para resolver problemas no implica la desaparici\u00c3\u00b3n del razonamiento l\u00c3\u00b3gico, adem\u00c3\u00a1s, ambas formas de trabajar se complementan y pueden, incluso, potenciarse entre s\u00c3. Por tanto, debemos formar a los alumnos en el uso de las nuevas tecnolog\u00c3as para resolver, visualizar o interactuar con un problema matem\u00c3\u00a1tico y su aplicaci\u00c3\u00b3n en la vida diaria. Un libro que aborda estas y otras inquietudes relacionadas con las matem\u00c3\u00a1ticas y la educaci\u00c3\u00b3n es [2]. En \u00c3\u00a9l se hace un repaso de distintos \u00c3\u00a1mbitos relacionados con la educaci\u00c3\u00b3n matem\u00c3\u00a1tica tanto en las etapas obligatorias como en la post-obligatoria, as\u00c3 como cuestiones que deben ser transversales a lo largo de toda la ense\u00c3\u00b1anza de las matem\u00c3\u00a1ticas. Tambi\u00c3\u00a9n se detallan algunos aspectos sobre la formaci\u00c3\u00b3n profesional del profesorado de matem\u00c3\u00a1ticas. Por tanto, ha sido una obra de referencia en las dos \u00c3\u00baltimas d\u00c3\u00a9cadas y puede ser un complemento a la lectura de este art\u00c3culo. A lo largo del art\u00c3culo trataremos los siguientes aspectos: En primer lugar, sentaremos el marco normativo, m\u00c3\u00a1s concretamente, hablaremos sobre las competencias STEM y digital. Analizaremos el manejo que tienen los profesores y los alumnos en las herramientas digitales relacionadas con las matem\u00c3\u00a1ticas. Para ello, se ha llevado a cabo una encuesta a docentes y alumnos sobre el uso de diferentes herramientas como LaTeX, Wolfram Alpha o Geogebra. Utilizaremos los programas de libre acceso WxMaxima y Geogebra para resolver un ejercicio de la prueba de acceso a la Universidad de Extremaudra y analizar c\u00c3\u00b3mo podr\u00c3an ayudar al alumnado. Dada la necesidad de formaci\u00c3\u00b3n en herramientas digitales espec\u00c3ficas de matem\u00c3\u00a1ticas, propondremos un curso para iniciar a docentes y alumnos en el manejo de WxMaxima y Geogebra. Finalmente, cerraremos el documento con una secci\u00c3\u00b3n dedicada a conclusiones obtenidas y posibles l\u00c3neas de investigaci\u00c3\u00b3n que se podr\u00c3an explorar a partir de este trabajo. La educaci\u00c3\u00b3n de nuestros d\u00c3as se basa en el desarrollo del curr\u00c3culo mediante las competencias b\u00c3\u00a1sicas o clave (seg\u00c3\u00ban la ley a la que hagamos referencia). Aunque en el panorama internacional ya se hablaba sobre la educaci\u00c3\u00b3n por competencias desde que Philippe Perrenoud las introdujese en 1998 [16] y, posteriormente, la Recomendaci\u00c3\u00b3n del Parlamento Europeo y del Consejo 2006/962/CE, de 18 de diciembre de 2006, sobre las competencias clave para el aprendizaje es la primera vez que un organismo europeo recomendaba la implantaci\u00c3\u00b3n de este tipo de educaci\u00c3\u00b3n. En Espa\u00c3\u00b1a hicieron su aparici\u00c3\u00b3n en la Ley Org\u00c3\u00a1nica 2/2006, de 3 de mayo, de Educaci\u00c3\u00b3n, aunque no se mencionaban las mismas de forma expresa, ya dejaba ver el car\u00c3\u00a1cter europe\u00c3sta del que se quer\u00c3a dotar a la eduaci\u00c3\u00b3n. Las competencias se fueron asentando con el paso de los a\u00c3\u00b1os, hasta que a finales de 2013 la Ley Org\u00c3\u00a1nica 8/2013, de 9 de diciembre, para la mejora de la calidad educativa, LOMCE en adelante, recoge por primera vez en Espa\u00c3\u00b1a las siete competencias claves del sistema educativo espa\u00c3\u00b1ol y sienta las relaciones entre las competencias, los contenidos y los criterios de evaluaci\u00c3\u00b3n de los distintos niveles educativos a trav\u00c3\u00a9s de la Orden ECD/65/2015, de 21 de enero, por la que se describen las relaciones entre las competencias, los contenidos y los criterios de evaluaci\u00c3\u00b3n de la educaci\u00c3\u00b3n primaria, la eduaci\u00c3\u00b3n secundaria obligatoria y el bachillerato. El caracter competencial en la educaci\u00c3\u00b3n secundaria sigue vigente con la nueva legislaci\u00c3\u00b3n, la Ley Org\u00c3\u00a1nica 3/2020, de 29 de diciembre, por la que se modifica la Ley Org\u00c3\u00a1nica 2/2006, de 3 de mayo, de Educaci\u00c3\u00b3n (LOMLOE). En ella se describen las competencias clave, entre las que se encuentran la competencia Matem\u00c3\u00a1tica y de ciencias, tecnolog\u00c3a e ingenier\u00c3a (STEM) y la competencia digital. Se establece que la competencia matem\u00c3\u00a1tica es aquella que \u00e2\u20ac\u0153implica la capacidad de aplicar el razonamiento matem\u00c3\u00a1tico y sus herramientas para describir, interpretar y predecir distintos fen\u00c3\u00b3menos\u00e2\u20ac\ufffd [4, Anexo I,2.a]. Por tanto, el estudio de las asignaturas de matem\u00c3\u00a1ticas no debe buscar la memorizaci\u00c3\u00b3n de f\u00c3\u00b3rmulas, problemas t\u00c3picos o definiciones concretas, sino que, a partir de ciertos conocimientos te\u00c3\u00b3ricos, ha de permitir interpretar el mundo que nos rodea para resolver ploblemas con herramientas matem\u00c3\u00a1ticas. No se trata entonces de aprender cu\u00c3\u00a1les son las herramientas matem\u00c3\u00a1ticas, sino c\u00c3\u00b3mo aplicar estas herramientas en el mundo exterior. Por ejemplo, no hay raz\u00c3\u00b3n ninguna para memorizar la famosa f\u00c3\u00b3rmula del Teorema de Pit\u00c3\u00a1goras si no sabemos en qu\u00c3\u00a9 situaciones es pertinente el uso de este conocimiento matem\u00c3\u00a1tico. As\u00c3, esta f\u00c3\u00b3rmula puede servir como mero ejercicio mental de memorizaci\u00c3\u00b3n, o puede servirnos para analizar una rampa de un acceso para minusv\u00c3\u00a1lidos que nos encontremos en cualquier acera de nuestra ciudad. Por ejemplo, si el tri\u00c3\u00a1ngulo de la Figura 1 representa una de dichas rampas entonces podemos calcular la longitud de dicha rampa gracias a que a2=b2+c2superscript\u011f\ufffd\u2018\ufffd2superscript\u011f\ufffd\u2018\ufffd2superscript\u011f\ufffd\u2018\ufffd2a^{2}=b^{2}+c^{2}italic_a start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = italic_b start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_c start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT y tambi\u00c3\u00a9n podemos ver el \u00c3\u00a1ngulo de inclinaci\u00c3\u00b3n de la rampa con las relaciones trigonom\u00c3\u00a9tricas y establecer si la rampa cumple o no con las medidas para la accesibilidad del moviliario urbano. Se trata por tanto de relacionar las f\u00c3\u00b3rmulas y herramientas matem\u00c3\u00a1ticas con el mundo que nos rodea, de forma que lo hagamos entendible desde un punto de vista matem\u00c3\u00a1tico. De todo ello trata el libro Mirar la ciudad con ojos matem\u00c3\u00a1ticos, [1], L. Blanco establece distintos itinerarios por la ciudad de Badajoz en los que iremos paseando a la vez que realizamos peque\u00c3\u00b1as actividades de reflexi\u00c3\u00b3n o de c\u00c3\u00a1lculo matem\u00c3\u00a1tico en las que emplearemos algunas de las herramientas que aprendemos en la escuela y que muchos alumnos piensan que no tienen utilidad. En el informe PISA [15, p. 7] se introduce el concepto de alfabetizaci\u00c3\u00b3n matem\u00c3\u00a1tica que, a su vez es recogido en castellano en [8, p. 10]: La alfabetizaci\u00c3\u00b3n matem\u00c3\u00a1tica es la capacidad de un individuo de razonar matem\u00c3\u00a1ticamente y de formular, emplear e interpretar las matem\u00c3\u00a1ticas para resolver problemas en una amplia variedad de contextos de la vida real. Esto incluye conceptos, procedimientos, datos y herramientas para describir, explicar y predecir fen\u00c3\u00b3menos. Ayuda a los individuos a conocer el papel que cumplen las matem\u00c3\u00a1ticas en el mundo y hacer los juicios y tomar las decisiones bien fundamentadas que necesitan los ciudadanos reflexivos, constructivos y comprometidos del siglo XXI. Continuando con el mismo documento, el CEMat aporta algunas indicaciones que deben dejar de realizarse en la Educaci\u00c3\u00b3n Secundaria Obligatoria y el Bachillerato, por ejemplo \u00e2\u20ac\u0153utilizar f\u00c3\u00b3rmulas dadas como modelos de problemas del mundo real, sin analizar de d\u00c3\u00b3nde surge el modelo\u00e2\u20ac\ufffd o \u00e2\u20ac\u0153expresar ecuaciones de una funci\u00c3\u00b3n de forma anal\u00c3tica, con el exclusivo objeto de representarlas gr\u00c3\u00a1ficamente\u00e2\u20ac\ufffd. Todo ello sugiere que las matem\u00c3\u00a1ticas y el mundo que conocemos deben estar relacionados y el objeto de estudio de las matem\u00c3\u00a1ticas debe ser precisamente entender dicha relaci\u00c3\u00b3n. Respecto a la competencia digital [4, Anexo I, 3] \u00e2\u20ac\u0153es aquella que implica el uso creativo, cr\u00c3tico y seguro de las tecnolog\u00c3as de la informaci\u00c3\u00b3n y la comunicaci\u00c3\u00b3n\u00e2\u20ac\ufffd. De forma que Esta competencia supone, adem\u00c3\u00a1s de la adecuaci\u00c3\u00b3n a los cambios que introducen las nuevas tecnolog\u00c3as [\u00e2\u20ac\u00a6] para ser competente en un entorno digital. Requiere de conocimientos relacionados con el lenguaje espec\u00c3fico b\u00c3\u00a1sico: textual, num\u00c3\u00a9rico, ic\u00c3\u00b3nico, visual, gr\u00c3\u00a1fico y sonoro, as\u00c3 como sus pautas de decodificaci\u00c3\u00b3n y transferencia. Esto conlleva el conocimiento de las principales aplicaciones inform\u00c3\u00a1ticas. Por tanto, con ojos matem\u00c3\u00a1ticos, el uso de las nuevas tecnolog\u00c3as puede servirnos para complementar las explicaciones te\u00c3\u00b3ricas. Al igual que el uso de la calculadora no implica que la suma de fracciones no tenga que ser estudiada, por ejemplo, el aprendizaje en el uso de herramientas inform\u00c3\u00a1ticas para el c\u00c3\u00a1lculo matem\u00c3\u00a1tico no implica que esos contenidos te\u00c3\u00b3ricos no deban ser explicados, sino que el alumno tendr\u00c3\u00a1 una forma m\u00c3\u00a1s de comprobar si los resultados que va obteniendo son correctos. En el [17] se pone este mismo ejemplo de la calculadora como herramienta plenamente instaurada en el aula, pero que \u00e2\u20ac\u0153como toda herramienta, es indispensable aprender a utilizarla para que el alumnado no la considere un sustituto del razonamiento matem\u00c3\u00a1tico\u00e2\u20ac\ufffd, es decir, no deben verse las herramientas digitales como un sutitutivo del razonamiento, sino como herramientas que exploten \u00e2\u20ac\u0153las posibilidades que ofrece para agilizar procesos de c\u00c3\u00a1lculo en las aulas y para que los alumnos puedan centrarse en la comprensi\u00c3\u00b3n de los nuevos conceptos\u00e2\u20ac\ufffd. Seg\u00c3\u00ban [14], \u00e2\u20ac\u0153La tecnolog\u00c3a como recurso de aprendizaje tiene que estar integrada en el curr\u00c3culum, es decir, el maestro formado tiene que saber a la hora de dise\u00c3\u00b1ar una actividad si decide emplear un recurso tecnol\u00c3\u00b3gico, cu\u00c3\u00a1ndo y c\u00c3\u00b3mo hacerlo\u00e2\u20ac\ufffd y as\u00c3 se establece en la Orden ECD/65/2015. En ella podemos apreciar que se indica textualmente que se debe conocer el lenguaje b\u00c3\u00a1sico de las herramientas digitales en relaci\u00c3\u00b3n con conocimientos num\u00c3\u00a9ricos y gr\u00c3\u00a1ficos, lo que implica el conocimiento de las principales aplicaciones inform\u00c3\u00a1ticas. Parece, por tanto, necesario relacionar las dos competencias con las que estamos tratanto, la matem\u00c3\u00a1tica y la digital, de manera que se complementen mutuamente. A pesar de que el uso de herramientas digitales est\u00c3\u00a1 expresamente recogido en el curr\u00c3culo de la educaci\u00c3\u00b3n secundaria de las asignaturas de matem\u00c3\u00a1ticas, el informe realizado por la Real Sociedad Matem\u00c3\u00a1tica Espa\u00c3\u00b3la y la Sociedad Cient\u00c3fica Inform\u00c3\u00a1tica de Espa\u00c3\u00b1a en 2020 [18] reconoce que \u00e2\u20ac\u0153la gran mayor\u00c3a de los libros sigue incorporando la tecnolog\u00c3a de modo anecd\u00c3\u00b3tico y muy ligada a la calculadora\u00e2\u20ac\ufffd, adem\u00c3\u00a1s de reflejar la gran diferencia que hay en los docentes, \u00e2\u20ac\u0153desde profesorado muy tecnologizado que incorpora geometr\u00c3a din\u00c3\u00a1mica, hojas de c\u00c3\u00a1lculo, software de representaci\u00c3\u00b3n gr\u00c3\u00a1fica y hasta lenguajes de programaci\u00c3\u00b3n en su docencia de matem\u00c3\u00a1tica, hasta profesorado que proh\u00c3be el uso de la calculadora en ESO\u00e2\u20ac\ufffd. En [10], se propuso una serie de actividades con Geogebra basados en rompecabezas, llegando a la conclusi\u00c3\u00b3n de que \u00e2\u20ac\u0153aprender Geometr\u00c3a utilizando rompecabezas fue percibido por la mayor\u00c3a de los estudiantes como una experiencia agradable que les permite descubrir nuevas cosas\u00e2\u20ac\ufffd y que al docente le sirve \u00e2\u20ac\u0153no s\u00c3\u00b3lo para estimular el pensamiento geom\u00c3\u00a9trico, sino tambi\u00c3\u00a9n fomentar el inter\u00c3\u00a9s y motivaci\u00c3\u00b3n hacia aprendizaje de la Geometr\u00c3a\u00e2\u20ac\ufffd. Adem\u00c3\u00a1s, el uso de las nuevas tecnolog\u00c3as en el aula tiene importantes implicaciones pedag\u00c3\u00b3gicas, como pueden ser, seg\u00c3\u00ban [14]: \u00e2\u20ac\u0153la creaci\u00c3\u00b3n un entorno interactivo de ense\u00c3\u00b1anza / aprendizaje en el cual los aprendices pueden ser indistintamente emisores y receptores de informaci\u00c3\u00b3n, lo que provoca alta motivaci\u00c3\u00b3n en el aprendiz\u00e2\u20ac\ufffd, que repercutir\u00c3\u00a1 directamente en el clima de la clase; \u00e2\u20ac\u0153la ense\u00c3\u00b1anza se adapta a las necesidades espec\u00c3ficas del alumno\u00e2\u20ac\ufffd, lo que favorece una de las obligaciones de todo docente, la atenci\u00c3\u00b3n a la diversidad; \u00e2\u20ac\u0153se facilita la ense\u00c3\u00b1anza cooperativa\u00e2\u20ac\ufffd, favoreciendo as\u00c3 las relaciones sociales y la empat\u00c3a entre discentes; y por \u00c3\u00baltimo \u00e2\u20ac\u0153se fomenta el autoaprendizaje\u00e2\u20ac\ufffd, es decir, estamos repercutiendo positivamente en la adquisici\u00c3\u00b3n de otra de las competencias b\u00c3\u00a1sicas de especial importancia en la educaci\u00c3\u00b3n integral de los alumnos, aprender a aprender. Una vez que hemos visto las dos competencias fundamentales que se buscan estudiar en este trabajo, cabe destacar que la Real Sociedad Matem\u00c3\u00a1tica Espa\u00c3\u00b1ola est\u00c3\u00a1 haciendo importantes esfuerzos por estudiar c\u00c3\u00b3mo aunar estas dos competencias durante todo el per\u00c3odo de escolaridad. M\u00c3\u00a1s concretamente, en [17] se establece que \u00e2\u20ac\u0153la educaci\u00c3\u00b3n y, espec\u00c3ficamente, el aprendizaje de las matem\u00c3\u00a1ticas, no pueden ser ajenas a los cambios que nos conducen hacia una sociedad m\u00c3\u00a1s tecnificada y digitalizada\u00e2\u20ac\ufffd. Analizaremos en la pr\u00c3\u00b3xima secci\u00c3\u00b3n, la necesidad de formaci\u00c3\u00b3n del profesorado en el uso y utilidad de las herramientas digitales. Seg\u00c3\u00ban Carioca et. al. [7], la necesidad de formaci\u00c3\u00b3n del profesorado en el uso de las herramientas digitales es una necesidad prioritaria de nuestros d\u00c3as, no tanto en el uso de las propias herramientas, sino en la utilidad did\u00c3\u00a1ctica que tienen y en c\u00c3\u00b3mo llevarlas al aula. Adem\u00c3\u00a1s, Mart\u00c3n destaca en [14, p. 44] que \u00e2\u20ac\u0153debido a la rapidez de los avances tecnol\u00c3\u00b3gicos se hace m\u00c3\u00a1s patente que nunca la asunci\u00c3\u00b3n del profesorado en general de la necesidad de un reciclaje en su formaci\u00c3\u00b3n tecnol\u00c3\u00b3gica y en el uso pedag\u00c3\u00b3gico de la tecnolog\u00c3a\u00e2\u20ac\ufffd. Necesidad que se subraya en el Libro Blanco de las Matem\u00c3\u00a1ticas [17, p.33] m\u00c3\u00a1s de una d\u00c3\u00a9cada despu\u00c3\u00a9s: \u00e2\u20ac\u0153el uso de tecnolog\u00c3as en las aulas requiere de un conocimiento did\u00c3\u00a1ctico que va m\u00c3\u00a1s all\u00c3\u00a1 del conocimiento de su simple uso\u00e2\u20ac\ufffd. Ya hemos se\u00c3\u00b1alado en las secciones anteriores, el papel de las nuevas tecnolog\u00c3as en la ense\u00c3\u00b1anza de las matem\u00c3\u00a1ticas. Sin embargo, a\u00c3\u00ban hay docentes que se limitan al uso de las clases magistrales para la ense\u00c3\u00b1anza de esta materia. El objetivo principal de este art\u00c3culo es realizar un estudio en docentes para comprobar el uso que le dan a distintas herramientas digitales, as\u00c3 como el grado de conocimiento que poseen de ellas. M\u00c3\u00a1s a\u00c3\u00ban, nos interesa ver c\u00c3\u00b3mo percibe el alumnado la implementaci\u00c3\u00b3n de las herramientas digitales en la ense\u00c3\u00b1anza de las matem\u00c3\u00a1ticas. Todo esto nos lleva a realizar una encuesta a docentes y alumnado, en la que se les pregunte por distintos aspectos relacionados con las herramientas digitales y, m\u00c3\u00a1s espec\u00c3ficamente, por aquellas relacionadas con las matem\u00c3\u00a1ticas. A ra\u00c3z de estas encuestas, podremos establecer distintas comparativas en cuanto al uso de las herramientas digitales por parte de los docentes en el aula o por parte de los alumnos en sus casas, as\u00c3 como intentar entender los beneficios y los perjuicios que declaran ambos colectivos en el uso de las herramientas digitales en la ense\u00c3\u00b1anza de las matem\u00c3\u00a1ticas. En esta secci\u00c3\u00b3n veremos las principales respuestas a las encuestas realizadas a docentes y alumnos durante el curso 2020-2021. La muestra tomada para el estudio en los docentes ha sido el conjunto de profesores de Ciencias (Matem\u00c3\u00a1ticas, F\u00c3sica, Qu\u00c3mica y Biolog\u00c3a) del centro en el que el autor realiz\u00c3\u00b3 las pr\u00c3\u00a1cticas del M\u00c3\u00a1ster de Formaci\u00c3\u00b3n del Profesorado, durante el curso 2020-2021, el Colegio Santa Teresa de Jes\u00c3\u00bas en Badajoz, cuya titularidad es privada\u00e2\u20ac\u201cconcertada para los niveles de la ESO y privada\u00e2\u20ac\u201cno concertada para los niveles de Bachillerato. Adem\u00c3\u00a1s, para obtener m\u00c3\u00a1s informaci\u00c3\u00b3n, se ha ampliado la muestra con el conjunto de los profesores de Ciencias del Instituto de Educaci\u00c3\u00b3n Secundaria \u00e2\u20ac\u0153El Sur\u00e2\u20ac\ufffd, de la ciudad de Lepe, cuya titularidad es p\u00c3\u00bablica. La muestra tomada en los alumnos ha sido exclusivamente del Colegio Santa Teresa de Badajoz, m\u00c3\u00a1s concretamente los alumnos de los grupos donde mi tutora de pr\u00c3\u00a1cticas imparte clases, es decir, 4.\u00c2\u00ba de la ESO, 1.\u00c2\u00ba y 2.\u00c2\u00ba de Bachillerato, tanto la rama de Matem\u00c3\u00a1ticas de Ciencias Sociales como de la de Matem\u00c3\u00a1ticas para Ciencias. Por supuesto, la encuesta ha sido an\u00c3\u00b3nima y voluntaria. Las preguntas que se hicieron a ambos colectivos pueden encontrarse en los siguientes enlaces: Docentes: https://drive.google.com/file/d/1r-_YReEOhFgaTqtXX2TqPu94N4EQoDFW/view?usp=share_link Alumnado: https://drive.google.com/file/d/1460CqUUTl63VheDltHetF_r2OuMZmJeC/view?usp=share_link Se pueden observar que las preguntas son parecidas, de forma que podamos establecer algunas relaciones. Analizaremos primero las respuestas de los docentes, despu\u00c3\u00a9s la del alumnado, y finalmente comparemos ambos colectivos. Entre los docentes se han registrado un total de 12 respuestas. Empezando por la formaci\u00c3\u00b3n, observamos que la mayor\u00c3a (58,3%percent58.358{,}3 %) de docentes provienen de licenciaturas, por lo que han pasado al menos diez a\u00c3\u00b1os desde que egregaron y, posiblemente, no tengan toda la formaci\u00c3\u00b3n en el uso de las TIC con fines did\u00c3\u00a1cticos como ser\u00c3a deseable. Sin embargo, todos los docentes reconocen su utilidad y s\u00c3\u00b3lo el 8,3%percent8.38{,}3 % admite no saber usarlas. Algunas de las respuestas m\u00c3\u00a1s interesantes a la pregunta \u00c2\u00bfC\u00c3\u00b3mo crees que las herramientas digitales (en general) pueden ayudar a los alumnos en el aula o fuera de ella?, han sido: Pueden visualizar contenidos complejos de reproducir sin digitalizaci\u00c3\u00b3n. La motivaci\u00c3\u00b3n hacia la asignatura es mayor utilizando una herramienta digital. Pueden ayudar a comprender y aprender m\u00c3\u00a1s y mejor que con el m\u00c3\u00a9todo tradicional. Les ayuda a que los estudios sean m\u00c3\u00a1s cercanos. Adem\u00c3\u00a1s, dos tercios del profesorado encuestado afirma haber realizado cursos de formaci\u00c3\u00b3n en herramientas digitales en el \u00c3\u00baltimo a\u00c3\u00b1o, quiz\u00c3\u00a1 debido a que han tenido que actualizarse r\u00c3\u00a1pidamente por los confinamientos y la situaci\u00c3\u00b3n del COVID\u00e2\u20ac\u201c19, mientras que un 16,7%percent16.716{,}7 % afirma haber realizado cursos en los \u00c3\u00baltimos cinco a\u00c3\u00b1os y el otro 16,7%percent16.716{,}7 % afirma no haber realizado cursos desde hace m\u00c3\u00a1s de diez a\u00c3\u00b1os. Muchos de los cursos ofertados por el Centro de Profesores y Recursos (CPR) son de manejo elemental y, precisamente por esto, algunos de los docentes que usan estas herramientas terminan no haciendo los cursos. Se pregunt\u00c3\u00b3 tambi\u00c3\u00a9n sobre el nivel de uso de distintas herramientas (ofim\u00c3\u00a1tica, Kahoot!, generador de nubes de palabras, mapas conceptuales, Canva, Genially y Powtoon) para la elaboraci\u00c3\u00b3n de material did\u00c3\u00a1ctico. Las respuestas se recogen en la Figura 2. Cabe destacar el uso casi a diario de las herramientas de ofim\u00c3\u00a1tica, y un uso algo menor para Kahoot! y herramientas de creaci\u00c3\u00b3n de mapas conceptuales. El resto de aplicaciones tiene un uso pr\u00c3\u00a1cticamente nulo. En el \u00c3\u00a1mbito espec\u00c3fico de las herramientas digitales relacionadas con las matem\u00c3\u00a1ticas, sobre el conocimiento en general de ciertas herramientas se han obtenido las respuestas recogidas en la Figura 3. Donde apreciamos que todos los docentes conocen el editor de f\u00c3\u00b3rmulas de Word, pero que la mayor\u00c3a (siete de los doce encuestados) no conocen LaTeX para la edici\u00c3\u00b3n de texto cient\u00c3fico. Sobre las herramientas de c\u00c3\u00a1lculo destaca que casi todos conocen Geogebra, pero la mayor\u00c3a desconocen programas de c\u00c3\u00a1lculo simb\u00c3\u00b3lico como WxMaxima, Wolfram Alpha o Wolfram Mathematica. Centr\u00c3\u00a1ndonos, por tanto, en el uso del editor de f\u00c3\u00b3rmulas de Word, cinco docentes afirman usarlo con mucha frecuencia y dos de ellos a diario, indicando, en la siguiente pregunta, que han aprendido a usarlo, mayoritariamente de manera autodidacta. En cuanto a Geogebra, la mayor\u00c3a de respuesta se ubica en que su uso es espor\u00c3\u00a1dico (alguna vez) y que la mayor\u00c3a, de nuevo, han sido autodidactas en su aprendizaje. Algunas opiniones de los docentes sobre c\u00c3\u00b3mo ayudan estas herramientas espec\u00c3ficamente matem\u00c3\u00a1ticas a los alumnos son: Permite obtener multitud de ejemplos y generalizar contenidos trabajados. Muy \u00c3\u00batil en geometr\u00c3a, estad\u00c3stica y an\u00c3\u00a1lisis. Pueden hacer m\u00c3\u00a1s atractiva la asignatura y les puede motivar m\u00c3\u00a1s su estudio. Facilitar los c\u00c3\u00a1lculos, comprobar sus resultados, visualizar. Les hacen desarrollar la \u00e2\u20ac\u2122imaginaci\u00c3\u00b3n\u00e2\u20ac\u2122 y capacidad de deducci\u00c3\u00b3n y resoluci\u00c3\u00b3n de problemas y teor\u00c3as. Esto se corresponde con la idea generalizada que ya puntualizamos en la secci\u00c3\u00b3n anterior y que en [8] transmite el CEMAT, y es que es necesario \u00e2\u20ac\u0153usar utilidades inform\u00c3\u00a1ticas para desarrollar estructuras conceptuales\u00e2\u20ac\ufffd en detrimento del c\u00c3\u00a1lculo con \u00e2\u20ac\u0153l\u00c3\u00a1piz y papel\u00e2\u20ac\ufffd ya que \u00e2\u20ac\u0153solucionar problemas con ayuda del ordenador es un ejercicio que permite adquirir la costumbre de enfrentarse a problemas predefinidos de una forma rigurosa y sistem\u00c3\u00a1tica\u00e2\u20ac\ufffd. Como \u00c3\u00baltimo apunte, algunas de las respuestas m\u00c3\u00a1s interesantes de los docentes a si les gustar\u00c3a recibir alg\u00c3\u00ban tipo de formaci\u00c3\u00b3n sobre el uso de estas herramientas fueron: Geogebra, sobre la realizaci\u00c3\u00b3n de recursos interactivos. Geogebra y WxMaxima. S\u00c3, ser\u00c3a muy bueno aprender todas las funcionalidades de todas estas herramientas. S\u00c3, sobre Geogebra, con un curso pr\u00c3\u00a1ctico. S\u00c3. Me gustar\u00c3a saber emplear en mis clases m\u00c3\u00a1s de las herramientas digitales que ya uso. De estas respuestas se deduce el inter\u00c3\u00a9s del profesorado en la formaci\u00c3\u00b3n en herramientas digitales espec\u00c3ficas de las matem\u00c3\u00a1ticas para su utilizaci\u00c3\u00b3n en el aula y que, adem\u00c3\u00a1s opinan que pueden tener un importante beneficio en el alumnado. As\u00c3, en la secci\u00c3\u00b3n 5 se propondr\u00c3\u00a1 un curso formativo para docentes en las herramientas WxMaxima y Geogebra. En este caso, hemos obtenido 40 respuestas por parte del alumnado. Empezaremos localizando en los cursos a estos alumnos, el 20%percent2020 % corresponde a alumnos de 4.\u00c2\u00ba de la ESO, el 52,5%percent52.552{,}5 % a alumnos de 1.\u00c2\u00ba de Bachillerato y el 27,5%percent27.527{,}5 % de 2.\u00c2\u00ba de Bachillerato. Para empezar, cabe destacar que todos afirmaron que las herramientas digitales son \u00c3\u00batiles, y s\u00c3\u00b3lo el 5%percent55 % de ellos admiti\u00c3\u00b3 no saber utilizarlas. Algunas de las respuestas m\u00c3\u00a1s interesantes a la pregunta \u00c2\u00bfC\u00c3\u00b3mo crees que las herramientas digitales (en general) pueden ayudarte en el aula o fuera de ella?, han sido: Sobre todo en la din\u00c3\u00a1mica que estableces con el profesor, teniendo en cuenta que es mucho m\u00c3\u00a1s entretenida la clase y se te pasa mucho m\u00c3\u00a1s r\u00c3\u00a1pido. A la hora de poder hacer trabajos, estudiar o incluso informarme de cosas que no sab\u00c3a antes que pueden ser interesantes. Creo que la comunicaci\u00c3\u00b3n mejorar\u00c3a mucho entre alumnos y profesores. Tambi\u00c3\u00a9n har\u00c3a que las clases fueran m\u00c3\u00a1s din\u00c3\u00a1micas. Ayudan a organizarte mejor, y a veces te hacen las cosas m\u00c3\u00a1s f\u00c3\u00a1ciles, m\u00c3\u00a1s visuales. Adem\u00c3\u00a1s te permite preguntar al profesor aunque no est\u00c3\u00a9 en horario de clases. Cuando se pregunta al alumnado sobre el uso de distintas herramientas generales (ofim\u00c3\u00a1tica, Kahoot!, generador de nubes de palabras, mapas conceptuales, Canva, Genially y Powtoon), se obtienen las respuestas recogidas en la Figura 4. Donde destaca especialmente el uso bastante extendido de las aplicaciones de ofim\u00c3\u00a1tica y algo menor el uso de Kahoot!, adem\u00c3\u00a1s de un uso pr\u00c3\u00a1cticamente nulo del resto de herramientas. Centr\u00c3\u00a1ndonos en las herramientas digitales matem\u00c3\u00a1ticas, se pregunt\u00c3\u00b3 a los alumnos por las mismas herramientas que a los docentes, obteniendo las respuestas recogidas en la Figura 5. Siguen destacando el editor de f\u00c3\u00b3rmulas de Word y Geogebra, aunque sus usos sean pr\u00c3\u00a1cticamente nulos tal y como se recoge en la Figura 6. As\u00c3, algunas de las respuestas m\u00c3\u00a1s interesantes a la pregunta \u00c2\u00bfTe gustar\u00c3a recibir alg\u00c3\u00ban tipo de formaci\u00c3\u00b3n sobre alguna de las herramientas matem\u00c3\u00a1ticas?, fueron: S\u00c3, sinceramente de todas. Porque recientemente he visto como era la de Geogebra y, me ha parecido que est\u00c3\u00a1 muy avanzada y tiene muy buenas cosas. No tengo ninguna preferencia y la formaci\u00c3\u00b3n deber\u00c3a ser una breve introducci\u00c3\u00b3n o algo por el estilo. S\u00c3, como WxMaxima u otra para saber m\u00c3\u00a1s sobre ellas. A trav\u00c3\u00a9s de alg\u00c3\u00ban seminario o v\u00c3deos explicativos. No me interesa en este momento. Observamos que, a pesar de haber algunas respuestas negativas a recibir alg\u00c3\u00ban tipo de formaci\u00c3\u00b3n, la mayor\u00c3a de alumnos reconoci\u00c3\u00b3 querer formarse en este tipo de herramientas. Y, finalmente, sobre por qu\u00c3\u00a9 creen que estas les pueden ayudar en casa o en el aula, algunas de las respuestas m\u00c3\u00a1s representativas fueron: Una mayor precisi\u00c3\u00b3n en casos de gr\u00c3\u00a1ficas, exactitud en c\u00c3\u00a1lculos y control y organizaci\u00c3\u00b3n cuando se necesario manejar mucho c\u00c3\u00a1lculos diferentes. A la hora de las correcciones son m\u00c3\u00a1s precisas que a lo mejor hacer una representaci\u00c3\u00b3n gr\u00c3\u00a1fica en la pizarra. Haciendo ejercicios que no entiendo, para poder prepararme un examen y as\u00c3 saber si hago bien los ejercicios. No s\u00c3\u00a9 a los dem\u00c3\u00a1s, pero a mi durante la cuarentena me salvaron la evaluaci\u00c3\u00b3n, porque pon\u00c3a los ejercicios y ya est\u00c3\u00a1 ja ja (Pero era porque no me enteraba, lo prometo). Por tanto, a pesar de que en la respuesta anterior hubo alumnos que no quer\u00c3an formarse, en esta pregunta se aprecia una opini\u00c3\u00b3n generalizada en torno a que el uso de este tipo de herramientas puede ayudar en casa y en el aula. Incluso la \u00c3\u00baltima respuesta la he incluido porque hay alumnos para los que el uso de las herramientas inform\u00c3\u00a1ticas es circunstancial y anecd\u00c3\u00b3tico, y no est\u00c3\u00a1 relacionado con el trabajo o el aprendizaje matem\u00c3\u00a1tico. Teniendo en cuenta lo expuesto en las secciones de an\u00c3\u00a1lisis de las respuestas de docentes y alumnos, podemos destacar las siguientes conclusiones importantes: Ambos colectivos consideran \u00c3\u00batil el uso de las herramientas digitales. De manera general, docentes y discentes tienen conocimientos sobre herramientas poco creativas y efectivas, como pueden ser las de ofim\u00c3\u00a1tica; empieza a haber discrepancias en herramientas que necesitan un mayor grado de creatividad como pueden ser Kahoot!, Canva o Genially. El uso de dichas herramientas ofim\u00c3\u00a1ticas est\u00c3\u00a1 muy extendido, pr\u00c3\u00a1cticamente a diario por parte de docentes y alumnos, pero el resto de herramientas son usadas de manera espor\u00c3\u00a1dica. Ambos grupos consideran que las redes sociales pueden ayudar a la comunicaci\u00c3\u00b3n docente\u00e2\u20ac\u201cdiscente y por tanto resaltan la importancia de una conversaci\u00c3\u00b3n fluida y, en cierto modo, distendida. Sobre las herramientas de car\u00c3\u00a1cter matem\u00c3\u00a1tico, el desconocimiento es pr\u00c3\u00a1cticamente absoluto, salvando quiz\u00c3\u00a1 los casos del editor de f\u00c3\u00b3rmulas de Word y Geogebra. El conocimiento del primero de ellos quiz\u00c3\u00a1 sea debido al amplio uso que han reconocido de las herramientas de ofim\u00c3\u00a1tica. El conocimiento y uso de Geogebra quiz\u00c3\u00a1 merezca un estudio m\u00c3\u00a1s en profundidad, pero en cualquier caso es una de las herramientas m\u00c3\u00a1s sencillas e intuitivas de utilizar y que tiene una dilatada experiencia en el sector educativo, por lo que muchos docentes, cada vez m\u00c3\u00a1s, la utilizan en clase con distintos fines. Por ejemplo [11], estudia el uso de Geogebra como facilitador del aprendizaje en el An\u00c3\u00a1lisis, concretamente establece que Geogebra favorece \u00e2\u20ac\u0153la utilizaci\u00c3\u00b3n de las funciones de variable real como instrumento de modelizaci\u00c3\u00b3n y herramienta de soluci\u00c3\u00b3n de situaciones problem\u00c3\u00a1ticas intra y extra matem\u00c3\u00a1ticas\u00e2\u20ac\ufffd, as\u00c3 como \u00e2\u20ac\u0153la visualizaci\u00c3\u00b3n din\u00c3\u00a1mica de los comportamientos funcionales\u00e2\u20ac\ufffd. Aunque algunas herramientas, tanto generales como matem\u00c3\u00a1ticas, son conocidas, la gran mayor\u00c3a de herramientas son, o bien desconocidas, o bien de poca utilizaci\u00c3\u00b3n. Esto nos lleva a preguntarnos si quiz\u00c3\u00a1 se deba a que no han recibido ning\u00c3\u00ban tipo de formaci\u00c3\u00b3n sobre sus diferentes usos. Ya que, en cierta medida no podemos utilizar algo que no conocemos. En esta l\u00c3nea se investig\u00c3\u00b3 en el art\u00c3culo [7] la formaci\u00c3\u00b3n continuada en herramientas inform\u00c3\u00a1ticas del profesorado de Extremadura y del Alentejo portugu\u00c3\u00a9s, determinando que \u00e2\u20ac\u0153en Extremadura [\u00e2\u20ac\u00a6] la formaci\u00c3\u00b3n permanente del profesorado no necesita incidir tanto en la preparaci\u00c3\u00b3n t\u00c3\u00a9cnica en el campo de la inform\u00c3\u00a1tica cuanto en la utilizaci\u00c3\u00b3n did\u00c3\u00a1ctica del ordenador en el contexto escolar\u00e2\u20ac\ufffd. Es decir, tenemos profesores que entienden el uso del ordenador y de herramientas inform\u00c3\u00a1ticas, pero no saben c\u00c3\u00b3mo implementarlas en el aula. As\u00c3, a modo de conclusi\u00c3\u00b3n, observamos que hay consenso en que las nuevas tencnolog\u00c3as est\u00c3\u00a1n aqu\u00c3 para quedarse, por lo que, en nuestro caso particular, docentes y discentes entienden la importancia y el amplio abanico que pueden ofrecer herramientas inform\u00c3\u00a1ticas a la mejora de la calidad educativa. El software WxMaxima es un programa de software libre, esto es, gratuito, lo cu\u00c3\u00a1l facilita su difusi\u00c3\u00b3n y utilizaci\u00c3\u00b3n, a diferencia de otros programas que requieren una licencia de pago. Puede descargarse para distintos sistemas operativos como Windows, Mac OS, Linux o Ubuntu, por lo que pr\u00c3\u00a1cticamente podremos instalarlo en cualquier ordenador e incluso tiene su versi\u00c3\u00b3n en Android, por lo que algunos alumnos podr\u00c3\u00a1n incluso trabajar con sus dispositivos m\u00c3\u00b3viles. Se trata de un programa que, m\u00c3\u00a1s all\u00c3\u00a1 del propio c\u00c3\u00a1lculo, tiene grandes implicaciones pedag\u00c3\u00b3gicas, como apunta Jorquera en [13, p.11-12]: Permite realizar c\u00c3\u00a1lculos reales, de mayor dificultad matem\u00c3\u00a1tica evitando perder tiempo en el c\u00c3\u00a1lculo rutinario, con lo que se puede dedicar m\u00c3\u00a1s tiempo a la explicaci\u00c3\u00b3n de los conceptos que a las habilidades de c\u00c3\u00a1lculo. Ser\u00c3\u00a1 \u00c3\u00batil en algunos casos, e in\u00c3\u00batil en otros. No hay que forzar su uso en todas las ocasiones ya que esto ser\u00c3a un error, pero hay contextos en los cuales el error ser\u00c3a no usarlo. Se fomenta m\u00c3\u00a1s el trabajo creativo en detrimento del rutinario. Por su parte, Geogebra tiene una versi\u00c3\u00b3n de escritorio y una versi\u00c3\u00b3n en l\u00c3nea, ambas gratuitas. Adem\u00c3\u00a1s, en la p\u00c3\u00a1gina de inicio de Geogebra existen un gran abanico de actividades en l\u00c3nea y descargables para realizar en el aula con esta aplicaci\u00c3\u00b3n. Est\u00c3\u00a1 en espa\u00c3\u00b1ol, lo cual es una gran ventaja para muchos docentes y alumnos. Y tiene una interfaz sencilla e intuitiva, que cualquiera puede aprender a manejarla simplemente probando sus distintas herramientas. A pesar de ello, tiene un gran n\u00c3\u00bamero de funciones m\u00c3\u00a1s complejas para crear actividades muy interesantes. En este sentido, \u00e2\u20ac\u0153Geogebra mejora significativamente el aprendizaje de la capacidad de razonamiento y demostraci\u00c3\u00b3n, de comunicaci\u00c3\u00b3n matem\u00c3\u00a1tica as\u00c3 como la capacidad de resoluci\u00c3\u00b3n de problemas\u00e2\u20ac\ufffd [12], as\u00c3 como \u00e2\u20ac\u0153contribuy\u00c3\u00b3 a que mejorasen sus actitudes hacia las matem\u00c3\u00a1ticas durante su uso, exhibiendo gusto, implicaci\u00c3\u00b3n y autoconfianza en matem\u00c3\u00a1ticas\u00e2\u20ac\ufffd [12]. Veamos, mediante un ejercicio de la prueba de acceso a la Universidad de Extremadura correspondiente al bloque de Geometr\u00c3a de la asignatura Matem\u00c3\u00a1ticas II, c\u00c3\u00b3mo WxMaxima y Geogebra se complementan para una resoluci\u00c3\u00b3n sencilla. Para ello, resolveremos el ejercicio manualmente y con ambos programas, argumentando cu\u00c3\u00a1l es m\u00c3\u00a1s idoneo en cada situaci\u00c3\u00b3n. Este ejercicio apareci\u00c3\u00b3 en la convocatoria ordinaria del curso 2020\u00e2\u20ac\u201c2021 y su encunciado fue el siguiente: Sea el plano \u00ce \u00ce de ecuaci\u00c3\u00b3n 2\u00e2\ufffd\u00a2x+y\u00e2\u02c6\u2019z\u00e2\u02c6\u20192=02\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a7202x+y-z-2=02 italic_x + italic_y - italic_z - 2 = 0 y la recta r\u011f\ufffd\u2018\u0178ritalic_r dada por x3=y\u00e2\u02c6\u20192\u00e2\u02c6\u20193=z\u00e2\u02c6\u201913\u011f\ufffd\u2018\u00a53\u011f\ufffd\u2018\u00a623\u011f\ufffd\u2018\u00a713 start_ARG italic_x end_ARG start_ARG 3 end_ARG = divide start_ARG italic_y - 2 end_ARG start_ARG - 3 end_ARG = divide start_ARG italic_z - 1 end_ARG start_ARG 3 end_ARG. Estudie la posici\u00c3\u00b3n relativa de la recta respecto al plano. Calcule la distancia de la recta al plano. Debemos tener en cuenta que un punto de la recta es P=(0,2,1)\u011f\ufffd\u2018\u01920.2.1P=(0,2,1)italic_P = ( 0,2,1 ) y su vector director es u\u00e2\u2020\u2019=(3,\u00e2\u02c6\u20193,3)\u00e2\u2020\u2019\u011f\ufffd\u2018\u00a233.3 start_ARG italic_u end_ARG = ( 3 , - 3,3 ). Por otro lado el vector normal del plano es n\u00e2\u2020\u2019=(2,1,\u00e2\u02c6\u20191)\u00e2\u2020\u2019\u011f\ufffd\u2018\u203a2.11 start_ARG italic_n end_ARG = ( 2,1 , - 1 ). As\u00c3, como y comprobando si P\u011f\ufffd\u2018\u0192Pitalic_P pertenece, o no, a \u00ce \u00ce , Luego el plano y la recta son paralelos. La distancia vendr\u00c3\u00a1 dada por La idea que tenemos que seguir es la misma que la resoluci\u00c3\u00b3n manual. En primer lugar, definimos los vectores director de la recta y normal del plano, y realizamos su producto escalar (Figura 7): Se define la funci\u00c3\u00b3n que nos indica si un punto pertenece o no al plano \u00ce \u00ce y sustituimos el punto P=(0,2,1)\u011f\ufffd\u2018\u01920.2.1P=(0,2,1)italic_P = ( 0,2,1 ) (Figura 8): Como u\u00e2\u2020\u2019\u00e2\u2039\u2026n\u00e2\u2020\u2019=0\u00e2\u2039\u2026\u00e2\u2020\u2019\u011f\ufffd\u2018\u00a2\u00e2\u2020\u2019\u011f\ufffd\u2018\u203a0 start_ARG italic_u end_ARG \u00e2\u2039\u2026 over\u00e2\u2020\u2019 start_ARG italic_n end_ARG = 0 y P\u00e2\u02c6\u2030\u00ce \u011f\ufffd\u2018\u0192\u00ce P \u00e2\u02c6\u2030 roman_\u00ce , se deduce que la recta r\u011f\ufffd\u2018\u0178ritalic_r y el plano \u00ce \u00ce son paralelos, por lo que su distancia puede ser calculada como sigue (Figura 9) Y el ejercicio quedar\u00c3a resuelto. Primero definimos el plano y la recta dados, as\u00c3 como el punto P=(0,2,1)\u011f\ufffd\u2018\u01920.2.1P=(0,2,1)italic_P = ( 0,2,1 ) (Figura 10). A continuaci\u00c3\u00b3n, trazamos la recta perpendicular al plano que pasa por P\u011f\ufffd\u2018\u0192Pitalic_P y se\u00c3\u00b1alamos como P\u00e2\u20ac\u00b2superscript\u011f\ufffd\u2018\u0192\u00e2\u20ac\u00b2P^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT el punto donde intersecta esta perpendicular con el plano \u00ce \u00ce , es decir, la proyecci\u00c3\u00b3n de P\u011f\ufffd\u2018\u0192Pitalic_P en \u00ce \u00ce (Figura 11) Para finalizar, s\u00c3\u00b3lo tendremos que utilizar la herramienta de distancia se\u00c3\u00b1alando los puntos P\u011f\ufffd\u2018\u0192Pitalic_P y P\u00e2\u20ac\u00b2superscript\u011f\ufffd\u2018\u0192\u00e2\u20ac\u00b2P^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT (Figura 12). Obteniendo el resultado aproximado de 0\u00e2\u20ac\u00b2\u00e2\ufffd\u00a241\u00e2\u2030\u02c616superscript0\u00e2\u20ac\u00b241160^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT 41 \u00e2\u2030\u02c6 divide start_ARG 1 end_ARG start_ARG square-root start_ARG 6 end_ARG end_ARG, concluyendo as\u00c3 el ejercicio. En este caso es clara la diferencia entre las tres resoluciones: La resoluci\u00c3\u00b3n manual es tediosa y falta de visualizaci\u00c3\u00b3n, algo clave en la parte de Geometr\u00c3a, ya que es la parte de las matem\u00c3\u00a1ticas m\u00c3\u00a1s visual. La resoluci\u00c3\u00b3n con WxMaxima hace sencillos los c\u00c3\u00a1lculos, pero de nuevo carece de visualizaci\u00c3\u00b3n. Bien es cierto que, adem\u00c3\u00a1s, tiene un lenguaje particular y es necesario saber escribir las operaciones y funciones, ya que, de lo contrario, podemos tardar mucho en resolver un ejercicio. La resoluci\u00c3\u00b3n con Geogebra es eminentemente visual, de hecho, para resolver el primer apartado basta con representar ambos objetos para darnos cuenta de su posici\u00c3\u00b3n relativa. M\u00c3\u00a1s complicado es, sin embargo, el segundo apartado, ya que debemos conocer que la distancia entre una recta y un plano paralelos es la distancia entre un punto cualquiera de la recta hasta su proyecci\u00c3\u00b3n en el plano, lo cual no es tan sencillo de realizar en Geogebra ya que tendremos que calcular la perpendicular, la intersecci\u00c3\u00b3n y despu\u00c3\u00a9s la distancia. Adem\u00c3\u00a1s, observamos que la distancia obtenida es una aproximaci\u00c3\u00b3n y no el valor exacto. Por tanto, mi conclusi\u00c3\u00b3n en este ejercicio es que la soluci\u00c3\u00b3n \u00c3\u00b3ptima vendr\u00c3a dada por una mezcla de los dos programas, el primer apartado se resolver\u00c3a f\u00c3\u00a1cilmente con Geogebra mientras que para el segundo apartado emplear\u00c3a WxMaxima. Teniendo en cuenta que a lo largo del trabajo se ha pretendido inculcar una visi\u00c3\u00b3n de las herramientas digitales como facilitadoras del aprendizaje, pero que tanto docentes como alumnos no conocen su funcionamiento, el autor propone un curso/seminario formativo orientado a docentes. Estar\u00c3\u00a1 compuesto por cuatro sesiones y se trabajar\u00c3\u00a1n los aspectos y utilidades fundamentales de WxMaxima y Geogebra recogidos en las Tablas 1, 2, 3 y 4. En total, este curso/seminario consta de 21 v\u00c3deotutoriales con una duraci\u00c3\u00b3n de dos horas y media aproximadamente. Trece de ellos est\u00c3\u00a1n dedicados, entre las dos primeras sesiones, a WxMaxima, con una duraci\u00c3\u00b3n de 1 hora y 25 minutos aproximadamente; y ocho v\u00c3deos, los correspondientes a las sesiones tercera y cuarta, dedicados a Geogebra, con una duraci\u00c3\u00b3n aproximada de una hora y cinco minutos. Como hemos venido haciendo hincapi\u00c3\u00a9, su objetivo es brindar a los docentes las herramientas y utilidades b\u00c3\u00a1sicas de estos dos programas para que puedan adaptar los ejercicios del d\u00c3a a d\u00c3a en el aula e implementar el uso de las herramientas digitales para la resoluci\u00c3\u00b3n y visualizaci\u00c3\u00b3n de contenidos matem\u00c3\u00a1ticos, as\u00c3 como de la mejora de la asimilaci\u00c3\u00b3n de los conceptos y una mejora de la predisposici\u00c3\u00b3na a aprender matem\u00c3\u00a1ticas. A modo de conclusi\u00c3\u00b3n, podemos extraer algunas de las ideas fundamentales que se han desarrollado a lo largo del trabajo: En primer lugar, el aprendizaje del contenido matem\u00c3\u00a1tico y de procesos de resoluci\u00c3\u00b3n de problemas no est\u00c3\u00a1 re\u00c3\u00b1ido con el hecho de aprender el uso de herramientas digitales. Esto se debe a que ambos m\u00c3\u00a9todos de resoluci\u00c3\u00b3n se complementan. Hemos visto, dentro de los ejercicios resueltos, que un programa puede servir mejor que el otro para \u00e2\u20ac\u0153hacer cuentas\u00e2\u20ac\ufffd o para representar, pero en cualquiera de los dos programas, se ha de tener una visi\u00c3\u00b3n general de la parte te\u00c3\u00b3rica para poder seguir el hilo argumental del problema y obtener la soluci\u00c3\u00b3n. Esto puede ayudar a la autocorrecci\u00c3\u00b3n de los ejercicios que, habitualmente, los alumnos tienen como tarea para casa; tambi\u00c3\u00a9n puede ayudar a que alumnos con altas capacidades indaguen e investiguen en mayor profundidad, buscando nuevos retos y problemas m\u00c3\u00a1s complicados; e incluso, puede ayudar, al aprendizaje por descubrimiento o al just in time teaching, es decir, darle respuestas al alumno en el momento en que se haga las cuestiones, por lo que los programas pueden servir para dejarles probar y, como docentes, les ayudaremos en sus procesos de descubrimiento. En segundo lugar, creo que hay mucho camino por delante en cuanto a la implantaci\u00c3\u00b3n de las nuevas tecnolog\u00c3as en los centros educativos. Aunque es verdad que cada vez se invierte m\u00c3\u00a1s en adaptar las aulas a las nuevas tecnolog\u00c3as (pizarras digitales, proyectores o aulas virtuales), no podemos decir lo mismo sobre la inversi\u00c3\u00b3n en la formaci\u00c3\u00b3n de los docentes en el uso de estas herramientas. Esto implica que las nuevas tecnolog\u00c3as pueden ser en ciertos casos, vistas como una fuente adicional de estr\u00c3\u00a9s en el profesorado, por ejemplo ante la posibilidad de que el docente tenga preparada una clase y, el d\u00c3a que pretenda impartirla, no funcione internet; o que las herramientas sean vistas m\u00c3\u00a1s como un elemento extra\u00c3\u00b1o que como un medio educativo. Tampoco los docentes conocen todas las funcionalidades que estas les ofrecen, por tanto, muchos de ellos seguir\u00c3\u00a1n con sus rutinas sin saber los beneficios de dichas herramientas. Como hemos dicho, hay mucho camino por recorrer, lo cual es bueno, pr\u00c3\u00a1cticamente cualquier iniciativa formativa ser\u00c3\u00a1 bien acogida por la comunidad educativa, tanto de formaci\u00c3\u00b3n al profesorado como de formaci\u00c3\u00b3n al alumnado, ya que ambos colectivos observan que las herramientas digitales tienen un gran potencial, pero no saben c\u00c3\u00b3mo aprovecharlo. Por \u00c3\u00baltimo, teniendo en cuenta estas conclusiones, podemos proponer las siguientes l\u00c3neas de investigaci\u00c3\u00b3n para las que ser\u00c3\u00a1 necesario un an\u00c3\u00a1lisis m\u00c3\u00a1s detallado de las diferencias en el uso y en la concepci\u00c3\u00b3n de las herramientas digitales en la educaci\u00c3\u00b3n secundaria: Lo primero en lo que deber\u00c3amos pensar es en realizar una encuesta a un espacio muestral m\u00c3\u00a1s amplio y elegido considerando ciertas variables (formaci\u00c3\u00b3n inicial del profesorado, titulaci\u00c3\u00b3n de acceso al cuerpo de profesores de secundaria, a\u00c3\u00b1os de experiencia como docente, contexto socioecon\u00c3\u00b3mico del centro, etc.), con el objetivo de poder obtener conclusiones m\u00c3\u00a1s significativas para una poblaci\u00c3\u00b3n mayor. Una vez realizado el curso introductorio de las herramientas digitales WxMaxima y Geogebra, realizar un seguimiento, por ejemplo, tomar dos grupos de alumnos que cursen la misma asignatura de matem\u00c3\u00a1ticas en el mismo curso. A uno de estos grupos se le asignar\u00c3\u00a1 un profesor que no haya realizado el curso introductorio y seguir\u00c3\u00a1 una metodolog\u00c3a sin TIC. Al otro grupo, se le asignar\u00c3\u00a1 un profesor que s\u00c3 haya realizado el curso, que haya intentado introducir estas herramientas a lo largo de las explicaciones. Finalmente, se comparar\u00c3\u00a1 si el uso de las herramientas digitales ha influido no s\u00c3\u00b3lo en los resultados, sino en la aceptaci\u00c3\u00b3n de la asignatura de matem\u00c3\u00a1ticas, en la motivaci\u00c3\u00b3n con que van a clase y en la satisfacci\u00c3\u00b3n y la percepci\u00c3\u00b3n de aprendizaje de los alumnos. Por \u00c3\u00baltimo, en caso de que lo anterior refleje un aumento significativo de los resultados acad\u00c3\u00a9micos y la motivaci\u00c3\u00b3n del alumno por la asignatura, cabr\u00c3a plantear un curso de material m\u00c3\u00a1s avanzado con el que puedan seguir profundizando en el uso de WxMaxima y Geogebra los docentes que hicieron el primer curso. As\u00c3, de nuevo, tras un dominio m\u00c3\u00a1s avanzado de las herramientas podr\u00c3amos hacer un estudio comparativo entre ambos grupos, uno con un docente que tenga un menor dominio, que solo haya realizado el primer curso, y otro con un profesor que haya realizado el curso avanzado.",
        "keywords": ""
    },
    {
        "id": 8,
        "title": "Algorithms for constrained optimal transport",
        "abstract": "AbstractWe derive iterative scaling algorithms of the Sinkhorn-Knopp (SK) type for constrained optimal transport. The constraints are in the form of prior-imposed zeroes in the transport plan. Based on classical Bregman arguments, we prove asymptotic convergence of our algorithms to a unique optimal solution. New insights obtained from the convergence proof are highlighted. An example from electrical vehicle charging in a smart city context is outlined, in which the prior zero-constraints prevent energy from being transported from some providers to some vehicles.",
        "corpus": "1 We derive iterative scaling algorithms of the Sinkhorn-Knopp (SK) type for constrained optimal transport. The constraints are in the form of prior-imposed zeroes in the transport plan. Based on classical Bregman arguments, we prove asymptotic convergence of our algorithms to a unique optimal solution. New insights obtained from the convergence proof are highlighted. An example from electrical vehicle charging in a smart city context is outlined, in which the prior zero-constraints prevent energy from being transported from some providers to some vehicles. Optimal Transport (OT) has emerged as a key enabling mathematical technology which is driving a growing number of contemporary engineering applications in fields such as machine learning, image processing, and in optimization and control [1], [2], [3]. The field is an old one, dating back to Monge in the 18th century. Nevertheless, OT is now attracting accelerated attention from both theoreticians and practitioners alike, with widespread application in engineering practice. OT refers to a class of problems in which we seek to transport a finite resource (e.g.\u00c2 mass) from a distributed source to a distributed target, in some optimal manner. For example, the classical problems of Monge and Kantorovitch relate to the transportation of a distributed pile of sand [4] from one location to another. The contemporary analogues of these formulations (for example, in economics) arise in resource (re)allocation problems, and in supply-demand matching problems\u00c2 [5]. Closely related problems arise in key machine learning (ML) settings, such as domain adaptation. Here, source data are optimally adapted (i.e.\u00c2 transported) for use in a related, but distinct, target domain\u00c2 [6]. An example is \u00e2\u20ac\u0153data repair\u00e2\u20ac\ufffd, in which OT is used to de-bias ML tasks in order to improve their fairness properties. Classifiers and recommender systems\u00e2\u20ac\u201dtrained on data with fairness deficiencies such as representation bias, dependence on protected attributes, etc.\u00e2\u20ac\u201dcan be fairness-repaired using methods of OT [7]. In this paper, we confine ourselves to the discrete case, in which the resource (mass) is distributed across a finite (though typically large) number of states in both the source and target. For every pair of source-target states, the designer specifies a cost per unit mass of transporting the resource from this source state to this target state. The OT problem then involves the design of a transport plan that specifies the amount of resource to be transported for every one of these source-target state pairs, in a way that minimizes the total cost of transport. A feature of our setting of the OT problem in this paper is that we impose constraints in which some source states are not allowed to transport to some target states. These prior zero-transport constraints may arise for a variety of reasons. For example, in economics, certain producers may not be allowed to supply a product to certain consumers. In fairness-aware domain adaptation for ML (above), data for a particular demographic group may not be mapped to a different demographic group. These OT problems give rise to linear programs of very large scale\u00c2 [8]. Linear programming solvers are known to scale poorly, and much of the current OT work focuses on regularizing the classical OT problem to ensure tractability at scale. The best known of these approaches is the entropic regularisation of the OT problem\u00c2 [8]. In essence, this amounts to the addition of an extra term in the (total cost) objective, which penalizes a specified divergence of the transport plan from a prior-defined ideal plan [9]. The resulting optimization problem is then strongly convex on a compact convex set, and can be solved efficiently using a Sinkhorn-Knopp-type (SK) iterative scaling algorithm, with its favourable large-scale computational properties\u00c2 [10], [11]. These computational OT results and guarantees\u00e2\u20ac\u201dbased on the SK algorithm\u00e2\u20ac\u201d have been central to the widespread adoption of the OT paradigm in applications, particularly in ML [4], [6], [12], [13]. In contrast to previous results in the literature, our purpose in this paper is to consider OT problems in which some elements of the transport plan are forced to be zero a priori, and to derive iterative scaling algorithms of the SK-type to solve these problems. We use Bregman-type arguments [14] to prove convergence of our algorithms to the (unique) solution of the OT problems under consideration. We outline an application of our results in a smart cities context, where prior zeroes in the transport plan are an important constraint. OT problems are often cast in the language of probability, where the resource (mass) to be transported is a probability measure, and so the net resource (mass) is normalized to one. The transport plan is thus a bivariate probability mass function (pmf), and the source and target distributions are its two marginals. We speak of a transport plan that moves the source distribution (marginal) to the target distribution (marginal). In this way, OT can be viewed as a mathematical framework for measuring the distance between (source and target marginal) probability distributions, this distance being the minimal expected cost associated with the optimal transport plan\u00c2 [4]. This Kantorovich-Rubinstein (also called Wasserstein or earth-mover\u00e2\u20ac\u2122s) norm\u00c2 [4] for classical entropy-regularized OT gives rise to a unique solution of a strongly convex optimization problem on a compact convex support\u00c2 [15], [16], with linear convergence of the SK iterative scaling algorithm to this unique solution\u00c2 [17]. If, as in this paper, we impose prior zero-constraints on some elements of the transport plan, there may not exist a plan that satisfies exact marginal constraints at the source and target, as already noted. Another situation in which a transport plan satisfying exact marginal constraints does not exist is unbalanced OT (UOT) [16], in which the prescribed net masses of the source and target are not the same. Earlier, in\u00c2 [18], an SK-type iterative scaling algorithm was derived for unconstrained UOT (i.e.\u00c2 without prior zero-constraints on the transport plan), by relaxing the source and target marginal constraints via extra terms in the cost that penalize noncompliance with the marginal constraints. This was shown to converge linearly to a unique solution. In [16], the authors study the UOT case with prior zero-constraints on the transport plan. They prove that the SK algorithm has two convergent subsequences in this case and they propose a transport plan which is the component-wise geometric mean of the limits plans of the two convergent subsequences The paper is organized as follows: in Section\u00c2 III, our OT problem is specified with prior constraints on the pattern of the transport plan. After developing background material, two iterative scaling algorithms are presented in Section IV for OT problems with prior zero-constraints. Section V presents some properties of the resulting OT plans. Section VI provides the proof of convergence or our algorithms. Finally, a use-case from the domain of smart mobility is outlined in Section VII, illustrating the efficacy of our new algorithms. Consider an OT problem in which we have a finite number, m\u011f\ufffd\u2018\u0161mitalic_m, of source agents (i.e.\u00c2 source states), i=1,2,\u00e2\u20ac\u00a6,m\u011f\ufffd\u2018\u201312\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u0161i=1,2, = 1 , 2 , \u00e2\u20ac\u00a6 , italic_m, and a finite number, n\u011f\ufffd\u2018\u203anitalic_n, of target agents (i.e.\u00c2 target states), j=1,2,\u00e2\u20ac\u00a6,n\u011f\ufffd\u2018\u201412\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u203aj=1,2, = 1 , 2 , \u00e2\u20ac\u00a6 , italic_n. Suppose each source agent, i\u011f\ufffd\u2018\u2013iitalic_i, has capacity or mass, u~i>0subscript~\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u20130 start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT > 0, and each target agent, j\u011f\ufffd\u2018\u2014jitalic_j, desires a capacity or mass, v~j>0subscript~\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u20140 start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT > 0. We wish to transport the masses of the source agents to the target agents. For the time being, we impose mass balance (conservation), i.e. that is, \u011f\ufffd\u0178\ufffd\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2u~=\u011f\ufffd\u0178\ufffd\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2v~superscript1\u00e2\u20ac\u00b2~\u011f\ufffd\u2018\u00a2superscript1\u00e2\u20ac\u00b2~\u011f\ufffd\u2018\u00a3{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT over~ start_ARG italic_u end_ARG = bold_1 start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT over~ start_ARG italic_v end_ARG where \u011f\ufffd\u0178\ufffd1{ is a vector of ones, of appropriate length. Let ti\u00e2\ufffd\u00a2j\u00e2\u2030\u00a50subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140t_{ij} 0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT \u00e2\u2030\u00a5 0 be the mass or capacity that source agent, i\u011f\ufffd\u2018\u2013iitalic_i, transports to target agent, j\u011f\ufffd\u2018\u2014jitalic_j. We will refer to the m\u00c3\u2014n\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u203am nitalic_m \u00c3\u2014 italic_n matrix, T={ti\u00e2\ufffd\u00a2j}\u011f\ufffd\u2018\u2021subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014T= = { italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT }, as the transport plan. As a consequence of the capacity constraints of the source and target agents, we must have or, T\u00e2\ufffd\u00a2\u011f\ufffd\u0178\ufffd=u~\u011f\ufffd\u2018\u20211~\u011f\ufffd\u2018\u00a2T{ bold_1 = over~ start_ARG italic_u end_ARG, and or, T\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2\u011f\ufffd\u0178\ufffd=v~superscript\u011f\ufffd\u2018\u2021\u00e2\u20ac\u00b21~\u011f\ufffd\u2018\u00a3T^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT bold_1 = over~ start_ARG italic_v end_ARG. Note that constraints (1), (2) and (3) imply that Next, suppose that a specific source agent, i\u011f\ufffd\u2018\u2013iitalic_i, never transports to a specific target agent, j\u011f\ufffd\u2018\u2014jitalic_j, so that ti\u00e2\ufffd\u00a2j=0subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140t_{ij}=0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 0. We let \u011f\ufffd\u2019\u00b5\u011f\ufffd\u2019\u00b5 be the set of these prior non-transporting index pairs: The set of allowable transport plans is given by We assume that for every i\u011f\ufffd\u2018\u2013iitalic_i, that there is at least one (i,j)\u00e2\u02c6\u2030\u011f\ufffd\u2019\u00b5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5(i,j) italic_i , italic_j ) \u00e2\u02c6\u2030 caligraphic_Z and for every j\u011f\ufffd\u2018\u2014jitalic_j, there is also at least one (i,j)\u00e2\u02c6\u2030\u011f\ufffd\u2019\u00b5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5(i,j) italic_i , italic_j ) \u00e2\u02c6\u2030 caligraphic_Z; i.e.\u00c2 if ti\u00e2\ufffd\u00a2j>0subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140t_{ij}>0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT > 0 for all (i,j)\u00e2\u02c6\u2030\u011f\ufffd\u2019\u00b5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5(i,j) italic_i , italic_j ) \u00e2\u02c6\u2030 caligraphic_Z then, T\u011f\ufffd\u2018\u2021Titalic_T has no zero-rows or zero-columns. If \u011f\ufffd\u2019\u00b5\u011f\ufffd\u2019\u00b5 is empty, i.e.\u00c2 if every source agent can transport to every target agent, then the marginal constraints (2) and (3) are feasible (i.e. there is at least one solution in \u011f\ufffd\u2019\u00af\u011f\ufffd\u2019\u00af for example, T\u00e2\u2030\u00a1u~\u00e2\ufffd\u00a2v~\u00e2\u20ac\u00b2/\u011f\ufffd\u0178\ufffd\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2v~\u011f\ufffd\u2018\u2021~\u011f\ufffd\u2018\u00a2superscript~\u011f\ufffd\u2018\u00a3\u00e2\u20ac\u00b2superscript1\u00e2\u20ac\u00b2~\u011f\ufffd\u2018\u00a3T \u00e2\u2030\u00a1 over~ start_ARG italic_u end_ARG over~ start_ARG italic_v end_ARG start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT / bold_1 start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT over~ start_ARG italic_v end_ARG). However, if \u011f\ufffd\u2019\u00b5\u011f\ufffd\u2019\u00b5 is non-empty, then (2) and (3) may not be feasible (i.e.\u00c2 there may not be any solution in \u011f\ufffd\u2019\u00af\u011f\ufffd\u2019\u00af An example is given by m=n=2\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u203a2m=n=2italic_m = italic_n = 2 and \u011f\ufffd\u2019\u00b5\u00e2\u2030\u00a1{(2,2)}\u011f\ufffd\u2019\u00b522 \u00e2\u2030\u00a1 { ( 2 , 2 ) }: Suppose that there is a cost, ci\u00e2\ufffd\u00a2j\u00e2\u02c6\u02c6\u00e2\u201e\ufffdsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u00e2\u201e\ufffdc_{ij} start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R, of moving a unit mass from source, i\u011f\ufffd\u2018\u2013iitalic_i, to target, j\u011f\ufffd\u2018\u2014jitalic_j. Then, the total cost of transport is \u00e2\u02c6\u2018(i,j)\u00e2\u02c6\u2030\u011f\ufffd\u2019\u00b5ci\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2ti\u00e2\ufffd\u00a2jsubscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014 start_POSTSUBSCRIPT ( italic_i , italic_j ) \u00e2\u02c6\u2030 caligraphic_Z end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT This gives rise to the constrained OT problem: Next, suppose that it is also desirable for T\u011f\ufffd\u2018\u2021Titalic_T to be close to some ideal (desired) transport plan, T~\u00e2\u02c6\u02c6\u011f\ufffd\u2019\u00af~\u011f\ufffd\u2018\u2021\u011f\ufffd\u2019\u00af start_ARG italic_T end_ARG \u00e2\u02c6\u02c6 caligraphic_T (8) with t~i\u00e2\ufffd\u00a2j>0subscript~\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140 start_ARG italic_t end_ARG start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT > 0 for (i,j)\u00e2\u02c6\u2030\u011f\ufffd\u2019\u00b5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5(i,j) italic_i , italic_j ) \u00e2\u02c6\u2030 caligraphic_Z. We therefore modify the cost to where \u00ce\u00b30>0subscript\u011f\ufffd\u203a\u00be00 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT > 0 is a pre-assigned regularization constant, and the Kullback-Leibler (K\u00e2\ufffd\u00a2L\u011f\ufffd\ufffd\u00be\u011f\ufffd\ufffd\u00bfKLitalic_K italic_L) divergence [9] of T\u011f\ufffd\u2018\u2021Titalic_T from T~~\u011f\ufffd\u2018\u2021 start_ARG italic_T end_ARG is defined as where, for any two scalar, t\u00e2\u2030\u00a50\u011f\ufffd\u2018\u00a10t 0italic_t \u00e2\u2030\u00a5 0 and t~>0~\u011f\ufffd\u2018\u00a10 start_ARG italic_t end_ARG > 0, we define One may readily show that, for all t\u00e2\u2030\u00a50\u011f\ufffd\u2018\u00a10t 0italic_t \u00e2\u2030\u00a5 0 and t~>0~\u011f\ufffd\u2018\u00a10 start_ARG italic_t end_ARG > 0, k\u00e2\ufffd\u00a2l\u00e2\ufffd\u00a2(t|t~)\u00e2\u2030\u00a50\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2122conditional\u011f\ufffd\u2018\u00a1~\u011f\ufffd\u2018\u00a10kl(t| 0italic_k italic_l ( italic_t | over~ start_ARG italic_t end_ARG ) \u00e2\u2030\u00a5 0; also k\u00e2\ufffd\u00a2l\u00e2\ufffd\u00a2(t|t~)=0\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2122conditional\u011f\ufffd\u2018\u00a1~\u011f\ufffd\u2018\u00a10kl(t| italic_l ( italic_t | over~ start_ARG italic_t end_ARG ) = 0 iff t=t~\u011f\ufffd\u2018\u00a1~\u011f\ufffd\u2018\u00a1t= = over~ start_ARG italic_t end_ARG. Hence, for all T\u00e2\u02c6\u02c6\u011f\ufffd\u2019\u00af\u011f\ufffd\u2018\u2021\u011f\ufffd\u2019\u00afT \u00e2\u02c6\u02c6 caligraphic_T, K\u00e2\ufffd\u00a2L\u00e2\ufffd\u00a2(T|T~)\u00e2\u2030\u00a50\u011f\ufffd\ufffd\u00be\u011f\ufffd\ufffd\u00bfconditional\u011f\ufffd\u2018\u2021~\u011f\ufffd\u2018\u20210KL(T| 0italic_K italic_L ( italic_T | over~ start_ARG italic_T end_ARG ) \u00e2\u2030\u00a5 0 and K\u00e2\ufffd\u00a2L\u00e2\ufffd\u00a2(T|T~)=0\u011f\ufffd\ufffd\u00be\u011f\ufffd\ufffd\u00bfconditional\u011f\ufffd\u2018\u2021~\u011f\ufffd\u2018\u20210KL(T| italic_L ( italic_T | over~ start_ARG italic_T end_ARG ) = 0 iff T=T~\u011f\ufffd\u2018\u2021~\u011f\ufffd\u2018\u2021T= = over~ start_ARG italic_T end_ARG. Note again that original optimization problem (9) is a linear programming problem and may be computationally burdensome to solve. So, a common solution approach is approximately to solve the original problem (9) by minimizing the regularized cost in (11) with \u00ce\u00b30subscript\u011f\ufffd\u203a\u00be0 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT small but postive. This problem can be solved more efficiently than the original problem. Next, note that ci\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2ti\u00e2\ufffd\u00a2j=\u00ce\u00b30\u00e2\ufffd\u00a2ti\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2log\u00e2\ufffd\u00a1(1exp\u00e2\ufffd\u00a1(\u00e2\u02c6\u2019ci\u00e2\ufffd\u00a2j/\u00ce\u00b30))subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u203a\u00be0subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20141subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u203a\u00be0c_{ij}t_{ij}= start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = italic_\u00ce\u00b3 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT roman_log ( divide start_ARG 1 end_ARG start_ARG roman_exp ( - italic_c start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT / italic_\u00ce\u00b3 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) end_ARG ) and define Then, whenever ti\u00e2\ufffd\u00a2j\u00e2\u2030 0subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140t_{ij} 0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT \u00e2\u2030 0, (16) also holds for ti\u00e2\ufffd\u00a2j=0subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140t_{ij}=0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 0 , (i,j)\u00e2\u02c6\u2030\u011f\ufffd\u2019\u00b5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5(i,j) italic_i , italic_j ) \u00e2\u02c6\u2030 caligraphic_Z. Hence, cost (11) can be expressed as \u00ce\u00b30\u00e2\ufffd\u00a2K\u00e2\ufffd\u00a2L\u00e2\ufffd\u00a2(T|K)+\u00e2\u02c6\u2018(i,j)\u00e2\u02c6\u2030\u011f\ufffd\u2019\u00b5\u00ce\u00b30\u00e2\ufffd\u00a2(t~i\u00e2\ufffd\u00a2j\u00e2\u02c6\u2019ki\u00e2\ufffd\u00a2j)subscript\u011f\ufffd\u203a\u00be0\u011f\ufffd\ufffd\u00be\u011f\ufffd\ufffd\u00bfconditional\u011f\ufffd\u2018\u2021\u011f\ufffd\ufffd\u00besubscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5subscript\u011f\ufffd\u203a\u00be0subscript~\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_K italic_L ( italic_T | italic_K ) + \u00e2\u02c6\u2018 start_POSTSUBSCRIPT ( italic_i , italic_j ) \u00e2\u02c6\u2030 caligraphic_Z end_POSTSUBSCRIPT italic_\u00ce\u00b3 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( over~ start_ARG italic_t end_ARG start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT - italic_k start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ). Therefore, we consider the new optimization problem: where \u011f\ufffd\u2019\u00b0\u00e2\ufffd\u00a2(u~,v~)\u011f\ufffd\u2019\u00b0~\u011f\ufffd\u2018\u00a2~\u011f\ufffd\u2018\u00a3 ( over~ start_ARG italic_u end_ARG , over~ start_ARG italic_v end_ARG ) is given by (10). When the optimization problem (17) is feasible (i.e.\u00c2 \u011f\ufffd\u2019\u00b0\u00e2\ufffd\u00a2(u~,v~)\u011f\ufffd\u2019\u00b0~\u011f\ufffd\u2018\u00a2~\u011f\ufffd\u2018\u00a3 ( over~ start_ARG italic_u end_ARG , over~ start_ARG italic_v end_ARG ) is non-empty), its solution can be obtained using the Sinkhorn-Knopp (SK) Algorithm [17]. Sinkhorn-Knopp (SK) Algorithm. Initialize d2\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(0)=1subscript\u011f\ufffd\u2018\u20182\u011f\ufffd\u2018\u201401d_{2j}(0)=1italic_d start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT ( 0 ) = 1. Iterate for l=0,1,\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u212201\u00e2\u20ac\u00a6l=0,1, = 0 , 1 , \u00e2\u20ac\u00a6 \u00e2\u2013\u00a1\u00e2\u2013\u00a1{ 220.50885pt} If (17) is feasible, the sequence, {T\u00e2\ufffd\u00a2(l)}\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u2122 italic_T ( italic_l ) } converges to a limit, T\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018\u2021T^{*}italic_T start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT, which is the unique minimizer for (17) [16]. If ti\u00e2\ufffd\u00a2j\u00e2\u02c6\u2014=0subscriptsuperscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140t^{*}_{ij}=0italic_t start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 0 for some (i,j)\u00e2\u02c6\u2030\u011f\ufffd\u2019\u00b5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5(i,j) italic_i , italic_j ) \u00e2\u02c6\u2030 caligraphic_Z, then either {di\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2(l)}subscript\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2122 italic_d start_POSTSUBSCRIPT italic_i italic_i end_POSTSUBSCRIPT ( italic_l ) } or {d2\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(l)}subscript\u011f\ufffd\u2018\u20182\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u2122 italic_d start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT ( italic_l ) } do not converge. If (17) is not feasible, the sequence, {T\u00e2\ufffd\u00a2(l)}\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u2122 italic_T ( italic_l ) } has two convergent subsequences with different limits [16]. If \u011f\ufffd\u2019\u00b5\u011f\ufffd\u2019\u00b5 is non-empty, it may not be possible to simultaneously satisfy the marginal constraints, (2) and (3). If\u00e2\u20ac\u201das already imposed in (8)\u00e2\u20ac\u201dT\u011f\ufffd\u2018\u2021Titalic_T has no enforced rows of zeroes, the row constraints can always be achieved, as explained in Remark 2, below. Therefore, consider the situation in which row constraints (2) are satisfied but column constraints (3) are not necessarily satisfied. Instead of requiring satisfaction of the column constraints, we add a KL-based penalty term to the cost function, which is a measure of non-compliance with the column constraints, v~~\u011f\ufffd\u2018\u00a3 start_ARG italic_v end_ARG. We therefore consider a new optimization problem given by where K\u00e2\ufffd\u00a2L\u00e2\ufffd\u00a2(vT|v~)=\u00e2\u02c6\u2018j=1nk\u00e2\ufffd\u00a2l\u00e2\ufffd\u00a2(vTj|v~j)\u011f\ufffd\ufffd\u00be\u011f\ufffd\ufffd\u00bfconditionalsubscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2021~\u011f\ufffd\u2018\u00a3superscriptsubscript\u011f\ufffd\u2018\u20141\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2122conditionalsubscript\u011f\ufffd\u2018\u00a3subscript\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u2014subscript~\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2014KL(v_{T}| italic_L ( italic_v start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT | over~ start_ARG italic_v end_ARG ) = \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_k italic_l ( italic_v start_POSTSUBSCRIPT italic_T start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT | over~ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ), vTj\u00e2\u2030\u00a1\u00e2\u02c6\u2018i=1mti\u00e2\ufffd\u00a2jsubscript\u011f\ufffd\u2018\u00a3subscript\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u2014superscriptsubscript\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\u0161subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014v_{T_{j}}{ start_POSTSUBSCRIPT italic_T start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT \u00e2\u2030\u00a1 \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT, \u00ce\u00b3>0\u011f\ufffd\u203a\u00be0 > 0, For any admissible u~~\u011f\ufffd\u2018\u00a2 start_ARG italic_u end_ARG, one can always obtain a T\u011f\ufffd\u2018\u2021Titalic_T in \u011f\ufffd\u2019\u00b1\u00e2\ufffd\u00a2(u~)\u011f\ufffd\u2019\u00b1~\u011f\ufffd\u2018\u00a2 ( over~ start_ARG italic_u end_ARG ) with ti\u00e2\ufffd\u00a2j>0subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140t_{ij}>0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT > 0 for all (i,j)\u00e2\u02c6\u2030\u011f\ufffd\u2019\u00b5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5(i,j) italic_i , italic_j ) \u00e2\u02c6\u2030 caligraphic_Z. Simply choose any T\u00e2\u02c6\u02c6\u011f\ufffd\u2019\u00af\u011f\ufffd\u2018\u2021\u011f\ufffd\u2019\u00afT \u00e2\u02c6\u02c6 caligraphic_T with ti\u00e2\ufffd\u00a2j>0subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140t_{ij}>0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT > 0 for all (i,j)\u00e2\u02c6\u2030\u011f\ufffd\u2019\u00b5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5(i,j) italic_i , italic_j ) \u00e2\u02c6\u2030 caligraphic_Z, and scale each of its rows to yield a new matrix in \u011f\ufffd\u2019\u00b1\u00e2\ufffd\u00a2(u~)\u011f\ufffd\u2019\u00b1~\u011f\ufffd\u2018\u00a2 ( over~ start_ARG italic_u end_ARG ). Therefore, \u011f\ufffd\u2019\u00b1\u00e2\ufffd\u00a2(u~)\u011f\ufffd\u2019\u00b1~\u011f\ufffd\u2018\u00a2 ( over~ start_ARG italic_u end_ARG ) is non-empty, and since we are minimizing a continuous strictly convex function (21) over a compact convex set (22), a unique minimizer exists. \u00e2\u2013\u00a1\u00e2\u2013\u00a1{ 220.50885pt} [19] considers a generalization of the problem considered here. To highlight the novelty of our work we make the following comments. It is true that our problem is a special case of the initial general problem considered in [19] by, among other things, specializing to the bivariate (so, bi-marginal) case, and taking ci\u00e2\ufffd\u00a2j=\u00e2\u02c6\ufffdsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014c_{ij}= start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = \u00e2\u02c6\ufffd for all entries in the transport plan that are to be zero. However, our algorithms\u00e2\u20ac\u201dwhich have been designed, among other things, to be relevant in important applications of OT, such as the sharing economy application of our Section\u00c2 VII\u00e2\u20ac\u201dare not presented in [19]. More substantially, we note the following difference. In order to prove convergence of their algorithm to solve their general problem, it is assumed that all the elements of their cost tensor \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a are finite (Assumption C on page 5, left column, of [19]). Under this assumption, our problem is not a special case of the problem solved by the algorithm in [19], because for our problem to be a special case, some of the elements of their cost tensor \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a must be infinite. This assumption is used in the proof of Lemma III.8 in [19]. Note also that prior zeros are not imposed on their transport tensor, M\u011f\ufffd\u2018\u20acMitalic_M (corresponding to our transport matrix, T\u011f\ufffd\u2018\u2021Titalic_T). We now present the main results of the paper. These results yield iterative scaling algorithms that produce a sequence, {T(l} italic_T ( italic_l }, converging to the optimal transport plan, T\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018\u2021T^{*}italic_T start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT, for (21). In particular, two algorithms are presented. Algorithm 1 is obtained using results in [14]. Algorithm 2 is equivalent to Algorithm I and is presented for comparison to other related algorithms such as the SK Algorithm. A third algorithm, the Chizat Algorithm is a related algorithm from the literature that is included to provide context for our contributions. Algorithm 1. Initialize T\u00e2\ufffd\u00a2(0)=K,v\u00e2\ufffd\u00a2(0)=v~formulae-sequence\u011f\ufffd\u2018\u20210\u011f\ufffd\ufffd\u00be\u011f\ufffd\u2018\u00a30~\u011f\ufffd\u2018\u00a3T(0)=K,v(0)= ( 0 ) = italic_K , italic_v ( 0 ) = over~ start_ARG italic_v end_ARG. Iterate for l=0,1,\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u212201\u00e2\u20ac\u00a6l=0,1, = 0 , 1 , \u00e2\u20ac\u00a6 \u00e2\u2013\u00a1\u00e2\u2013\u00a1{ 220.50885pt} The following theorem provides the main result of this paper. A proof is provided in Section VI. Consider the sequence, {T\u00e2\ufffd\u00a2(l),v\u00e2\ufffd\u00a2(l)}\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2122 italic_T ( italic_l ) , italic_v ( italic_l ) }, generated by Algorithm 1. This sequence converges to the (unique) limit, (T\u00e2\u02c6\u2014,v\u00e2\u02c6\u2014)superscript\u011f\ufffd\u2018\u2021superscript\u011f\ufffd\u2018\u00a3(T^{*},v^{*})( italic_T start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT , italic_v start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT ), and T\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018\u2021T^{*}italic_T start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT is the minimizer for the optimization problem given by (21). Since from (23), liml\u00e2\u2020\u2019\u00e2\u02c6\ufffdc1\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2(l)=1subscript\u00e2\u2020\u2019\u011f\ufffd\u2018\u2122subscript\u011f\ufffd\u2018\ufffd1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u21221 start_POSTSUBSCRIPT italic_l \u00e2\u2020\u2019 \u00e2\u02c6\ufffd end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 1 italic_i end_POSTSUBSCRIPT ( italic_l ) = 1 for all i\u011f\ufffd\u2018\u2013iitalic_i. In Lemma 2 (see Section\u00c2 V), it will be shown that ti\u00e2\ufffd\u00a2j\u00e2\u02c6\u2014>0subscriptsuperscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140t^{*}_{ij}>0italic_t start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT > 0 for all (i,j)\u00e2\u02c6\u2030\u011f\ufffd\u2019\u00b5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5(i,j) italic_i , italic_j ) \u00e2\u02c6\u2030 caligraphic_Z. Hence, T\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018\u2021T^{*}italic_T start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT is guaranteed not to contain any row of zeroes, and it follows from (25) that liml\u00e2\u2020\u2019\u00e2\u02c6\ufffdc2\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(l)=1subscript\u00e2\u2020\u2019\u011f\ufffd\u2018\u2122subscript\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u21221 start_POSTSUBSCRIPT italic_l \u00e2\u2020\u2019 \u00e2\u02c6\ufffd end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT ( italic_l ) = 1 for all j\u011f\ufffd\u2018\u2014jitalic_j. From (24), we see that and, since T\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018\u2021T^{*}italic_T start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT does not contain any column of zeroes, we must have vj\u00e2\u02c6\u2014>0subscriptsuperscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u20140v^{*}_{j}>0italic_v start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT > 0, \u00e2\u02c6\u20acjfor-all\u011f\ufffd\u2018\u2014 j\u00e2\u02c6\u20ac italic_j. It now follows, from (27) and (28), that \u00e2\u02c6\u2018j=1nvj\u00e2\u02c6\u2014=\u00e2\u02c6\u2018i=1mu~isuperscriptsubscript\u011f\ufffd\u2018\u20141\u011f\ufffd\u2018\u203asuperscriptsubscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2014superscriptsubscript\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\u0161subscript~\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT = \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT over~ start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and so v\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018\u00a3v^{*}italic_v start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT and u~~\u011f\ufffd\u2018\u00a2 start_ARG italic_u end_ARG are balanced (i.e. mass-conserving). The above result holds even in the unbalanced (i.e.\u00c2 non-mass-conserving) problem, \u00e2\u02c6\u2018i=1mu~i\u00e2\u2030 \u00e2\u02c6\u2018j=1nv~jsuperscriptsubscript\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\u0161subscript~\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u2013superscriptsubscript\u011f\ufffd\u2018\u20141\u011f\ufffd\u2018\u203asubscript~\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2014 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT over~ start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u2030 \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT over~ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT. In this case, application of the SK algorithm produces a sequence, {T\u00e2\ufffd\u00a2(l)}\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u2122 italic_T ( italic_l ) }, which has two convergent subsequences with different limits [16]. \u00e2\u2013\u00a1\u00e2\u2013\u00a1{ 220.50885pt} In order to obtain an algorithm for comparison with the SK algorithm, we introduce scaling parameters, d1\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2(l)subscript\u011f\ufffd\u2018\u20181\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2122d_{1i}(l)italic_d start_POSTSUBSCRIPT 1 italic_i end_POSTSUBSCRIPT ( italic_l ) and d2\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(l)subscript\u011f\ufffd\u2018\u20182\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u2122d_{2j}(l)italic_d start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT ( italic_l ), defined by Then The sequence, {T\u00e2\ufffd\u00a2(l)}\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u2122 italic_T ( italic_l ) }, obtained from Algorithm\u00c2 1, can then also be obtained from the following algorithm. Algorithm 2. Initialize d2\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(0)=1.subscript\u011f\ufffd\u2018\u20182\u011f\ufffd\u2018\u201401d_{2j}(0)=1.italic_d start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT ( 0 ) = 1 . Iterate for l=0,1,\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u212201\u00e2\u20ac\u00a6l=0,1, = 0 , 1 , \u00e2\u20ac\u00a6 \u00e2\u2013\u00a1\u00e2\u2013\u00a1{ 220.50885pt} Since v~j,vj\u00e2\u02c6\u2014>0subscript~\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2014subscriptsuperscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u20140 start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_v start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT > 0 for all j\u011f\ufffd\u2018\u2014jitalic_j, it follows from (32) that the sequence {d2\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(l)}subscript\u011f\ufffd\u2018\u20182\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u2122 italic_d start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT ( italic_l ) } has a limit d2\u00e2\ufffd\u00a2j\u00e2\u02c6\u2014subscriptsuperscript\u011f\ufffd\u2018\u20182\u011f\ufffd\u2018\u2014d^{*}_{2j}italic_d start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT which is non-zero for all j\u011f\ufffd\u2018\u2014jitalic_j. Now (31) implies that that the sequence {d1\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2(l)}subscript\u011f\ufffd\u2018\u20181\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2122 italic_d start_POSTSUBSCRIPT 1 italic_i end_POSTSUBSCRIPT ( italic_l ) } has a limit d1\u00e2\ufffd\u00a2i\u00e2\u02c6\u2014subscriptsuperscript\u011f\ufffd\u2018\u20181\u011f\ufffd\u2018\u2013d^{*}_{1i}italic_d start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 italic_i end_POSTSUBSCRIPT for all i\u011f\ufffd\u2018\u2013iitalic_i. Moreover (33) and (34) show that these limits satisfy and (35) results in \u00e2\u2013\u00a1\u00e2\u2013\u00a1{ 220.50885pt} If one considers the limit, as \u00ce\u00b3\u00e2\u2020\u2019\u00e2\u02c6\ufffd\u00e2\u2020\u2019\u011f\ufffd\u203a\u00be \u00e2\u2020\u2019 \u00e2\u02c6\ufffd, in Algorithm\u00c2 2, one obtains the SK algorithm [17], whose sequence, {T\u00e2\ufffd\u00a2(l)}\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u2122 italic_T ( italic_l ) }, converges to the minimizer for optimization problem (17), provided this problem is feasible. \u00e2\u2013\u00a1\u00e2\u2013\u00a1{ 220.50885pt} Before proceeding we note that [18] considers a problem which is related (but different from) to the problem considered here. Namely, to solve where uTi=\u00e2\u02c6\u2018j=1nti\u00e2\ufffd\u00a2jsubscript\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u2013superscriptsubscript\u011f\ufffd\u2018\u20141\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014u_{T_{i}}= start_POSTSUBSCRIPT italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT = \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT for all i\u011f\ufffd\u2018\u2013iitalic_i, ki\u00e2\ufffd\u00a2j=exp\u00e2\ufffd\u00a1(\u00e2\u02c6\u2019ci\u00e2\ufffd\u00a2j/\u00ce\u00b30)\u00e2\ufffd\u00a2\u00c2 for all\u00c2 \u00e2\ufffd\u00a2(i,j)subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u203a\u00be0\u00c2 for all\u00c2 \u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014k_{ij}= for all }(i,j)italic_k start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = roman_exp ( - italic_c start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT / italic_\u00ce\u00b3 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) for all ( italic_i , italic_j ) and \u00ce\u00b31,\u00ce\u00b32>0subscript\u011f\ufffd\u203a\u00be1subscript\u011f\ufffd\u203a\u00be20 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u00ce\u00b3 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT > 0. In [18], neither marginal constraint is enforced and none of the elements of T\u011f\ufffd\u2018\u2021Titalic_T are constrained to be zero. This is in contrast to the current paper, in which the source marginal is constrained to be u~~\u011f\ufffd\u2018\u00a2 start_ARG italic_u end_ARG, and some of the elements of T\u011f\ufffd\u2018\u2021Titalic_T are enforced to be zero, specifically ti\u00e2\ufffd\u00a2j=0subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140t_{ij}=0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 0 for (i,j)\u00e2\u02c6\u02c6\u011f\ufffd\u2019\u00b5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5(i,j) italic_i , italic_j ) \u00e2\u02c6\u02c6 caligraphic_Z. [18] shows that the sequence, {T\u00e2\ufffd\u00a2(l)}\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u2122 italic_T ( italic_l ) }, generated by the following algorithm converges to a limit which is the minimizer for optimization problem (38). Chizat Algorithm. Initialize d2\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(0)=1.subscript\u011f\ufffd\u2018\u20182\u011f\ufffd\u2018\u201401d_{2j}(0)=1.italic_d start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT ( 0 ) = 1 . Iterate for l=0,1,\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u212201\u00e2\u20ac\u00a6l=0,1, = 0 , 1 , \u00e2\u20ac\u00a6 \u00e2\u2013\u00a1\u00e2\u2013\u00a1{ 220.50885pt} Remarkably, if one considers the limit as \u00ce\u00b31\u00e2\u2020\u2019\u00e2\u02c6\ufffd\u00e2\u2020\u2019subscript\u011f\ufffd\u203a\u00be1 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2020\u2019 \u00e2\u02c6\ufffd, then the Chizat algorithm reduces to our Algorithm 2 in the case where there are no constraints on T\u011f\ufffd\u2018\u2021Titalic_T and all the elements of T~~\u011f\ufffd\u2018\u2021 start_ARG italic_T end_ARG equal one. If T\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018\u2021T^{*}italic_T start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT is a minimizer for (21), then ti\u00e2\ufffd\u00a2j\u00e2\u02c6\u2014>0subscriptsuperscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140t^{*}_{ij}>0italic_t start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT > 0 for all (i,j)\u00e2\u02c6\u2030\u011f\ufffd\u2019\u00b5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5(i,j) italic_i , italic_j ) \u00e2\u02c6\u2030 caligraphic_Z. Suppose that T\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018\u2021T^{*}italic_T start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT is a minimizer for (21). From Remark 2, there is a T^\u00e2\u02c6\u02c6\u011f\ufffd\u2019\u00b1\u00e2\ufffd\u00a2(u~)^\u011f\ufffd\u2018\u2021\u011f\ufffd\u2019\u00b1~\u011f\ufffd\u2018\u00a2 start_ARG italic_T end_ARG \u00e2\u02c6\u02c6 caligraphic_V ( over~ start_ARG italic_u end_ARG ) with t^i\u00e2\ufffd\u00a2j>0subscript^\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140 start_ARG italic_t end_ARG start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT > 0 for all (i,j)\u00e2\u02c6\u2030\u011f\ufffd\u2019\u00b5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5(i,j) italic_i , italic_j ) \u00e2\u02c6\u2030 caligraphic_Z. Since \u011f\ufffd\u2019\u00b1\u00e2\ufffd\u00a2(u~)\u011f\ufffd\u2019\u00b1~\u011f\ufffd\u2018\u00a2 ( over~ start_ARG italic_u end_ARG ) is convex, (1\u00e2\u02c6\u2019\u00ce\u00bb)\u00e2\ufffd\u00a2T\u00e2\u02c6\u2014+\u00ce\u00bb\u00e2\ufffd\u00a2T^1\u011f\ufffd\u0153\u2020superscript\u011f\ufffd\u2018\u2021\u011f\ufffd\u0153\u2020^\u011f\ufffd\u2018\u2021(1- 1 - italic_\u00ce\u00bb ) italic_T start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT + italic_\u00ce\u00bb over^ start_ARG italic_T end_ARG is in \u011f\ufffd\u2019\u00b1\u00e2\ufffd\u00a2(u~)\u011f\ufffd\u2019\u00b1~\u011f\ufffd\u2018\u00a2 ( over~ start_ARG italic_u end_ARG ) for all \u00ce\u00bb\u00e2\u02c6\u02c6[0,1]\u011f\ufffd\u0153\u202001 \u00e2\u02c6\u02c6 [ 0 , 1 ]. Also, there are bounds, \u00ce\u00b21subscript\u011f\ufffd\u203a\u00bd1 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and \u00ce\u00b22subscript\u011f\ufffd\u203a\u00bd2 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, such that, if ti\u00e2\ufffd\u00a2j\u00e2\u02c6\u2014>0subscriptsuperscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140t^{*}_{ij}>0italic_t start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT > 0 then for any (i,j)\u00e2\u02c6\u2030\u011f\ufffd\u2019\u00b5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5(i,j) italic_i , italic_j ) \u00e2\u02c6\u2030 caligraphic_Z, 0<\u00ce\u00b21\u00e2\u2030\u00a4ti\u00e2\ufffd\u00a2j\u00e2\u2030\u00a4\u00ce\u00b220subscript\u011f\ufffd\u203a\u00bd1subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u203a\u00bd20< t_{ij} < italic_\u00ce\u00b2 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_\u00ce\u00b2 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT for T=(1\u00e2\u02c6\u2019\u00ce\u00bb)\u00e2\ufffd\u00a2T\u00e2\u02c6\u2014+\u00ce\u00bb\u00e2\ufffd\u00a2T^\u00e2\ufffd\u00a2\u00c2 and\u00c2 \u00e2\ufffd\u00a2\u00ce\u00bb\u00e2\u02c6\u02c6[0,1]\u011f\ufffd\u2018\u20211\u011f\ufffd\u0153\u2020superscript\u011f\ufffd\u2018\u2021\u011f\ufffd\u0153\u2020^\u011f\ufffd\u2018\u2021\u00c2 and\u00c2 \u011f\ufffd\u0153\u202001T=(1- and } = ( 1 - italic_\u00ce\u00bb ) italic_T start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT + italic_\u00ce\u00bb over^ start_ARG italic_T end_ARG and italic_\u00ce\u00bb \u00e2\u02c6\u02c6 [ 0 , 1 ]. The function to be minimized in (21) can be expressed as Consider any \u00ce\u00bb\u00e2\u02c6\u02c6(0,1]\u011f\ufffd\u0153\u202001 \u00e2\u02c6\u02c6 ( 0 , 1 ] and T=(1\u00e2\u02c6\u2019\u00ce\u00bb)\u00e2\ufffd\u00a2T\u00e2\u02c6\u2014+\u00ce\u00bb\u00e2\ufffd\u00a2T^\u011f\ufffd\u2018\u20211\u011f\ufffd\u0153\u2020superscript\u011f\ufffd\u2018\u2021\u011f\ufffd\u0153\u2020^\u011f\ufffd\u2018\u2021T=(1- = ( 1 - italic_\u00ce\u00bb ) italic_T start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT + italic_\u00ce\u00bb over^ start_ARG italic_T end_ARG. By the mean value theorem, \u00e2\u02c6\u0192 \u00ce\u00bb\u00c2\u00af\u00e2\u02c6\u02c6(0,\u00ce\u00bb)\u00c2\u00af\u011f\ufffd\u0153\u20200\u011f\ufffd\u0153\u2020 start_ARG italic_\u00ce\u00bb end_ARG \u00e2\u02c6\u02c6 ( 0 , italic_\u00ce\u00bb ) such that where T\u00c2\u00af=(1\u00e2\u02c6\u2019\u00ce\u00bb\u00c2\u00af)\u00e2\ufffd\u00a2T\u00e2\u02c6\u2014+\u00ce\u00bb\u00c2\u00af\u00e2\ufffd\u00a2T^\u00c2\u00af\u011f\ufffd\u2018\u20211\u00c2\u00af\u011f\ufffd\u0153\u2020superscript\u011f\ufffd\u2018\u2021\u00c2\u00af\u011f\ufffd\u0153\u2020^\u011f\ufffd\u2018\u2021 start_ARG italic_T end_ARG = ( 1 - under\u00c2\u00af start_ARG italic_\u00ce\u00bb end_ARG ) italic_T start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT + under\u00c2\u00af start_ARG italic_\u00ce\u00bb end_ARG over^ start_ARG italic_T end_ARG and If ti\u00e2\ufffd\u00a2j\u00e2\u02c6\u2014>0subscriptsuperscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140t^{*}_{ij}>0italic_t start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT > 0 then, for all \u00ce\u00bb\u00e2\u02c6\u02c6(0,1]\u011f\ufffd\u0153\u202001 \u00e2\u02c6\u02c6 ( 0 , 1 ], we have 0<\u00ce\u00b21\u00e2\u2030\u00a4t\u00c2\u00afi\u00e2\ufffd\u00a2j\u00e2\u2030\u00a4\u00ce\u00b220subscript\u011f\ufffd\u203a\u00bd1subscript\u00c2\u00af\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u203a\u00bd20< < italic_\u00ce\u00b2 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 under\u00c2\u00af start_ARG italic_t end_ARG start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_\u00ce\u00b2 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, and 0<\u00ce\u00b21\u00e2\u2030\u00a4\u00e2\u02c6\u2018l=1mt\u00c2\u00afl\u00e2\ufffd\u00a2j\u00e2\u2030\u00a4\u00ce\u00b230subscript\u011f\ufffd\u203a\u00bd1superscriptsubscript\u011f\ufffd\u2018\u21221\u011f\ufffd\u2018\u0161subscript\u00c2\u00af\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u203a\u00bd30< < italic_\u00ce\u00b2 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_l = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT under\u00c2\u00af start_ARG italic_t end_ARG start_POSTSUBSCRIPT italic_l italic_j end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_\u00ce\u00b2 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT for some \u00ce\u00b23subscript\u011f\ufffd\u203a\u00bd3 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT. Hence \u00e2\u02c6\u201af\u00e2\u02c6\u201ati\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(T\u00c2\u00af)\u00e2\ufffd\u00a2(t^i\u00e2\ufffd\u00a2j\u00e2\u02c6\u2019ti\u00e2\ufffd\u00a2j\u00e2\u02c6\u2014)\u00e2\u2030\u00a4\u00ce\u00b3i\u00e2\ufffd\u00a2j\u011f\ufffd\u2018\u201csubscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u00c2\u00af\u011f\ufffd\u2018\u2021subscript^\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscriptsuperscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u203a\u00be\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014 f}{ t_{ij}}( start_ARG \u00e2\u02c6\u201a italic_f end_ARG start_ARG \u00e2\u02c6\u201a italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT end_ARG ( under\u00c2\u00af start_ARG italic_T end_ARG ) ( over^ start_ARG italic_t end_ARG start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT - italic_t start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ) \u00e2\u2030\u00a4 italic_\u00ce\u00b3 start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT for some \u00ce\u00b3i\u00e2\ufffd\u00a2jsubscript\u011f\ufffd\u203a\u00be\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014 start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT. Suppose that ti\u00e2\ufffd\u00a2j\u00e2\u02c6\u2014=0subscriptsuperscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140t^{*}_{ij}=0italic_t start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 0 for some (i,j)\u00e2\u02c6\u2030\u011f\ufffd\u2019\u00b5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5(i,j) italic_i , italic_j ) \u00e2\u02c6\u2030 caligraphic_Z. Then lim\u00ce\u00bb\u00e2\u2020\u20190t\u00c2\u00afi\u00e2\ufffd\u00a2j=ti\u00e2\ufffd\u00a2j\u00e2\u02c6\u2014=0subscript\u00e2\u2020\u2019\u011f\ufffd\u0153\u20200subscript\u00c2\u00af\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscriptsuperscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140 0} start_POSTSUBSCRIPT italic_\u00ce\u00bb \u00e2\u2020\u2019 0 end_POSTSUBSCRIPT under\u00c2\u00af start_ARG italic_t end_ARG start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = italic_t start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 0; and lim\u00ce\u00bb\u00e2\u2020\u20190\u00e2\u02c6\u201af\u00e2\u02c6\u201ati\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(T\u00c2\u00af)\u00e2\ufffd\u00a2(t^i\u00e2\ufffd\u00a2j\u00e2\u02c6\u2019ti\u00e2\ufffd\u00a2j\u00e2\u02c6\u2014)=\u00e2\u02c6\u2019\u00e2\u02c6\ufffdsubscript\u00e2\u2020\u2019\u011f\ufffd\u0153\u20200\u011f\ufffd\u2018\u201csubscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u00c2\u00af\u011f\ufffd\u2018\u2021subscript^\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscriptsuperscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014 0} f}{ t_{ij}}( start_POSTSUBSCRIPT italic_\u00ce\u00bb \u00e2\u2020\u2019 0 end_POSTSUBSCRIPT divide start_ARG \u00e2\u02c6\u201a italic_f end_ARG start_ARG \u00e2\u02c6\u201a italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT end_ARG ( under\u00c2\u00af start_ARG italic_T end_ARG ) ( over^ start_ARG italic_t end_ARG start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT - italic_t start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ) = - \u00e2\u02c6\ufffd. This implies that, for \u00ce\u00bb>0\u011f\ufffd\u0153\u20200 > 0 sufficiently small, \u00e2\u02c6\u2018(i,j)\u00e2\u02c6\u2030\u011f\ufffd\u2019\u00b5\u00e2\u02c6\u201af\u00e2\u02c6\u201ati\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(T\u00c2\u00af)\u00e2\ufffd\u00a2(t^i\u00e2\ufffd\u00a2j\u00e2\u02c6\u2019ti\u00e2\ufffd\u00a2j\u00e2\u02c6\u2014)<0subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5\u011f\ufffd\u2018\u201csubscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u00c2\u00af\u011f\ufffd\u2018\u2021subscript^\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscriptsuperscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140 f}{ t_{ij}}( ( start_POSTSUBSCRIPT ( italic_i , italic_j ) \u00e2\u02c6\u2030 caligraphic_Z end_POSTSUBSCRIPT divide start_ARG \u00e2\u02c6\u201a italic_f end_ARG start_ARG \u00e2\u02c6\u201a italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT end_ARG ( under\u00c2\u00af start_ARG italic_T end_ARG ) ( over^ start_ARG italic_t end_ARG start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT - italic_t start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ) < 0 which along with (42) yields the contradiction, f\u00e2\ufffd\u00a2(T)<f\u00e2\ufffd\u00a2(T\u00e2\u02c6\u2014).\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u201csuperscript\u011f\ufffd\u2018\u2021f(T)<f(T^{*}).italic_f ( italic_T ) < italic_f ( italic_T start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT ) . \u00c2 The following result can be obtained from the discussion of Algorithm 2; see Remark 5. However we wish to provide a proof which is independent of any algorithm. A matrix, T\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018\u2021T^{*}italic_T start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT, solves the OT problem given by (21) iff \u00e2\u02c6\u0192 positive scalars, d11,\u00e2\u20ac\u00a6,d1\u00e2\ufffd\u00a2msubscript\u011f\ufffd\u2018\u201811\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u20181\u011f\ufffd\u2018\u0161d_{11}, start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_d start_POSTSUBSCRIPT 1 italic_m end_POSTSUBSCRIPT and d21,\u00e2\u20ac\u00a6,d2\u00e2\ufffd\u00a2nsubscript\u011f\ufffd\u2018\u201821\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u20182\u011f\ufffd\u2018\u203ad_{21}, start_POSTSUBSCRIPT 21 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_d start_POSTSUBSCRIPT 2 italic_n end_POSTSUBSCRIPT, such that, for all (i,j)\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014(i,j)( italic_i , italic_j ) (37) and (36) hold. If (i,j)\u00e2\u02c6\u02c6\u011f\ufffd\u2019\u00b5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5(i,j) italic_i , italic_j ) \u00e2\u02c6\u02c6 caligraphic_Z, we have ti\u00e2\ufffd\u00a2j\u00e2\u02c6\u2014=ki\u00e2\ufffd\u00a2j=0subscriptsuperscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140t^{*}_{ij}=k_{ij}=0italic_t start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = italic_k start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 0 and the expression for ti\u00e2\ufffd\u00a2j\u00e2\u02c6\u2014subscriptsuperscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014t^{*}_{ij}italic_t start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT in (37) holds. The Lagrangian associated with this optimization problem is For (i,j)\u00e2\u02c6\u2030\u011f\ufffd\u2019\u00b5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5(i,j) italic_i , italic_j ) \u00e2\u02c6\u2030 caligraphic_Z and ti\u00e2\ufffd\u00a2j\u00e2\u2030 0subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140t_{ij} 0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT \u00e2\u2030 0, From Lemma 1, we know that ti\u00e2\ufffd\u00a2j\u00e2\u02c6\u2014>0subscriptsuperscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140t^{*}_{ij}>0italic_t start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT > 0 for all (i,j)\u00e2\u02c6\u2030\u011f\ufffd\u2019\u00b5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5(i,j) italic_i , italic_j ) \u00e2\u02c6\u2030 caligraphic_Z. Hence T\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018\u2021T^{*}italic_T start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT is a minimizer iff \u00e2\u02c6\u0192 scalars, \u00ce\u00b11,\u00e2\u20ac\u00a6,\u00ce\u00b1msubscript\u011f\ufffd\u203a\u00bc1\u00e2\u20ac\u00a6subscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u0161 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_\u00ce\u00b1 start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT, such that \u00e2\u02c6\u201aL\u00e2\u02c6\u201ati\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(T\u00e2\u02c6\u2014,\u00ce\u00b1)=0\u011f\ufffd\ufffd\u00bfsubscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014superscript\u011f\ufffd\u2018\u2021\u011f\ufffd\u203a\u00bc0 L}{ t_{ij}}(T^{*}, start_ARG \u00e2\u02c6\u201a italic_L end_ARG start_ARG \u00e2\u02c6\u201a italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT end_ARG ( italic_T start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT , italic_\u00ce\u00b1 ) = 0 for all (i,j)\u00e2\u02c6\u2030\u011f\ufffd\u2019\u00b5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5(i,j) italic_i , italic_j ) \u00e2\u02c6\u2030 caligraphic_Z, that is, log\u00e2\ufffd\u00a1(ti\u00e2\ufffd\u00a2j\u00e2\u02c6\u2014ki\u00e2\ufffd\u00a2j)=\u00e2\u02c6\u2019\u00ce\u00b1i\u00e2\u02c6\u2019\u00ce\u00b2jsubscriptsuperscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u203a\u00bd\u011f\ufffd\u2018\u2014 ( divide start_ARG italic_t start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT end_ARG start_ARG italic_k start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT end_ARG ) = - italic_\u00ce\u00b1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - italic_\u00ce\u00b2 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, where Hence where d1\u00e2\ufffd\u00a2i\u00e2\u2030\u00a1exp\u00e2\ufffd\u00a1(\u00e2\u02c6\u2019\u00ce\u00b1i)subscript\u011f\ufffd\u2018\u20181\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u2013d_{1i} start_POSTSUBSCRIPT 1 italic_i end_POSTSUBSCRIPT \u00e2\u2030\u00a1 roman_exp ( - italic_\u00ce\u00b1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) and d2\u00e2\ufffd\u00a2j\u00e2\u2030\u00a1exp\u00e2\ufffd\u00a1(\u00e2\u02c6\u2019\u00ce\u00b2j)subscript\u011f\ufffd\u2018\u20182\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u203a\u00bd\u011f\ufffd\u2018\u2014d_{2j} start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT \u00e2\u2030\u00a1 roman_exp ( - italic_\u00ce\u00b2 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ). Using the row constraints, we have u~i=\u00e2\u02c6\u2018j=1mti\u00e2\ufffd\u00a2j\u00e2\u02c6\u2014=\u00e2\u02c6\u2018j=1md1\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2ki\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2d2\u00e2\ufffd\u00a2jsubscript~\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u2013superscriptsubscript\u011f\ufffd\u2018\u20141\u011f\ufffd\u2018\u0161subscriptsuperscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014superscriptsubscript\u011f\ufffd\u2018\u20141\u011f\ufffd\u2018\u0161subscript\u011f\ufffd\u2018\u20181\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018\u20182\u011f\ufffd\u2018\u2014 start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_t start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT 1 italic_i end_POSTSUBSCRIPT italic_k start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT. Hence, d1\u00e2\ufffd\u00a2i=u~i\u00e2\u02c6\u2018j=1mki\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2d2\u00e2\ufffd\u00a2jsubscript\u011f\ufffd\u2018\u20181\u011f\ufffd\u2018\u2013subscript~\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u2013superscriptsubscript\u011f\ufffd\u2018\u20141\u011f\ufffd\u2018\u0161subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018\u20182\u011f\ufffd\u2018\u2014d_{1i}= start_POSTSUBSCRIPT 1 italic_i end_POSTSUBSCRIPT = divide start_ARG over~ start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG start_ARG \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_k start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT end_ARG. It follows, from (44) and (45), that that is, d2\u00e2\ufffd\u00a2j1+\u00ce\u00b3\u00ce\u00b3\u00e2\ufffd\u00a2\u00e2\u02c6\u2018i=1md1\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2ki\u00e2\ufffd\u00a2j=v~jsuperscriptsubscript\u011f\ufffd\u2018\u20182\u011f\ufffd\u2018\u20141\u011f\ufffd\u203a\u00be\u011f\ufffd\u203a\u00besuperscriptsubscript\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\u0161subscript\u011f\ufffd\u2018\u20181\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript~\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2014d_{2j}^{ start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT divide start_ARG 1 + italic_\u00ce\u00b3 end_ARG start_ARG italic_\u00ce\u00b3 end_ARG end_POSTSUPERSCRIPT \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT 1 italic_i end_POSTSUBSCRIPT italic_k start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = over~ start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, or \u00c2 To prove Theorem 1, we need a result from [14]. Let and, for a fixed x~\u00e2\u02c6\u02c6\u011f\ufffd\u2019\u00b3~\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2019\u00b3 start_ARG italic_x end_ARG \u00e2\u02c6\u02c6 caligraphic_X, consider the strictly convex function, f:\u011f\ufffd\u2019\u00b3\u00c2\u00af\u00e2\u2020\u2019\u00e2\u201e\ufffd:\u011f\ufffd\u2018\u201c\u00e2\u2020\u2019\u00c2\u00af\u011f\ufffd\u2019\u00b3\u00e2\u201e\ufffdf: : over\u00c2\u00af start_ARG caligraphic_X end_ARG \u00e2\u2020\u2019 blackboard_R, given by where \u011f\ufffd\u2019\u00b3\u00c2\u00af\u00c2\u00af\u011f\ufffd\u2019\u00b3 start_ARG caligraphic_X end_ARG is the closure of \u011f\ufffd\u2019\u00b3\u011f\ufffd\u2019\u00b3 that is Also, let Ai\u00e2\u02c6\u02c6\u00e2\u201e\ufffdmi\u00c3\u2014qsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u2013superscript\u00e2\u201e\ufffdsubscript\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffdA_{i} q}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00c3\u2014 italic_q end_POSTSUPERSCRIPT and bi\u00e2\u02c6\u02c6\u00e2\u201e\ufffdmisubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013superscript\u00e2\u201e\ufffdsubscript\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2013b_{i} start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, for i=1,2,\u00e2\u20ac\u00a6,N\u011f\ufffd\u2018\u201312\u00e2\u20ac\u00a6\u011f\ufffd\u2018\ufffdi=1,2, = 1 , 2 , \u00e2\u20ac\u00a6 , italic_N, for some positive integers, N\u011f\ufffd\u2018\ufffdNitalic_N and misubscript\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2013m_{i}italic_m start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, and consider the following optimization problem: Let \u011f\ufffd\u2019\ufffdisubscript\u011f\ufffd\u2019\ufffd\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT be the closed convex set, {x\u00e2\u02c6\u02c6\u00e2\u201e\ufffdq:Ai\u00e2\ufffd\u00a2x=bi}conditional-set\u011f\ufffd\u2018\u00a5superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013 italic_x \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_q end_POSTSUPERSCRIPT : italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_x = italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT }, and assume that \u011f\ufffd\u2019\ufffd\u00e2\u2030\u00a1\u00e2\u2039\u201ai=1N\u011f\ufffd\u2019\ufffdi\u011f\ufffd\u2019\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2019\ufffd\u011f\ufffd\u2018\u2013 \u00e2\u2030\u00a1 \u00e2\u2039\u201a start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT caligraphic_C start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is non-empty. We also require the following assumption. For each i=1,2,\u00e2\u20ac\u00a6,N\u011f\ufffd\u2018\u201312\u00e2\u20ac\u00a6\u011f\ufffd\u2018\ufffdi=1,2, = 1 , 2 , \u00e2\u20ac\u00a6 , italic_N and x\u00e2\u02c6\u02c6\u011f\ufffd\u2019\u00b3\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2019\u00b3x \u00e2\u02c6\u02c6 caligraphic_X, \u00e2\u02c6\u0192 y\u00e2\u02c6\u2014\u00e2\u02c6\u02c6\u011f\ufffd\u2019\u00b3\u00e2\u02c6\u00a9\u011f\ufffd\u2019\ufffdisuperscript\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2019\u00b3subscript\u011f\ufffd\u2019\ufffd\u011f\ufffd\u2018\u2013y^{*} start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT \u00e2\u02c6\u02c6 caligraphic_X \u00e2\u02c6\u00a9 caligraphic_C start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT such that Note that, in this assumption, optimization is over \u011f\ufffd\u2019\u00b3\u00e2\u02c6\u00a9\u011f\ufffd\u2019\ufffdi\u011f\ufffd\u2019\u00b3subscript\u011f\ufffd\u2019\ufffd\u011f\ufffd\u2018\u2013 \u00e2\u02c6\u00a9 caligraphic_C start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and not over \u011f\ufffd\u2019\u00b3\u00c2\u00af\u00e2\u02c6\u00a9\u011f\ufffd\u2019\ufffdi\u00c2\u00af\u011f\ufffd\u2019\u00b3subscript\u011f\ufffd\u2019\ufffd\u011f\ufffd\u2018\u2013 start_ARG caligraphic_X end_ARG \u00e2\u02c6\u00a9 caligraphic_C start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. We will denote the point y\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018\u00a6y^{*}italic_y start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT above by Pi\u00e2\ufffd\u00a2(x)subscript\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a5P_{i}(x)italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) and refer to it as the K\u00e2\ufffd\u00a2L\u011f\ufffd\ufffd\u00be\u011f\ufffd\ufffd\u00bfKLitalic_K italic_L-projection of x\u011f\ufffd\u2018\u00a5xitalic_x onto \u011f\ufffd\u2019\ufffdisubscript\u011f\ufffd\u2019\ufffd\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. Let p\u011f\ufffd\u2018\ufffdpitalic_p be a permutation on {1,2,\u00e2\u20ac\u00a6,N}12\u00e2\u20ac\u00a6\u011f\ufffd\u2018\ufffd 1 , 2 , \u00e2\u20ac\u00a6 , italic_N }, that is where pksuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02dcp^{k}italic_p start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT is the application of p\u011f\ufffd\u2018\ufffdpitalic_p, k\u011f\ufffd\u2018\u02dckitalic_k times. The following result may be gleaned from [14]. Suppose \u011f\ufffd\u2019\ufffd\u00e2\u02c6\u00a9\u011f\ufffd\u2019\u00b3\u00c2\u00af\u011f\ufffd\u2019\ufffd\u00c2\u00af\u011f\ufffd\u2019\u00b3 \u00e2\u02c6\u00a9 over\u00c2\u00af start_ARG caligraphic_X end_ARG is non-empty, that Assumption 1 holds, and where il+1=p\u00e2\ufffd\u00a2(il)subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u21221\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2122i_{l+1}=p(i_{l})italic_i start_POSTSUBSCRIPT italic_l + 1 end_POSTSUBSCRIPT = italic_p ( italic_i start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT ). Then, liml\u00e2\u2020\u2019\u00e2\u02c6\ufffdx\u00e2\ufffd\u00a2(l)=x\u00e2\u02c6\u2014\u00e2\u02c6\u02c6\u011f\ufffd\u2019\ufffd\u00e2\u02c6\u00a9\u011f\ufffd\u2019\u00b3\u00c2\u00afsubscript\u00e2\u2020\u2019\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2122superscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2019\ufffd\u00c2\u00af\u011f\ufffd\u2019\u00b3 start_POSTSUBSCRIPT italic_l \u00e2\u2020\u2019 \u00e2\u02c6\ufffd end_POSTSUBSCRIPT italic_x ( italic_l ) = italic_x start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT \u00e2\u02c6\u02c6 caligraphic_C \u00e2\u02c6\u00a9 over\u00c2\u00af start_ARG caligraphic_X end_ARG. Moreover, if where \u00e2\u20ac\u00b2 denotes transpose, then The algorithm in Theorem\u00c2 2 initially chooses some point, x\u00e2\ufffd\u00a2(0)\u00e2\u02c6\u02c6\u011f\ufffd\u2019\u00b3\u011f\ufffd\u2018\u00a50\u011f\ufffd\u2019\u00b3x(0) ( 0 ) \u00e2\u02c6\u02c6 caligraphic_X. It then cycles indefinitely through each index, i\u011f\ufffd\u2018\u2013iitalic_i, and projects onto \u011f\ufffd\u2019\ufffdisubscript\u011f\ufffd\u2019\ufffd\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. It can be viewed as an alternating projection algorithm. The resulting sequence, {x\u00e2\ufffd\u00a2(l)}l=0\u00e2\u02c6\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u21220 italic_x ( italic_l ) } start_POSTSUBSCRIPT italic_l = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\ufffd end_POSTSUPERSCRIPT, converges to a point which is common to all of the sets, \u011f\ufffd\u2019\ufffdisubscript\u011f\ufffd\u2019\ufffd\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and \u011f\ufffd\u2019\u00b3\u00c2\u00af\u00c2\u00af\u011f\ufffd\u2019\u00b3 start_ARG caligraphic_X end_ARG. In addition, if \u00e2\u02c6\u2021f\u00e2\ufffd\u00a2(x\u00e2\ufffd\u00a2(0))\u00e2\u02c6\u2021\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u00a50 f(x(0))\u00e2\u02c6\u2021 italic_f ( italic_x ( 0 ) ) satisfies (50), then x\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018\u00a5x^{*}italic_x start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT is a minimizer for optimization problem (47). This algorithm is very useful when one can readily solve the optimization problems in (48). The optimization problem of this paper (21) can be rewritten as min(T,v)\u00e2\u02c6\u02c6\u011f\ufffd\u2019\u00af\u00e2\ufffd\u00a2\u011f\ufffd\u2019\u00b1\u00c2\u00af\u00e2\ufffd\u00a1J\u00e2\ufffd\u00a2(T,v)subscript\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u00a3\u00c2\u00af\u011f\ufffd\u2019\u00af\u011f\ufffd\u2019\u00b1\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u00a3 start_POSTSUBSCRIPT ( italic_T , italic_v ) \u00e2\u02c6\u02c6 over\u00c2\u00af start_ARG caligraphic_T caligraphic_V end_ARG end_POSTSUBSCRIPT italic_J ( italic_T , italic_v ), subject to where \u00ce\u00b3>0\u011f\ufffd\u203a\u00be0 > 0 and Let q=nT+n\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u203aq=n_{T}+nitalic_q = italic_n start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT + italic_n, where nTsubscript\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2021n_{T}italic_n start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT is the number of index pairs (i,j)\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014(i,j)( italic_i , italic_j ) not in \u011f\ufffd\u2019\u00b5\u011f\ufffd\u2019\u00b5 Then, by appropriate definition of x\u011f\ufffd\u2018\u00a5xitalic_x in \u00e2\u201e\ufffdqsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd start_POSTSUPERSCRIPT italic_q end_POSTSUPERSCRIPT, one can associate each element of x\u011f\ufffd\u2018\u00a5xitalic_x to an element of T\u011f\ufffd\u2018\u2021Titalic_T or \u00ce\u00b3\u00e2\ufffd\u00a2v\u011f\ufffd\u203a\u00be\u011f\ufffd\u2018\u00a3 vitalic_\u00ce\u00b3 italic_v. We denote this by x=vec\u00e2\ufffd\u00a2(T,\u00ce\u00b3\u00e2\ufffd\u00a2v)\u011f\ufffd\u2018\u00a5vec\u011f\ufffd\u2018\u2021\u011f\ufffd\u203a\u00be\u011f\ufffd\u2018\u00a3x= v)italic_x = vec ( italic_T , italic_\u00ce\u00b3 italic_v ) and the objective function in (53) can be written as f\u00e2\ufffd\u00a2(x)=K\u00e2\ufffd\u00a2L\u00e2\ufffd\u00a2(x|x~)\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u00a5\u011f\ufffd\ufffd\u00be\u011f\ufffd\ufffd\u00bfconditional\u011f\ufffd\u2018\u00a5~\u011f\ufffd\u2018\u00a5f(x)=KL(x| ( italic_x ) = italic_K italic_L ( italic_x | over~ start_ARG italic_x end_ARG ), where x~=vec\u00e2\ufffd\u00a2(K,\u00ce\u00b3\u00e2\ufffd\u00a2v~)~\u011f\ufffd\u2018\u00a5vec\u011f\ufffd\ufffd\u00be\u011f\ufffd\u203a\u00be~\u011f\ufffd\u2018\u00a3 start_ARG italic_x end_ARG = vec ( italic_K , italic_\u00ce\u00b3 over~ start_ARG italic_v end_ARG ). Also, the constraints in (52) can be expressed as A1\u00e2\ufffd\u00a2x=b1,A2\u00e2\ufffd\u00a2x=b2formulae-sequencesubscript\u011f\ufffd\ufffd\u00b41\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\ufffd\u00b42\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\ufffd2A_{1}x=b_{1}, start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_x = italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_x = italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, where If (T,v),(S,w)\u00e2\u02c6\u02c6\u011f\ufffd\u2019\u00af\u00e2\ufffd\u00a2\u011f\ufffd\u2019\u00b1\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2020\u011f\ufffd\u2018\u00a4\u011f\ufffd\u2019\u00af\u011f\ufffd\u2019\u00b1(T,v),(S,w) italic_T , italic_v ) , ( italic_S , italic_w ) \u00e2\u02c6\u02c6 caligraphic_T caligraphic_V, y=vec\u00e2\ufffd\u00a2(T,\u00ce\u00b3\u00e2\ufffd\u00a2v)\u011f\ufffd\u2018\u00a6vec\u011f\ufffd\u2018\u2021\u011f\ufffd\u203a\u00be\u011f\ufffd\u2018\u00a3y= v)italic_y = vec ( italic_T , italic_\u00ce\u00b3 italic_v ), x=vec\u00e2\ufffd\u00a2(S,\u00ce\u00b3\u00e2\ufffd\u00a2w)\u011f\ufffd\u2018\u00a5vec\u011f\ufffd\u2018\u2020\u011f\ufffd\u203a\u00be\u011f\ufffd\u2018\u00a4x= w)italic_x = vec ( italic_S , italic_\u00ce\u00b3 italic_w ): If (S,w)\u00e2\u02c6\u02c6\u011f\ufffd\u2019\u00af\u00e2\ufffd\u00a2\u011f\ufffd\u2019\u00b1\u011f\ufffd\u2018\u2020\u011f\ufffd\u2018\u00a4\u011f\ufffd\u2019\u00af\u011f\ufffd\u2019\u00b1(S,w) italic_S , italic_w ) \u00e2\u02c6\u02c6 caligraphic_T caligraphic_V then iff ti\u00e2\ufffd\u00a2j\u00e2\u02c6\u2014=c1\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2si\u00e2\ufffd\u00a2j,vj\u00e2\u02c6\u2014=wjformulae-sequencesubscriptsuperscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018\ufffd1\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018 \u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscriptsuperscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018\u00a4\u011f\ufffd\u2018\u2014t^{*}_{ij}=c_{1i}s_{ij}, start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = italic_c start_POSTSUBSCRIPT 1 italic_i end_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT , italic_v start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = italic_w start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, where Since ti\u00e2\ufffd\u00a2j=0subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140t_{ij}=0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 0 for (i,j)\u00e2\u02c6\u02c6\u011f\ufffd\u2019\u00b5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5(i,j) italic_i , italic_j ) \u00e2\u02c6\u02c6 caligraphic_Z, the Lagrangian associated with this optimization problem is When (i,j)\u00e2\u02c6\u2030\u011f\ufffd\u2019\u00b5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5(i,j) italic_i , italic_j ) \u00e2\u02c6\u2030 caligraphic_Z, Setting these to zero yields Hence, ti\u00e2\ufffd\u00a2j\u00e2\u02c6\u2014=si\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2exp\u00e2\ufffd\u00a1(\u00e2\u02c6\u2019\u00ce\u00b1i)=c1\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2si\u00e2\ufffd\u00a2jsubscriptsuperscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018 \u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\ufffd1\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018 \u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014t^{*}_{ij}=s_{ij} start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = italic_s start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT roman_exp ( - italic_\u00ce\u00b1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = italic_c start_POSTSUBSCRIPT 1 italic_i end_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT, where c1\u00e2\ufffd\u00a2i=exp\u00e2\ufffd\u00a1(\u00e2\u02c6\u2019\u00ce\u00b1i)subscript\u011f\ufffd\u2018\ufffd1\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u2013c_{1i}= start_POSTSUBSCRIPT 1 italic_i end_POSTSUBSCRIPT = roman_exp ( - italic_\u00ce\u00b1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) and vj\u00e2\u02c6\u2014=wjsubscriptsuperscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018\u00a4\u011f\ufffd\u2018\u2014v^{*}_{j}=w_{j}italic_v start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = italic_w start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT. Also, \u00e2\u02c6\u2018j=1nti\u00e2\ufffd\u00a2j\u00e2\u02c6\u2014=u~isuperscriptsubscript\u011f\ufffd\u2018\u20141\u011f\ufffd\u2018\u203asubscriptsuperscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript~\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_t start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = over~ start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT implies (54). \u00c2 If (S,w)\u00e2\u02c6\u02c6\u011f\ufffd\u2019\u00af\u00e2\ufffd\u00a2\u011f\ufffd\u2019\u00b1\u011f\ufffd\u2018\u2020\u011f\ufffd\u2018\u00a4\u011f\ufffd\u2019\u00af\u011f\ufffd\u2019\u00b1(S,w) italic_S , italic_w ) \u00e2\u02c6\u02c6 caligraphic_T caligraphic_V then iff ti\u00e2\ufffd\u00a2j\u00e2\u02c6\u2014=c2\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2si\u00e2\ufffd\u00a2j,vj\u00e2\u02c6\u2014=c2\u00e2\ufffd\u00a2j\u00e2\u02c6\u20191\u00ce\u00b3\u00e2\ufffd\u00a2wjformulae-sequencesubscriptsuperscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018 \u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscriptsuperscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2014superscriptsubscript\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\u20141\u011f\ufffd\u203a\u00besubscript\u011f\ufffd\u2018\u00a4\u011f\ufffd\u2018\u2014t^{*}_{ij}=c_{2j}s_{ij}, start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = italic_c start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT , italic_v start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = italic_c start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - divide start_ARG 1 end_ARG start_ARG italic_\u00ce\u00b3 end_ARG end_POSTSUPERSCRIPT italic_w start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, where Since ti\u00e2\ufffd\u00a2j=0subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140t_{ij}=0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 0 for (i,j)\u00e2\u02c6\u02c6\u011f\ufffd\u2019\u00b5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5(i,j) italic_i , italic_j ) \u00e2\u02c6\u02c6 caligraphic_Z, the Lagrangian associated with this optimization problem is given by When (i,j)\u00e2\u02c6\u2030\u011f\ufffd\u2019\u00b5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5(i,j) italic_i , italic_j ) \u00e2\u02c6\u2030 caligraphic_Z, Setting these to zero results in Hence, ti\u00e2\ufffd\u00a2j\u00e2\u02c6\u2014=si\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2c2\u00e2\ufffd\u00a2jsubscriptsuperscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018 \u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\u2014t^{*}_{ij}=s_{ij}c_{2j}italic_t start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = italic_s start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT where c2\u00e2\ufffd\u00a2j=exp\u00e2\ufffd\u00a1(\u00e2\u02c6\u2019\u00ce\u00b2j)subscript\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u203a\u00bd\u011f\ufffd\u2018\u2014c_{2j}= start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT = roman_exp ( - italic_\u00ce\u00b2 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ). Also, vj\u00e2\u02c6\u2014=wj\u00e2\ufffd\u00a2exp\u00e2\ufffd\u00a1(\u00ce\u00b2j/\u00ce\u00b3)=c2\u00e2\ufffd\u00a2j\u00e2\u02c6\u20191/\u00ce\u00b3\u00e2\ufffd\u00a2wjsubscriptsuperscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018\u00a4\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u203a\u00bd\u011f\ufffd\u2018\u2014\u011f\ufffd\u203a\u00besuperscriptsubscript\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\u20141\u011f\ufffd\u203a\u00besubscript\u011f\ufffd\u2018\u00a4\u011f\ufffd\u2018\u2014v^{*}_{j}=w_{j} start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = italic_w start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT roman_exp ( italic_\u00ce\u00b2 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT / italic_\u00ce\u00b3 ) = italic_c start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 / italic_\u00ce\u00b3 end_POSTSUPERSCRIPT italic_w start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT. Due to the column sum constraints, we must have c2\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2\u00e2\u02c6\u2018i=1msi\u00e2\ufffd\u00a2j=\u00e2\u02c6\u2018i=1mti\u00e2\ufffd\u00a2j\u00e2\u02c6\u2014=vj\u00e2\u02c6\u2014=c2\u00e2\ufffd\u00a2j\u00e2\u02c6\u20191/\u00ce\u00b3\u00e2\ufffd\u00a2wjsubscript\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\u2014superscriptsubscript\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\u0161subscript\u011f\ufffd\u2018 \u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014superscriptsubscript\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\u0161subscriptsuperscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscriptsuperscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2014superscriptsubscript\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\u20141\u011f\ufffd\u203a\u00besubscript\u011f\ufffd\u2018\u00a4\u011f\ufffd\u2018\u2014c_{2j} start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_t start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = italic_v start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = italic_c start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 / italic_\u00ce\u00b3 end_POSTSUPERSCRIPT italic_w start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, that is, c2\u00e2\ufffd\u00a2j1+\u00ce\u00b3\u00ce\u00b3\u00e2\ufffd\u00a2\u00e2\u02c6\u2018i=1msi\u00e2\ufffd\u00a2j=wjsuperscriptsubscript\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\u20141\u011f\ufffd\u203a\u00be\u011f\ufffd\u203a\u00besuperscriptsubscript\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\u0161subscript\u011f\ufffd\u2018 \u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018\u00a4\u011f\ufffd\u2018\u2014c_{2j}^{ start_POSTSUBSCRIPT 2 italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT divide start_ARG 1 + italic_\u00ce\u00b3 end_ARG start_ARG italic_\u00ce\u00b3 end_ARG end_POSTSUPERSCRIPT \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = italic_w start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, which implies (55). \u00c2 It follows, from Theorem 2 and Lemmas 3 and 4, that the sequence, {(T(l),v(l)} ( italic_T ( italic_l ) , italic_v ( italic_l ) }, converges to a limit, (T\u00e2\u02c6\u2014,v\u00e2\u02c6\u2014)superscript\u011f\ufffd\u2018\u2021superscript\u011f\ufffd\u2018\u00a3(T^{*},v^{*})( italic_T start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT , italic_v start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT ), with T\u00e2\u02c6\u2014\u00e2\u02c6\u02c6\u011f\ufffd\u2019\u00afsuperscript\u011f\ufffd\u2018\u2021\u011f\ufffd\u2019\u00afT^{*} start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT \u00e2\u02c6\u02c6 caligraphic_T, v\u00e2\u02c6\u2014\u00e2\u02c6\u02c6\u00e2\u201e\ufffd+nsuperscript\u011f\ufffd\u2018\u00a3subscriptsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u203av^{*} start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT + end_POSTSUBSCRIPT, and this limit satisfies the constraints in (52). We now only need to prove that \u00e2\u02c6\u2021f\u00e2\ufffd\u00a2(x\u00e2\ufffd\u00a2(0))\u00e2\u02c6\u2021\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u00a50 f(x(0))\u00e2\u02c6\u2021 italic_f ( italic_x ( 0 ) ) satisfies (50), where x\u00e2\ufffd\u00a2(0)=vec\u00e2\ufffd\u00a2(K,\u00ce\u00b3\u00e2\ufffd\u00a2v~)\u011f\ufffd\u2018\u00a50vec\u011f\ufffd\ufffd\u00be\u011f\ufffd\u203a\u00be~\u011f\ufffd\u2018\u00a3x(0)= ( 0 ) = vec ( italic_K , italic_\u00ce\u00b3 over~ start_ARG italic_v end_ARG ). With J\u011f\ufffd\ufffd\u00bdJitalic_J given by (53), we have, for ti\u00e2\ufffd\u00a2j>0subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140t_{ij}>0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT > 0 and vj>0subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u20140v_{j}>0italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT > 0, Hence, \u00e2\u02c6\u201aJ\u00e2\u02c6\u201ati\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(K,v~)=0,\u00e2\u02c6\u201aJ\u00e2\u02c6\u201a\u00ce\u00b3\u00e2\ufffd\u00a2vj\u00e2\ufffd\u00a2(K,v~)=0formulae-sequence\u011f\ufffd\ufffd\u00bdsubscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\ufffd\u00be~\u011f\ufffd\u2018\u00a30\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u203a\u00besubscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2014\u011f\ufffd\ufffd\u00be~\u011f\ufffd\u2018\u00a30 J}{ t_{ij}}(K, J}{% v_{j}}(K, start_ARG \u00e2\u02c6\u201a italic_J end_ARG start_ARG \u00e2\u02c6\u201a italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT end_ARG ( italic_K , over~ start_ARG italic_v end_ARG ) = 0 , divide start_ARG \u00e2\u02c6\u201a italic_J end_ARG start_ARG \u00e2\u02c6\u201a italic_\u00ce\u00b3 italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_ARG ( italic_K , over~ start_ARG italic_v end_ARG ) = 0, and \u00e2\u02c6\u2021f\u00e2\ufffd\u00a2(x\u00e2\ufffd\u00a2(0))i=0\u00e2\u02c6\u2021\u011f\ufffd\u2018\u201csubscript\u011f\ufffd\u2018\u00a50\u011f\ufffd\u2018\u20130 f(x(0))_{i}=0\u00e2\u02c6\u2021 italic_f ( italic_x ( 0 ) ) start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 0 for i=1,2,\u00e2\u20ac\u00a6,q\u011f\ufffd\u2018\u201312\u00e2\u20ac\u00a6\u011f\ufffd\u2018\ufffdi=1,2, = 1 , 2 , \u00e2\u20ac\u00a6 , italic_q. Therefore, \u00e2\u02c6\u2021f\u00e2\ufffd\u00a2(x\u00e2\ufffd\u00a2(0))\u00e2\u02c6\u2021\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u00a50 f(x(0))\u00e2\u02c6\u2021 italic_f ( italic_x ( 0 ) ) satisfies (50). \u00e2\u2013 \u00e2\u2013 { 220.50885pt} SK-type iterations make sense for large-scale problems. Smart cities are a natural place to look for such problems, and, in particular, sharing economy [20] applications, since these are precisely the problem domains where allocation of resources at scale emerge, and where the scale of the problem is subject to temporal variations. One such problem arises in the context of charging m\u011f\ufffd\u2018\u0161mitalic_m electric vehicles (EVs) overnight in a city such as London. With the advent of vehicle-to-grid (V2G), vehicle-to-vehicle (V2V) and widespread availability of solar, it is likely that many entities that currently consume energy will become prosumers in the near future; i.e.\u00c2 most homes, and even cars, will consume energy and also make energy available, depending on the circumstance. Such a scenario is clearly very large scale, with a potentially very large number, m\u011f\ufffd\u2018\u0161mitalic_m, of EVs (there are currently more than 2.5M cars registered in London), and a large number, n\u011f\ufffd\u2018\u203anitalic_n, of energy providers (consisting of conventional utilities, energy brokerages, households and even other cars, and constituting the target agents of our OT setup in Section\u00c2 III). In the setting of this paper (Section\u00c2 III), each EV specifies the energy it requires in KWhrs, and then this demand for energy is communicated (i.e.\u00c2 \u00e2\u20ac\u02dctransported\u00e2\u20ac\u2122) to a set of providers. Each provider may set a cost based on their type of energy generation, their proximity to the car being charged, and the type of vehicle being charged. In addition, some providers may prohibit certain types of vehicles, for example plug-in hybrid vehicles (PHEVs), or vehicles that are very large in size. Our OT formulation (21) captures the realistic scenario in which the n\u011f\ufffd\u2018\u203anitalic_n energy providers make available flexible amounts of energy, nominally v~~\u011f\ufffd\u2018\u00a3 start_ARG italic_v end_ARG, to m\u011f\ufffd\u2018\u0161mitalic_m EVs whose demands are exactly u~~\u011f\ufffd\u2018\u00a2 start_ARG italic_u end_ARG. Furthermore, energy transfer between specified provider-EV pairs, (i,j)\u00e2\u02c6\u02c6\u011f\ufffd\u2019\u00b5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5(i,j) italic_i , italic_j ) \u00e2\u02c6\u02c6 caligraphic_Z (5), are not allowed a priori. To simulate this scenario, consider m=10,000\u011f\ufffd\u2018\u016110000m=10,000italic_m = 10 , 000 EVs requiring charging and n=10\u011f\ufffd\u2018\u203a10n=10italic_n = 10 energy providers. We simulate the specified energy charging requirement, u~isubscript~\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u2013 start_ARG italic_u end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, i=1,\u00e2\u20ac\u00a6,m\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u0161i=1, = 1 , \u00e2\u20ac\u00a6 , italic_m, of each EV via independent and uniform draws in the range (0,1)01(0,1)( 0 , 1 ) KWhrs. We simulate the nominal available energy of each supplier, v~jsubscript~\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2014 start_ARG italic_v end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, j=1,\u00e2\u20ac\u00a6,n\u011f\ufffd\u2018\u20141\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u203aj=1, = 1 , \u00e2\u20ac\u00a6 , italic_n, in the same way. Therefore, (1) may not hold, i.e.\u00c2 the transport problem may be unbalanced, in that the total energy required by the EVs may differ from the total nominal energy made available by the providers. This UOT problem is also solved by our algorithms. To effect prior zero constraints, we assume that even-indexed cars are PHEVs, and that even-indexed providers will not supply these PHEVs. This defines a transport plan with m\u00e2\ufffd\u00a2n4\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u203a4 start_ARG italic_m italic_n end_ARG start_ARG 4 end_ARG pre-specified zeroes. The non-zero elements of K\u011f\ufffd\ufffd\u00beKitalic_K in (15) are obtained with t~i\u00e2\ufffd\u00a2j=1subscript~\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20141 start_ARG italic_t end_ARG start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 1 and \u00ce\u00b30=1.99subscript\u011f\ufffd\u203a\u00be01.99 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = 1.99, and the transport cost, ci\u00e2\ufffd\u00a2jsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014c_{ij}italic_c start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT, \u00e2\u02c6\u20ac(i,j)\u00e2\u02c6\u2030\u011f\ufffd\u2019\u00b5for-all\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5 ( italic_i , italic_j ) \u00e2\u02c6\u2030 caligraphic_Z are again iid uniformly drawn from (0,1)01(0,1)( 0 , 1 ). We use Algorithm 1, with \u00ce\u00b3=1.005\u011f\ufffd\u203a\u00be1.005 = 1.005 (21), to obtain the OT plan, T\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018\u2021T^{*}italic_T start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT. Figure 1 illustrates the convergence of the algorithm for 10 simulation runs. Let T\u00e2\ufffd\u00a2(l\u00e2\u02c6\u20191)\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u21221T(l-1)italic_T ( italic_l - 1 ) and T\u00e2\ufffd\u00a2(l)\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u2122T(l)italic_T ( italic_l ) be the transport plans obtained from two consecutive iterations of the algorithm in any one simulation, and let \u00ce\u201d\u00e2\ufffd\u00a2(l)\u00ce\u201d\u011f\ufffd\u2018\u2122 ( italic_l ) be the matrix with (i,j)\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014(i,j)( italic_i , italic_j )th entry defined as \u00ce\u00b4i\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(l)=|ti\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(l)\u00e2\u02c6\u2019ti\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(l\u00e2\u02c6\u20191)|subscript\u011f\ufffd\u203a\u00bf\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u2122subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u2122subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u21221 start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ( italic_l ) = | italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ( italic_l ) - italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ( italic_l - 1 ) |. Figure 1 plots the log of the sum of the \u00ce\u00b4i\u00e2\ufffd\u00a2jsubscript\u011f\ufffd\u203a\u00bf\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014 start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPTs, normalised by the first log-sum, for each of the 10 simulations, i.e. log\u00e2\ufffd\u00a1(\u00e2\u02c6\u2018(i,j)\u00e2\u02c6\u2030\u011f\ufffd\u2019\u00b5|ti\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(l)\u00e2\u02c6\u2019ti\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(l\u00e2\u02c6\u20191)|)log\u00e2\ufffd\u00a1(\u00e2\u02c6\u2018(i,j)\u00e2\u02c6\u2030\u011f\ufffd\u2019\u00b5|ti\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(1)\u00e2\u02c6\u2019ti\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(0)|)subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u2122subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u21221subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00b5subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20141subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140 { start_ARG roman_log ( \u00e2\u02c6\u2018 start_POSTSUBSCRIPT ( italic_i , italic_j ) \u00e2\u02c6\u2030 caligraphic_Z end_POSTSUBSCRIPT | italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ( italic_l ) - italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ( italic_l - 1 ) | ) end_ARG start_ARG roman_log ( \u00e2\u02c6\u2018 start_POSTSUBSCRIPT ( italic_i , italic_j ) \u00e2\u02c6\u2030 caligraphic_Z end_POSTSUBSCRIPT | italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ( 1 ) - italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ( 0 ) | ) end_ARG. We have normalized in order to facilitate comparison of the different simulations. In this paper, we have presented SK-type algorithms for constrained optimal transport. Specifically, our algorithms allow for transport plans that force some entries to be zero a priori. The convergence proof is based on Bregman-type ideas. An example in resource allocation for the sharing economy is provided, pointing to situations in which our algorithm is relevant. Future work will investigate extension of this work to problems that incorporate other forms of regularisation terms [21], and other potential use-cases.",
        "keywords": ""
    },
    {
        "id": 9,
        "title": "A contribution to the theory of \u00cf\u0192\u011f\ufffd\u0153\ufffd\\sigmaitalic_\u00cf\u0192-properties of a finite group\u00e2\u20ac\u00a0\u00e2\u20ac\u00a0thanks: Research was supported by the National\nNatural Science Foundation of China\n(No. 12171126, 12101165).\nResearch of the third author and the fourth author was\nsupported by the Ministry of Education of the\nRepublic of Belarus (No.\u00c2\u00a020211328, 20211778).\n\nIn memory of Professor Francesco de Giovanni",
        "abstract": "AbstractLet\u00cf\u0192={\u00cf\u0192i\u00e2\u02c6\u00a3i\u00e2\u02c6\u02c6I}\u011f\ufffd\u0153\ufffdconditional-setsubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2013\u011f\ufffd\ufffd\u00bc\\sigma=\\{\\sigma_{i}\\mid i\\in I\\}italic_\u00cf\u0192 = { italic_\u00cf\u0192 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u02c6\u00a3 italic_i \u00e2\u02c6\u02c6 italic_I }be some\npartition of the set of all primes.\nA subgroupA\u011f\ufffd\ufffd\u00b4Aitalic_Aof a finite groupG\u011f\ufffd\ufffd\u00baGitalic_Gis said to be: (i)\u00cf\u0192\u011f\ufffd\u0153\ufffd\\sigmaitalic_\u00cf\u0192-subnormalinG\u011f\ufffd\ufffd\u00baGitalic_Gif\nthere is a subgroup chainA=A0\u00e2\u2030\u00a4A1\u00e2\u2030\u00a4\u00e2\u2039\u00af\u00e2\u2030\u00a4An=G\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\ufffd\u00b40subscript\u011f\ufffd\ufffd\u00b41\u00e2\u2039\u00afsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u203a\u011f\ufffd\ufffd\u00baA=A_{0}\\leq A_{1}\\leq\\cdots\\leq A_{n}=Gitalic_A = italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 \u00e2\u2039\u00af \u00e2\u2030\u00a4 italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = italic_Gsuch that eitherAi\u00e2\u02c6\u20191\u00e2\ufffd\u00a2\u00e2\u0160\u00b4\u00e2\ufffd\u00a2Aisubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u20131\u00e2\u0160\u00b4subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u2013A_{i-1}\\trianglelefteq A_{i}italic_A start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT \u00e2\u0160\u00b4 italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPTorAi/(Ai\u00e2\u02c6\u20191)Aisubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u2013subscriptsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u20131subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u2013A_{i}/(A_{i-1})_{A_{i}}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / ( italic_A start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPTis a\u00cf\u0192jsubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2014{\\sigma}_{j}italic_\u00cf\u0192 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT-group,j=j\u00e2\ufffd\u00a2(i)\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u2013j=j(i)italic_j = italic_j ( italic_i ), for alli=1,\u00e2\u20ac\u00a6,n\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u203ai=1,\\ldots,nitalic_i = 1 , \u00e2\u20ac\u00a6 , italic_n;\n(ii)modularinG\u011f\ufffd\ufffd\u00baGitalic_Gif the following conditions are held:\n(1)\u00e2\u0178\u00a8X,A\u00e2\u02c6\u00a9Z\u00e2\u0178\u00a9=\u00e2\u0178\u00a8X,A\u00e2\u0178\u00a9\u00e2\u02c6\u00a9Z\u011f\ufffd\u2018\u2039\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2039\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\ufffd\\langle X,A\\cap Z\\rangle=\\langle X,A\\rangle\\cap Z\u00e2\u0178\u00a8 italic_X , italic_A \u00e2\u02c6\u00a9 italic_Z \u00e2\u0178\u00a9 = \u00e2\u0178\u00a8 italic_X , italic_A \u00e2\u0178\u00a9 \u00e2\u02c6\u00a9 italic_Zfor allX\u00e2\u2030\u00a4G,Z\u00e2\u2030\u00a4Gformulae-sequence\u011f\ufffd\u2018\u2039\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00baX\\leq G,Z\\leq Gitalic_X \u00e2\u2030\u00a4 italic_G , italic_Z \u00e2\u2030\u00a4 italic_Gsuch thatX\u00e2\u2030\u00a4Z\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\ufffdX\\leq Zitalic_X \u00e2\u2030\u00a4 italic_Z, and\n(2)\u00e2\u0178\u00a8A,Y\u00e2\u02c6\u00a9Z\u00e2\u0178\u00a9=\u00e2\u0178\u00a8A,Y\u00e2\u0178\u00a9\u00e2\u02c6\u00a9Z\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\ufffd\\langle A,Y\\cap Z\\rangle=\\langle A,Y\\rangle\\cap Z\u00e2\u0178\u00a8 italic_A , italic_Y \u00e2\u02c6\u00a9 italic_Z \u00e2\u0178\u00a9 = \u00e2\u0178\u00a8 italic_A , italic_Y \u00e2\u0178\u00a9 \u00e2\u02c6\u00a9 italic_Zfor allY\u00e2\u2030\u00a4G,Z\u00e2\u2030\u00a4Gformulae-sequence\u011f\ufffd\u2018\u0152\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00baY\\leq G,Z\\leq Gitalic_Y \u00e2\u2030\u00a4 italic_G , italic_Z \u00e2\u2030\u00a4 italic_Gsuch thatA\u00e2\u2030\u00a4Z\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\ufffdA\\leq Zitalic_A \u00e2\u2030\u00a4 italic_Z; (iii)\u00cf\u0192\u011f\ufffd\u0153\ufffd\\sigmaitalic_\u00cf\u0192-quasinormal inG\u011f\ufffd\ufffd\u00baGitalic_GifA\u011f\ufffd\ufffd\u00b4Aitalic_Ais\u00cf\u0192\u011f\ufffd\u0153\ufffd\\sigmaitalic_\u00cf\u0192-subnormal and modular inG\u011f\ufffd\ufffd\u00baGitalic_G.We obtain a description of finite groups in which\u00cf\u0192\u011f\ufffd\u0153\ufffd\\sigmaitalic_\u00cf\u0192-quasinormality (respectively, modularity) is a\ntransitive relation. Some known results are extended.00footnotetext:Keywords: finite group, modular subgroup,\u00cf\u0192\u011f\ufffd\u0153\ufffd\\sigmaitalic_\u00cf\u0192-subnormal subgroup,\u00cf\u0192\u011f\ufffd\u0153\ufffd\\sigmaitalic_\u00cf\u0192-quasinormal subgroup,Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q\\sigma Titalic_Q italic_\u00cf\u0192 italic_T-group.00footnotetext:Mathematics Subject Classification (2010): 20D10, 20D15, 20D30.",
        "corpus": "Let \u00cf\u0192={\u00cf\u0192i\u00e2\u02c6\u00a3i\u00e2\u02c6\u02c6I}\u011f\ufffd\u0153\ufffdconditional-setsubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2013\u011f\ufffd\ufffd\u00bc i I = { italic_\u00cf\u0192 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u02c6\u00a3 italic_i \u00e2\u02c6\u02c6 italic_I } be some partition of the set of all primes. A subgroup A\u011f\ufffd\ufffd\u00b4Aitalic_A of a finite group G\u011f\ufffd\ufffd\u00baGitalic_G is said to be: (i) \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G if there is a subgroup chain A=A0\u00e2\u2030\u00a4A1\u00e2\u2030\u00a4\u00e2\u2039\u00af\u00e2\u2030\u00a4An=G\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\ufffd\u00b40subscript\u011f\ufffd\ufffd\u00b41\u00e2\u2039\u00afsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u203a\u011f\ufffd\ufffd\u00baA=A_{0} A_{1} A_{n}=Gitalic_A = italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 \u00e2\u2039\u00af \u00e2\u2030\u00a4 italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = italic_G such that either Ai\u00e2\u02c6\u20191\u00e2\ufffd\u00a2\u00e2\u0160\u00b4\u00e2\ufffd\u00a2Aisubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u20131\u00e2\u0160\u00b4subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u2013A_{i-1} A_{i}italic_A start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT \u00e2\u0160\u00b4 italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT or Ai/(Ai\u00e2\u02c6\u20191)Aisubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u2013subscriptsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u20131subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u2013A_{i}/(A_{i-1})_{A_{i}}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / ( italic_A start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT is a \u00cf\u0192jsubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2014{ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT-group, j=j\u00e2\ufffd\u00a2(i)\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u2013j=j(i)italic_j = italic_j ( italic_i ), for all i=1,\u00e2\u20ac\u00a6,n\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u203ai=1, = 1 , \u00e2\u20ac\u00a6 , italic_n; (ii) modular in G\u011f\ufffd\ufffd\u00baGitalic_G if the following conditions are held: (1) \u00e2\u0178\u00a8X,A\u00e2\u02c6\u00a9Z\u00e2\u0178\u00a9=\u00e2\u0178\u00a8X,A\u00e2\u0178\u00a9\u00e2\u02c6\u00a9Z\u011f\ufffd\u2018\u2039\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2039\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\ufffd X,A Z X,A Z\u00e2\u0178\u00a8 italic_X , italic_A \u00e2\u02c6\u00a9 italic_Z \u00e2\u0178\u00a9 = \u00e2\u0178\u00a8 italic_X , italic_A \u00e2\u0178\u00a9 \u00e2\u02c6\u00a9 italic_Z for all X\u00e2\u2030\u00a4G,Z\u00e2\u2030\u00a4Gformulae-sequence\u011f\ufffd\u2018\u2039\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00baX G,Z Gitalic_X \u00e2\u2030\u00a4 italic_G , italic_Z \u00e2\u2030\u00a4 italic_G such that X\u00e2\u2030\u00a4Z\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\ufffdX Zitalic_X \u00e2\u2030\u00a4 italic_Z, and (2) \u00e2\u0178\u00a8A,Y\u00e2\u02c6\u00a9Z\u00e2\u0178\u00a9=\u00e2\u0178\u00a8A,Y\u00e2\u0178\u00a9\u00e2\u02c6\u00a9Z\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\ufffd A,Y Z A,Y Z\u00e2\u0178\u00a8 italic_A , italic_Y \u00e2\u02c6\u00a9 italic_Z \u00e2\u0178\u00a9 = \u00e2\u0178\u00a8 italic_A , italic_Y \u00e2\u0178\u00a9 \u00e2\u02c6\u00a9 italic_Z for all Y\u00e2\u2030\u00a4G,Z\u00e2\u2030\u00a4Gformulae-sequence\u011f\ufffd\u2018\u0152\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00baY G,Z Gitalic_Y \u00e2\u2030\u00a4 italic_G , italic_Z \u00e2\u2030\u00a4 italic_G such that A\u00e2\u2030\u00a4Z\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\ufffdA Zitalic_A \u00e2\u2030\u00a4 italic_Z; (iii) \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G if A\u011f\ufffd\ufffd\u00b4Aitalic_A is \u00cf\u0192\u011f\ufffd\u0153\ufffd and modular in G\u011f\ufffd\ufffd\u00baGitalic_G. We obtain a description of finite groups in which \u00cf\u0192\u011f\ufffd\u0153\ufffd (respectively, modularity) is a transitive relation. Some known results are extended. Throughout this paper, all groups are finite and G\u011f\ufffd\ufffd\u00baGitalic_G always denotes a finite group; \u00e2\u201e\u2019\u00e2\ufffd\u00a2(G)\u00e2\u201e\u2019\u011f\ufffd\ufffd\u00ba{ L}(G)caligraphic_L ( italic_G ) is the lattice of all subgroups of G\u011f\ufffd\ufffd\u00baGitalic_G; G\u011f\ufffd\ufffd\u00baGitalic_G is said to be an M\u011f\ufffd\u2018\u20acMitalic_M-group [1] if the lattice \u00e2\u201e\u2019\u00e2\ufffd\u00a2(G)\u00e2\u201e\u2019\u011f\ufffd\ufffd\u00ba{ L}(G)caligraphic_L ( italic_G ) is modular. Moreover, \u00e2\u201e\u2122\u00e2\u201e\u2122 is the set of all primes, \u00cf\u20ac\u00e2\u0160\u2020\u00e2\u201e\u2122\u011f\ufffd\u0153\u2039\u00e2\u201e\u2122 \u00e2\u0160\u2020 blackboard_P, \u00cf\u20ac\u00e2\u20ac\u00b2=\u00e2\u201e\u2122\u00e2\u02c6\u2013\u00cf\u20acsuperscript\u011f\ufffd\u0153\u2039\u00e2\u20ac\u00b2\u00e2\u201e\u2122\u011f\ufffd\u0153\u2039 start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT = blackboard_P \u00e2\u02c6\u2013 italic_\u00cf\u20ac, and \u00cf\u0192={\u00cf\u0192i\u00e2\u02c6\u00a3i\u00e2\u02c6\u02c6I}\u011f\ufffd\u0153\ufffdconditional-setsubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2013\u011f\ufffd\ufffd\u00bc i I = { italic_\u00cf\u0192 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u02c6\u00a3 italic_i \u00e2\u02c6\u02c6 italic_I } is some partition of \u00e2\u201e\u2122\u00e2\u201e\u2122 If n\u011f\ufffd\u2018\u203anitalic_n is an integer, the symbol \u00cf\u20ac\u00e2\ufffd\u00a2(n)\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\u203a ( italic_n ) denotes the set of all primes dividing n\u011f\ufffd\u2018\u203anitalic_n; as usual, \u00cf\u20ac\u00e2\ufffd\u00a2(G)=\u00cf\u20ac\u00e2\ufffd\u00a2(|G|)\u011f\ufffd\u0153\u2039\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u0153\u2039\u011f\ufffd\ufffd\u00ba ( italic_G ) = italic_\u00cf\u20ac ( | italic_G | ), the set of all primes dividing the order of G\u011f\ufffd\ufffd\u00baGitalic_G; \u00cf\u0192\u00e2\ufffd\u00a2(n)={\u00cf\u0192i\u00e2\u02c6\u00a3\u00cf\u0192i\u00e2\u02c6\u00a9\u00cf\u20ac\u00e2\ufffd\u00a2(n)\u00e2\u2030 \u00e2\u02c6\u2026}\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u203aconditional-setsubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\u203a ( italic_n ) = { italic_\u00cf\u0192 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u02c6\u00a3 italic_\u00cf\u0192 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u02c6\u00a9 italic_\u00cf\u20ac ( italic_n ) \u00e2\u2030 \u00e2\u02c6\u2026 } and \u00cf\u0192\u00e2\ufffd\u00a2(G)=\u00cf\u0192\u00e2\ufffd\u00a2(|G|)\u011f\ufffd\u0153\ufffd\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u0153\ufffd\u011f\ufffd\ufffd\u00ba ( italic_G ) = italic_\u00cf\u0192 ( | italic_G | ) [2, 3]. A group G\u011f\ufffd\ufffd\u00baGitalic_G is said to be [2, 3]: \u00cf\u0192\u011f\ufffd\u0153\ufffd if G\u011f\ufffd\ufffd\u00baGitalic_G is a \u00cf\u0192isubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT-group for some i\u011f\ufffd\u2018\u2013iitalic_i; \u00cf\u0192\u011f\ufffd\u0153\ufffd if G\u011f\ufffd\ufffd\u00baGitalic_G is a direct product of \u00cf\u0192\u011f\ufffd\u0153\ufffd groups. A subgroup A\u011f\ufffd\ufffd\u00b4Aitalic_A of G\u011f\ufffd\ufffd\u00baGitalic_G is said to be quasinormal (Ore) or permutable (Stonehewer) in G\u011f\ufffd\ufffd\u00baGitalic_G if A\u011f\ufffd\ufffd\u00b4Aitalic_A permutes with every subgroup H\u011f\ufffd\ufffd\u00bbHitalic_H of G\u011f\ufffd\ufffd\u00baGitalic_G, that is, A\u00e2\ufffd\u00a2H=H\u00e2\ufffd\u00a2A\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00bb\u011f\ufffd\ufffd\u00bb\u011f\ufffd\ufffd\u00b4AH=HAitalic_A italic_H = italic_H italic_A. The quasinormal subgroups have many interesting and useful for applications properties. For instance, if A\u011f\ufffd\ufffd\u00b4Aitalic_A is quasinormal in G\u011f\ufffd\ufffd\u00baGitalic_G, then: A\u011f\ufffd\ufffd\u00b4Aitalic_A is subnormal in G\u011f\ufffd\ufffd\u00baGitalic_G (Ore [4]), A/AG\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00baA/A_{G}italic_A / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is nilpotent (Ito and Szep [5]), every chief factor H/K\u011f\ufffd\ufffd\u00bb\u011f\ufffd\ufffd\u00beH/Kitalic_H / italic_K of G\u011f\ufffd\ufffd\u00baGitalic_G between AGsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00baA_{G}italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT and AGsuperscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00baA^{G}italic_A start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT is central, that is, CG\u00e2\ufffd\u00a2(H/K)=Gsubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00bb\u011f\ufffd\ufffd\u00be\u011f\ufffd\ufffd\u00baC_{G}(H/K)=Gitalic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_H / italic_K ) = italic_G (Maier and Schmid [6]), and, in general, the section A/AG\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00baA/A_{G}italic_A / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is not necessarily abelian (Thomson [7]). Quasinormal subgroups have a close connection with the so-called modular subgroups. Recall that a subgroup M\u011f\ufffd\u2018\u20acMitalic_M of G\u011f\ufffd\ufffd\u00baGitalic_G is said to be: (i) modular in G\u011f\ufffd\ufffd\u00baGitalic_G [1] if M\u011f\ufffd\u2018\u20acMitalic_M is a modular element (in the sense of Kurosh [1, p. 43]) of the lattice \u00e2\u201e\u2019\u00e2\ufffd\u00a2(G)\u00e2\u201e\u2019\u011f\ufffd\ufffd\u00ba{ L}(G)caligraphic_L ( italic_G ), that is, (1) \u00e2\u0178\u00a8X,M\u00e2\u02c6\u00a9Z\u00e2\u0178\u00a9=\u00e2\u0178\u00a8X,M\u00e2\u0178\u00a9\u00e2\u02c6\u00a9Z\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd X,M Z X,M Z\u00e2\u0178\u00a8 italic_X , italic_M \u00e2\u02c6\u00a9 italic_Z \u00e2\u0178\u00a9 = \u00e2\u0178\u00a8 italic_X , italic_M \u00e2\u0178\u00a9 \u00e2\u02c6\u00a9 italic_Z for all X\u00e2\u2030\u00a4G,Z\u00e2\u2030\u00a4Gformulae-sequence\u011f\ufffd\u2018\u2039\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00baX G,Z Gitalic_X \u00e2\u2030\u00a4 italic_G , italic_Z \u00e2\u2030\u00a4 italic_G such that X\u00e2\u2030\u00a4Z\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\ufffdX Zitalic_X \u00e2\u2030\u00a4 italic_Z, and (2) \u00e2\u0178\u00a8M,Y\u00e2\u02c6\u00a9Z\u00e2\u0178\u00a9=\u00e2\u0178\u00a8M,Y\u00e2\u0178\u00a9\u00e2\u02c6\u00a9Z\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\ufffd M,Y Z M,Y Z\u00e2\u0178\u00a8 italic_M , italic_Y \u00e2\u02c6\u00a9 italic_Z \u00e2\u0178\u00a9 = \u00e2\u0178\u00a8 italic_M , italic_Y \u00e2\u0178\u00a9 \u00e2\u02c6\u00a9 italic_Z for all Y\u00e2\u2030\u00a4G,Z\u00e2\u2030\u00a4Gformulae-sequence\u011f\ufffd\u2018\u0152\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00baY G,Z Gitalic_Y \u00e2\u2030\u00a4 italic_G , italic_Z \u00e2\u2030\u00a4 italic_G such that M\u00e2\u2030\u00a4Z\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffdM Zitalic_M \u00e2\u2030\u00a4 italic_Z; (ii) submodular in G\u011f\ufffd\ufffd\u00baGitalic_G if there is a subgroup chain A=A0\u00e2\u2030\u00a4A1\u00e2\u2030\u00a4\u00e2\u2039\u00af\u00e2\u2030\u00a4An=G\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\ufffd\u00b40subscript\u011f\ufffd\ufffd\u00b41\u00e2\u2039\u00afsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u203a\u011f\ufffd\ufffd\u00baA=A_{0} A_{1} A_{n}=Gitalic_A = italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 \u00e2\u2039\u00af \u00e2\u2030\u00a4 italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = italic_G such that Ai\u00e2\u02c6\u20191subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u20131A_{i-1}italic_A start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT is modular in Aisubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u2013A_{i}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT for all i=1,\u00e2\u20ac\u00a6,n\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u203ai=1, = 1 , \u00e2\u20ac\u00a6 , italic_n. Every quasinormal is clearly modular in the group. Moreover, the following remarkable result is well-known. Theorem A (Schmidt [1, Theorem 5.1.1]) A subgroup A\u011f\ufffd\ufffd\u00b4Aitalic_A of G\u011f\ufffd\ufffd\u00baGitalic_G is quasinormal in G\u011f\ufffd\ufffd\u00baGitalic_G if and only if A\u011f\ufffd\ufffd\u00b4Aitalic_A is subnormal and modular in G\u011f\ufffd\ufffd\u00baGitalic_G. This result made it possible to find an analogue of quasinormality in the theory of the \u00cf\u0192\u011f\ufffd\u0153\ufffd of a group [8]. A subgroup A\u011f\ufffd\ufffd\u00b4Aitalic_A of G\u011f\ufffd\ufffd\u00baGitalic_G is said to be \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G [2, 3] if there is a subgroup chain A=A0\u00e2\u2030\u00a4A1\u00e2\u2030\u00a4\u00e2\u2039\u00af\u00e2\u2030\u00a4An=G\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\ufffd\u00b40subscript\u011f\ufffd\ufffd\u00b41\u00e2\u2039\u00afsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u203a\u011f\ufffd\ufffd\u00baA=A_{0} A_{1} A_{n}=Gitalic_A = italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 \u00e2\u2039\u00af \u00e2\u2030\u00a4 italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = italic_G such that either Ai\u00e2\u02c6\u20191\u00e2\ufffd\u00a2\u00e2\u0160\u00b4\u00e2\ufffd\u00a2Aisubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u20131\u00e2\u0160\u00b4subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u2013A_{i-1} A_{i}italic_A start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT \u00e2\u0160\u00b4 italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT or Ai/(Ai\u00e2\u02c6\u20191)Aisubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u2013subscriptsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u20131subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u2013A_{i}/(A_{i-1})_{A_{i}}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / ( italic_A start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT is \u00cf\u0192\u011f\ufffd\u0153\ufffd{ for all i=1,\u00e2\u20ac\u00a6,n\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u203ai=1, = 1 , \u00e2\u20ac\u00a6 , italic_n; \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G (J.C. Beidleman) if x\u00e2\u02c6\u02c6NG\u00e2\ufffd\u00a2(A)\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b4x N_{G}(A)italic_x \u00e2\u02c6\u02c6 italic_N start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_A ) for all x\u00e2\u02c6\u02c6G\u011f\ufffd\u2018\u00a5\u011f\ufffd\ufffd\u00bax Gitalic_x \u00e2\u02c6\u02c6 italic_G such that \u00cf\u0192\u00e2\ufffd\u00a2(|x|)\u00e2\u02c6\u00a9\u00cf\u0192\u00e2\ufffd\u00a2(A)=\u00e2\u02c6\u2026\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u00a5\u011f\ufffd\u0153\ufffd\u011f\ufffd\ufffd\u00b4 ( | italic_x | ) \u00e2\u02c6\u00a9 italic_\u00cf\u0192 ( italic_A ) = \u00e2\u02c6\u2026. Definition 1.1. We say that a subgroup A\u011f\ufffd\ufffd\u00b4Aitalic_A of G\u011f\ufffd\ufffd\u00baGitalic_G is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G if A\u011f\ufffd\ufffd\u00b4Aitalic_A is \u00cf\u0192\u011f\ufffd\u0153\ufffd and modular in G\u011f\ufffd\ufffd\u00baGitalic_G. Before continuing, consider some examples. Example 1.2. (i) In the first limiting case, when \u00cf\u0192={\u00e2\u201e\u2122}\u011f\ufffd\u0153\ufffd\u00e2\u201e\u2122 = { blackboard_P }, every group is \u00cf\u0192\u011f\ufffd\u0153\ufffd and every subgroup of any group is \u00cf\u0192\u011f\ufffd\u0153\ufffd Therefore in this case a subgroup A\u011f\ufffd\ufffd\u00b4Aitalic_A of G\u011f\ufffd\ufffd\u00baGitalic_G is \u00cf\u0192\u011f\ufffd\u0153\ufffd if and only if it is modular in G\u011f\ufffd\ufffd\u00baGitalic_G. (ii) In the second limiting case, when \u00cf\u0192=\u00cf\u01921={{2},{3},{5}\u00e2\ufffd\u00a2\u00e2\u20ac\u00a6}\u011f\ufffd\u0153\ufffdsuperscript\u011f\ufffd\u0153\ufffd1235\u00e2\u20ac\u00a6 = italic_\u00cf\u0192 start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT = { { 2 } , { 3 } , { 5 } \u00e2\u20ac\u00a6 }, a subgroup A\u011f\ufffd\ufffd\u00b4Aitalic_A of G\u011f\ufffd\ufffd\u00baGitalic_G is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G if and only if it is subnormal in G\u011f\ufffd\ufffd\u00baGitalic_G. Therefore in this case, in view of Theorem A, a subgroup A\u011f\ufffd\ufffd\u00b4Aitalic_A of G\u011f\ufffd\ufffd\u00baGitalic_G is \u00cf\u0192\u011f\ufffd\u0153\ufffd if and only if it is quasinormal in G\u011f\ufffd\ufffd\u00baGitalic_G. (iii) In the case \u00cf\u0192=\u00cf\u01921\u00e2\ufffd\u00a2\u00cf\u20ac={{p1},\u00e2\u20ac\u00a6,{pn},\u00cf\u20ac\u00e2\u20ac\u00b2}\u011f\ufffd\u0153\ufffdsuperscript\u011f\ufffd\u0153\ufffd1\u011f\ufffd\u0153\u2039subscript\u011f\ufffd\u2018\ufffd1\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203asuperscript\u011f\ufffd\u0153\u2039\u00e2\u20ac\u00b2 = italic_\u00cf\u0192 start_POSTSUPERSCRIPT 1 italic_\u00cf\u20ac end_POSTSUPERSCRIPT = { { italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT } , \u00e2\u20ac\u00a6 , { italic_p start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } , italic_\u00cf\u20ac start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT }, where \u00cf\u20ac={p1,\u00e2\u20ac\u00a6,pn}\u011f\ufffd\u0153\u2039subscript\u011f\ufffd\u2018\ufffd1\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a = { italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_p start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }, a subgroup A\u011f\ufffd\ufffd\u00b4Aitalic_A of G\u011f\ufffd\ufffd\u00baGitalic_G is \u00cf\u01921\u00e2\ufffd\u00a2\u00cf\u20acsuperscript\u011f\ufffd\u0153\ufffd1\u011f\ufffd\u0153\u2039 start_POSTSUPERSCRIPT 1 italic_\u00cf\u20ac end_POSTSUPERSCRIPT-subnormal in G\u011f\ufffd\ufffd\u00baGitalic_G if and only if G\u011f\ufffd\ufffd\u00baGitalic_G has a subgroup chain A=A0\u00e2\u2030\u00a4A1\u00e2\u2030\u00a4\u00e2\u2039\u00af\u00e2\u2030\u00a4An=G\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\ufffd\u00b40subscript\u011f\ufffd\ufffd\u00b41\u00e2\u2039\u00afsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u203a\u011f\ufffd\ufffd\u00baA=A_{0} A_{1} A_{n}=Gitalic_A = italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 \u00e2\u2039\u00af \u00e2\u2030\u00a4 italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = italic_G such that either Ai\u00e2\u02c6\u20191\u00e2\ufffd\u00a2\u00e2\u0160\u00b4\u00e2\ufffd\u00a2Aisubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u20131\u00e2\u0160\u00b4subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u2013A_{i-1} A_{i}italic_A start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT \u00e2\u0160\u00b4 italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT or Ai/(Ai\u00e2\u02c6\u20191)Aisubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u2013subscriptsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u20131subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u2013A_{i}/(A_{i-1})_{A_{i}}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / ( italic_A start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT is a \u00cf\u20ac\u00e2\u20ac\u00b2superscript\u011f\ufffd\u0153\u2039\u00e2\u20ac\u00b2{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT-group for all i=1,\u00e2\u20ac\u00a6,n\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u203ai=1, = 1 , \u00e2\u20ac\u00a6 , italic_n. In this case we say, following [9, 10, 11], that A\u011f\ufffd\ufffd\u00b4Aitalic_A is 1\u00e2\ufffd\u00a2\u00cf\u20ac1\u011f\ufffd\u0153\u20391 italic_\u00cf\u20ac-subnormal in G\u011f\ufffd\ufffd\u00baGitalic_G, and we say that A\u011f\ufffd\ufffd\u00b4Aitalic_A is 1\u00e2\ufffd\u00a2\u00cf\u20ac1\u011f\ufffd\u0153\u20391 italic_\u00cf\u20ac-quasinormal in G\u011f\ufffd\ufffd\u00baGitalic_G if A\u011f\ufffd\ufffd\u00b4Aitalic_A is 1\u00e2\ufffd\u00a2\u00cf\u20ac1\u011f\ufffd\u0153\u20391 italic_\u00cf\u20ac-subnormal and modular in G\u011f\ufffd\ufffd\u00baGitalic_G. Note, in passing, that A\u011f\ufffd\ufffd\u00b4Aitalic_A is 1\u00e2\ufffd\u00a2\u00cf\u20ac1\u011f\ufffd\u0153\u20391 italic_\u00cf\u20ac-subnormal in G\u011f\ufffd\ufffd\u00baGitalic_G if and only if A\u011f\ufffd\ufffd\u00b4Aitalic_A is \u011f\ufffd\u201d\u2030\u011f\ufffd\u201d\u2030 in G\u011f\ufffd\ufffd\u00baGitalic_G in the sence of Kegel [12], where \u011f\ufffd\u201d\u2030\u011f\ufffd\u201d\u2030 is the class of all \u00cf\u20ac\u00e2\u20ac\u00b2superscript\u011f\ufffd\u0153\u2039\u00e2\u20ac\u00b2 start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT-groups. (iv) In the other classical case \u00cf\u0192=\u00cf\u0192\u00cf\u20ac={\u00cf\u20ac,\u00cf\u20ac\u00e2\u20ac\u00b2}\u011f\ufffd\u0153\ufffdsuperscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u0153\u2039\u011f\ufffd\u0153\u2039superscript\u011f\ufffd\u0153\u2039\u00e2\u20ac\u00b2 = italic_\u00cf\u0192 start_POSTSUPERSCRIPT italic_\u00cf\u20ac end_POSTSUPERSCRIPT = { italic_\u00cf\u20ac , italic_\u00cf\u20ac start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT } a subgroup A\u011f\ufffd\ufffd\u00b4Aitalic_A of G\u011f\ufffd\ufffd\u00baGitalic_G is \u00cf\u0192\u00cf\u20acsuperscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u0153\u2039{ start_POSTSUPERSCRIPT italic_\u00cf\u20ac end_POSTSUPERSCRIPT-subnormal in G\u011f\ufffd\ufffd\u00baGitalic_G if and only if G\u011f\ufffd\ufffd\u00baGitalic_G has a subgroup chain A=A0\u00e2\u2030\u00a4A1\u00e2\u2030\u00a4\u00e2\u2039\u00af\u00e2\u2030\u00a4An=G\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\ufffd\u00b40subscript\u011f\ufffd\ufffd\u00b41\u00e2\u2039\u00afsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u203a\u011f\ufffd\ufffd\u00baA=A_{0} A_{1} A_{n}=Gitalic_A = italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 \u00e2\u2039\u00af \u00e2\u2030\u00a4 italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = italic_G such that either Ai\u00e2\u02c6\u20191\u00e2\ufffd\u00a2\u00e2\u0160\u00b4\u00e2\ufffd\u00a2Aisubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u20131\u00e2\u0160\u00b4subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u2013A_{i-1} A_{i}italic_A start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT \u00e2\u0160\u00b4 italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, or Ai/(Ai\u00e2\u02c6\u20191)Aisubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u2013subscriptsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u20131subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u2013A_{i}/(A_{i-1})_{A_{i}}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / ( italic_A start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT is a \u00cf\u20ac\u011f\ufffd\u0153\u2039{ or Ai/(Ai\u00e2\u02c6\u20191)Aisubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u2013subscriptsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u20131subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u2013A_{i}/(A_{i-1})_{A_{i}}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / ( italic_A start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT is a \u00cf\u20ac\u00e2\u20ac\u00b2superscript\u011f\ufffd\u0153\u2039\u00e2\u20ac\u00b2{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT-group for all i=1,\u00e2\u20ac\u00a6,n\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u203ai=1, = 1 , \u00e2\u20ac\u00a6 , italic_n. In this case we say that A\u011f\ufffd\ufffd\u00b4Aitalic_A is \u00cf\u20ac,\u00cf\u20ac\u00e2\u20ac\u00b2\u011f\ufffd\u0153\u2039superscript\u011f\ufffd\u0153\u2039\u00e2\u20ac\u00b2 , italic_\u00cf\u20ac start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT-subnormal in G\u011f\ufffd\ufffd\u00baGitalic_G [9, 10, 11], and we say that A\u011f\ufffd\ufffd\u00b4Aitalic_A is \u00cf\u20ac,\u00cf\u20ac\u00e2\u20ac\u00b2\u011f\ufffd\u0153\u2039superscript\u011f\ufffd\u0153\u2039\u00e2\u20ac\u00b2 , italic_\u00cf\u20ac start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT-quasinormal in G\u011f\ufffd\ufffd\u00baGitalic_G if A\u011f\ufffd\ufffd\u00b4Aitalic_A is \u00cf\u20ac,\u00cf\u20ac\u00e2\u20ac\u00b2\u011f\ufffd\u0153\u2039superscript\u011f\ufffd\u0153\u2039\u00e2\u20ac\u00b2 , italic_\u00cf\u20ac start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT-subnormal and modular in G\u011f\ufffd\ufffd\u00baGitalic_G. The theory of \u00cf\u0192\u011f\ufffd\u0153\ufffd subgroups was constructed in the paper [13]. In particular, it was proven the following result covering in the case \u00cf\u0192=\u00cf\u01921={{2},{3},{5}\u00e2\ufffd\u00a2\u00e2\u20ac\u00a6}\u011f\ufffd\u0153\ufffdsuperscript\u011f\ufffd\u0153\ufffd1235\u00e2\u20ac\u00a6 = italic_\u00cf\u0192 start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT = { { 2 } , { 3 } , { 5 } \u00e2\u20ac\u00a6 } the above mentioned results in [4, 5, 6]. Theorem B (See Theorem C in [13]). Let A\u011f\ufffd\ufffd\u00b4Aitalic_A be a \u00cf\u0192\u011f\ufffd\u0153\ufffd subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G. Then the following statements hold: (i) A\u011f\ufffd\ufffd\u00b4Aitalic_A permutes with all Hall \u00cf\u0192isubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT-subgroups of G\u011f\ufffd\ufffd\u00baGitalic_G for all i\u011f\ufffd\u2018\u2013iitalic_i. (ii) The quotients AG/AGsuperscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00baA^{G}/A_{G}italic_A start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT and G/CG\u00e2\ufffd\u00a2(AG/AG)\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00basuperscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00baG/C_{G}(A^{G}/A_{G})italic_G / italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_A start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ) are \u00cf\u0192\u011f\ufffd\u0153\ufffd and (iii) Every chief factor H/K\u011f\ufffd\ufffd\u00bb\u011f\ufffd\ufffd\u00beH/Kitalic_H / italic_K of G\u011f\ufffd\ufffd\u00baGitalic_G between AGsuperscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00baA^{G}italic_A start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT and AGsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00baA_{G}italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G , that is, (H/K)\u00e2\u2039\u0160(G/CG\u00e2\ufffd\u00a2(H/K))right-normal-factor-semidirect-product\u011f\ufffd\ufffd\u00bb\u011f\ufffd\ufffd\u00be\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00bb\u011f\ufffd\ufffd\u00be(H/K) italic_H / italic_K ) \u00e2\u2039\u0160 ( italic_G / italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_H / italic_K ) ) is \u00cf\u0192\u011f\ufffd\u0153\ufffd (iv) For every i\u011f\ufffd\u2018\u2013iitalic_i such that \u00cf\u0192i\u00e2\u02c6\u02c6\u00cf\u0192\u00e2\ufffd\u00a2(G/CG\u00e2\ufffd\u00a2(AG/AG))subscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u0153\ufffd\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00basuperscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00ba start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 italic_\u00cf\u0192 ( italic_G / italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_A start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ) ) we have \u00cf\u0192i\u00e2\u02c6\u02c6\u00cf\u0192\u00e2\ufffd\u00a2(AG/AG).subscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u0153\ufffdsuperscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00ba start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 italic_\u00cf\u0192 ( italic_A start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ) . (v) A\u011f\ufffd\ufffd\u00b4Aitalic_A is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G. A group G\u011f\ufffd\ufffd\u00baGitalic_G is said to be a P\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2021PTitalic_P italic_T-group [14, 2.0.2] if quasinormality is a transitive relation on G\u011f\ufffd\ufffd\u00baGitalic_G, that is, if H\u011f\ufffd\ufffd\u00bbHitalic_H is a quasinormal subgroup of K\u011f\ufffd\ufffd\u00beKitalic_K and K\u011f\ufffd\ufffd\u00beKitalic_K is a quasinormal subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G, then H\u011f\ufffd\ufffd\u00bbHitalic_H is a quasinormal subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G. The description of P\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2021PTitalic_P italic_T-groups was first obtained by Zacher [15], for the soluble case, and by Robinson in [16], for the general case. Bearing in mind the results in [15, 16] and many other known results on P\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2021PTitalic_P italic_T-groups (see, in particular, Chapter 2 in [14]), it seems to be natural to ask: Question 1.3. What is the structure of G\u011f\ufffd\ufffd\u00baGitalic_G provided \u00cf\u0192\u011f\ufffd\u0153\ufffd is a transitive relation in G\u011f\ufffd\ufffd\u00baGitalic_G? Question 1.4. What is the structure of G\u011f\ufffd\ufffd\u00baGitalic_G provided modularity is a transitive relation in G\u011f\ufffd\ufffd\u00baGitalic_G? Note that in view of Example 1.2(i), Question 1.4 is a special case of Question 1.3, where \u00cf\u0192={\u00e2\u201e\u2122}\u011f\ufffd\u0153\ufffd\u00e2\u201e\u2122 = { blackboard_P }. Note also that for the case when G\u011f\ufffd\ufffd\u00baGitalic_G is a soluble group, the answers to both of these questions are known. Frigerio proved [18] (see also [19]) that modularity is a transitive relation in a soluble group G\u011f\ufffd\ufffd\u00baGitalic_G if and only if G\u011f\ufffd\ufffd\u00baGitalic_G is an M\u011f\ufffd\u2018\u20acMitalic_M-group. An important step in solving the general Problem 1.3 was made in the paper [17], where it was proven the following theorem turn into Frigerion result in the case where \u00cf\u0192={\u00e2\u201e\u2122}\u011f\ufffd\u0153\ufffd\u00e2\u201e\u2122 = { blackboard_P }. Theorem C (X.-F. Zhang, W. Guo, I.N. Safonova, A.N. Skiba [17]). Let G\u011f\ufffd\ufffd\u00baGitalic_G be a soluble group and D=G\u011f\ufffd\u201d\u2018\u00cf\u0192\u011f\ufffd\ufffd\u00b7superscript\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\u201d\u2018\u011f\ufffd\u0153\ufffdD=G^{ = italic_G start_POSTSUPERSCRIPT fraktur_N start_POSTSUBSCRIPT italic_\u00cf\u0192 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT. Then \u00cf\u0192\u011f\ufffd\u0153\ufffd is a transitive relation in G\u011f\ufffd\ufffd\u00baGitalic_G if and only if the following conditions hold: (i) G=D\u00e2\u2039\u0160M\u011f\ufffd\ufffd\u00baright-normal-factor-semidirect-product\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u20acG=D Mitalic_G = italic_D \u00e2\u2039\u0160 italic_M, where D\u011f\ufffd\ufffd\u00b7Ditalic_D is an abelian Hall subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G of odd order, M\u011f\ufffd\u2018\u20acMitalic_M is a \u00cf\u0192\u011f\ufffd\u0153\ufffd M\u011f\ufffd\u2018\u20acMitalic_M-group. (ii) every element of G\u011f\ufffd\ufffd\u00baGitalic_G induces a power automorphism on D\u011f\ufffd\ufffd\u00b7Ditalic_D, (iii) O\u00cf\u0192i\u00e2\ufffd\u00a2(D)subscript\u011f\ufffd\u2018\u201asubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\ufffd\u00b7O_{ start_POSTSUBSCRIPT italic_\u00cf\u0192 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_D ) has a normal complement in a Hall \u00cf\u0192isubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT-subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G for all i\u011f\ufffd\u2018\u2013iitalic_i. Conversely, if Conditions (i), (ii) and (iii) hold for some subgroups D\u011f\ufffd\ufffd\u00b7Ditalic_D and M\u011f\ufffd\u2018\u20acMitalic_M of G\u011f\ufffd\ufffd\u00baGitalic_G, then \u00cf\u0192\u011f\ufffd\u0153\ufffd is a transitive relation in G\u011f\ufffd\ufffd\u00baGitalic_G. In this theorem, G\u011f\ufffd\u201d\u2018\u00cf\u0192superscript\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\u201d\u2018\u011f\ufffd\u0153\ufffdG^{ start_POSTSUPERSCRIPT fraktur_N start_POSTSUBSCRIPT italic_\u00cf\u0192 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT denotes the \u00cf\u0192\u011f\ufffd\u0153\ufffd residual of G\u011f\ufffd\ufffd\u00baGitalic_G, that is, the intersection of all normal subgroups N\u011f\ufffd\u2018\ufffdNitalic_N of G\u011f\ufffd\ufffd\u00baGitalic_G with \u00cf\u0192\u011f\ufffd\u0153\ufffd quotient G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N. Definition 1.5. We say that G\u011f\ufffd\ufffd\u00baGitalic_G is: (i) a Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q Titalic_Q italic_\u00cf\u0192 italic_T-group if the \u00cf\u0192\u011f\ufffd\u0153\ufffd is a transitive relation on G\u011f\ufffd\ufffd\u00baGitalic_G, that is, if H\u011f\ufffd\ufffd\u00bbHitalic_H is a \u00cf\u0192\u011f\ufffd\u0153\ufffd subgroup of K\u011f\ufffd\ufffd\u00beKitalic_K and K\u011f\ufffd\ufffd\u00beKitalic_K is a \u00cf\u0192\u011f\ufffd\u0153\ufffd subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G, then H\u011f\ufffd\ufffd\u00bbHitalic_H is a \u00cf\u0192\u011f\ufffd\u0153\ufffd subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G; (ii) an M\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2021MTitalic_M italic_T-group if the modularity is a transitive relation in G\u011f\ufffd\ufffd\u00baGitalic_G. It is clear that an M\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2021MTitalic_M italic_T-group is exactly a Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q Titalic_Q italic_\u00cf\u0192 italic_T-group where \u00cf\u0192={\u00e2\u201e\u2122}\u011f\ufffd\u0153\ufffd\u00e2\u201e\u2122 = { blackboard_P }. In this article, expanding the corresponding results of the papers [16, 17, 21], we answer Questions 1.3 and 1.4 in the general case. Definition 1.6. We say that (D,Z\u00e2\ufffd\u00a2(D);U1,\u00e2\u20ac\u00a6,Uk)\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02dc(D,Z(D);U_{1}, italic_D , italic_Z ( italic_D ) ; italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) is a Robinson complex if the following fold: (i) D\u00e2\u2030 1\u011f\ufffd\ufffd\u00b71D 1italic_D \u00e2\u2030 1 is a perfect normal subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G, (ii) D/Z\u00e2\ufffd\u00a2(D)=U1/Z\u00e2\ufffd\u00a2(D)\u00c3\u2014\u00e2\u2039\u00af\u00c3\u2014Uk/Z\u00e2\ufffd\u00a2(D)\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u2018\u02c61\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7\u00e2\u2039\u00afsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7D/Z(D)=U_{1}/Z(D) U_{k}/Z(D)italic_D / italic_Z ( italic_D ) = italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT / italic_Z ( italic_D ) \u00c3\u2014 \u00e2\u2039\u00af \u00c3\u2014 italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT / italic_Z ( italic_D ), where Ui/Z\u00e2\ufffd\u00a2(D)subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7U_{i}/Z(D)italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / italic_Z ( italic_D ) is a simple non-abelian chief factor of G\u011f\ufffd\ufffd\u00baGitalic_G, Z\u00e2\ufffd\u00a2(D)=\u00ce\u00a6\u00e2\ufffd\u00a2(D)\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7\u00ce\u00a6\u011f\ufffd\ufffd\u00b7Z(D)= ( italic_D ) = roman_\u00ce\u00a6 ( italic_D ), and (iii) every chief factor of G\u011f\ufffd\ufffd\u00baGitalic_G below Z\u00e2\ufffd\u00a2(D)\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7Z(D)italic_Z ( italic_D ) is cyclic. Example 1.7. Let G=S\u00e2\ufffd\u00a2L\u00e2\ufffd\u00a2(2,7)\u00c3\u2014A7\u00c3\u2014A5\u00c3\u2014B\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2020\u011f\ufffd\ufffd\u00bf27subscript\u011f\ufffd\ufffd\u00b47subscript\u011f\ufffd\ufffd\u00b45\u011f\ufffd\ufffd\u00b5G=SL(2,7) A_{7} A_{5} Bitalic_G = italic_S italic_L ( 2 , 7 ) \u00c3\u2014 italic_A start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT \u00c3\u2014 italic_A start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT \u00c3\u2014 italic_B, where B=C43\u00e2\u2039\u0160C7\u011f\ufffd\ufffd\u00b5right-normal-factor-semidirect-productsubscript\u011f\ufffd\ufffd\u00b643subscript\u011f\ufffd\ufffd\u00b67B=C_{43} C_{7}italic_B = italic_C start_POSTSUBSCRIPT 43 end_POSTSUBSCRIPT \u00e2\u2039\u0160 italic_C start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT is a non-abelian group of order 301. Then is a Robinson complex of G\u011f\ufffd\ufffd\u00baGitalic_G. Now let G=An\u00e2\u2030\u20acCp=K\u00e2\u2039\u0160Cp\u011f\ufffd\ufffd\u00ba\u00e2\u2030\u20acsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdright-normal-factor-semidirect-product\u011f\ufffd\ufffd\u00besubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdG=A_{n} C_{p}=K C_{p}italic_G = italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT \u00e2\u2030\u20ac italic_C start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT = italic_K \u00e2\u2039\u0160 italic_C start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT, where K\u011f\ufffd\ufffd\u00beKitalic_K is the base group of the regular wreath product of the alternating group Ansubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u203aA_{n}italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT of degree n>4\u011f\ufffd\u2018\u203a4n>4italic_n > 4 with a group Cpsubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdC_{p}italic_C start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT of prime order p\u011f\ufffd\u2018\ufffdpitalic_p. Then K\u011f\ufffd\ufffd\u00beKitalic_K is a minimal normal subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G by [20, Chapter A, 18.5(a) ]. Hence G\u011f\ufffd\ufffd\u00baGitalic_G has no a Robinson complex. We say, following Robinson [16], that G\u011f\ufffd\ufffd\u00baGitalic_G satisfies: (1) \u011f\ufffd\ufffd\ufffdpsubscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\ufffd{ N}_{p}bold_N start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT if whenever N\u011f\ufffd\u2018\ufffdNitalic_N is a soluble normal subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G, p\u00e2\u20ac\u00b2superscript\u011f\ufffd\u2018\ufffd\u00e2\u20ac\u00b2p^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT-elements of G\u011f\ufffd\ufffd\u00baGitalic_G induce power automorphism in Op\u00e2\ufffd\u00a2(G/N)subscript\u011f\ufffd\u2018\u201a\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdO_{p}(G/N)italic_O start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_G / italic_N ); (2) \u011f\ufffd\ufffd\ufffdpsubscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\ufffd{ P}_{p}bold_P start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT if whenever N\u011f\ufffd\u2018\ufffdNitalic_N is a soluble normal subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G, every subgroup of Op\u00e2\ufffd\u00a2(G/N)subscript\u011f\ufffd\u2018\u201a\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdO_{p}(G/N)italic_O start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_G / italic_N ) is quasinormal in every Sylow p\u011f\ufffd\u2018\ufffdpitalic_p-subgroup of G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N. Every subnormal subgroup is both submodular and \u00cf\u0192\u011f\ufffd\u0153\ufffd in the group. Thus the following well-known result partially describes the structure of insoluble Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q Titalic_Q italic_\u00cf\u0192 italic_T-groups. Theorem D (Robinson [16]). G\u011f\ufffd\ufffd\u00baGitalic_G is a P\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2021PTitalic_P italic_T-group if and only if G\u011f\ufffd\ufffd\u00baGitalic_G has a normal perfect subgroup D\u011f\ufffd\ufffd\u00b7Ditalic_D such that: (i) G/D\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7G/Ditalic_G / italic_D is a soluble P\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2021PTitalic_P italic_T-group, and (i) if D\u00e2\u2030 1\u011f\ufffd\ufffd\u00b71D 1italic_D \u00e2\u2030 1, G\u011f\ufffd\ufffd\u00baGitalic_G has a Robinson complex (D,Z\u00e2\ufffd\u00a2(D);U1,\u00e2\u20ac\u00a6,Uk)\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02dc(D,Z(D);U_{1}, italic_D , italic_Z ( italic_D ) ; italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) and (iii) for any set {i1,\u00e2\u20ac\u00a6,ir}\u00e2\u0160\u2020{1,\u00e2\u20ac\u00a6,k}subscript\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u01781\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u02dc italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT } \u00e2\u0160\u2020 { 1 , \u00e2\u20ac\u00a6 , italic_k }, where 1\u00e2\u2030\u00a4r<k1\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u02dc1 r<k1 \u00e2\u2030\u00a4 italic_r < italic_k, G\u011f\ufffd\ufffd\u00baGitalic_G and G/Ui1\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2\u00e2\u2039\u00af\u00e2\ufffd\u00a2Uir\u00e2\u20ac\u00b2\u011f\ufffd\ufffd\u00basuperscriptsubscript\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00b2\u00e2\u2039\u00afsuperscriptsubscript\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u0178\u00e2\u20ac\u00b2G/U_{i_{1}}^{ U_{i_{r}}^{ / italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u2039\u00af italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT satisfy \u011f\ufffd\ufffd\ufffdpsubscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\ufffd{ N}_{p}bold_N start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u00e2\u02c6\u02c6\u00cf\u20ac\u00e2\ufffd\u00a2(Z\u00e2\ufffd\u00a2(D))\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7p \u00e2\u02c6\u02c6 italic_\u00cf\u20ac ( italic_Z ( italic_D ) ) and \u011f\ufffd\ufffd\ufffdpsubscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\ufffd{ P}_{p}bold_P start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u00e2\u02c6\u02c6\u00cf\u20ac\u00e2\ufffd\u00a2(D)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u2039\u011f\ufffd\ufffd\u00b7p \u00e2\u02c6\u02c6 italic_\u00cf\u20ac ( italic_D ). Now, recall that G\u011f\ufffd\ufffd\u00baGitalic_G is a non-abelian P\u011f\ufffd\u2018\u0192Pitalic_P-group (see [1, p. 49]) if G=A\u00e2\u2039\u0160\u00e2\u0178\u00a8t\u00e2\u0178\u00a9\u011f\ufffd\ufffd\u00baright-normal-factor-semidirect-product\u011f\ufffd\ufffd\u00b4delimited-\u00e2\u0178\u00a8\u00e2\u0178\u00a9\u011f\ufffd\u2018\u00a1G=A t = italic_A \u00e2\u2039\u0160 \u00e2\u0178\u00a8 italic_t \u00e2\u0178\u00a9, where A\u011f\ufffd\ufffd\u00b4Aitalic_A is an elementary abelian p\u011f\ufffd\u2018\ufffdpitalic_p-group and an element t\u011f\ufffd\u2018\u00a1titalic_t of prime order q\u00e2\u2030 p\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdq pitalic_q \u00e2\u2030 italic_p induces a non-trivial power automorphism on A\u011f\ufffd\ufffd\u00b4Aitalic_A. In this case we say that G\u011f\ufffd\ufffd\u00baGitalic_G is a P\u011f\ufffd\u2018\u0192Pitalic_P-group of type (p,q)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd(p,q)( italic_p , italic_q ). Definition 1.8. We say that: (i) G\u011f\ufffd\ufffd\u00baGitalic_G satisfies \u011f\ufffd\ufffd\ufffd\u00cf\u0192\u00e2\ufffd\u00a2(p,q)subscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd{ Q}_{ start_POSTSUBSCRIPT italic_\u00cf\u0192 ( italic_p , italic_q ) end_POSTSUBSCRIPT if whenever N\u011f\ufffd\u2018\ufffdNitalic_N is a soluble normal subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G and P/N\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\ufffdP/Nitalic_P / italic_N is a normal \u00cf\u0192\u011f\ufffd\u0153\ufffd P\u011f\ufffd\u2018\u0192Pitalic_P-subgroup of type (p,q)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd(p,q)( italic_p , italic_q ) of G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N, every subgroup of P/N\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\ufffdP/Nitalic_P / italic_N is modular in G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N. If G\u011f\ufffd\ufffd\u00baGitalic_G satisfies \u011f\ufffd\ufffd\ufffd\u00cf\u0192\u00e2\ufffd\u00a2(p,q)subscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd{ Q}_{ start_POSTSUBSCRIPT italic_\u00cf\u0192 ( italic_p , italic_q ) end_POSTSUBSCRIPT and \u00cf\u0192={\u00e2\u201e\u2122}\u011f\ufffd\u0153\ufffd\u00e2\u201e\u2122 = { blackboard_P }, then say, following [21], that G\u011f\ufffd\ufffd\u00baGitalic_G satisfies \u011f\ufffd\ufffd\u0152p,qsubscript\u011f\ufffd\ufffd\u0152\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd{ M}_{p,q}bold_M start_POSTSUBSCRIPT italic_p , italic_q end_POSTSUBSCRIPT. (ii) G\u011f\ufffd\ufffd\u00baGitalic_G satisfies \u011f\ufffd\ufffd\ufffd\u00cf\u0192\u00e2\ufffd\u00a2Psubscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u0192{ Q}_{ P}bold_Q start_POSTSUBSCRIPT italic_\u00cf\u0192 italic_P end_POSTSUBSCRIPT if G\u011f\ufffd\ufffd\u00baGitalic_G satisfies \u011f\ufffd\ufffd\ufffd\u00cf\u0192\u00e2\ufffd\u00a2(p,q)subscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd{ Q}_{ start_POSTSUBSCRIPT italic_\u00cf\u0192 ( italic_p , italic_q ) end_POSTSUBSCRIPT for each pair p,q\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdp,qitalic_p , italic_q such that there is a P\u011f\ufffd\u2018\u0192Pitalic_P-group of type (p,q)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd(p,q)( italic_p , italic_q ). In this paper, based on Theorems C and D, we prove the following result. Theorem E. A group G\u011f\ufffd\ufffd\u00baGitalic_G is a Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q Titalic_Q italic_\u00cf\u0192 italic_T-group if and only if G\u011f\ufffd\ufffd\u00baGitalic_G has a perfect normal subgroup D\u011f\ufffd\ufffd\u00b7Ditalic_D such that: (i) G/D\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7G/Ditalic_G / italic_D is a soluble Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q Titalic_Q italic_\u00cf\u0192 italic_T-group, (ii) if D\u00e2\u2030 1\u011f\ufffd\ufffd\u00b71D 1italic_D \u00e2\u2030 1, G\u011f\ufffd\ufffd\u00baGitalic_G has a Robinson complex (D,Z\u00e2\ufffd\u00a2(D);U1,\u00e2\u20ac\u00a6,Uk)\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02dc(D,Z(D);U_{1}, italic_D , italic_Z ( italic_D ) ; italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) and (iii) for any set {i1,\u00e2\u20ac\u00a6,ir}\u00e2\u0160\u2020{1,\u00e2\u20ac\u00a6,k}subscript\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u01781\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u02dc italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT } \u00e2\u0160\u2020 { 1 , \u00e2\u20ac\u00a6 , italic_k }, where 1\u00e2\u2030\u00a4r<k1\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u02dc1 r<k1 \u00e2\u2030\u00a4 italic_r < italic_k, the groups G\u011f\ufffd\ufffd\u00baGitalic_G and G/Ui1\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2\u00e2\u2039\u00af\u00e2\ufffd\u00a2Uir\u00e2\u20ac\u00b2\u011f\ufffd\ufffd\u00basuperscriptsubscript\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00b2\u00e2\u2039\u00afsuperscriptsubscript\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u0178\u00e2\u20ac\u00b2G/U_{i_{1}}^{ U_{i_{r}}^{ / italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u2039\u00af italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT satisfy \u011f\ufffd\ufffd\ufffdpsubscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\ufffd{ N}_{p}bold_N start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u00e2\u02c6\u02c6{2,3}\u00e2\u02c6\u00a9\u00cf\u20ac\u00e2\ufffd\u00a2(Z\u00e2\ufffd\u00a2(D))\u011f\ufffd\u2018\ufffd23\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7p \u00e2\u02c6\u02c6 { 2 , 3 } \u00e2\u02c6\u00a9 italic_\u00cf\u20ac ( italic_Z ( italic_D ) ), \u011f\ufffd\ufffd\ufffdpsubscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\ufffd{ P}_{p}bold_P start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u00e2\u02c6\u02c6\u00cf\u20ac\u00e2\ufffd\u00a2(D)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u2039\u011f\ufffd\ufffd\u00b7p \u00e2\u02c6\u02c6 italic_\u00cf\u20ac ( italic_D ), and \u011f\ufffd\ufffd\ufffd\u00cf\u0192(p,q){ Q}_{ start_POSTSUBSCRIPT italic_\u00cf\u0192 ( italic_p , italic_q end_POSTSUBSCRIPT ) for all {p,q}\u00e2\u02c6\u00a9\u00cf\u20ac\u00e2\ufffd\u00a2(D)\u00e2\u2030 \u00e2\u02c6\u2026\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u2039\u011f\ufffd\ufffd\u00b7 italic_p , italic_q } \u00e2\u02c6\u00a9 italic_\u00cf\u20ac ( italic_D ) \u00e2\u2030 \u00e2\u02c6\u2026. Theorem E gives a solution to Question 1.3. The following special case of Theorem E gives a solution to Question 1.4. Theorem F. A group G\u011f\ufffd\ufffd\u00baGitalic_G is an M\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2021MTitalic_M italic_T-group if and only if G\u011f\ufffd\ufffd\u00baGitalic_G has a perfect normal subgroup D\u011f\ufffd\ufffd\u00b7Ditalic_D such that: (i) G/D\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7G/Ditalic_G / italic_D is an M\u011f\ufffd\u2018\u20acMitalic_M-group, (ii) if D\u00e2\u2030 1\u011f\ufffd\ufffd\u00b71D 1italic_D \u00e2\u2030 1, G\u011f\ufffd\ufffd\u00baGitalic_G has a Robinson complex (D,Z\u00e2\ufffd\u00a2(D);U1,\u00e2\u20ac\u00a6,Uk)\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02dc(D,Z(D);U_{1}, italic_D , italic_Z ( italic_D ) ; italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) and (iii) for any set {i1,\u00e2\u20ac\u00a6,ir}\u00e2\u0160\u2020{1,\u00e2\u20ac\u00a6,k}subscript\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u01781\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u02dc italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT } \u00e2\u0160\u2020 { 1 , \u00e2\u20ac\u00a6 , italic_k }, where 1\u00e2\u2030\u00a4r<k1\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u02dc1 r<k1 \u00e2\u2030\u00a4 italic_r < italic_k, G\u011f\ufffd\ufffd\u00baGitalic_G and G/Ui1\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2\u00e2\u2039\u00af\u00e2\ufffd\u00a2Uir\u00e2\u20ac\u00b2\u011f\ufffd\ufffd\u00basuperscriptsubscript\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00b2\u00e2\u2039\u00afsuperscriptsubscript\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u0178\u00e2\u20ac\u00b2G/U_{i_{1}}^{ U_{i_{r}}^{ / italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u2039\u00af italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT satisfy \u011f\ufffd\ufffd\ufffdpsubscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\ufffd{ N}_{p}bold_N start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u00e2\u02c6\u02c6{2,3}\u00e2\u02c6\u00a9\u00cf\u20ac\u00e2\ufffd\u00a2(Z\u00e2\ufffd\u00a2(D))\u011f\ufffd\u2018\ufffd23\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7p \u00e2\u02c6\u02c6 { 2 , 3 } \u00e2\u02c6\u00a9 italic_\u00cf\u20ac ( italic_Z ( italic_D ) ), \u011f\ufffd\ufffd\ufffdpsubscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\ufffd{ P}_{p}bold_P start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u00e2\u02c6\u02c6\u00cf\u20ac\u00e2\ufffd\u00a2(D)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u2039\u011f\ufffd\ufffd\u00b7p \u00e2\u02c6\u02c6 italic_\u00cf\u20ac ( italic_D ), and \u011f\ufffd\ufffd\u0152p,qsubscript\u011f\ufffd\ufffd\u0152\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd{ M}_{p,q}bold_M start_POSTSUBSCRIPT italic_p , italic_q end_POSTSUBSCRIPT for all pairs {p,q}\u00e2\u02c6\u00a9\u00cf\u20ac\u00e2\ufffd\u00a2(D)\u00e2\u2030 \u00e2\u02c6\u2026.\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u2039\u011f\ufffd\ufffd\u00b7 italic_p , italic_q } \u00e2\u02c6\u00a9 italic_\u00cf\u20ac ( italic_D ) \u00e2\u2030 \u00e2\u02c6\u2026 . We prove Theorem E (and so Theorem F, as well) in Section 3. In Section 4 we discuss some other applications of these results. The first lemma is a corollary of general properties of modular subgroups [1, p. 201] and \u00cf\u0192\u011f\ufffd\u0153\ufffd subgroups [3, Lemma 2.6]. Lemma 2.1. Let A\u011f\ufffd\ufffd\u00b4Aitalic_A, B\u011f\ufffd\ufffd\u00b5Bitalic_B and N\u011f\ufffd\u2018\ufffdNitalic_N be subgroups of G\u011f\ufffd\ufffd\u00baGitalic_G, where A\u011f\ufffd\ufffd\u00b4Aitalic_A is \u00cf\u0192\u011f\ufffd\u0153\ufffd and N\u011f\ufffd\u2018\ufffdNitalic_N is normal in G\u011f\ufffd\ufffd\u00baGitalic_G. (1) The subgroup A\u00e2\u02c6\u00a9B\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b5A Bitalic_A \u00e2\u02c6\u00a9 italic_B is \u00cf\u0192\u011f\ufffd\u0153\ufffd in B\u011f\ufffd\ufffd\u00b5Bitalic_B. (2) The subgroup A\u00e2\ufffd\u00a2N/N\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdAN/Nitalic_A italic_N / italic_N is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N. (3) If N\u00e2\u2030\u00a4B\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b5N Bitalic_N \u00e2\u2030\u00a4 italic_B and B/N\u011f\ufffd\ufffd\u00b5\u011f\ufffd\u2018\ufffdB/Nitalic_B / italic_N is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N, then B\u011f\ufffd\ufffd\u00b5Bitalic_B is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G. (4) B\u011f\ufffd\ufffd\u00b5Bitalic_B is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G, then \u00e2\u0178\u00a8A,B\u00e2\u0178\u00a9\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b5 A,B italic_A , italic_B \u00e2\u0178\u00a9 is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G. Lemma 2.2 A subgroup A\u011f\ufffd\ufffd\u00b4Aitalic_A of G\u011f\ufffd\ufffd\u00baGitalic_G is a maximal \u00cf\u0192\u011f\ufffd\u0153\ufffd subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G if and only if either A\u011f\ufffd\ufffd\u00b4Aitalic_A is normal in G\u011f\ufffd\ufffd\u00baGitalic_G and G/A\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b4G/Aitalic_G / italic_A is a simple gropup or AG<Asubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b4A_{G}<Aitalic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT < italic_A and G/AG\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00baG/A_{G}italic_G / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is a \u00cf\u0192\u011f\ufffd\u0153\ufffd non-abelian group of order p\u00e2\ufffd\u00a2q\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdpqitalic_p italic_q for primes p\u011f\ufffd\u2018\ufffdpitalic_p and q\u011f\ufffd\u2018\ufffdqitalic_q. Proof. First assume that A\u011f\ufffd\ufffd\u00b4Aitalic_A is a maximal \u00cf\u0192\u011f\ufffd\u0153\ufffd subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G. If A\u011f\ufffd\ufffd\u00b4Aitalic_A is normal in G\u011f\ufffd\ufffd\u00baGitalic_G, then G/A=G/AG\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00baG/A=G/A_{G}italic_G / italic_A = italic_G / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is simple. Now assume that A\u011f\ufffd\ufffd\u00b4Aitalic_A is not normal in G\u011f\ufffd\ufffd\u00baGitalic_G, so AG=Gsuperscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00baA^{G}=Gitalic_A start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT = italic_G and, in view of Theorem B(ii), G/AG\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00baG/A_{G}italic_G / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is a \u00cf\u0192isubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT-group for some i\u011f\ufffd\u2018\u2013iitalic_i. Hence every subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G containing AGsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00baA_{G}italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G by [3, Lemma 2.6(5)]. On the other hand, U/AG\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00baU/A_{G}italic_U / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is modular in G\u011f\ufffd\ufffd\u00baGitalic_G if and only if U\u011f\ufffd\u2018\u02c6Uitalic_U is modular in G\u011f\ufffd\ufffd\u00baGitalic_G by [1, Page 201, Properties (3)(4)]. Therefore, in fact, A\u011f\ufffd\ufffd\u00b4Aitalic_A is a maximal modular subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G. Hence G/AG\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00baG/A_{G}italic_G / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is a non-abelian group of order p\u00e2\ufffd\u00a2q\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdpqitalic_p italic_q for primes p,q\u00e2\u02c6\u02c6\u00cf\u0192i\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2013p,q , italic_q \u00e2\u02c6\u02c6 italic_\u00cf\u0192 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT by [1, Lemma 5.1.2]. Now assume that AG<A<Gsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00baA_{G}<A<Gitalic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT < italic_A < italic_G and G/AG\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00baG/A_{G}italic_G / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is a \u00cf\u0192\u011f\ufffd\u0153\ufffd non-abelian group of order p\u00e2\ufffd\u00a2q\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdpqitalic_p italic_q for primes p\u011f\ufffd\u2018\ufffdpitalic_p and q\u011f\ufffd\u2018\ufffdqitalic_q. Then A\u011f\ufffd\ufffd\u00b4Aitalic_A is a maximal subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G and A\u011f\ufffd\ufffd\u00b4Aitalic_A is a \u00cf\u0192\u011f\ufffd\u0153\ufffd subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G. Moreover, A/AG\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00baA/A_{G}italic_A / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is modular in G/AG\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00baG/A_{G}italic_G / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT by [1, Lemma 5.1.2], so A\u011f\ufffd\ufffd\u00b4Aitalic_A is a maximal modular subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G by [1, Page 201, Property (4)]. Hence A\u011f\ufffd\ufffd\u00b4Aitalic_A is a maximal \u00cf\u0192\u011f\ufffd\u0153\ufffd subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G. Finally, assume that A\u011f\ufffd\ufffd\u00b4Aitalic_A is normal in G\u011f\ufffd\ufffd\u00baGitalic_G and G/A\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b4G/Aitalic_G / italic_A is a simple non-abelian group, then A\u011f\ufffd\ufffd\u00b4Aitalic_A is a maximal modular subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G by [1, Lemma 5.1.2] and A\u011f\ufffd\ufffd\u00b4Aitalic_A \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G. Hence A\u011f\ufffd\ufffd\u00b4Aitalic_A is a maximal \u00cf\u0192\u011f\ufffd\u0153\ufffd subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G. The lemma is proved. We say that a subgroup A\u011f\ufffd\ufffd\u00b4Aitalic_A of G\u011f\ufffd\ufffd\u00baGitalic_G is said to be \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G if there is a subgroup chain A=A0\u00e2\u2030\u00a4A1\u00e2\u2030\u00a4\u00e2\u2039\u00af\u00e2\u2030\u00a4An=G\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\ufffd\u00b40subscript\u011f\ufffd\ufffd\u00b41\u00e2\u2039\u00afsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u203a\u011f\ufffd\ufffd\u00baA=A_{0} A_{1} A_{n}=Gitalic_A = italic_A start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 \u00e2\u2039\u00af \u00e2\u2030\u00a4 italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = italic_G such that Ai\u00e2\u02c6\u20191subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u20131A_{i-1}italic_A start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT is \u00cf\u0192\u011f\ufffd\u0153\ufffd in Aisubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u2013A_{i}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT for all i=1,\u00e2\u20ac\u00a6,n\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u203ai=1, = 1 , \u00e2\u20ac\u00a6 , italic_n. It is clear that G\u011f\ufffd\ufffd\u00baGitalic_G is a Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q Titalic_Q italic_\u00cf\u0192 italic_T-group if and only if every of its \u00cf\u0192\u011f\ufffd\u0153\ufffd subgroups is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G. The class of groups \u011f\ufffd\u201d\u2030\u011f\ufffd\u201d\u2030 is a hereditary formation if \u011f\ufffd\u201d\u2030\u011f\ufffd\u201d\u2030 is closed under taking derect products, homomorphic images and subgroups. If \u011f\ufffd\u201d\u2030\u00e2\u2030 \u00e2\u02c6\u2026\u011f\ufffd\u201d\u2030 \u00e2\u2030 \u00e2\u02c6\u2026 is a hereditary formation, then the symbol G\u011f\ufffd\u201d\u2030superscript\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u201d\u2030G^{ start_POSTSUPERSCRIPT fraktur_F end_POSTSUPERSCRIPT denotes the \u011f\ufffd\u201d\u2030\u011f\ufffd\u201d\u2030 of G\u011f\ufffd\ufffd\u00baGitalic_G, that is, the intersection of all normal subgroups N\u011f\ufffd\u2018\ufffdNitalic_N of G\u011f\ufffd\ufffd\u00baGitalic_G with G/N\u00e2\u02c6\u02c6\u011f\ufffd\u201d\u2030\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffd\u011f\ufffd\u201d\u2030G/N / italic_N \u00e2\u02c6\u02c6 fraktur_F. We use \u011f\ufffd\u201d\u201e\u00e2\u02c6\u2014superscript\u011f\ufffd\u201d\u201e start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT to denote the class of all abelian groups of squarefree exponent. It is clear that \u011f\ufffd\u201d\u201e\u00e2\u02c6\u2014superscript\u011f\ufffd\u201d\u201e start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT is a hereditary formation. Lemma 2.3. Let A\u011f\ufffd\ufffd\u00b4Aitalic_A, B\u011f\ufffd\ufffd\u00b5Bitalic_B and N\u011f\ufffd\u2018\ufffdNitalic_N be subgroups of G\u011f\ufffd\ufffd\u00baGitalic_G, where A\u011f\ufffd\ufffd\u00b4Aitalic_A is \u00cf\u0192\u011f\ufffd\u0153\ufffd G\u011f\ufffd\ufffd\u00baGitalic_G and N\u011f\ufffd\u2018\ufffdNitalic_N is normal G\u011f\ufffd\ufffd\u00baGitalic_G in G\u011f\ufffd\ufffd\u00baGitalic_G. (1) A\u00e2\u02c6\u00a9B\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b5A Bitalic_A \u00e2\u02c6\u00a9 italic_B is \u00cf\u0192\u011f\ufffd\u0153\ufffd G\u011f\ufffd\ufffd\u00baGitalic_G in B\u011f\ufffd\ufffd\u00b5Bitalic_B. (2) A\u00e2\ufffd\u00a2N/N\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdAN/Nitalic_A italic_N / italic_N is \u00cf\u0192\u011f\ufffd\u0153\ufffd G\u011f\ufffd\ufffd\u00baGitalic_G in G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N. (3) If N\u00e2\u2030\u00a4K\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00beN Kitalic_N \u00e2\u2030\u00a4 italic_K and K/N\u011f\ufffd\ufffd\u00be\u011f\ufffd\u2018\ufffdK/Nitalic_K / italic_N is \u00cf\u0192\u011f\ufffd\u0153\ufffd G\u011f\ufffd\ufffd\u00baGitalic_G in G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N, then K\u011f\ufffd\ufffd\u00beKitalic_K is \u00cf\u0192\u011f\ufffd\u0153\ufffd G\u011f\ufffd\ufffd\u00baGitalic_G in G.\u011f\ufffd\ufffd\u00baG.italic_G . (4) A\u011f\ufffd\u201d\u201e\u00e2\u02c6\u2014superscript\u011f\ufffd\ufffd\u00b4superscript\u011f\ufffd\u201d\u201eA^{{ start_POSTSUPERSCRIPT fraktur_A start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT is subnormal in G\u011f\ufffd\ufffd\u00baGitalic_G. (5) If G=U1\u00c3\u2014\u00e2\u2039\u00af\u00c3\u2014Uk\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\u2018\u02c61\u00e2\u2039\u00afsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02dcG=U_{1} U_{k}italic_G = italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00c3\u2014 \u00e2\u2039\u00af \u00c3\u2014 italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT, where Uisubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013U_{i}italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is a simple non-abelian group, then A\u011f\ufffd\ufffd\u00b4Aitalic_A is normal in G\u011f\ufffd\ufffd\u00baGitalic_G. Proof. (1)\u00e2\u20ac\u201c(4). These assertions follow from Lemma 2.6 in [3] and corresponding lemmas in [19]. (5) Let E=Ui\u00e2\ufffd\u00a2A\u011f\ufffd\ufffd\u00b8subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u011f\ufffd\ufffd\u00b4E=U_{i}Aitalic_E = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_A, where Ui\u00e2\u2030\u00b0Anot-less-than-nor-greater-thansubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u011f\ufffd\ufffd\u00b4U_{i} Aitalic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u2030\u00b0 italic_A. We show that A\u00e2\ufffd\u00a2\u00e2\u0160\u00b4\u00e2\ufffd\u00a2E\u011f\ufffd\ufffd\u00b4\u00e2\u0160\u00b4\u011f\ufffd\ufffd\u00b8A Eitalic_A \u00e2\u0160\u00b4 italic_E. The subgroup A\u011f\ufffd\ufffd\u00b4Aitalic_A is \u00cf\u0192\u011f\ufffd\u0153\ufffd G\u011f\ufffd\ufffd\u00baGitalic_G in E\u011f\ufffd\ufffd\u00b8Eitalic_E by Part (1) and A<E\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b8A<Eitalic_A < italic_E, so there is a subgroup chain A=E0<E1<\u00e2\u2039\u00af<Et\u00e2\u02c6\u20191<Et=E\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\ufffd\u00b80subscript\u011f\ufffd\ufffd\u00b81\u00e2\u2039\u00afsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a11subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a1\u011f\ufffd\ufffd\u00b8A=E_{0}<E_{1}< = italic_E start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT < italic_E start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < \u00e2\u2039\u00af < italic_E start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT < italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_E such that Ei\u00e2\u02c6\u20191subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u20131E_{i-1}italic_E start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT is a maximal \u00cf\u0192\u011f\ufffd\u0153\ufffd subgroup of Eisubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u2013E_{i}italic_E start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT for all i=1,\u00e2\u20ac\u00a6,t\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u00a1i=1, = 1 , \u00e2\u20ac\u00a6 , italic_t and for M=Et\u00e2\u02c6\u20191\u011f\ufffd\u2018\u20acsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a11M=E_{t-1}italic_M = italic_E start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT we have M=A\u00e2\ufffd\u00a2(M\u00e2\u02c6\u00a9Ui)\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u20acsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013M=A(M U_{i})italic_M = italic_A ( italic_M \u00e2\u02c6\u00a9 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ), where M\u00e2\u02c6\u00a9Ui\u011f\ufffd\u2018\u20acsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013M U_{i}italic_M \u00e2\u02c6\u00a9 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is \u00cf\u0192\u011f\ufffd\u0153\ufffd in Uisubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013U_{i}italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. Then M\u00e2\u02c6\u00a9Ui<Ui\u011f\ufffd\u2018\u20acsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013M U_{i}<U_{i}italic_M \u00e2\u02c6\u00a9 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT < italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT since M<E\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b8M<Eitalic_M < italic_E. Therefore M\u00e2\u02c6\u00a9Ui=1=A\u00e2\u02c6\u00a9Ui\u011f\ufffd\u2018\u20acsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u20131\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013M U_{i}=1=A U_{i}italic_M \u00e2\u02c6\u00a9 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 1 = italic_A \u00e2\u02c6\u00a9 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT by Lemma 2.2 since Uisubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013U_{i}italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is a simple non-abelian group, so A\u011f\ufffd\ufffd\u00b4Aitalic_A is a maximal \u00cf\u0192\u011f\ufffd\u0153\ufffd subgroup of E\u011f\ufffd\ufffd\u00b8Eitalic_E. Assume that A\u011f\ufffd\ufffd\u00b4Aitalic_A is not normal in E\u011f\ufffd\ufffd\u00b8Eitalic_E. Then E/AE=Ui\u00e2\ufffd\u00a2A/AE\u011f\ufffd\ufffd\u00b8subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b8subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b8E/A_{E}=U_{i}A/A_{E}italic_E / italic_A start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_A / italic_A start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT is a group of order q\u00e2\ufffd\u00a2r\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178qritalic_q italic_r for primes q\u011f\ufffd\u2018\ufffdqitalic_q and r\u011f\ufffd\u2018\u0178ritalic_r by Lemma 2.2, where Ui\u00e2\u2030\u0192Ui\u00e2\ufffd\u00a2AE/AE\u00e2\u2030\u00a4E/AEsimilar-to-or-equalssubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b8subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b8\u011f\ufffd\ufffd\u00b8subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b8U_{i} U_{i}A_{E}/A_{E} E/A_{E}italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u2030\u0192 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT / italic_A start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_E / italic_A start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT. This contradiction show that Ui\u00e2\u2030\u00a4NE\u00e2\ufffd\u00a2(A)subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b8\u011f\ufffd\ufffd\u00b4U_{i} N_{E}(A)italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_N start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ( italic_A ), so G\u00e2\u2030\u00a4NG\u00e2\ufffd\u00a2(A)\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b4G N_{G}(A)italic_G \u00e2\u2030\u00a4 italic_N start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_A ). Hence we have (5). The lemma is proved. Lemma 2.4. If G\u011f\ufffd\ufffd\u00baGitalic_G is a Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q Titalic_Q italic_\u00cf\u0192 italic_T-group, then every quotient G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N of G\u011f\ufffd\ufffd\u00baGitalic_G is also a Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q Titalic_Q italic_\u00cf\u0192 italic_T-group. Proof. Let L/N\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\ufffdL/Nitalic_L / italic_N be a \u00cf\u0192\u011f\ufffd\u0153\ufffd subgroup of G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N. Then L\u011f\ufffd\ufffd\u00bfLitalic_L is a \u00cf\u0192\u011f\ufffd\u0153\ufffd subgroup in G\u011f\ufffd\ufffd\u00baGitalic_G by Lemma 2.3(3), so L\u011f\ufffd\ufffd\u00bfLitalic_L is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G by hypothesis and then L/N\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\ufffdL/Nitalic_L / italic_N is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N by Lemma 2.1(2). Hence G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N is a Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q Titalic_Q italic_\u00cf\u0192 italic_T-group. The lemma is proved. Lemma 2.5. If G\u011f\ufffd\ufffd\u00baGitalic_G is a Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q Titalic_Q italic_\u00cf\u0192 italic_T-group, then G/R\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2026G/Ritalic_G / italic_R satisfies \u011f\ufffd\ufffd\ufffd\u00cf\u0192\u00e2\ufffd\u00a2Psubscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u0192{ Q}_{ P}bold_Q start_POSTSUBSCRIPT italic_\u00cf\u0192 italic_P end_POSTSUBSCRIPT for every normal subgroup R\u011f\ufffd\u2018\u2026Ritalic_R of G\u011f\ufffd\ufffd\u00baGitalic_G. Proof. In view of Lemma 2.4, we can assume without loss of generality that R=1\u011f\ufffd\u2018\u20261R=1italic_R = 1. Let P/N\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\ufffdP/Nitalic_P / italic_N be any normal \u00cf\u0192\u011f\ufffd\u0153\ufffd non-abelian P\u011f\ufffd\u2018\u0192Pitalic_P-subgroup of type (p,q)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd(p,q)( italic_p , italic_q ) of G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N and let L/N\u00e2\u2030\u00a4P/N\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\ufffdL/N P/Nitalic_L / italic_N \u00e2\u2030\u00a4 italic_P / italic_N. Then L/N\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\ufffdL/Nitalic_L / italic_N is modular in P/N\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\ufffdP/Nitalic_P / italic_N by [1, Lemma 2.4.1], so L/N\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\ufffdL/Nitalic_L / italic_N is submodular in G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N. On the other hand, L/N\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\ufffdL/Nitalic_L / italic_N is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N since P/N\u00e2\u2030\u00a4O\u00cf\u0192i\u00e2\ufffd\u00a2(G/N)\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u201asubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdP/N O_{ / italic_N \u00e2\u2030\u00a4 italic_O start_POSTSUBSCRIPT italic_\u00cf\u0192 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_G / italic_N ) for some i\u011f\ufffd\u2018\u2013iitalic_i. Therefore L/N\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\ufffdL/Nitalic_L / italic_N is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N and so L\u011f\ufffd\ufffd\u00bfLitalic_L is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G by Lemma 2.3(3). Hence L\u011f\ufffd\ufffd\u00bfLitalic_L is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G by hypothesis, so L/N\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\ufffdL/Nitalic_L / italic_N is modular in G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N by [1, Page 201, Property (3)]. Therefore G\u011f\ufffd\ufffd\u00baGitalic_G satisfies \u011f\ufffd\ufffd\ufffd\u00cf\u0192\u00e2\ufffd\u00a2Psubscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u0192{ Q}_{ P}bold_Q start_POSTSUBSCRIPT italic_\u00cf\u0192 italic_P end_POSTSUBSCRIPT. The lemma is proved. We use G\u011f\ufffd\u201d\u2013superscript\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u201d\u2013G^{ start_POSTSUPERSCRIPT fraktur_S end_POSTSUPERSCRIPT (respectively, G\u011f\ufffd\u201d\u02dcsuperscript\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u201d\u02dcG^{ start_POSTSUPERSCRIPT fraktur_U end_POSTSUPERSCRIPT) to denote the soluble (respectively, the supersoluble) residual of G\u011f\ufffd\ufffd\u00baGitalic_G. Lemma 2.6. Let G\u011f\ufffd\ufffd\u00baGitalic_G be a non-soluble group and suppose that G\u011f\ufffd\ufffd\u00baGitalic_G has a Robinson complex (D,Z\u00e2\ufffd\u00a2(D);U1,\u00e2\u20ac\u00a6,Uk),\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02dc(D,Z(D);U_{1}, italic_D , italic_Z ( italic_D ) ; italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) , where D=G\u011f\ufffd\u201d\u2013=G\u011f\ufffd\u201d\u02dc\u011f\ufffd\ufffd\u00b7superscript\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u201d\u2013superscript\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u201d\u02dcD=G^{ = italic_G start_POSTSUPERSCRIPT fraktur_S end_POSTSUPERSCRIPT = italic_G start_POSTSUPERSCRIPT fraktur_U end_POSTSUPERSCRIPT. Let U\u011f\ufffd\u2018\u02c6Uitalic_U be a \u00cf\u0192\u011f\ufffd\u0153\ufffd non-\u00cf\u0192\u011f\ufffd\u0153\ufffd subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G of minimal order. Then: (1) If U\u00e2\ufffd\u00a2Ui\u00e2\u20ac\u00b2/Ui\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u02c6superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2UU_{i}^{ italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT / italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G/Ui\u00e2\u20ac\u00b2\u011f\ufffd\ufffd\u00basuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2G/U_{i}^{ / italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT for all i=1,\u00e2\u20ac\u00a6,k\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u02dci=1, = 1 , \u00e2\u20ac\u00a6 , italic_k, then U\u011f\ufffd\u2018\u02c6Uitalic_U is supersoluble. (2) If U\u011f\ufffd\u2018\u02c6Uitalic_U is supersoluble and U\u00e2\ufffd\u00a2L/L\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00bf\u011f\ufffd\ufffd\u00bfUL/Litalic_U italic_L / italic_L is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G/L\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00bfG/Litalic_G / italic_L for all non-trivial nilpotent normal subgroups L\u011f\ufffd\ufffd\u00bfLitalic_L of G\u011f\ufffd\ufffd\u00baGitalic_G, then U\u011f\ufffd\u2018\u02c6Uitalic_U is a cyclic p\u011f\ufffd\u2018\ufffdpitalic_p-group for some prime p\u011f\ufffd\u2018\ufffdpitalic_p. Proof. Suppose that this lemma is false and let G\u011f\ufffd\ufffd\u00baGitalic_G be a counterexample of minimal order. (1) Assume this is false. Suppose that U\u00e2\u02c6\u00a9D\u00e2\u2030\u00a4Z\u00e2\ufffd\u00a2(D)\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7U D Z(D)italic_U \u00e2\u02c6\u00a9 italic_D \u00e2\u2030\u00a4 italic_Z ( italic_D ). Then every chief factor of U\u011f\ufffd\u2018\u02c6Uitalic_U below U\u00e2\u02c6\u00a9Z\u00e2\ufffd\u00a2(D)=U\u00e2\u02c6\u00a9D\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b7U Z(D)=U Ditalic_U \u00e2\u02c6\u00a9 italic_Z ( italic_D ) = italic_U \u00e2\u02c6\u00a9 italic_D is cyclic and, also, U\u00e2\ufffd\u00a2D/D\u00e2\u2030\u0192U/(U\u00e2\u02c6\u00a9D)similar-to-or-equals\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b7UD/D U/(U D)italic_U italic_D / italic_D \u00e2\u2030\u0192 italic_U / ( italic_U \u00e2\u02c6\u00a9 italic_D ) is supersoluble. Hence U\u011f\ufffd\u2018\u02c6Uitalic_U is supersoluble, a contradiction. Therefore U\u00e2\u02c6\u00a9D\u00e2\u2030\u00b0Z\u00e2\ufffd\u00a2(D)not-less-than-nor-greater-than\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7U D Z(D)italic_U \u00e2\u02c6\u00a9 italic_D \u00e2\u2030\u00b0 italic_Z ( italic_D ). Moreover, Lemma 2.3(1)(2) implies that (U\u00e2\u02c6\u00a9D)\u00e2\ufffd\u00a2Z\u00e2\ufffd\u00a2(D)/Z\u00e2\ufffd\u00a2(D)\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7(U D)Z(D)/Z(D)( italic_U \u00e2\u02c6\u00a9 italic_D ) italic_Z ( italic_D ) / italic_Z ( italic_D ) is \u00cf\u0192\u011f\ufffd\u0153\ufffd in D/Z\u00e2\ufffd\u00a2(D)\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7D/Z(D)italic_D / italic_Z ( italic_D ) and so (U\u00e2\u02c6\u00a9D)\u00e2\ufffd\u00a2Z\u00e2\ufffd\u00a2(D)/Z\u00e2\ufffd\u00a2(D)\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7(U D)Z(D)/Z(D)( italic_U \u00e2\u02c6\u00a9 italic_D ) italic_Z ( italic_D ) / italic_Z ( italic_D ) is a non-trivial normal subgroup of D/Z\u00e2\ufffd\u00a2(D)\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7D/Z(D)italic_D / italic_Z ( italic_D ) by Lemma 2.3(5). Hence for some i\u011f\ufffd\u2018\u2013iitalic_i we have Ui/Z\u00e2\ufffd\u00a2(D)\u00e2\u2030\u00a4(U\u00e2\u02c6\u00a9D)\u00e2\ufffd\u00a2Z\u00e2\ufffd\u00a2(D)/Z\u00e2\ufffd\u00a2(D),subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7U_{i}/Z(D) D)Z(D)/Z(D),italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / italic_Z ( italic_D ) \u00e2\u2030\u00a4 ( italic_U \u00e2\u02c6\u00a9 italic_D ) italic_Z ( italic_D ) / italic_Z ( italic_D ) , so Ui\u00e2\u2030\u00a4(U\u00e2\u02c6\u00a9D)\u00e2\ufffd\u00a2Z\u00e2\ufffd\u00a2(D).subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7U_{i} D)Z(D).italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u2030\u00a4 ( italic_U \u00e2\u02c6\u00a9 italic_D ) italic_Z ( italic_D ) . But then Ui\u00e2\u20ac\u00b2\u00e2\u2030\u00a4((U\u00e2\u02c6\u00a9D)\u00e2\ufffd\u00a2Z\u00e2\ufffd\u00a2(D))\u00e2\u20ac\u00b2\u00e2\u2030\u00a4U\u00e2\u02c6\u00a9D.superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b7U_{i}^{ D)Z(D))^{ U D.italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u2030\u00a4 ( ( italic_U \u00e2\u02c6\u00a9 italic_D ) italic_Z ( italic_D ) ) start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u2030\u00a4 italic_U \u00e2\u02c6\u00a9 italic_D . By hypothesis, U\u00e2\ufffd\u00a2Ui\u00e2\u20ac\u00b2/Ui\u00e2\u20ac\u00b2=U/Ui\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u02c6superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u02c6superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2UU_{i}^{ italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT / italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT = italic_U / italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G/Ui\u00e2\u20ac\u00b2\u011f\ufffd\ufffd\u00basuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2G/U_{i}^{ / italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT and so U\u011f\ufffd\u2018\u02c6Uitalic_U is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G by Lemma 2.1(3), a contradiction. Therefore Statement (1) holds. (2) Assume that this is false. Let N=U\u011f\ufffd\u201d\u2018\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u201d\u2018N=U^{{ = italic_U start_POSTSUPERSCRIPT fraktur_N end_POSTSUPERSCRIPT be the nilpotent residual of U\u011f\ufffd\u2018\u02c6Uitalic_U. Then N<U\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02c6N<Uitalic_N < italic_U since U\u011f\ufffd\u2018\u02c6Uitalic_U supersoluble, so N\u011f\ufffd\u2018\ufffdNitalic_N is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G by the minimality of U\u011f\ufffd\u2018\u02c6Uitalic_U. It is also clear that every proper subgroup S\u011f\ufffd\u2018\u2020Sitalic_S of U\u011f\ufffd\u2018\u02c6Uitalic_U with N\u00e2\u2030\u00a4S\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2020N Sitalic_N \u00e2\u2030\u00a4 italic_S is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G, so S\u011f\ufffd\u2018\u2020Sitalic_S is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G. Therefore, if U\u011f\ufffd\u2018\u02c6Uitalic_U has at least two distinct maximal subgroups S\u011f\ufffd\u2018\u2020Sitalic_S and W\u011f\ufffd\u2018\u0160Witalic_W such that N\u00e2\u2030\u00a4S\u00e2\u02c6\u00a9W\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2020\u011f\ufffd\u2018\u0160N S Witalic_N \u00e2\u2030\u00a4 italic_S \u00e2\u02c6\u00a9 italic_W, then U=\u00e2\u0178\u00a8S,W\u00e2\u0178\u00a9\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2020\u011f\ufffd\u2018\u0160U= S,W = \u00e2\u0178\u00a8 italic_S , italic_W \u00e2\u0178\u00a9 is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G by Lemma 2.1(4), contrary to the choice of U\u011f\ufffd\u2018\u02c6Uitalic_U. Hence U/N\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\ufffdU/Nitalic_U / italic_N is a cyclic p\u011f\ufffd\u2018\ufffdpitalic_p-group for some prime p\u011f\ufffd\u2018\ufffdpitalic_p and N\u00e2\u2030 1\u011f\ufffd\u2018\ufffd1N 1italic_N \u00e2\u2030 1 since U\u011f\ufffd\u2018\u02c6Uitalic_U is not cyclic. Now we show that U\u011f\ufffd\u2018\u02c6Uitalic_U is a P\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2021PTitalic_P italic_T-group. Let S\u011f\ufffd\u2018\u2020Sitalic_S be a proper subnormal subgroup of U\u011f\ufffd\u2018\u02c6Uitalic_U. Then S\u011f\ufffd\u2018\u2020Sitalic_S is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G, so S\u011f\ufffd\u2018\u2020Sitalic_S is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G and hence S\u011f\ufffd\u2018\u2020Sitalic_S is \u00cf\u0192\u011f\ufffd\u0153\ufffd in U\u011f\ufffd\u2018\u02c6Uitalic_U by Lemma 2.1(1). Therefore S\u011f\ufffd\u2018\u2020Sitalic_S is quasinormal in U\u011f\ufffd\u2018\u02c6Uitalic_U by Theorem\u00c2 A. Therefore U\u011f\ufffd\u2018\u02c6Uitalic_U is a soluble P\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2021PTitalic_P italic_T-group, so N=U\u011f\ufffd\u201d\u2018\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u201d\u2018N=U^{{ = italic_U start_POSTSUPERSCRIPT fraktur_N end_POSTSUPERSCRIPT is a Hall abelian subgroup of U\u011f\ufffd\u2018\u02c6Uitalic_U by[14, Theorem 2.1.11]. It follows that N\u00e2\u2030\u00a4U\u011f\ufffd\u201d\u201e\u00e2\u02c6\u2014\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u02c6superscript\u011f\ufffd\u201d\u201eN U^{{ \u00e2\u2030\u00a4 italic_U start_POSTSUPERSCRIPT fraktur_A start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT and so U\u011f\ufffd\u201d\u201e\u00e2\u02c6\u2014=N\u00e2\ufffd\u00a2V,superscript\u011f\ufffd\u2018\u02c6superscript\u011f\ufffd\u201d\u201e\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2030U^{{ start_POSTSUPERSCRIPT fraktur_A start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT = italic_N italic_V , where V\u011f\ufffd\u2018\u2030Vitalic_V is a maximal subgroup of a cyclic Sylow p\u011f\ufffd\u2018\ufffdpitalic_p-subgroup P\u00e2\u2030\u0192U/Nsimilar-to-or-equals\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\ufffdP U/Nitalic_P \u00e2\u2030\u0192 italic_U / italic_N of U\u011f\ufffd\u2018\u02c6Uitalic_U. Hence N\u00e2\ufffd\u00a2V\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2030NVitalic_N italic_V is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G and N\u00e2\ufffd\u00a2V\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2030NVitalic_N italic_V is subnormal in G\u011f\ufffd\ufffd\u00baGitalic_G by Lemma 2.3(4). Therefore N\u00e2\ufffd\u00a2V\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2030NVitalic_N italic_V is quasinormal in G\u011f\ufffd\ufffd\u00baGitalic_G by Theorem\u00c2 A. Assume that for some minimal normal subgroup R\u011f\ufffd\u2018\u2026Ritalic_R of G\u011f\ufffd\ufffd\u00baGitalic_G we have R\u00e2\u2030\u00a4(N\u00e2\ufffd\u00a2V)G\u011f\ufffd\u2018\u2026subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2030\u011f\ufffd\ufffd\u00baR \u00e2\u2030\u00a4 ( italic_N italic_V ) start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT. Then U/R\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2026U/Ritalic_U / italic_R is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G/R\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2026G/Ritalic_G / italic_R by hypothesis, so U\u011f\ufffd\u2018\u02c6Uitalic_U is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G, a contradiction. Therefore (N\u00e2\ufffd\u00a2V)G=1subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2030\u011f\ufffd\ufffd\u00ba1(NV)_{G}=1( italic_N italic_V ) start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = 1, so N\u00e2\ufffd\u00a2V\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2030NVitalic_N italic_V is nilpotent and N\u00e2\ufffd\u00a2V\u00e2\u2030\u00a4Z\u00e2\u02c6\ufffd\u00e2\ufffd\u00a2(G)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2030subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00baNV Z_{ italic_V \u00e2\u2030\u00a4 italic_Z start_POSTSUBSCRIPT \u00e2\u02c6\ufffd end_POSTSUBSCRIPT ( italic_G ) by [14, Corollary 1.5.6] and then U=N\u00e2\ufffd\u00a2P\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0192U=NPitalic_U = italic_N italic_P is nilpotent, so N=1\u011f\ufffd\u2018\ufffd1N=1italic_N = 1, a contradcition. Therefore Statement (2) holds. The lemma is proved. Lemma 2.7. Suppose that a soluble group G=D\u00e2\u2039\u0160M\u011f\ufffd\ufffd\u00baright-normal-factor-semidirect-product\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u20acG=D Mitalic_G = italic_D \u00e2\u2039\u0160 italic_M satisfies Conditions (i), (ii) and (iii) in Theorem C. If A\u011f\ufffd\ufffd\u00b4Aitalic_A is a \u00cf\u0192\u011f\ufffd\u0153\ufffd \u00cf\u0192\u011f\ufffd\u0153\ufffd subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G such that A\u00e2\u2030\u00a4M\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u20acA Mitalic_A \u00e2\u2030\u00a4 italic_M, then D\u00e2\u2030\u00a4CG\u00e2\ufffd\u00a2(A)\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b4D C_{G}(A)italic_D \u00e2\u2030\u00a4 italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_A ). Proof. Let A\u011f\ufffd\ufffd\u00b4Aitalic_A be a \u00cf\u0192isubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT-group and x\u011f\ufffd\u2018\u00a5xitalic_x an element of prime power order pnsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203ap^{n}italic_p start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT of D\u011f\ufffd\ufffd\u00b7Ditalic_D. Let Hksubscript\u011f\ufffd\ufffd\u00bb\u011f\ufffd\u2018\u02dcH_{k}italic_H start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT be a Hall \u00cf\u0192ksubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u02dc start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT-subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G. Then, by hypothesis, Hk=O\u00cf\u0192k\u00e2\ufffd\u00a2(D)\u00c3\u2014Sksubscript\u011f\ufffd\ufffd\u00bb\u011f\ufffd\u2018\u02dcsubscript\u011f\ufffd\u2018\u201asubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u02dc\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u2018\u2020\u011f\ufffd\u2018\u02dcH_{k}=O_{ S_{k}italic_H start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = italic_O start_POSTSUBSCRIPT italic_\u00cf\u0192 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_D ) \u00c3\u2014 italic_S start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT, where O\u00cf\u0192k\u00e2\ufffd\u00a2(D)subscript\u011f\ufffd\u2018\u201asubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u02dc\u011f\ufffd\ufffd\u00b7O_{ start_POSTSUBSCRIPT italic_\u00cf\u0192 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_D ) and Sksubscript\u011f\ufffd\u2018\u2020\u011f\ufffd\u2018\u02dcS_{k}italic_S start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT are Hall subgroups of G\u011f\ufffd\ufffd\u00baGitalic_G. Since A\u011f\ufffd\ufffd\u00b4Aitalic_A is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G, A\u00e2\u2030\u00a4Hi\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\ufffd\u00bb\u011f\ufffd\u2018\u2013A H_{i}italic_A \u00e2\u2030\u00a4 italic_H start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT by Lemma 2.6(7) in [3]. On the other hand, since A\u00e2\u2030\u00a4M\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u20acA Mitalic_A \u00e2\u2030\u00a4 italic_M, A\u00e2\u02c6\u00a9D=1\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b71A D=1italic_A \u00e2\u02c6\u00a9 italic_D = 1. Therefore A=(A\u00e2\u02c6\u00a9O\u00cf\u0192i\u00e2\ufffd\u00a2(D))\u00c3\u2014(A\u00e2\u02c6\u00a9Si)=A\u00e2\u02c6\u00a9Si\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\u2018\u201asubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\u2018\u2020\u011f\ufffd\u2018\u2013\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\u2018\u2020\u011f\ufffd\u2018\u2013A=(A O_{ S_{i})=A S_{i}italic_A = ( italic_A \u00e2\u02c6\u00a9 italic_O start_POSTSUBSCRIPT italic_\u00cf\u0192 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_D ) ) \u00c3\u2014 ( italic_A \u00e2\u02c6\u00a9 italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = italic_A \u00e2\u02c6\u00a9 italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, so A\u00e2\u2030\u00a4Si\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\u2018\u2020\u011f\ufffd\u2018\u2013A S_{i}italic_A \u00e2\u2030\u00a4 italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and hence O\u00cf\u0192i\u00e2\ufffd\u00a2(D)\u00e2\u2030\u00a4CG\u00e2\ufffd\u00a2(A)subscript\u011f\ufffd\u2018\u201asubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b4O_{ C_{G}(A)italic_O start_POSTSUBSCRIPT italic_\u00cf\u0192 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_D ) \u00e2\u2030\u00a4 italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_A ). Now, let k\u00e2\u2030 i\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2013k iitalic_k \u00e2\u2030 italic_i. Then A\u011f\ufffd\ufffd\u00b4Aitalic_A is a Hall \u00cf\u0192isubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT-subgroup of V:=O\u00cf\u0192k\u00e2\ufffd\u00a2(D)\u00e2\ufffd\u00a2Aassign\u011f\ufffd\u2018\u2030subscript\u011f\ufffd\u2018\u201asubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u02dc\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b4V:=O_{ := italic_O start_POSTSUBSCRIPT italic_\u00cf\u0192 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_D ) italic_A and A\u011f\ufffd\ufffd\u00b4Aitalic_A is \u00cf\u0192\u011f\ufffd\u0153\ufffd in V\u011f\ufffd\u2018\u2030Vitalic_V by Lemma 2.6(1) in [3], so V=O\u00cf\u0192k\u00e2\ufffd\u00a2(D)\u00c3\u2014A\u011f\ufffd\u2018\u2030subscript\u011f\ufffd\u2018\u201asubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u02dc\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b4V=O_{ Aitalic_V = italic_O start_POSTSUBSCRIPT italic_\u00cf\u0192 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_D ) \u00c3\u2014 italic_A by Lemma 2.6(10) in [3] and hence D\u00e2\u2030\u00a4CG\u00e2\ufffd\u00a2(A)\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b4D C_{G}(A)italic_D \u00e2\u2030\u00a4 italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_A ). The lemma is proved. Lemma 2.8 (See Lemma 5.1.9 in [1]). Let A\u011f\ufffd\ufffd\u00b4Aitalic_A be a subgroup of prime power order of G\u011f\ufffd\ufffd\u00baGitalic_G. (1) If A\u011f\ufffd\ufffd\u00b4Aitalic_A is modular but not subnormal in G\u011f\ufffd\ufffd\u00baGitalic_G, then where AG/AGsuperscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00baA^{G}/A_{G}italic_A start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is a non-abelian P\u011f\ufffd\u2018\u0192Pitalic_P-group of order prime to |K/AG|\u011f\ufffd\ufffd\u00besubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00ba|K/A_{G}|| italic_K / italic_A start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT |. (2) A\u011f\ufffd\ufffd\u00b4Aitalic_A is modular in G\u011f\ufffd\ufffd\u00baGitalic_G if and only if A\u011f\ufffd\ufffd\u00b4Aitalic_A is modular in \u00e2\u0178\u00a8x,A\u00e2\u0178\u00a9\u011f\ufffd\u2018\u00a5\u011f\ufffd\ufffd\u00b4 x,A italic_x , italic_A \u00e2\u0178\u00a9 for all x\u00e2\u02c6\u02c6G\u011f\ufffd\u2018\u00a5\u011f\ufffd\ufffd\u00bax Gitalic_x \u00e2\u02c6\u02c6 italic_G of prime power order. Lemma 2.9. If G/Z\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Zitalic_G / italic_Z is p\u011f\ufffd\u2018\ufffdpitalic_p-closed for some prime p\u011f\ufffd\u2018\ufffdpitalic_p and Z\u00e2\u2030\u00a4Z\u00e2\u02c6\ufffd\u00e2\ufffd\u00a2(G)\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00baZ Z_{ \u00e2\u2030\u00a4 italic_Z start_POSTSUBSCRIPT \u00e2\u02c6\ufffd end_POSTSUBSCRIPT ( italic_G ), then G\u011f\ufffd\ufffd\u00baGitalic_G is p\u011f\ufffd\u2018\ufffdpitalic_p-closed. Proof. Since Z\u00e2\u2030\u00a4Z\u00e2\u02c6\ufffd\u00e2\ufffd\u00a2(G)\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00baZ Z_{ \u00e2\u2030\u00a4 italic_Z start_POSTSUBSCRIPT \u00e2\u02c6\ufffd end_POSTSUBSCRIPT ( italic_G ), for a Sylow p\u011f\ufffd\u2018\ufffdpitalic_p-subgroup Zpsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdZ_{p}italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT of Z\u011f\ufffd\u2018\ufffdZitalic_Z we have Z=Zp\u00c3\u2014W\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0160Z=Z_{p} Witalic_Z = italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT \u00c3\u2014 italic_W, where Zpsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdZ_{p}italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT and W\u011f\ufffd\u2018\u0160Witalic_W are characteristic in Z\u011f\ufffd\u2018\ufffdZitalic_Z and so normal in G\u011f\ufffd\ufffd\u00baGitalic_G. Let P/Z\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\ufffdP/Zitalic_P / italic_Z be a normal Sylow p\u011f\ufffd\u2018\ufffdpitalic_p-subgroup of G/Z\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Zitalic_G / italic_Z and V\u011f\ufffd\u2018\u2030Vitalic_V a Sylow p\u011f\ufffd\u2018\ufffdpitalic_p-subgroup of P\u011f\ufffd\u2018\u0192Pitalic_P. Then Zp\u00e2\u2030\u00a4Vsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2030Z_{p} Vitalic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_V and P=V\u00e2\ufffd\u00a2Z=V\u00c3\u2014W\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u0160P=VZ=V Witalic_P = italic_V italic_Z = italic_V \u00c3\u2014 italic_W since W\u00e2\u2030\u00a4Z\u00e2\u02c6\ufffd\u00e2\ufffd\u00a2(G)\u00e2\u02c6\u00a9P\u00e2\u2030\u00a4Z\u00e2\u02c6\ufffd\u00e2\ufffd\u00a2(P)\u011f\ufffd\u2018\u0160subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u0192subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0192W Z_{ P Z_{ \u00e2\u2030\u00a4 italic_Z start_POSTSUBSCRIPT \u00e2\u02c6\ufffd end_POSTSUBSCRIPT ( italic_G ) \u00e2\u02c6\u00a9 italic_P \u00e2\u2030\u00a4 italic_Z start_POSTSUBSCRIPT \u00e2\u02c6\ufffd end_POSTSUBSCRIPT ( italic_P ). Therefore V\u011f\ufffd\u2018\u2030Vitalic_V is characteristic in P\u011f\ufffd\u2018\u0192Pitalic_P and so normal in G\u011f\ufffd\ufffd\u00baGitalic_G. The lemma is proved. Lemma 2.10. Let G=Q\u00e2\u2039\u0160P\u011f\ufffd\ufffd\u00baright-normal-factor-semidirect-product\u011f\ufffd\u2018\u201e\u011f\ufffd\u2018\u0192G=Q Pitalic_G = italic_Q \u00e2\u2039\u0160 italic_P be a non-abelian P\u011f\ufffd\u2018\u0192Pitalic_P-group of type (q,p)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd(q,p)( italic_q , italic_p ). (1) PG=Gsuperscript\u011f\ufffd\u2018\u0192\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00baP^{G}=Gitalic_P start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT = italic_G. (2) G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N is a non-abelian P\u011f\ufffd\u2018\u0192Pitalic_P-group of type (q,p)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd(q,p)( italic_q , italic_p ) for every proper normal subgroup N\u011f\ufffd\u2018\ufffdNitalic_N of G\u011f\ufffd\ufffd\u00baGitalic_G. Proof. See Lemma 2.2.2 in [1]. Lemma 2.11. If A\u011f\ufffd\ufffd\u00b4Aitalic_A and B\u011f\ufffd\ufffd\u00b5Bitalic_B are normal subgroups of G\u011f\ufffd\ufffd\u00baGitalic_G, then every chief factor H/K\u011f\ufffd\ufffd\u00bb\u011f\ufffd\ufffd\u00beH/Kitalic_H / italic_K of G\u011f\ufffd\ufffd\u00baGitalic_G below A\u00e2\ufffd\u00a2B\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b5ABitalic_A italic_B is G\u011f\ufffd\ufffd\u00baGitalic_G-isomorphic to either a chiew factor of G\u011f\ufffd\ufffd\u00baGitalic_G below A\u011f\ufffd\ufffd\u00b4Aitalic_A or a chief factor of G\u011f\ufffd\ufffd\u00baGitalic_G between B\u00e2\u02c6\u00a9A\u011f\ufffd\ufffd\u00b5\u011f\ufffd\ufffd\u00b4B Aitalic_B \u00e2\u02c6\u00a9 italic_A and B\u011f\ufffd\ufffd\u00b5Bitalic_B. Proof. This assertion follows from the G\u011f\ufffd\ufffd\u00baGitalic_G-isomorphism A\u00e2\ufffd\u00a2B/A\u00e2\u2030\u0192B/(B\u00e2\u02c6\u00a9A)similar-to-or-equals\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b5\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b5\u011f\ufffd\ufffd\u00b5\u011f\ufffd\ufffd\u00b4AB/A B/(B A)italic_A italic_B / italic_A \u00e2\u2030\u0192 italic_B / ( italic_B \u00e2\u02c6\u00a9 italic_A ) and the Jordan-H\u00c3\u00b6lder theorem for the \u00ce\u00a9\u00ce\u00a9 seties of a group (see [20, Chapter A, 3.2]). From Proposition 2.2.8 in [14] we get the following useful lemma. Lemma 2.12. Let \u011f\ufffd\u201d\u2030\u011f\ufffd\u201d\u2030 be a non-empty hereditary formation. (1) If N\u011f\ufffd\u2018\ufffdNitalic_N is a normal subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G, then (G/N)\u011f\ufffd\u201d\u2030=G\u011f\ufffd\u201d\u2030\u00e2\ufffd\u00a2N/N.superscript\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffd\u011f\ufffd\u201d\u2030superscript\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u201d\u2030\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd(G/N)^{ italic_G / italic_N ) start_POSTSUPERSCRIPT fraktur_F end_POSTSUPERSCRIPT = italic_G start_POSTSUPERSCRIPT fraktur_F end_POSTSUPERSCRIPT italic_N / italic_N . (2) If E\u011f\ufffd\ufffd\u00b8Eitalic_E is a subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G, then E\u011f\ufffd\u201d\u2030\u00e2\u2030\u00a4G\u011f\ufffd\u201d\u2030superscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u201d\u2030superscript\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u201d\u2030E^{ G^{ start_POSTSUPERSCRIPT fraktur_F end_POSTSUPERSCRIPT \u00e2\u2030\u00a4 italic_G start_POSTSUPERSCRIPT fraktur_F end_POSTSUPERSCRIPT and N\u00e2\ufffd\u00a2(N\u00e2\ufffd\u00a2E)\u011f\ufffd\u201d\u2030=N\u00e2\ufffd\u00a2E\u011f\ufffd\u201d\u2030\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u201d\u2030\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u201d\u2030N(NE)^{ ( italic_N italic_E ) start_POSTSUPERSCRIPT fraktur_F end_POSTSUPERSCRIPT = italic_N italic_E start_POSTSUPERSCRIPT fraktur_F end_POSTSUPERSCRIPT. Lemma 2.13. Let (D,Z\u00e2\ufffd\u00a2(D);U1,\u00e2\u20ac\u00a6,Uk)\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02dc(D,Z(D);U_{1}, italic_D , italic_Z ( italic_D ) ; italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) be a Robinson complex of G\u011f\ufffd\ufffd\u00baGitalic_G and N\u011f\ufffd\u2018\ufffdNitalic_N a normal subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G. (1) Ui\u00e2\u20ac\u00b2/(Ui\u00e2\u20ac\u00b2\u00e2\u02c6\u00a9Z\u00e2\ufffd\u00a2(D))superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7U_{i}^{ Z(D))italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT / ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_Z ( italic_D ) ) is a simple non-abelian group and Ui\u00e2\u20ac\u00b2\u00e2\u02c6\u00a9Z\u00e2\ufffd\u00a2(D)=\u00ce\u00a6\u00e2\ufffd\u00a2(Ui\u00e2\u20ac\u00b2)=Z\u00e2\ufffd\u00a2(Ui\u00e2\u20ac\u00b2)superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7\u00ce\u00a6superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2U_{i}^{ Z(D)= start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_Z ( italic_D ) = roman_\u00ce\u00a6 ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) = italic_Z ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ). In particular, Ui\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2U_{i}^{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT is a quasi-simple group. (2) If N=Ui\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2N=U_{i}^{ = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT and k\u00e2\u2030 1\u011f\ufffd\u2018\u02dc1k 1italic_k \u00e2\u2030 1, then (D/N,Z\u00e2\ufffd\u00a2(D/N);U1\u00e2\ufffd\u00a2N/N,\u00e2\u20ac\u00a6,Ui\u00e2\u02c6\u20191\u00e2\ufffd\u00a2N/N,Ui+1\u00e2\ufffd\u00a2N/N,\u00e2\u2039\u00af,N\u00e2\ufffd\u00a2Uk/N)\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u02c61\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u00e2\u2039\u00af\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\ufffd(D/N,Z(D/N);U_{1}N/N, italic_D / italic_N , italic_Z ( italic_D / italic_N ) ; italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N / italic_N , \u00e2\u20ac\u00a6 , italic_U start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT italic_N / italic_N , italic_U start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPT italic_N / italic_N , \u00e2\u2039\u00af , italic_N italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT / italic_N ) is a Robinson complex of G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N and Ui/N=Z\u00e2\ufffd\u00a2(D)\u00e2\ufffd\u00a2N/N=Z\u00e2\ufffd\u00a2(D/N)subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffdU_{i}/N=Z(D)N/N=Z(D/N)italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / italic_N = italic_Z ( italic_D ) italic_N / italic_N = italic_Z ( italic_D / italic_N ). (3) If N\u011f\ufffd\u2018\ufffdNitalic_N is nilpotent, then (D\u00e2\ufffd\u00a2N/N,Z\u00e2\ufffd\u00a2(D)\u00e2\ufffd\u00a2N/N;U1\u00e2\ufffd\u00a2N/N,\u00e2\u20ac\u00a6,N\u00e2\ufffd\u00a2Uk/N)\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u02c61\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u00e2\u20ac\u00a6\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\ufffd(DN/N,Z(D)N/N;U_{1}N/N, italic_D italic_N / italic_N , italic_Z ( italic_D ) italic_N / italic_N ; italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N / italic_N , \u00e2\u20ac\u00a6 , italic_N italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT / italic_N ) is a Robinson complex of G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N and Z\u00e2\ufffd\u00a2(D)\u00e2\ufffd\u00a2N/N=Z\u00e2\ufffd\u00a2(D/N)\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffdZ(D)N/N=Z(D/N)italic_Z ( italic_D ) italic_N / italic_N = italic_Z ( italic_D / italic_N ). (4) If p\u00e2\u02c6\u02c6\u00cf\u20ac\u00e2\ufffd\u00a2(Z\u00e2\ufffd\u00a2(D))\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7p \u00e2\u02c6\u02c6 italic_\u00cf\u20ac ( italic_Z ( italic_D ) ), then p\u00e2\u02c6\u02c6\u00cf\u20ac\u00e2\ufffd\u00a2(Z\u00e2\ufffd\u00a2(Ui\u00e2\u20ac\u00b2))\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2p \u00e2\u02c6\u02c6 italic_\u00cf\u20ac ( italic_Z ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) ) for some i\u011f\ufffd\u2018\u2013iitalic_i. In particular, p\u00e2\u02c6\u02c6{2,3}\u011f\ufffd\u2018\ufffd23p \u00e2\u02c6\u02c6 { 2 , 3 }. Proof. Let Z:=Z\u00e2\ufffd\u00a2(D)=\u00ce\u00a6\u00e2\ufffd\u00a2(D)assign\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7\u00ce\u00a6\u011f\ufffd\ufffd\u00b7Z:=Z(D)= := italic_Z ( italic_D ) = roman_\u00ce\u00a6 ( italic_D ). (1) First observe that Ui=Ui\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2Z=Ui\u011f\ufffd\u201d\u2013\u00e2\ufffd\u00a2Zsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u011f\ufffd\u201d\u2013\u011f\ufffd\u2018\ufffdU_{i}=U_{i}^{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT italic_Z = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT fraktur_S end_POSTSUPERSCRIPT italic_Z, where \u011f\ufffd\u201d\u2013\u011f\ufffd\u201d\u2013 is the class of all soluble groups, since Ui/Zsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffdU_{i}/Zitalic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / italic_Z is a simple non-abelian group and so Ui\u011f\ufffd\u201d\u2013\u00e2\u2030\u00a4Ui\u00e2\u20ac\u00b2\u00e2\u2030\u00a4Ui\u011f\ufffd\u201d\u2013superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u011f\ufffd\u201d\u2013superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u011f\ufffd\u201d\u2013U_{i}^{ U_{i}^{ U_{i}^{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT fraktur_S end_POSTSUPERSCRIPT \u00e2\u2030\u00a4 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u2030\u00a4 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT fraktur_S end_POSTSUPERSCRIPT. Hence Ui\u011f\ufffd\u201d\u2013=Ui\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u011f\ufffd\u201d\u2013superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2U_{i}^{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT fraktur_S end_POSTSUPERSCRIPT = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT is perfect. On the other hand, Ui/Z=Ui\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2Z/Z\u00e2\u2030\u0192Ui\u00e2\u20ac\u00b2/(Ui\u00e2\u20ac\u00b2\u00e2\u02c6\u00a9Z)subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsimilar-to-or-equalssuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffdU_{i}/Z=U_{i}^{ U_{i}^{ Z)italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / italic_Z = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT italic_Z / italic_Z \u00e2\u2030\u0192 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT / ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_Z ) is a simple non-abelian group. Therefore Ui\u00e2\u20ac\u00b2\u00e2\u02c6\u00a9Z=\u00ce\u00a6\u00e2\ufffd\u00a2(Ui\u00e2\u20ac\u00b2)=Z\u00e2\ufffd\u00a2(Ui\u00e2\u20ac\u00b2)superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffd\u00ce\u00a6superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2U_{i}^{ Z= start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_Z = roman_\u00ce\u00a6 ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) = italic_Z ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) since \u00ce\u00a6\u00e2\ufffd\u00a2(Ui\u00e2\u20ac\u00b2)\u00e2\u2030\u00a4\u00ce\u00a6\u00e2\ufffd\u00a2(D)\u00ce\u00a6superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u00ce\u00a6\u011f\ufffd\ufffd\u00b7 ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) \u00e2\u2030\u00a4 roman_\u00ce\u00a6 ( italic_D ). (2), (3) See Remark 1.6.8 in [14] or Lemma 3.1 in [11]. (4) Assume that p\u00e2\u02c6\u2030\u00cf\u20ac\u00e2\ufffd\u00a2(Z\u00e2\ufffd\u00a2(Ui\u00e2\u20ac\u00b2))\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2p \u00e2\u02c6\u2030 italic_\u00cf\u20ac ( italic_Z ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) ) for all i\u011f\ufffd\u2018\u2013iitalic_i and let Z=Zp\u00c3\u2014V\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2030Z=Z_{p} Vitalic_Z = italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT \u00c3\u2014 italic_V, where Zpsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdZ_{p}italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT is the Sylow p\u011f\ufffd\u2018\ufffdpitalic_p-subgroup of Z\u011f\ufffd\u2018\ufffdZitalic_Z. Then Zp\u00e2\u02c6\u00a9Ui\u00e2\u20ac\u00b2=1subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b21Z_{p} U_{i}^{ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT \u00e2\u02c6\u00a9 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT = 1, so Ui\u00e2\u20ac\u00b2\u00e2\u02c6\u00a9Z=Ui\u00e2\u20ac\u00b2\u00e2\u02c6\u00a9V=\u00ce\u00a6\u00e2\ufffd\u00a2(Ui\u00e2\u20ac\u00b2)=Z\u00e2\ufffd\u00a2(Ui\u00e2\u20ac\u00b2)superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u2030\u00ce\u00a6superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2U_{i}^{ Z=U_{i}^{ V= start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_Z = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_V = roman_\u00ce\u00a6 ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) = italic_Z ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) for all i\u011f\ufffd\u2018\u2013iitalic_i. On the other hand, D=U1\u00e2\u2039\u00afUk=ZU1\u00e2\u20ac\u00b2\u00e2\u2039\u00afUk\u00e2\u20ac\u00b2=Zp(V(U1\u00e2\u20ac\u00b2\u00e2\u2039\u00afUk\u00e2\u20ac\u00b2)D=U_{1} U_{k}=ZU_{1}^{ U_{k}^{ } U_{k}^{ = italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2039\u00af italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = italic_Z italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u2039\u00af italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT = italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_V ( italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u2039\u00af italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ), so D=V\u00e2\ufffd\u00a2(U1\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2\u00e2\u2039\u00af\u00e2\ufffd\u00a2Uk\u00e2\u20ac\u00b2)\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u2030superscriptsubscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00b2\u00e2\u2039\u00afsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02dc\u00e2\u20ac\u00b2D=V(U_{1}^{ U_{k}^{ = italic_V ( italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u2039\u00af italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) since Zp\u00e2\u2030\u00a4\u00ce\u00a6\u00e2\ufffd\u00a2(D)subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u00ce\u00a6\u011f\ufffd\ufffd\u00b7Z_{p} start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT \u00e2\u2030\u00a4 roman_\u00ce\u00a6 ( italic_D ). Hence Z\u00e2\u2030\u00a4V\u00e2\ufffd\u00a2(U1\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2\u00e2\u2039\u00af\u00e2\ufffd\u00a2Uk\u00e2\u20ac\u00b2)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2030superscriptsubscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00b2\u00e2\u2039\u00afsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02dc\u00e2\u20ac\u00b2Z V(U_{1}^{ U_{k}^{ \u00e2\u2030\u00a4 italic_V ( italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u2039\u00af italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ). But V\u011f\ufffd\u2018\u2030Vitalic_V and every subgroup Ui\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2U_{i}^{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT has no a composition factor of order p\u011f\ufffd\u2018\ufffdpitalic_p by Lemma 2.11, a contradiction. Therefore p\u00e2\u02c6\u02c6\u00cf\u20ac\u00e2\ufffd\u00a2(Z\u00e2\ufffd\u00a2(Ui\u00e2\u20ac\u00b2))\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2p \u00e2\u02c6\u02c6 italic_\u00cf\u20ac ( italic_Z ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) ) for some i\u011f\ufffd\u2018\u2013iitalic_i, where Ui\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2U_{i}^{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT is a quasi-simple group by Part (1). But then |Z\u00e2\ufffd\u00a2(Ui\u00e2\u20ac\u00b2)|\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2|Z(U_{i}^{ italic_Z ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) | divides the order of the Schur multiplier M\u00e2\ufffd\u00a2(Ui\u00e2\u20ac\u00b2/Z\u00e2\ufffd\u00a2(Ui\u00e2\u20ac\u00b2))\u011f\ufffd\u2018\u20acsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2M(U_{i}^{ ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT / italic_Z ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) ) of Ui\u00e2\u20ac\u00b2/Z\u00e2\ufffd\u00a2(Ui\u00e2\u20ac\u00b2)superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2U_{i}^{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT / italic_Z ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ). Hence \u00cf\u20ac\u00e2\ufffd\u00a2(Z\u00e2\ufffd\u00a2(Ui\u00e2\u20ac\u00b2))\u00e2\u0160\u2020{2,3}\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b223 ( italic_Z ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) ) \u00e2\u0160\u2020 { 2 , 3 } (see Section 4.15(A) in [22, Ch. 4]. Therefore p\u00e2\u02c6\u02c6{2,3}\u011f\ufffd\u2018\ufffd23p \u00e2\u02c6\u02c6 { 2 , 3 }. Hence we have (4). The lemma is proved. Lemma 2.14. Let U\u011f\ufffd\u2018\u02c6Uitalic_U and N\u00e2\ufffd\u00a2\u00e2\u0160\u00b4\u00e2\ufffd\u00a2G\u011f\ufffd\u2018\ufffd\u00e2\u0160\u00b4\u011f\ufffd\ufffd\u00baN Gitalic_N \u00e2\u0160\u00b4 italic_G be subgroups of G\u011f\ufffd\ufffd\u00baGitalic_G, where U\u011f\ufffd\u2018\u02c6Uitalic_U is of prime power order. Suppose that U\u00e2\ufffd\u00a2N/N\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdUN/Nitalic_U italic_N / italic_N is a modular non-subnormal subgroup of G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N. Then where UG\u00e2\ufffd\u00a2N/(U\u00e2\ufffd\u00a2N)Gsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00baU^{G}N/(UN)_{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT italic_N / ( italic_U italic_N ) start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is a non-abelian P\u011f\ufffd\u2018\u0192Pitalic_P-group of order prime to |K/U\u00e2\ufffd\u00a2NG|\u011f\ufffd\ufffd\u00be\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00ba|K/UN_{G}|| italic_K / italic_U italic_N start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT |. Proof. The subgroup U\u00e2\ufffd\u00a2N/N\u00e2\u2030\u0192U/(U\u00e2\u02c6\u00a9N)similar-to-or-equals\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\ufffdUN/N U/(U N)italic_U italic_N / italic_N \u00e2\u2030\u0192 italic_U / ( italic_U \u00e2\u02c6\u00a9 italic_N ) of G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N is of prime power order, so we can apply Lemma 2.8(1). First observe that (U\u00e2\ufffd\u00a2N/N)G/N=(U\u00e2\ufffd\u00a2N)G/Nsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffd(UN/N)_{G/N}=(UN)_{G}/N( italic_U italic_N / italic_N ) start_POSTSUBSCRIPT italic_G / italic_N end_POSTSUBSCRIPT = ( italic_U italic_N ) start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT / italic_N and (U\u00e2\ufffd\u00a2N/N)G/N=(U\u00e2\ufffd\u00a2N)G/N=UG\u00e2\ufffd\u00a2N/Nsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd(UN/N)^{G/N}=(UN)^{G}/N=U^{G}N/N( italic_U italic_N / italic_N ) start_POSTSUPERSCRIPT italic_G / italic_N end_POSTSUPERSCRIPT = ( italic_U italic_N ) start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_N = italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT italic_N / italic_N. Therefore, by Lemma 2.8(1), where is a non-abelian P\u011f\ufffd\u2018\u0192Pitalic_P-group of order prime to |(K/N)/(U\u00e2\ufffd\u00a2N/N)G/N|\u011f\ufffd\ufffd\u00be\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffd|(K/N)/(UN/N)_{G/N}|| ( italic_K / italic_N ) / ( italic_U italic_N / italic_N ) start_POSTSUBSCRIPT italic_G / italic_N end_POSTSUBSCRIPT | and so to |K/(U\u00e2\ufffd\u00a2N)G|\u011f\ufffd\ufffd\u00besubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00ba|K/(UN)_{G}|| italic_K / ( italic_U italic_N ) start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT |. The lemma is proved. A group G\u011f\ufffd\ufffd\u00baGitalic_G is called \u00cf\u20ac\u011f\ufffd\u0153\u2039 if G\u011f\ufffd\ufffd\u00baGitalic_G has a normal Hall \u00cf\u20ac\u011f\ufffd\u0153\u2039 The following lemma is well-known [20, Chapter A, 13.2]. Lemma 2.15. If H\u011f\ufffd\ufffd\u00bbHitalic_H is a normal subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G and H/(H\u00e2\u02c6\u00a9\u00ce\u00a6\u00e2\ufffd\u00a2(G))\u011f\ufffd\ufffd\u00bb\u011f\ufffd\ufffd\u00bb\u00ce\u00a6\u011f\ufffd\ufffd\u00baH/(H / ( italic_H \u00e2\u02c6\u00a9 roman_\u00ce\u00a6 ( italic_G ) ) is \u00cf\u20ac\u011f\ufffd\u0153\u2039 then H\u011f\ufffd\ufffd\u00bbHitalic_H is \u00cf\u20ac\u011f\ufffd\u0153\u2039 Recall that a group G\u011f\ufffd\ufffd\u00baGitalic_G is said to be a P\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018\u0192P^{*}italic_P start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT-group if G=A\u00e2\u2039\u0160\u00e2\u0178\u00a8t\u00e2\u0178\u00a9\u011f\ufffd\ufffd\u00baright-normal-factor-semidirect-product\u011f\ufffd\ufffd\u00b4delimited-\u00e2\u0178\u00a8\u00e2\u0178\u00a9\u011f\ufffd\u2018\u00a1G=A t = italic_A \u00e2\u2039\u0160 \u00e2\u0178\u00a8 italic_t \u00e2\u0178\u00a9, where A\u011f\ufffd\ufffd\u00b4Aitalic_A is an elementary abelian subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G, |t|=rn\u011f\ufffd\u2018\u00a1superscript\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u203a|t|=r^{n}| italic_t | = italic_r start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT for some prime r\u011f\ufffd\u2018\u0178ritalic_r and t\u011f\ufffd\u2018\u00a1titalic_t induces a power automorphism of prime order on A\u011f\ufffd\ufffd\u00b4Aitalic_A [1, p. 69]. Lemma 2.16. Let G=A\u00e2\u2039\u0160\u00e2\u0178\u00a8t\u00e2\u0178\u00a9\u011f\ufffd\ufffd\u00baright-normal-factor-semidirect-product\u011f\ufffd\ufffd\u00b4delimited-\u00e2\u0178\u00a8\u00e2\u0178\u00a9\u011f\ufffd\u2018\u00a1G=A t = italic_A \u00e2\u2039\u0160 \u00e2\u0178\u00a8 italic_t \u00e2\u0178\u00a9 be a P\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018\u0192P^{*}italic_P start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT-group and let |\u00e2\u0178\u00a8t\u00e2\u0178\u00a9|=pn.delimited-\u00e2\u0178\u00a8\u00e2\u0178\u00a9\u011f\ufffd\u2018\u00a1superscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a| t \u00e2\u0178\u00a8 italic_t \u00e2\u0178\u00a9 | = italic_p start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT . Then Z\u00e2\ufffd\u00a2(G)=\u00e2\u0178\u00a8tp\u00e2\u0178\u00a9=\u00ce\u00a6\u00e2\ufffd\u00a2(G)\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00badelimited-\u00e2\u0178\u00a8\u00e2\u0178\u00a9superscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffd\u00ce\u00a6\u011f\ufffd\ufffd\u00baZ(G)= t^{p} ( italic_G ) = \u00e2\u0178\u00a8 italic_t start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT \u00e2\u0178\u00a9 = roman_\u00ce\u00a6 ( italic_G ), G/Z\u00e2\ufffd\u00a2(G)\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00baG/Z(G)italic_G / italic_Z ( italic_G ) is a non-abelian P\u011f\ufffd\u2018\u0192Pitalic_P-group and the lattice \u00e2\u201e\u2019\u00e2\ufffd\u00a2(G)\u00e2\u201e\u2019\u011f\ufffd\ufffd\u00ba{ L}(G)caligraphic_L ( italic_G ) is modular. The following lemma is a corollary of Theorem C. Lemma 2.17. If G\u011f\ufffd\ufffd\u00baGitalic_G is a soluible Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q Titalic_Q italic_\u00cf\u0192 italic_T-group, then every subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G is a Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q Titalic_Q italic_\u00cf\u0192 italic_T-group. Proof of Theorem E. First assume that G\u011f\ufffd\ufffd\u00baGitalic_G is a Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q Titalic_Q italic_\u00cf\u0192 italic_T-group. Then G\u011f\ufffd\ufffd\u00baGitalic_G is a P\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2021PTitalic_P italic_T-group and every quotient G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N is a Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q Titalic_Q italic_\u00cf\u0192 italic_T-group by Lemma 2.4. Let D\u011f\ufffd\ufffd\u00b7Ditalic_D be the soluble residual of G\u011f\ufffd\ufffd\u00baGitalic_G. Then D\u011f\ufffd\ufffd\u00b7Ditalic_D is perfect and G/D\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7G/Ditalic_G / italic_D is a soluble group Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q Titalic_Q italic_\u00cf\u0192 italic_T-group, so Condition (i) holds for G\u011f\ufffd\ufffd\u00baGitalic_G. Now assume that D\u00e2\u2030 1\u011f\ufffd\ufffd\u00b71D 1italic_D \u00e2\u2030 1. Then, in view of Theorem D, G\u011f\ufffd\ufffd\u00baGitalic_G has a Robinson complex (D,Z(D);(D,Z(D);( italic_D , italic_Z ( italic_D ) ; U1,\u00e2\u20ac\u00a6,Uk)U_{1}, start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) such that for any set {i1,\u00e2\u20ac\u00a6,ir}\u00e2\u0160\u2020{1,\u00e2\u20ac\u00a6,k}subscript\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u01781\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u02dc italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT } \u00e2\u0160\u2020 { 1 , \u00e2\u20ac\u00a6 , italic_k }, where 1\u00e2\u2030\u00a4r<k1\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u02dc1 r<k1 \u00e2\u2030\u00a4 italic_r < italic_k, G\u011f\ufffd\ufffd\u00baGitalic_G and G/Ui1\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2\u00e2\u2039\u00af\u00e2\ufffd\u00a2Uir\u00e2\u20ac\u00b2\u011f\ufffd\ufffd\u00basuperscriptsubscript\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00b2\u00e2\u2039\u00afsuperscriptsubscript\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u0178\u00e2\u20ac\u00b2G/U_{i_{1}}^{ U_{i_{r}}^{ / italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u2039\u00af italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT satisfy \u011f\ufffd\ufffd\ufffdpsubscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\ufffd{ N}_{p}bold_N start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u00e2\u02c6\u02c6{2,3}\u00e2\u02c6\u00a9\u00cf\u20ac\u00e2\ufffd\u00a2(Z\u00e2\ufffd\u00a2(D))\u011f\ufffd\u2018\ufffd23\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7p \u00e2\u02c6\u02c6 { 2 , 3 } \u00e2\u02c6\u00a9 italic_\u00cf\u20ac ( italic_Z ( italic_D ) ) and \u011f\ufffd\ufffd\ufffdpsubscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\ufffd{ P}_{p}bold_P start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u00e2\u02c6\u02c6\u00cf\u20ac\u00e2\ufffd\u00a2(D)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u2039\u011f\ufffd\ufffd\u00b7p \u00e2\u02c6\u02c6 italic_\u00cf\u20ac ( italic_D ). Moreover, in view of Lemma 2.5, G\u011f\ufffd\ufffd\u00baGitalic_G and G/Ui1\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2\u00e2\u2039\u00af\u00e2\ufffd\u00a2Uir\u00e2\u20ac\u00b2\u011f\ufffd\ufffd\u00basuperscriptsubscript\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00b2\u00e2\u2039\u00afsuperscriptsubscript\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u0178\u00e2\u20ac\u00b2G/U_{i_{1}}^{ U_{i_{r}}^{ / italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u2039\u00af italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT satisfy \u011f\ufffd\ufffd\ufffd\u00cf\u0192\u00e2\ufffd\u00a2Psubscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u0192{ Q}_{ P}bold_Q start_POSTSUBSCRIPT italic_\u00cf\u0192 italic_P end_POSTSUBSCRIPT and, in particular, satisfy \u011f\ufffd\ufffd\ufffd\u00cf\u0192\u00e2\ufffd\u00a2(p,q)subscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd{ Q}_{ start_POSTSUBSCRIPT italic_\u00cf\u0192 ( italic_p , italic_q ) end_POSTSUBSCRIPT for all pairs {p,q}\u00e2\u02c6\u00a9\u00cf\u20ac\u00e2\ufffd\u00a2(D)\u00e2\u2030 \u00e2\u02c6\u2026\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u2039\u011f\ufffd\ufffd\u00b7 italic_p , italic_q } \u00e2\u02c6\u00a9 italic_\u00cf\u20ac ( italic_D ) \u00e2\u2030 \u00e2\u02c6\u2026. Hence Conditions (ii) and (iii) hold for G\u011f\ufffd\ufffd\u00baGitalic_G. Therefore the necessity of the condition of the theorem holds. Now, assume, arguing by contradiction, that G\u011f\ufffd\ufffd\u00baGitalic_G is a non-Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q Titalic_Q italic_\u00cf\u0192 italic_T-group of minimal order satisfying Conditions (i), (ii), and (iii). Then, in view of Lemma 2.13(4) and Theorem D, G\u011f\ufffd\ufffd\u00baGitalic_G is a P\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2021PTitalic_P italic_T-group, so D\u00e2\u2030 1\u011f\ufffd\ufffd\u00b71D 1italic_D \u00e2\u2030 1 and G\u011f\ufffd\ufffd\u00baGitalic_G has a \u00cf\u0192\u011f\ufffd\u0153\ufffd U\u011f\ufffd\u2018\u02c6Uitalic_U such that U\u011f\ufffd\u2018\u02c6Uitalic_U is not \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G but every \u00cf\u0192\u011f\ufffd\u0153\ufffd subgroup U0subscript\u011f\ufffd\u2018\u02c60U_{0}italic_U start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT of G\u011f\ufffd\ufffd\u00baGitalic_G with U0<Usubscript\u011f\ufffd\u2018\u02c60\u011f\ufffd\u2018\u02c6U_{0}<Uitalic_U start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT < italic_U is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G. Let Z=Z\u00e2\ufffd\u00a2(D).\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7Z=Z(D).italic_Z = italic_Z ( italic_D ) . (1) If N\u011f\ufffd\u2018\ufffdNitalic_N is either a non-identity normal nilpotent subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G or N=Ui\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2N=U_{i}^{ = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT for some i\u011f\ufffd\u2018\u2013iitalic_i, then G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N is a Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q Titalic_Q italic_\u00cf\u0192 italic_T-group. First assume that k=1\u011f\ufffd\u2018\u02dc1k=1italic_k = 1 and N=U1\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00b2N=U_{1}^{ = italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT. Then D\u00e2\u20ac\u00b2=D=U1=U1\u00e2\u20ac\u00b2=Nsuperscript\u011f\ufffd\ufffd\u00b7\u00e2\u20ac\u00b2\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u2018\u02c61superscriptsubscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffdD^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT = italic_D = italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT = italic_N. Therefore G/N=G/D\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7G/N=G/Ditalic_G / italic_N = italic_G / italic_D is a Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q Titalic_Q italic_\u00cf\u0192 italic_T-group by Condition (i). Now assume that k>1\u011f\ufffd\u2018\u02dc1k>1italic_k > 1 and N=Ni\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2N=N_{i}^{ = italic_N start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT. We can assume without loss of generality that i=1\u011f\ufffd\u2018\u20131i=1italic_i = 1. Then (G/N)/(D/N)\u00e2\u2030\u0192G/Dsimilar-to-or-equals\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7(G/N)/(D/N) G/D( italic_G / italic_N ) / ( italic_D / italic_N ) \u00e2\u2030\u0192 italic_G / italic_D is a aoluble Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q Titalic_Q italic_\u00cf\u0192 italic_T-group and (D/N)\u00e2\u20ac\u00b2=D\u00e2\u20ac\u00b2/N=D/Nsuperscript\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u00e2\u20ac\u00b2superscript\u011f\ufffd\ufffd\u00b7\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd(D/N)^{ italic_D / italic_N ) start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT = italic_D start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT / italic_N = italic_D / italic_N. From Lemma 2.13(2) it follows that (D/N,Z\u00e2\ufffd\u00a2(D/N);U2\u00e2\ufffd\u00a2N/N,\u00e2\u20ac\u00a6,Uk\u00e2\ufffd\u00a2N/N)\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u02c62\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd(D/N,Z(D/N);U_{2}N/N, italic_D / italic_N , italic_Z ( italic_D / italic_N ) ; italic_U start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_N / italic_N , \u00e2\u20ac\u00a6 , italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT italic_N / italic_N ) is a Robinson complex of G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N and U1/N=Z\u00e2\ufffd\u00a2N/N=Z\u00e2\ufffd\u00a2(D/N)subscript\u011f\ufffd\u2018\u02c61\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffdU_{1}/N=ZN/N=Z(D/N)italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT / italic_N = italic_Z italic_N / italic_N = italic_Z ( italic_D / italic_N ), where Z\u00e2\ufffd\u00a2N/N\u00e2\u2030\u0192Z/(Z\u00e2\u02c6\u00a9N)similar-to-or-equals\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdZN/N Z/(Z N)italic_Z italic_N / italic_N \u00e2\u2030\u0192 italic_Z / ( italic_Z \u00e2\u02c6\u00a9 italic_N ). Moreover, by Condition (iii), if {i1,\u00e2\u20ac\u00a6,ir}\u00e2\u0160\u2020{2,\u00e2\u20ac\u00a6,k}subscript\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u01782\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u02dc italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT } \u00e2\u0160\u2020 { 2 , \u00e2\u20ac\u00a6 , italic_k }, where 2\u00e2\u2030\u00a4r<k2\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u02dc2 r<k2 \u00e2\u2030\u00a4 italic_r < italic_k, then the quotients G/N=G/U1\u00e2\u20ac\u00b2\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00basuperscriptsubscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00b2G/N=G/U_{1}^{ / italic_N = italic_G / italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT and, in view o lemma 2.12(2), satisfy \u011f\ufffd\ufffd\ufffdpsubscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\ufffd{ N}_{p}bold_N start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u00e2\u02c6\u02c6{2,3}\u00e2\u02c6\u00a9\u00cf\u20ac\u00e2\ufffd\u00a2(Z\u00e2\ufffd\u00a2N/N)\u011f\ufffd\u2018\ufffd23\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdp \u00e2\u02c6\u02c6 { 2 , 3 } \u00e2\u02c6\u00a9 italic_\u00cf\u20ac ( italic_Z italic_N / italic_N ), \u011f\ufffd\ufffd\ufffdpsubscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\ufffd{ P}_{p}bold_P start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u00e2\u02c6\u02c6\u00cf\u20ac(D/N))\u00e2\u0160\u2020\u00cf\u20ac(D)p \u00e2\u02c6\u02c6 italic_\u00cf\u20ac ( italic_D / italic_N ) ) \u00e2\u0160\u2020 italic_\u00cf\u20ac ( italic_D ), and \u011f\ufffd\ufffd\ufffd\u00cf\u0192\u00e2\ufffd\u00a2(p,q)subscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd{ Q}_{ start_POSTSUBSCRIPT italic_\u00cf\u0192 ( italic_p , italic_q ) end_POSTSUBSCRIPT for all pairs {p,q}\u00e2\u02c6\u00a9\u00cf\u20ac\u00e2\ufffd\u00a2(D/N)\u00e2\u2030 \u00e2\u02c6\u2026\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u2039\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd italic_p , italic_q } \u00e2\u02c6\u00a9 italic_\u00cf\u20ac ( italic_D / italic_N ) \u00e2\u2030 \u00e2\u02c6\u2026. Therefore the hypothesis holds for G/N=G/U1\u00e2\u20ac\u00b2\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00basuperscriptsubscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00b2G/N=G/U_{1}^{ / italic_N = italic_G / italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT, so G/Ui\u00e2\u20ac\u00b2\u011f\ufffd\ufffd\u00basuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2G/U_{i}^{ / italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT is a Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q Titalic_Q italic_\u00cf\u0192 italic_T-group for all i\u011f\ufffd\u2018\u2013iitalic_i by the choice of G\u011f\ufffd\ufffd\u00baGitalic_G. Similary, it can be proved that if N\u011f\ufffd\u2018\ufffdNitalic_N is a non-identity nilpotent normal subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G, then the hypothesis holds for G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N and so G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N is a Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q Titalic_Q italic_\u00cf\u0192 italic_T-group. (2) U\u011f\ufffd\u2018\u02c6Uitalic_U is supersoluble. It is clear that D=G\u011f\ufffd\u201d\u2013=G\u011f\ufffd\u201d\u02dc\u011f\ufffd\ufffd\u00b7superscript\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u201d\u2013superscript\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u201d\u02dcD=G^{ = italic_G start_POSTSUPERSCRIPT fraktur_S end_POSTSUPERSCRIPT = italic_G start_POSTSUPERSCRIPT fraktur_U end_POSTSUPERSCRIPT and U\u00e2\ufffd\u00a2Ui\u00e2\u20ac\u00b2/Ui\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u02c6superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2UU_{i}^{ italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT / italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G/Ui\u00e2\u20ac\u00b2\u011f\ufffd\ufffd\u00basuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2G/U_{i}^{ / italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT by Lemma 2.3(2). Therefore U\u00e2\ufffd\u00a2Ui\u00e2\u20ac\u00b2/Ui\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u02c6superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2UU_{i}^{ italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT / italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G/Ui\u00e2\u20ac\u00b2\u011f\ufffd\ufffd\u00basuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2G/U_{i}^{ / italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT by Claim (1) for all i\u011f\ufffd\u2018\u2013iitalic_i. Hence U\u011f\ufffd\u2018\u02c6Uitalic_U is supersoluble by Lemma 2.6(1). (3) Suppose that N\u011f\ufffd\u2018\ufffdNitalic_N is either a non-identity normal nilpotent subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G or N=Ui\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2N=U_{i}^{ = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT for some i\u011f\ufffd\u2018\u2013iitalic_i. If X\u011f\ufffd\u2018\u2039Xitalic_X is a subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G such that X\u00e2\ufffd\u00a2N/N\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdXN/Nitalic_X italic_N / italic_N is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N, then X\u00e2\ufffd\u00a2N/N\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdXN/Nitalic_X italic_N / italic_N is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N and X\u00e2\ufffd\u00a2N\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\ufffdXNitalic_X italic_N is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G. In particular, UG=1subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba1U_{G}=1italic_U start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = 1. In view of Claim (1), G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N is a Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q Titalic_Q italic_\u00cf\u0192 italic_T-group, so X\u00e2\ufffd\u00a2N/N\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdXN/Nitalic_X italic_N / italic_N is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N and hence X\u00e2\ufffd\u00a2N\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\ufffdXNitalic_X italic_N is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G by Lemma 2.1(3). Therefore, since U\u011f\ufffd\u2018\u02c6Uitalic_U is supersoluble by Claim (2), the choice of U\u011f\ufffd\u2018\u02c6Uitalic_U implies that UG=1subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba1U_{G}=1italic_U start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = 1. (4) U\u011f\ufffd\u2018\u02c6Uitalic_U is a cyclic p\u011f\ufffd\u2018\ufffdpitalic_p-group for some prime p\u011f\ufffd\u2018\ufffdpitalic_p and V:=U\u00e2\u02c6\u00a9Z\u00e2\u02c6\ufffd\u00e2\ufffd\u00a2(G)assign\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00baV:=U Z_{ := italic_U \u00e2\u02c6\u00a9 italic_Z start_POSTSUBSCRIPT \u00e2\u02c6\ufffd end_POSTSUBSCRIPT ( italic_G ) is the maximal subgroup of U\u011f\ufffd\u2018\u02c6Uitalic_U. Let N\u011f\ufffd\u2018\ufffdNitalic_N be a nilpotent non-identity normal subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G. Then U\u00e2\ufffd\u00a2N/N\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdUN/Nitalic_U italic_N / italic_N is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N by Lemma 2.3(2), so U\u00e2\ufffd\u00a2N/N\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdUN/Nitalic_U italic_N / italic_N is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N by Claim (1). Hence U\u011f\ufffd\u2018\u02c6Uitalic_U is a cyclic p\u011f\ufffd\u2018\ufffdpitalic_p-group for some prime p\u011f\ufffd\u2018\ufffdpitalic_p by Claim (2) and Lemma 2.6(2). Now, let V\u011f\ufffd\u2018\u2030Vitalic_V be the maximal subgroup of U\u011f\ufffd\u2018\u02c6Uitalic_U. Then V=U\u011f\ufffd\u201d\u201e\u00e2\u02c6\u2014\u011f\ufffd\u2018\u2030superscript\u011f\ufffd\u2018\u02c6superscript\u011f\ufffd\u201d\u201eV=U^{{ = italic_U start_POSTSUPERSCRIPT fraktur_A start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT is subnormal in G\u011f\ufffd\ufffd\u00baGitalic_G by Lemma 2.3(4) since U\u011f\ufffd\u2018\u02c6Uitalic_U is a cyclic p\u011f\ufffd\u2018\ufffdpitalic_p-group, hence V\u011f\ufffd\u2018\u2030Vitalic_V is quasinormal in G\u011f\ufffd\ufffd\u00baGitalic_G since G\u011f\ufffd\ufffd\u00baGitalic_G is a P\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2021PTitalic_P italic_T-group. Therefore V\u00e2\u2030\u00a4Z\u00e2\u02c6\ufffd\u00e2\ufffd\u00a2(G)\u011f\ufffd\u2018\u2030subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00baV Z_{ \u00e2\u2030\u00a4 italic_Z start_POSTSUBSCRIPT \u00e2\u02c6\ufffd end_POSTSUBSCRIPT ( italic_G ) by [14, Corollary 1.5.6] since VG=1=UGsubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\ufffd\u00ba1subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00baV_{G}=1=U_{G}italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = 1 = italic_U start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT by Claim (3). (5) G\u011f\ufffd\ufffd\u00baGitalic_G has a normal subgroup Cqsubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdC_{q}italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT of order q\u011f\ufffd\u2018\ufffdqitalic_q for some prime q\u011f\ufffd\u2018\ufffdqitalic_q. If Z\u00e2\u2030 1\u011f\ufffd\u2018\ufffd1Z 1italic_Z \u00e2\u2030 1, it is clear. Now assume that Z=1\u011f\ufffd\u2018\ufffd1Z=1italic_Z = 1. Then D=U1\u00c3\u2014\u00e2\u2039\u00af\u00c3\u2014Uk\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u2018\u02c61\u00e2\u2039\u00afsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02dcD=U_{1} U_{k}italic_D = italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00c3\u2014 \u00e2\u2039\u00af \u00c3\u2014 italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT, where Uisubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013U_{i}italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is a simple non-abelian minimal normal subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G for all i\u011f\ufffd\u2018\u2013iitalic_i. Let E=Ui\u00e2\ufffd\u00a2U\u011f\ufffd\ufffd\u00b8subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02c6E=U_{i}Uitalic_E = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_U, where Ui\u00e2\u2030\u00b0Unot-less-than-nor-greater-thansubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02c6U_{i} Uitalic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u2030\u00b0 italic_U. We show that Ui\u00e2\u2030\u00a4NG\u00e2\ufffd\u00a2(U)subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u02c6U_{i} N_{G}(U)italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_N start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_U ). Since U\u011f\ufffd\u2018\u02c6Uitalic_U is a \u00cf\u0192\u011f\ufffd\u0153\ufffd subgroup of E\u011f\ufffd\ufffd\u00b8Eitalic_E by Lemma 2.3(1), there is a subgroup chain U=E0<E1<\u00e2\u2039\u00af<Et\u00e2\u02c6\u20191<Et=E\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\ufffd\u00b80subscript\u011f\ufffd\ufffd\u00b81\u00e2\u2039\u00afsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a11subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a1\u011f\ufffd\ufffd\u00b8U=E_{0}<E_{1}< = italic_E start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT < italic_E start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < \u00e2\u2039\u00af < italic_E start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT < italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_E such that Ei\u00e2\u02c6\u20191subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u20131E_{i-1}italic_E start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT is a maximal \u00cf\u0192\u011f\ufffd\u0153\ufffd subgroup of Eisubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u2013E_{i}italic_E start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT for all i=1,\u00e2\u20ac\u00a6,t\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u00a1i=1, = 1 , \u00e2\u20ac\u00a6 , italic_t and for M=Et\u00e2\u02c6\u20191\u011f\ufffd\u2018\u20acsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a11M=E_{t-1}italic_M = italic_E start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT we have M=U\u00e2\ufffd\u00a2(M\u00e2\u02c6\u00a9Ui)\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u20acsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013M=U(M U_{i})italic_M = italic_U ( italic_M \u00e2\u02c6\u00a9 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ). Moreover, M\u00e2\u02c6\u00a9Ui\u011f\ufffd\u2018\u20acsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013M U_{i}italic_M \u00e2\u02c6\u00a9 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is \u00cf\u0192\u011f\ufffd\u0153\ufffd in E\u011f\ufffd\ufffd\u00b8Eitalic_E and M\u00e2\u02c6\u00a9Ui<Ui\u011f\ufffd\u2018\u20acsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013M U_{i}<U_{i}italic_M \u00e2\u02c6\u00a9 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT < italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT since M<E\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b8M<Eitalic_M < italic_E, so M\u00e2\u02c6\u00a9Ui=1\u011f\ufffd\u2018\u20acsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u20131M U_{i}=1italic_M \u00e2\u02c6\u00a9 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 1. Therefore U=M\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u20acU=Mitalic_U = italic_M is a maximal \u00cf\u0192\u011f\ufffd\u0153\ufffd subgroup of E\u011f\ufffd\ufffd\u00b8Eitalic_E. Assume that U\u011f\ufffd\u2018\u02c6Uitalic_U is not normal in E\u011f\ufffd\ufffd\u00b8Eitalic_E. Then, by Lemma 2.2, E/UE\u011f\ufffd\ufffd\u00b8subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b8E/U_{E}italic_E / italic_U start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT is a group of order q\u00e2\ufffd\u00a2r\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178qritalic_q italic_r for primes q\u011f\ufffd\u2018\ufffdqitalic_q and r\u011f\ufffd\u2018\u0178ritalic_r. But this is imposible since Ui\u00e2\u2030\u0192Ui\u00e2\ufffd\u00a2UE/UE\u00e2\u2030\u00a4E/UEsimilar-to-or-equalssubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b8subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b8\u011f\ufffd\ufffd\u00b8subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b8U_{i} U_{i}U_{E}/U_{E} E/U_{E}italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u2030\u0192 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_U start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT / italic_U start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_E / italic_U start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT. Therefore Ui\u00e2\u2030\u00a4NE\u00e2\ufffd\u00a2(U)subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u02c6U_{i} N_{E}(U)italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_N start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ( italic_U ) for all i\u011f\ufffd\u2018\u2013iitalic_i, so D\u00e2\u2030\u00a4NG\u00e2\ufffd\u00a2(U)\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u02c6D N_{G}(U)italic_D \u00e2\u2030\u00a4 italic_N start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_U ) and hence U\u00e2\u02c6\u00a9D\u00e2\u2030\u00a4Op\u00e2\ufffd\u00a2(D)=1\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u2018\u201a\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b71U D O_{p}(D)=1italic_U \u00e2\u02c6\u00a9 italic_D \u00e2\u2030\u00a4 italic_O start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_D ) = 1 by Claim (4). It follows than D\u00e2\ufffd\u00a2U=D\u00c3\u2014U\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u02c6DU=D Uitalic_D italic_U = italic_D \u00c3\u2014 italic_U, so 1<U\u00e2\u2030\u00a4CG\u00e2\ufffd\u00a2(D)1\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b71<U C_{G}(D)1 < italic_U \u00e2\u2030\u00a4 italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_D ). But CG\u00e2\ufffd\u00a2(D)\u00e2\u02c6\u00a9D=1subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b71C_{G}(D) D=1italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_D ) \u00e2\u02c6\u00a9 italic_D = 1 since Z=Z\u00e2\ufffd\u00a2(D)=1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b71Z=Z(D)=1italic_Z = italic_Z ( italic_D ) = 1. Therefore CG\u00e2\ufffd\u00a2(D)\u00e2\u2030\u0192CG\u00e2\ufffd\u00a2(D)\u00e2\ufffd\u00a2D/Dsimilar-to-or-equalssubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b7C_{G}(D) C_{G}(D)D/Ditalic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_D ) \u00e2\u2030\u0192 italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_D ) italic_D / italic_D is soluble. Hence for some prime q\u011f\ufffd\u2018\ufffdqitalic_q dividing |CG\u00e2\ufffd\u00a2(D)|subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7|C_{G}(D)|| italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_D ) | we have Oq\u00e2\ufffd\u00a2(CG\u00e2\ufffd\u00a2(D))\u00e2\u2030 1subscript\u011f\ufffd\u2018\u201a\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b71O_{q}(C_{G}(D)) 1italic_O start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ( italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_D ) ) \u00e2\u2030 1. But Oq\u00e2\ufffd\u00a2(CG\u00e2\ufffd\u00a2(D))subscript\u011f\ufffd\u2018\u201a\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7O_{q}(C_{G}(D))italic_O start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ( italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_D ) ) is characteristic in CG\u00e2\ufffd\u00a2(D)subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7C_{G}(D)italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_D ), so Oq\u00e2\ufffd\u00a2(CG\u00e2\ufffd\u00a2(D))subscript\u011f\ufffd\u2018\u201a\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7O_{q}(C_{G}(D))italic_O start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ( italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_D ) ) is normal in G\u011f\ufffd\ufffd\u00baGitalic_G and hence we have (5). (6) UGsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00baU^{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT is soluble. The subgroup Cq\u00e2\ufffd\u00a2U/Cqsubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdC_{q}U/C_{q}italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT italic_U / italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G/Cq\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdG/C_{q}italic_G / italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT by Lemma 2.3(2), so this subgroup is \u00cf\u0192\u011f\ufffd\u0153\ufffd and hence modular in G/Cq\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdG/C_{q}italic_G / italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT by Claim (3). First assume that Cq\u00e2\ufffd\u00a2U/Cqsubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdC_{q}U/C_{q}italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT italic_U / italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT is not subnormal in G/Cq\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdG/C_{q}italic_G / italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT. Then, by Lemma 2.14, Cq\u00e2\ufffd\u00a2UG/(Cq\u00e2\ufffd\u00a2U)Gsubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00basubscriptsubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00baC_{q}U^{G}/(C_{q}U)_{G}italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / ( italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT italic_U ) start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is a non-abelian P\u011f\ufffd\u2018\u0192Pitalic_P-group, so Cq\u00e2\ufffd\u00a2UG/(Cq\u00e2\ufffd\u00a2U)Gsubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00basubscriptsubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00baC_{q}U^{G}/(C_{q}U)_{G}italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / ( italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT italic_U ) start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is soluble and hence is soluble since Cq\u00e2\ufffd\u00a2Usubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02c6C_{q}Uitalic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT italic_U is soluble. Hence UGsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00baU^{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT is soluble. Now assume that Cq\u00e2\ufffd\u00a2U/Cqsubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdC_{q}U/C_{q}italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT italic_U / italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT is subnormal in G/Cq\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdG/C_{q}italic_G / italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT, so by Claim (4). Hence UGsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00baU^{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT is soluble. (7) U\u011f\ufffd\u2018\u02c6Uitalic_U is not subnormal in G\u011f\ufffd\ufffd\u00baGitalic_G. Assume that U\u011f\ufffd\u2018\u02c6Uitalic_U is subnormal in G\u011f\ufffd\ufffd\u00baGitalic_G. Then U\u011f\ufffd\u2018\u02c6Uitalic_U is quasinormal and so \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G since G\u011f\ufffd\ufffd\u00baGitalic_G is a P\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2021PTitalic_P italic_T-group, a contradiction. Hence we have (7). (8) |U|=p\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\ufffd|U|=p| italic_U | = italic_p. Assume that |U|>p\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\ufffd|U|>p| italic_U | > italic_p. Then 1<V\u00e2\u2030\u00a4R:=Op\u00e2\ufffd\u00a2(Z\u00e2\u02c6\ufffd\u00e2\ufffd\u00a2(G))1\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2026assignsubscript\u011f\ufffd\u2018\u201a\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00ba1<V R:=O_{p}(Z_{ < italic_V \u00e2\u2030\u00a4 italic_R := italic_O start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_Z start_POSTSUBSCRIPT \u00e2\u02c6\ufffd end_POSTSUBSCRIPT ( italic_G ) ) by Claim (4) and U\u00e2\u2030\u00b0Rnot-less-than-nor-greater-than\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2026U Ritalic_U \u00e2\u2030\u00b0 italic_R by Claim (7). Denote E=R\u00e2\ufffd\u00a2U\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u02c6E=RUitalic_E = italic_R italic_U. Then EG=UG\u00e2\ufffd\u00a2Rsuperscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\ufffd\u00basuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2026E^{G}=U^{G}Ritalic_E start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT = italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT italic_R and, in view of Claims (4) and (7), E\u011f\ufffd\ufffd\u00b8Eitalic_E is not subnormal in G\u011f\ufffd\ufffd\u00baGitalic_G. Moreover, E\u011f\ufffd\ufffd\u00b8Eitalic_E is \u00cf\u0192\u011f\ufffd\u0153\ufffd and so modular in G\u011f\ufffd\ufffd\u00baGitalic_G by Claim (3). The group U\u00e2\ufffd\u00a2R/R\u00e2\u2030\u0192U/(U\u00e2\u02c6\u00a9R)=U/Vsimilar-to-or-equals\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2030UR/R U/(U R)=U/Vitalic_U italic_R / italic_R \u00e2\u2030\u0192 italic_U / ( italic_U \u00e2\u02c6\u00a9 italic_R ) = italic_U / italic_V has order p\u011f\ufffd\u2018\ufffdpitalic_p, so (R\u00e2\ufffd\u00a2U)G=Rsubscript\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2026(RU)_{G}=R( italic_R italic_U ) start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = italic_R. In view of Lemma 2.14, where R\u00e2\ufffd\u00a2UG/R\u00e2\u2030\u0192UG/(UG\u00e2\u02c6\u00a9R)similar-to-or-equals\u011f\ufffd\u2018\u2026superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2026superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00basuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2026RU^{G}/R U^{G}/(U^{G} R)italic_R italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_R \u00e2\u2030\u0192 italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_R ) is a non-abelian P\u011f\ufffd\u2018\u0192Pitalic_P-group of order prime to K/R\u011f\ufffd\ufffd\u00be\u011f\ufffd\u2018\u2026K/Ritalic_K / italic_R. The group UG/(UG\u00e2\u02c6\u00a9R)superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00basuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2026U^{G}/(U^{G} R)italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_R ) is q\u011f\ufffd\u2018\ufffdqitalic_q-closed for some prime q\u011f\ufffd\u2018\ufffdqitalic_q dividing its order and so UGsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00baU^{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT is q\u011f\ufffd\u2018\ufffdqitalic_q-closed by Lemma 2.9 since UG\u00e2\u02c6\u00a9R\u00e2\u2030\u00a4Z\u00e2\u02c6\ufffd\u00e2\ufffd\u00a2(UG)superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2026subscript\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00baU^{G} R Z_{ start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_R \u00e2\u2030\u00a4 italic_Z start_POSTSUBSCRIPT \u00e2\u02c6\ufffd end_POSTSUBSCRIPT ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT ). If Q\u011f\ufffd\u2018\u201eQitalic_Q is the normal Sylow q\u011f\ufffd\u2018\ufffdqitalic_q-subgroup of UGsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00baU^{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT, then U\u00e2\u2030\u00b0Qnot-less-than-nor-greater-than\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u201eU Qitalic_U \u00e2\u2030\u00b0 italic_Q by Claim (7), so q\u00e2\u2030 p\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdq pitalic_q \u00e2\u2030 italic_p. Therefore UG/(UG\u00e2\u02c6\u00a9R)superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00basuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2026U^{G}/(U^{G} R)italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_R ) is a non-abelian P\u011f\ufffd\u2018\u0192Pitalic_P-group of type (q,p)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd(q,p)( italic_q , italic_p ), so UG=Q\u00e2\u2039\u0160Psuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00baright-normal-factor-semidirect-product\u011f\ufffd\u2018\u201e\u011f\ufffd\u2018\u0192U^{G}=Q Pitalic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT = italic_Q \u00e2\u2039\u0160 italic_P, where P\u011f\ufffd\u2018\u0192Pitalic_P is a non-normal Sylow p\u011f\ufffd\u2018\ufffdpitalic_p-subgroup of UGsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00baU^{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT, containing U\u011f\ufffd\u2018\u02c6Uitalic_U, and Q\u011f\ufffd\u2018\u201eQitalic_Q is subnormal in G\u011f\ufffd\ufffd\u00baGitalic_G. In particular, UGsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00baU^{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT and R\u00e2\ufffd\u00a2UG/R\u011f\ufffd\u2018\u2026superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2026RU^{G}/Ritalic_R italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_R are \u00cf\u20ac\u011f\ufffd\u0153\u2039 where \u00cf\u20ac={p,q}\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd = { italic_p , italic_q }, so G\u011f\ufffd\ufffd\u00baGitalic_G is \u00cf\u20ac\u011f\ufffd\u0153\u2039 and hence D\u011f\ufffd\ufffd\u00b7Ditalic_D and D/Z\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffdD/Zitalic_D / italic_Z are \u00cf\u20ac\u011f\ufffd\u0153\u2039 groups. Assume that UG\u00e2\u02c6\u00a9D\u00e2\u2030 1superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b71U^{G} D 1italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_D \u00e2\u2030 1. Since UG\u00e2\u02c6\u00a9D\u00e2\u2030\u00a4Z\u00e2\u2030\u00a4\u00ce\u00a6\u00e2\ufffd\u00a2(D)superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u00ce\u00a6\u011f\ufffd\ufffd\u00b7U^{G} D Z start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_D \u00e2\u2030\u00a4 italic_Z \u00e2\u2030\u00a4 roman_\u00ce\u00a6 ( italic_D ) by Claim (6), for some i\u011f\ufffd\u2018\u2013iitalic_i and for some r\u00e2\u02c6\u02c6{p,q}\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdr \u00e2\u02c6\u02c6 { italic_p , italic_q } the mumber r\u011f\ufffd\u2018\u0178ritalic_r divides |Ui/Z|subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd|U_{i}/Z|| italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / italic_Z |. It follows that Ui/Zsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffdU_{i}/Zitalic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / italic_Z is an abelian group, a contradiction. Therefore UG\u00e2\u02c6\u00a9D=1superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b71U^{G} D=1italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_D = 1 and so where G/D\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7G/Ditalic_G / italic_D is a soluble Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q Titalic_Q italic_\u00cf\u0192 italic_T-group by Condition (i). Therefore, in view of Theorem C, G/D=T\u00e2\u2039\u0160L\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7right-normal-factor-semidirect-product\u011f\ufffd\u2018\u2021\u011f\ufffd\ufffd\u00bfG/D=T Litalic_G / italic_D = italic_T \u00e2\u2039\u0160 italic_L, where T=(G/D)\u011f\ufffd\u201d\u2018\u00cf\u0192\u011f\ufffd\u2018\u2021superscript\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u201d\u2018\u011f\ufffd\u0153\ufffdT=(G/D)^{ = ( italic_G / italic_D ) start_POSTSUPERSCRIPT fraktur_N start_POSTSUBSCRIPT italic_\u00cf\u0192 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT and the following hold: T\u011f\ufffd\u2018\u2021Titalic_T is an abelian Hall subgroup of G/D\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7G/Ditalic_G / italic_D and all subgroups of T\u011f\ufffd\u2018\u2021Titalic_T are normal G/D\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7G/Ditalic_G / italic_D and the lattice \u00e2\u201e\u2019\u00e2\ufffd\u00a2(L)\u00e2\u201e\u2019\u011f\ufffd\ufffd\u00bf{ L}(L)caligraphic_L ( italic_L ), of all subgroups of L\u011f\ufffd\ufffd\u00bfLitalic_L, is modular. Then P\u00e2\ufffd\u00a2D/D\u00e2\u2030\u00b0Tnot-less-than-nor-greater-than\u011f\ufffd\u2018\u0192\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u2021PD/D Titalic_P italic_D / italic_D \u00e2\u2030\u00b0 italic_T, so U\u00e2\ufffd\u00a2D/D\u00e2\u2030\u00a4P\u00e2\ufffd\u00a2D/D\u00e2\u2030\u00a4Lx\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u0192\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b7superscript\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\u00a5UD/D PD/D L^{x}italic_U italic_D / italic_D \u00e2\u2030\u00a4 italic_P italic_D / italic_D \u00e2\u2030\u00a4 italic_L start_POSTSUPERSCRIPT italic_x end_POSTSUPERSCRIPT for some x\u00e2\u02c6\u02c6G/D\u011f\ufffd\u2018\u00a5\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7x G/Ditalic_x \u00e2\u02c6\u02c6 italic_G / italic_D. First assume that Q\u00e2\ufffd\u00a2D/D\u00e2\u2030\u00a4T\u011f\ufffd\u2018\u201e\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u2021QD/D Titalic_Q italic_D / italic_D \u00e2\u2030\u00a4 italic_T. Since U\u00e2\ufffd\u00a2D/D\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b7UD/Ditalic_U italic_D / italic_D is a \u00cf\u0192\u011f\ufffd\u0153\ufffd p\u011f\ufffd\u2018\ufffdpitalic_p-subgroup of G/D\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7G/Ditalic_G / italic_D by Lemmma 2.3(2), T\u00e2\u2030\u00a4CG/D\u00e2\ufffd\u00a2(U\u00e2\ufffd\u00a2D/D)\u011f\ufffd\u2018\u2021subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b7T C_{G/D}(UD/D)italic_T \u00e2\u2030\u00a4 italic_C start_POSTSUBSCRIPT italic_G / italic_D end_POSTSUBSCRIPT ( italic_U italic_D / italic_D ) by Lemma 2.7, so a contradiction. Hence Q\u00e2\ufffd\u00a2D/D\u00e2\u2030\u00b0Tnot-less-than-nor-greater-than\u011f\ufffd\u2018\u201e\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u2021QD/D Titalic_Q italic_D / italic_D \u00e2\u2030\u00b0 italic_T and so (Q\u00e2\ufffd\u00a2D/D)\u00e2\u2039\u0160(P\u00e2\ufffd\u00a2D/D)\u00e2\u2030\u00a4Lxright-normal-factor-semidirect-product\u011f\ufffd\u2018\u201e\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u0192\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b7superscript\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\u00a5(QD/D) L^{x}( italic_Q italic_D / italic_D ) \u00e2\u2039\u0160 ( italic_P italic_D / italic_D ) \u00e2\u2030\u00a4 italic_L start_POSTSUPERSCRIPT italic_x end_POSTSUPERSCRIPT since T\u011f\ufffd\u2018\u2021Titalic_T and Lxsuperscript\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\u00a5L^{x}italic_L start_POSTSUPERSCRIPT italic_x end_POSTSUPERSCRIPT are Hall subgroups of G/D\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7G/Ditalic_G / italic_D and Q\u00e2\ufffd\u00a2D/D\u011f\ufffd\u2018\u201e\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b7QD/Ditalic_Q italic_D / italic_D is a subnormal q\u011f\ufffd\u2018\ufffdqitalic_q-subgroup of G/D\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7G/Ditalic_G / italic_D. In view of Theorem 2.4.4 in [1], Lxsuperscript\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\u00a5L^{x}italic_L start_POSTSUPERSCRIPT italic_x end_POSTSUPERSCRIPT is a direct product of P\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018\u0192P^{*}italic_P start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT-groups Pisubscript\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2013P_{i}italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and primary groups Qjsubscript\u011f\ufffd\u2018\u201e\u011f\ufffd\u2018\u2014Q_{j}italic_Q start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT (that is, Qjsubscript\u011f\ufffd\u2018\u201e\u011f\ufffd\u2018\u2014Q_{j}italic_Q start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT is of prime power order) with relatively prime orders. Then for any factor Qjsubscript\u011f\ufffd\u2018\u201e\u011f\ufffd\u2018\u2014Q_{j}italic_Q start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT of Lxsuperscript\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\u00a5L^{x}italic_L start_POSTSUPERSCRIPT italic_x end_POSTSUPERSCRIPT we have Qj\u00e2\u2030\u00a4Z\u00e2\u02c6\ufffd\u00e2\ufffd\u00a2(Lx)subscript\u011f\ufffd\u2018\u201e\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\u00a5Q_{j} Z_{ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_Z start_POSTSUBSCRIPT \u00e2\u02c6\ufffd end_POSTSUBSCRIPT ( italic_L start_POSTSUPERSCRIPT italic_x end_POSTSUPERSCRIPT ), so Q\u00e2\ufffd\u00a2D/D\u00e2\u2030\u00b0Qjnot-less-than-nor-greater-than\u011f\ufffd\u2018\u201e\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u2018\u201e\u011f\ufffd\u2018\u2014QD/D Q_{j}italic_Q italic_D / italic_D \u00e2\u2030\u00b0 italic_Q start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT and P\u00e2\ufffd\u00a2D/D\u00e2\u2030\u00b0Qjnot-less-than-nor-greater-than\u011f\ufffd\u2018\u0192\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u2018\u201e\u011f\ufffd\u2018\u2014PD/D Q_{j}italic_P italic_D / italic_D \u00e2\u2030\u00b0 italic_Q start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT for all j\u011f\ufffd\u2018\u2014jitalic_j since UG\u00e2\u2030\u0192UG\u00e2\ufffd\u00a2D/D\u00e2\u2030\u0192Q\u00e2\ufffd\u00a2D/D\u00e2\u2039\u0160P\u00e2\ufffd\u00a2D/Dsimilar-to-or-equalssuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00basuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b7similar-to-or-equalsright-normal-factor-semidirect-product\u011f\ufffd\u2018\u201e\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u0192\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b7U^{G} U^{G}D/D QD/D PD/Ditalic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u00e2\u2030\u0192 italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT italic_D / italic_D \u00e2\u2030\u0192 italic_Q italic_D / italic_D \u00e2\u2039\u0160 italic_P italic_D / italic_D is not nilpotent. Therefore for some i\u011f\ufffd\u2018\u2013iitalic_i and k\u011f\ufffd\u2018\u02dckitalic_k we have Q\u00e2\ufffd\u00a2D/D\u00e2\u2030\u00a4Pi\u011f\ufffd\u2018\u201e\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2013QD/D P_{i}italic_Q italic_D / italic_D \u00e2\u2030\u00a4 italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and P\u00e2\ufffd\u00a2D/D\u00e2\u2030\u00a4Pk\u011f\ufffd\u2018\u0192\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u02dcPD/D P_{k}italic_P italic_D / italic_D \u00e2\u2030\u00a4 italic_P start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT, where [Pi,Pk]=1subscript\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u02dc1[P_{i},P_{k}]=1[ italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_P start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ] = 1 for i\u00e2\u2030 k\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dci kitalic_i \u00e2\u2030 italic_k, so i=k\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dci=kitalic_i = italic_k. Hence Q\u00e2\ufffd\u00a2D/D\u00e2\u2039\u0160P\u00e2\ufffd\u00a2D/D\u00e2\u2030\u00a4Pi=A\u00e2\u2039\u0160\u00e2\u0178\u00a8t\u00e2\u0178\u00a9right-normal-factor-semidirect-product\u011f\ufffd\u2018\u201e\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u0192\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2013right-normal-factor-semidirect-product\u011f\ufffd\ufffd\u00b4delimited-\u00e2\u0178\u00a8\u00e2\u0178\u00a9\u011f\ufffd\u2018\u00a1QD/D PD/D P_{i}=A t italic_D / italic_D \u00e2\u2039\u0160 italic_P italic_D / italic_D \u00e2\u2030\u00a4 italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_A \u00e2\u2039\u0160 \u00e2\u0178\u00a8 italic_t \u00e2\u0178\u00a9, where A\u011f\ufffd\ufffd\u00b4Aitalic_A is elementary abelian subgroup of Pisubscript\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2013P_{i}italic_P start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, |t|=rn\u011f\ufffd\u2018\u00a1superscript\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u203a|t|=r^{n}| italic_t | = italic_r start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT for some prime r\u011f\ufffd\u2018\u0178ritalic_r and t\u011f\ufffd\u2018\u00a1titalic_t induces a power automorphism of prime order on A\u011f\ufffd\ufffd\u00b4Aitalic_A. Therefore A\u011f\ufffd\ufffd\u00b4Aitalic_A is a q\u011f\ufffd\u2018\ufffdqitalic_q-group and t\u011f\ufffd\u2018\u00a1titalic_t is a p\u011f\ufffd\u2018\ufffdpitalic_p-element of Pksubscript\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u02dcP_{k}italic_P start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT by Lemma 2.16. Hence P\u00e2\u2030\u0192P\u00e2\ufffd\u00a2D/Dsimilar-to-or-equals\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u0192\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b7P PD/Ditalic_P \u00e2\u2030\u0192 italic_P italic_D / italic_D is a cyclic p\u011f\ufffd\u2018\ufffdpitalic_p-group. Since UG/(UG\u00e2\u02c6\u00a9R)superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00basuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2026U^{G}/(U^{G} R)italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_R ) is a non-abelian P\u011f\ufffd\u2018\u0192Pitalic_P-group and U\u00e2\u2030\u00b0UG\u00e2\u02c6\u00a9Rnot-less-than-nor-greater-than\u011f\ufffd\u2018\u02c6superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2026U U^{G} Ritalic_U \u00e2\u2030\u00b0 italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_R, U\u00e2\ufffd\u00a2(UG\u00e2\u02c6\u00a9R)/(UG\u00e2\u02c6\u00a9R)\u011f\ufffd\u2018\u02c6superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2026superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2026U(U^{G} R)/(U^{G} R)italic_U ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_R ) / ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_R ) is a Sylow p\u011f\ufffd\u2018\ufffdpitalic_p-subgroup of UG/(UG\u00e2\u02c6\u00a9R)superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00basuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2026U^{G}/(U^{G} R)italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_R ) and so U\u00e2\ufffd\u00a2(UG\u00e2\u02c6\u00a9R)\u011f\ufffd\u2018\u02c6superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2026U(U^{G} R)italic_U ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_R ) is a cyclic Sylow p\u011f\ufffd\u2018\ufffdpitalic_p-subgroup of UGsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00baU^{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT. It follows that either U\u00e2\ufffd\u00a2(UG\u00e2\u02c6\u00a9R)=U\u011f\ufffd\u2018\u02c6superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u02c6U(U^{G} R)=Uitalic_U ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_R ) = italic_U or U\u00e2\ufffd\u00a2(UG\u00e2\u02c6\u00a9R)=UG\u00e2\u02c6\u00a9R\u011f\ufffd\u2018\u02c6superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2026superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2026U(U^{G} R)=U^{G} Ritalic_U ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_R ) = italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_R. In the former case we have UG\u00e2\u02c6\u00a9R=V\u00e2\u2030\u00a4UGsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u2030subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00baU^{G} R=V U_{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_R = italic_V \u00e2\u2030\u00a4 italic_U start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT, which is impossible by Claim (3), so U\u00e2\ufffd\u00a2(UG\u00e2\u02c6\u00a9R)=UG\u00e2\u02c6\u00a9R\u011f\ufffd\u2018\u02c6superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2026superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u2026U(U^{G} R)=U^{G} Ritalic_U ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_R ) = italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_R and hence U\u011f\ufffd\u2018\u02c6Uitalic_U is subormal in G\u011f\ufffd\ufffd\u00baGitalic_G, contrary to Claim (7). Therefore we have (8). (9) U\u00e2\u2030\u00b0Dnot-less-than-nor-greater-than\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b7U Ditalic_U \u00e2\u2030\u00b0 italic_D. Assume U\u00e2\u2030\u00a4D\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b7U Ditalic_U \u00e2\u2030\u00a4 italic_D. From Claim (7) it follows that U\u00e2\u2030\u00b0Znot-less-than-nor-greater-than\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\ufffdU Zitalic_U \u00e2\u2030\u00b0 italic_Z and then, by Claim (8) and Lemma 2.3(1)(2)(5), for some i\u011f\ufffd\u2018\u2013iitalic_i we have U\u00e2\u2030\u0192U\u00e2\ufffd\u00a2Z/Z=Ui/Zsimilar-to-or-equals\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffdU UZ/Z=U_{i}/Zitalic_U \u00e2\u2030\u0192 italic_U italic_Z / italic_Z = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT / italic_Z, a contradiction. Hence we have\u00c2 (9). (10) Op\u00e2\ufffd\u00a2(D)=1subscript\u011f\ufffd\u2018\u201a\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b71O_{p}(D)=1italic_O start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_D ) = 1. Assume that G\u011f\ufffd\ufffd\u00baGitalic_G has a normal subgroup Zp\u00e2\u2030\u00a4Z=\u00ce\u00a6\u00e2\ufffd\u00a2(D)subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u00ce\u00a6\u011f\ufffd\ufffd\u00b7Z_{p} Z= start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_Z = roman_\u00ce\u00a6 ( italic_D ) of order p\u011f\ufffd\u2018\ufffdpitalic_p. Then Zp\u00e2\ufffd\u00a2Usubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02c6Z_{p}Uitalic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT italic_U is not subnormal in G\u011f\ufffd\ufffd\u00baGitalic_G by Claim (7) and, also, (Zp\u00e2\ufffd\u00a2U)G=Zpsubscriptsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd(Z_{p}U)_{G}=Z_{p}( italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT italic_U ) start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT by Claim (8) and (Zp\u00e2\ufffd\u00a2U)G=Zp\u00e2\ufffd\u00a2UGsuperscriptsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba(Z_{p}U)^{G}=Z_{p}U^{G}( italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT italic_U ) start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT = italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT, so G/Zp\u00e2\u2030\u0192Zp\u00e2\ufffd\u00a2UG/Zp\u00c3\u2014K/Zp,similar-to-or-equals\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00besubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdG/Z_{p} Z_{p}U^{G}/Z_{p} K/Z_{p},italic_G / italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT \u00e2\u2030\u0192 italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT \u00c3\u2014 italic_K / italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT , where Zp\u00e2\ufffd\u00a2UG/Zpsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdZ_{p}U^{G}/Z_{p}italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT is a non-abelian P\u011f\ufffd\u2018\u0192Pitalic_P-group of order pa\u00e2\ufffd\u00a2qbsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdp^{a}q^{b}italic_p start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT italic_q start_POSTSUPERSCRIPT italic_b end_POSTSUPERSCRIPT prime to |K/Zp|\u011f\ufffd\ufffd\u00besubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd|K/Z_{p}|| italic_K / italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT | by Lemma 2.14. Hence G/Zp\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdG/Z_{p}italic_G / italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT, D/Zp\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdD/Z_{p}italic_D / italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT, and D\u011f\ufffd\ufffd\u00b7Ditalic_D are {p,q}\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd italic_p , italic_q }-soluble and p\u011f\ufffd\u2018\ufffdpitalic_p divides |D/Zp|\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd|D/Z_{p}|| italic_D / italic_Z start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT |. Hence Op\u00e2\ufffd\u00a2(D/Z)\u00e2\u2030 1subscript\u011f\ufffd\u2018\u201a\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd1O_{p}(D/Z) 1italic_O start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_D / italic_Z ) \u00e2\u2030 1. This contradiction completes the proof of the claim. (11) Ui\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2U=Ui\u00e2\u20ac\u00b2\u00c3\u2014Usuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u02c6superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u02c6U_{i}^{ Uitalic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT italic_U = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00c3\u2014 italic_U and so Ui\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2Usuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u02c6U_{i}^{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT italic_U is not subnormal in G\u011f\ufffd\ufffd\u00baGitalic_G for all i\u011f\ufffd\u2018\u2013iitalic_i. In view of Claims (8) and (9), it is enough to show that Ui\u00e2\u20ac\u00b2\u00e2\u2030\u00a4NG\u00e2\ufffd\u00a2(U)superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u02c6U_{i}^{ N_{G}(U)italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u2030\u00a4 italic_N start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_U ). By Lemma 2.13(1), Ui\u00e2\u20ac\u00b2\u00e2\u02c6\u00a9Z=\u00ce\u00a6\u00e2\ufffd\u00a2(Ui\u00e2\u20ac\u00b2)=Z\u00e2\ufffd\u00a2(Ui\u00e2\u20ac\u00b2)superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffd\u00ce\u00a6superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2U_{i}^{ Z= start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_Z = roman_\u00ce\u00a6 ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) = italic_Z ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) and Ui\u00e2\u20ac\u00b2/\u00ce\u00a6\u00e2\ufffd\u00a2(Ui\u00e2\u20ac\u00b2)superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u00ce\u00a6superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2U_{i}^{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT / roman_\u00ce\u00a6 ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) is a simple non-abelian group. In particular, Ui\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2U_{i}^{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT is quasi-simple. Let E=Ui\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2U=Ui\u00e2\u20ac\u00b2\u00e2\u2039\u0160U\u011f\ufffd\ufffd\u00b8superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u02c6right-normal-factor-semidirect-productsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u02c6E=U_{i}^{ Uitalic_E = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT italic_U = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u2039\u0160 italic_U. Then E\u00e2\u20ac\u00b2=Ui\u00e2\u20ac\u00b2superscript\u011f\ufffd\ufffd\u00b8\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2E^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT. Let U=E0<E1<\u00e2\u2039\u00af<Et\u00e2\u02c6\u20191<Et=E\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\ufffd\u00b80subscript\u011f\ufffd\ufffd\u00b81\u00e2\u2039\u00afsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a11subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a1\u011f\ufffd\ufffd\u00b8U=E_{0}<E_{1}< = italic_E start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT < italic_E start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < \u00e2\u2039\u00af < italic_E start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT < italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_E be a subgroup chain such that Ei\u00e2\u02c6\u20191subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u20131E_{i-1}italic_E start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT is a maximal \u00cf\u0192\u011f\ufffd\u0153\ufffd subgroup of Eisubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u2013E_{i}italic_E start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT for all i=1,\u00e2\u20ac\u00a6,t\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u00a1i=1, = 1 , \u00e2\u20ac\u00a6 , italic_t and for M=Et\u00e2\u02c6\u20191\u011f\ufffd\u2018\u20acsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a11M=E_{t-1}italic_M = italic_E start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT we have M=U\u00e2\ufffd\u00a2(M\u00e2\u02c6\u00a9Ui\u00e2\u20ac\u00b2)\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u20acsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2M=U(M U_{i}^{ = italic_U ( italic_M \u00e2\u02c6\u00a9 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ). Then, by Lemma 2.2, we have either M=Et\u00e2\u02c6\u20191\u011f\ufffd\u2018\u20acsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a11M=E_{t-1}italic_M = italic_E start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT is a maximal normal subgroup of E\u011f\ufffd\ufffd\u00b8Eitalic_E or M\u011f\ufffd\u2018\u20acMitalic_M is a maximal subgroup of E\u011f\ufffd\ufffd\u00b8Eitalic_E such that E/ME\u011f\ufffd\ufffd\u00b8subscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b8E/M_{E}italic_E / italic_M start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT is a \u00cf\u0192\u011f\ufffd\u0153\ufffd non-abelian group of order q\u00e2\ufffd\u00a2r\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178qritalic_q italic_r for some primes q\u011f\ufffd\u2018\ufffdqitalic_q and r\u011f\ufffd\u2018\u0178ritalic_r. First assume that M\u011f\ufffd\u2018\u20acMitalic_M is normal in E\u011f\ufffd\ufffd\u00b8Eitalic_E. From E=Ui\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2U=Ui\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2M\u011f\ufffd\ufffd\u00b8superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u02c6superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u20acE=U_{i}^{ = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT italic_U = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT italic_M it follows that E/M\u00e2\u2030\u0192Ui\u00e2\u20ac\u00b2/(M\u00e2\u02c6\u00a9Ui\u00e2\u20ac\u00b2)similar-to-or-equals\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u20acsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u20acsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2E/M U_{i}^{ U_{i}^{ / italic_M \u00e2\u2030\u0192 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT / ( italic_M \u00e2\u02c6\u00a9 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) is a simple group and so Ui\u00e2\u20ac\u00b2/(M\u00e2\u02c6\u00a9Ui\u00e2\u20ac\u00b2)superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u20acsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2U_{i}^{ U_{i}^{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT / ( italic_M \u00e2\u02c6\u00a9 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) is a simple non-abelian group since Ui\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2U_{i}^{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT is perfect. Therefore M\u00e2\u02c6\u00a9Ui\u00e2\u20ac\u00b2=Ui\u00e2\u20ac\u00b2\u00e2\u02c6\u00a9Z=\u00ce\u00a6\u00e2\ufffd\u00a2(Ui\u00e2\u20ac\u00b2)\u011f\ufffd\u2018\u20acsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffd\u00ce\u00a6superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2M U_{i}^{ Z= \u00e2\u02c6\u00a9 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_Z = roman_\u00ce\u00a6 ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) is a p\u00e2\u20ac\u00b2superscript\u011f\ufffd\u2018\ufffd\u00e2\u20ac\u00b2p^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT-group by Claim (10), so U\u011f\ufffd\u2018\u02c6Uitalic_U is a Sylow p\u011f\ufffd\u2018\ufffdpitalic_p-subgroup of M=U\u00e2\ufffd\u00a2(M\u00e2\u02c6\u00a9Ui\u00e2\u20ac\u00b2)\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u20acsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2M=U(M U_{i}^{ = italic_U ( italic_M \u00e2\u02c6\u00a9 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ). Then, by the Frattini argument, E=M\u00e2\ufffd\u00a2NE\u00e2\ufffd\u00a2(U)=(M\u00e2\u02c6\u00a9Ui\u00e2\u20ac\u00b2)\u00e2\ufffd\u00a2NE\u00e2\ufffd\u00a2(U)=\u00ce\u00a6\u00e2\ufffd\u00a2(Ui\u00e2\u20ac\u00b2)\u00e2\ufffd\u00a2NE\u00e2\ufffd\u00a2(U)\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u20acsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u20acsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u02c6\u00ce\u00a6superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u02c6E=MN_{E}(U)=(M U_{i}^{ = italic_M italic_N start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ( italic_U ) = ( italic_M \u00e2\u02c6\u00a9 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) italic_N start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ( italic_U ) = roman_\u00ce\u00a6 ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) italic_N start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ( italic_U ). But \u00ce\u00a6\u00e2\ufffd\u00a2(Ui\u00e2\u20ac\u00b2)\u00e2\u2030\u00a4\u00ce\u00a6\u00e2\ufffd\u00a2(E)\u00ce\u00a6superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u00ce\u00a6\u011f\ufffd\ufffd\u00b8 ( italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) \u00e2\u2030\u00a4 roman_\u00ce\u00a6 ( italic_E ), therefore NE\u00e2\ufffd\u00a2(U)=Esubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b8N_{E}(U)=Eitalic_N start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ( italic_U ) = italic_E and so Ui\u00e2\u20ac\u00b2\u00e2\u2030\u00a4NG\u00e2\ufffd\u00a2(U)superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u02c6U_{i}^{ N_{G}(U)italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u2030\u00a4 italic_N start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_U ). Finally, assume that E/ME\u011f\ufffd\ufffd\u00b8subscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b8E/M_{E}italic_E / italic_M start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT is a non-abelian group of order q\u00e2\ufffd\u00a2r\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178qritalic_q italic_r with V/ME=(E/ME)\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u2030subscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b8superscript\u011f\ufffd\ufffd\u00b8subscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b8\u00e2\u20ac\u00b2V/M_{E}=(E/M_{E})^{ / italic_M start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT = ( italic_E / italic_M start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT. Then |(E/ME)/(E/ME)\u00e2\u20ac\u00b2|=(E/ME)/(V/ME)=|E/V|\u011f\ufffd\ufffd\u00b8subscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b8superscript\u011f\ufffd\ufffd\u00b8subscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b8\u00e2\u20ac\u00b2\u011f\ufffd\ufffd\u00b8subscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u2030subscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b8\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u2030|(E/M_{E})/(E/M_{E})^{ ( italic_E / italic_M start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ) / ( italic_E / italic_M start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT | = ( italic_E / italic_M start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ) / ( italic_V / italic_M start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ) = | italic_E / italic_V | is a prime, so V=Ui\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u2030superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2V=U_{i}^{ = italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT. Hence ME\u00e2\u2030\u00a4Ui\u00e2\u20ac\u00b2subscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b8superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2M_{E} U_{i}^{ start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT and Ui\u00e2\u20ac\u00b2/MEsuperscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2subscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\ufffd\u00b8U_{i}^{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT / italic_M start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT is a non-identity soluble group, so Ui\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2U_{i}^{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT is not perfect. This contradiction shows that we have (11). (12) UGsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00baU^{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT is not a non-abelian P\u011f\ufffd\u2018\u0192Pitalic_P-group. Assume that UGsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00baU^{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT is a non-abelian P\u011f\ufffd\u2018\u0192Pitalic_P-group. Then, in view of Claim (7), UG=Q\u00e2\u2039\u0160Usuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00baright-normal-factor-semidirect-product\u011f\ufffd\u2018\u201e\u011f\ufffd\u2018\u02c6U^{G}=Q Uitalic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT = italic_Q \u00e2\u2039\u0160 italic_U is of type (q,p)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd(q,p)( italic_q , italic_p ) for some prime q\u011f\ufffd\u2018\ufffdqitalic_q. Let \u00cf\u20ac={q,p}\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd = { italic_q , italic_p }. First suppose that \u00cf\u20ac\u00e2\u02c6\u00a9\u00cf\u20ac\u00e2\ufffd\u00a2(D)=\u00e2\u02c6\u2026\u011f\ufffd\u0153\u2039\u011f\ufffd\u0153\u2039\u011f\ufffd\ufffd\u00b7 \u00e2\u02c6\u00a9 italic_\u00cf\u20ac ( italic_D ) = \u00e2\u02c6\u2026. Then UG\u00e2\u02c6\u00a9D=1superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b71U^{G} D=1italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_D = 1, so [UG,D]=1superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b71[U^{G},D]=1[ italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT , italic_D ] = 1 and G\u011f\ufffd\ufffd\u00baGitalic_G is \u00cf\u20ac\u011f\ufffd\u0153\u2039 We show that G/D\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7G/Ditalic_G / italic_D is \u00cf\u20ac\u011f\ufffd\u0153\u2039 Let N=U1\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00b2N=U_{1}^{ = italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT and F=N\u00e2\ufffd\u00a2U=N\u00c3\u2014U\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02c6F=NU=N Uitalic_F = italic_N italic_U = italic_N \u00c3\u2014 italic_U. Then FG=N\u00e2\ufffd\u00a2UGsuperscript\u011f\ufffd\ufffd\u00b9\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00baF^{G}=NU^{G}italic_F start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT = italic_N italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT and FG=Nsubscript\u011f\ufffd\ufffd\u00b9\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdF_{G}=Nitalic_F start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = italic_N by Claim (8). In view of Claims (3) and (7), F/N\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\ufffdF/Nitalic_F / italic_N is not subnormal but modular in G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N and so where N\u00e2\ufffd\u00a2UG/N=O\u00cf\u20ac\u00e2\ufffd\u00a2(G/N)\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u201a\u011f\ufffd\u0153\u2039\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdNU^{G}/N=O_{ italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_N = italic_O start_POSTSUBSCRIPT italic_\u00cf\u20ac end_POSTSUBSCRIPT ( italic_G / italic_N ) and K/N=O\u00cf\u20ac\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(G/N)\u011f\ufffd\ufffd\u00be\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u201asuperscript\u011f\ufffd\u0153\u2039\u00e2\u20ac\u00b2\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdK/N=O_{ / italic_N = italic_O start_POSTSUBSCRIPT italic_\u00cf\u20ac start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ( italic_G / italic_N ), by Lemma 2.14. Therefore G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N is \u00cf\u20ac\u011f\ufffd\u0153\u2039 Hence G/D\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7G/Ditalic_G / italic_D is \u00cf\u20ac\u011f\ufffd\u0153\u2039 Let E\u011f\ufffd\ufffd\u00b8Eitalic_E be a minimal supplement to D\u011f\ufffd\ufffd\u00b7Ditalic_D in G\u011f\ufffd\ufffd\u00baGitalic_G. Then E\u00e2\u02c6\u00a9D\u00e2\u2030\u00a4\u00ce\u00a6\u00e2\ufffd\u00a2(E)\u011f\ufffd\ufffd\u00b8\u011f\ufffd\ufffd\u00b7\u00ce\u00a6\u011f\ufffd\ufffd\u00b8E D \u00e2\u02c6\u00a9 italic_D \u00e2\u2030\u00a4 roman_\u00ce\u00a6 ( italic_E ), so E\u011f\ufffd\ufffd\u00b8Eitalic_E is soluble and \u00cf\u20ac\u011f\ufffd\u0153\u2039 that is, E=O\u00cf\u20ac\u00e2\ufffd\u00a2(E)\u00c3\u2014O\u00cf\u20ac\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(E)\u011f\ufffd\ufffd\u00b8subscript\u011f\ufffd\u2018\u201a\u011f\ufffd\u0153\u2039\u011f\ufffd\ufffd\u00b8subscript\u011f\ufffd\u2018\u201asuperscript\u011f\ufffd\u0153\u2039\u00e2\u20ac\u00b2\u011f\ufffd\ufffd\u00b8E=O_{ O_{ = italic_O start_POSTSUBSCRIPT italic_\u00cf\u20ac end_POSTSUBSCRIPT ( italic_E ) \u00c3\u2014 italic_O start_POSTSUBSCRIPT italic_\u00cf\u20ac start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ( italic_E ) by Lemma 2.15 since G/D\u00e2\u2030\u0192E/(E\u00e2\u02c6\u00a9D)similar-to-or-equals\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b8\u011f\ufffd\ufffd\u00b8\u011f\ufffd\ufffd\u00b7G/D E/(E D)italic_G / italic_D \u00e2\u2030\u0192 italic_E / ( italic_E \u00e2\u02c6\u00a9 italic_D ). Let x\u00e2\u02c6\u02c6Gr\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u0178x G_{r}italic_x \u00e2\u02c6\u02c6 italic_G start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT, where Grsubscript\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u0178G_{r}italic_G start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT be a Sylow r\u011f\ufffd\u2018\u0178ritalic_r-subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G. Assume that r\u00e2\u02c6\u2030\u00cf\u20ac\u011f\ufffd\u2018\u0178\u011f\ufffd\u0153\u2039r \u00e2\u02c6\u2030 italic_\u00cf\u20ac. Then for some Sylow r\u011f\ufffd\u2018\u0178ritalic_r-subgroup Drsubscript\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u0178D_{r}italic_D start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT of D\u011f\ufffd\ufffd\u00b7Ditalic_D and a Sylow r\u011f\ufffd\u2018\u0178ritalic_r-subgroup Ersubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u0178E_{r}italic_E start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT of E\u011f\ufffd\ufffd\u00b8Eitalic_E and some y\u00e2\u02c6\u02c6G\u011f\ufffd\u2018\u00a6\u011f\ufffd\ufffd\u00bay Gitalic_y \u00e2\u02c6\u02c6 italic_G we have Gr=Dr\u00e2\ufffd\u00a2Erysubscript\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u0178superscriptsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u00a6G_{r}=D_{r}E_{r}^{y}italic_G start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT = italic_D start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT italic_E start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_y end_POSTSUPERSCRIPT. Hence x=d\u00e2\ufffd\u00a2e\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u2019x=deitalic_x = italic_d italic_e, where d\u00e2\u02c6\u02c6Dr\u011f\ufffd\u2018\u2018subscript\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u0178d D_{r}italic_d \u00e2\u02c6\u02c6 italic_D start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT and e\u00e2\u02c6\u02c6Ery\u011f\ufffd\u2018\u2019superscriptsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u00a6e E_{r}^{y}italic_e \u00e2\u02c6\u02c6 italic_E start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_y end_POSTSUPERSCRIPT. Then d\u00e2\u2030\u00a4CG\u00e2\ufffd\u00a2(U)\u011f\ufffd\u2018\u2018subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u02c6d C_{G}(U)italic_d \u00e2\u2030\u00a4 italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_U ) since [UG,D]=1superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b71[U^{G},D]=1[ italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT , italic_D ] = 1. Since |G:Ery|=|DEry:Ery|=|D:D\u00e2\u02c6\u00a9Ery||G:E_{r}^{y}|=|DE_{r}^{y}:E_{r}^{y}|=|D:D E_{r}^{y}|| italic_G : italic_E start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_y end_POSTSUPERSCRIPT | = | italic_D italic_E start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_y end_POSTSUPERSCRIPT : italic_E start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_y end_POSTSUPERSCRIPT | = | italic_D : italic_D \u00e2\u02c6\u00a9 italic_E start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_y end_POSTSUPERSCRIPT | is a \u00cf\u20ac\u00e2\u20ac\u00b2superscript\u011f\ufffd\u0153\u2039\u00e2\u20ac\u00b2 start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT-mumber, the Hall \u00cf\u20ac\u011f\ufffd\u0153\u2039 O\u00cf\u20ac\u00e2\ufffd\u00a2(Ey)subscript\u011f\ufffd\u2018\u201a\u011f\ufffd\u0153\u2039superscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a6O_{ start_POSTSUBSCRIPT italic_\u00cf\u20ac end_POSTSUBSCRIPT ( italic_E start_POSTSUPERSCRIPT italic_y end_POSTSUPERSCRIPT ) of Eysuperscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a6E^{y}italic_E start_POSTSUPERSCRIPT italic_y end_POSTSUPERSCRIPT is a Hall \u00cf\u20ac\u011f\ufffd\u0153\u2039 of G\u011f\ufffd\ufffd\u00baGitalic_G. Hence UG\u00e2\u2030\u00a4O\u00cf\u20ac\u00e2\ufffd\u00a2(Ey)superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\u2018\u201a\u011f\ufffd\u0153\u2039superscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a6U^{G} O_{ start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u00e2\u2030\u00a4 italic_O start_POSTSUBSCRIPT italic_\u00cf\u20ac end_POSTSUBSCRIPT ( italic_E start_POSTSUPERSCRIPT italic_y end_POSTSUPERSCRIPT ) and so e\u00e2\u2030\u00a4CG\u00e2\ufffd\u00a2(U)\u011f\ufffd\u2018\u2019subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u02c6e C_{G}(U)italic_e \u00e2\u2030\u00a4 italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_U ) since e\u00e2\u02c6\u02c6O\u00cf\u20ac\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(Ey)\u011f\ufffd\u2018\u2019subscript\u011f\ufffd\u2018\u201asuperscript\u011f\ufffd\u0153\u2039\u00e2\u20ac\u00b2superscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a6e O_{ \u00e2\u02c6\u02c6 italic_O start_POSTSUBSCRIPT italic_\u00cf\u20ac start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ( italic_E start_POSTSUPERSCRIPT italic_y end_POSTSUPERSCRIPT ). Therefore x\u00e2\u2030\u00a4CG\u00e2\ufffd\u00a2(U)\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u02c6x C_{G}(U)italic_x \u00e2\u2030\u00a4 italic_C start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_U ) and hence U\u011f\ufffd\u2018\u02c6Uitalic_U is normal and so modular in \u00e2\u0178\u00a8x,U\u00e2\u0178\u00a9\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u02c6 x,U italic_x , italic_U \u00e2\u0178\u00a9. Now let r\u00e2\u02c6\u02c6\u00cf\u20ac\u011f\ufffd\u2018\u0178\u011f\ufffd\u0153\u2039r \u00e2\u02c6\u02c6 italic_\u00cf\u20ac. Then V=UG\u00e2\ufffd\u00a2Gr\u011f\ufffd\u2018\u2030superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\u0178V=U^{G}G_{r}italic_V = italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT italic_G start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT is a \u00cf\u20ac\u011f\ufffd\u0153\u2039 G\u011f\ufffd\ufffd\u00baGitalic_G, so V\u00e2\u02c6\u00a9D=1\u011f\ufffd\u2018\u2030\u011f\ufffd\ufffd\u00b71V D=1italic_V \u00e2\u02c6\u00a9 italic_D = 1 and therefore V\u00e2\u2030\u0192V\u00e2\ufffd\u00a2D/Dsimilar-to-or-equals\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2030\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b7V VD/Ditalic_V \u00e2\u2030\u0192 italic_V italic_D / italic_D is a soluble Q\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2021Q Titalic_Q italic_\u00cf\u0192 italic_T-group by Lemma 2.17, so U\u011f\ufffd\u2018\u02c6Uitalic_U is \u00cf\u0192\u011f\ufffd\u0153\ufffd and so modular in V\u011f\ufffd\u2018\u2030Vitalic_V. Hence U\u011f\ufffd\u2018\u02c6Uitalic_U is modular in \u00e2\u0178\u00a8x,U\u00e2\u0178\u00a9\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u02c6 x,U italic_x , italic_U \u00e2\u0178\u00a9 by [1, Page 201, Property (2)]. Therefore U\u011f\ufffd\u2018\u02c6Uitalic_U is modular in G\u011f\ufffd\ufffd\u00baGitalic_G by Lemma 2.8(2) and so U\u011f\ufffd\u2018\u02c6Uitalic_U is \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G, a contradiction. Finally, if \u00cf\u20ac\u00e2\u02c6\u00a9\u00cf\u20ac\u00e2\ufffd\u00a2(D)\u00e2\u2030 \u00e2\u02c6\u2026\u011f\ufffd\u0153\u2039\u011f\ufffd\u0153\u2039\u011f\ufffd\ufffd\u00b7 \u00e2\u02c6\u00a9 italic_\u00cf\u20ac ( italic_D ) \u00e2\u2030 \u00e2\u02c6\u2026, then G\u011f\ufffd\ufffd\u00baGitalic_G satisfies \u011f\ufffd\ufffd\ufffd\u00cf\u0192\u00e2\ufffd\u00a2(p,q)subscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd{ Q}_{ start_POSTSUBSCRIPT italic_\u00cf\u0192 ( italic_p , italic_q ) end_POSTSUBSCRIPT by Condition (iii), so U\u011f\ufffd\u2018\u02c6Uitalic_U is modular and so \u00cf\u0192\u011f\ufffd\u0153\ufffd in G\u011f\ufffd\ufffd\u00baGitalic_G. This contradiction completes the proof of the claim. (13) G\u011f\ufffd\ufffd\u00baGitalic_G has a normal subgroup Cqsubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdC_{q}italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT of prime order q\u011f\ufffd\u2018\ufffdqitalic_q such that Cq\u00e2\u2030\u00a4Z\u00e2\ufffd\u00a2(U1\u00e2\u20ac\u00b2)=\u00ce\u00a6\u00e2\ufffd\u00a2(U1\u00e2\u20ac\u00b2)subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00b2\u00ce\u00a6superscriptsubscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00b2C_{q} Z(U_{1}^{ start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_Z ( italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) = roman_\u00ce\u00a6 ( italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ). Let E=U1\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2U=U1\u00e2\u20ac\u00b2\u00c3\u2014U\u011f\ufffd\ufffd\u00b8superscriptsubscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u02c6superscriptsubscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u02c6E=U_{1}^{ Uitalic_E = italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT italic_U = italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00c3\u2014 italic_U. Then E\u011f\ufffd\ufffd\u00b8Eitalic_E is modular and not subnormal in G\u011f\ufffd\ufffd\u00baGitalic_G by Claims (3) and (7). Moreover, EG=U1\u00e2\u20ac\u00b2subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\ufffd\u00basuperscriptsubscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00b2E_{G}=U_{1}^{ start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT by Claim (8) and E/U1\u00e2\u20ac\u00b2\u00e2\u2030\u0192Usimilar-to-or-equals\u011f\ufffd\ufffd\u00b8superscriptsubscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u02c6E/U_{1}^{ Uitalic_E / italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u2030\u0192 italic_U is a modular non-subnormal subgroup of G/U1\u00e2\u20ac\u00b2\u011f\ufffd\ufffd\u00basuperscriptsubscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00b2G/U_{1}^{ / italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT. Hence is a non-abelian P\u011f\ufffd\u2018\u0192Pitalic_P-group by Lemma 2.8(1). Hence 1<UG\u00e2\u02c6\u00a9U1\u00e2\u20ac\u00b2\u00e2\u2030\u00a4Z\u00e2\ufffd\u00a2(U1\u00e2\u20ac\u00b2)1superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00basuperscriptsubscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00b21<U^{G} U_{1}^{ Z(U_{1}^{ < italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u00e2\u02c6\u00a9 italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u2030\u00a4 italic_Z ( italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) by Claims (6) and (12). Hence G\u011f\ufffd\ufffd\u00baGitalic_G has a normal subgroup Cqsubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdC_{q}italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT of prime order q\u011f\ufffd\u2018\ufffdqitalic_q such that Cq\u00e2\u2030\u00a4U1\u00e2\u20ac\u00b2subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00b2C_{q} U_{1}^{ start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT. But U1\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00b2U_{1}^{ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT is a quasi-simple group by Lemma 2.13(1) and so Cq\u00e2\u2030\u00a4Z\u00e2\ufffd\u00a2(U1\u00e2\u20ac\u00b2)=\u00ce\u00a6\u00e2\ufffd\u00a2(U1\u00e2\u20ac\u00b2)subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00b2\u00ce\u00a6superscriptsubscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00b2C_{q} Z(U_{1}^{ start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_Z ( italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) = roman_\u00ce\u00a6 ( italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ). Final contradiction. From Claims (7), (9) and (11) it follows that E=Cq\u00e2\ufffd\u00a2U=Cq\u00c3\u2014U\u011f\ufffd\ufffd\u00b8subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02c6E=C_{q}U=C_{q} Uitalic_E = italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT italic_U = italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT \u00c3\u2014 italic_U is not subnormal in G\u011f\ufffd\ufffd\u00baGitalic_G and, in view of Claim (8), EG=Cqsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdE_{G}=C_{q}italic_E start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT. Hence G/EG\u00e2\u2030\u0192EG/EG\u00c3\u2014K/EG,similar-to-or-equals\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\ufffd\u00basuperscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00besubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\ufffd\u00baG/E_{G} E^{G}/E_{G} K/E_{G},italic_G / italic_E start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT \u00e2\u2030\u0192 italic_E start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_E start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT \u00c3\u2014 italic_K / italic_E start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT , where is a non-abelian P\u011f\ufffd\u2018\u0192Pitalic_P-group of order prime to |K/Cq|\u011f\ufffd\ufffd\u00besubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffd|K/C_{q}|| italic_K / italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT | by Lemma 2.8(1). Hence G\u011f\ufffd\ufffd\u00baGitalic_G is a \u00cf\u20ac\u011f\ufffd\u0153\u2039 group, where \u00cf\u20ac=\u00cf\u20ac\u00e2\ufffd\u00a2(UG/(Cq\u00e2\u02c6\u00a9UG))\u011f\ufffd\u0153\u2039\u011f\ufffd\u0153\u2039superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba U^{G}))italic_\u00cf\u20ac = italic_\u00cf\u20ac ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / ( italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT \u00e2\u02c6\u00a9 italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT ) ). Then D/Z\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffdD/Zitalic_D / italic_Z is \u00cf\u20ac\u011f\ufffd\u0153\u2039 But Cq\u00e2\u2030\u00a4\u00ce\u00a6\u00e2\ufffd\u00a2(U1\u00e2\u20ac\u00b2)\u00e2\u2030\u00a4\u00ce\u00a6\u00e2\ufffd\u00a2(D)=Zsubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffd\u00ce\u00a6superscriptsubscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00b2\u00ce\u00a6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffdC_{q} start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT \u00e2\u2030\u00a4 roman_\u00ce\u00a6 ( italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ) \u00e2\u2030\u00a4 roman_\u00ce\u00a6 ( italic_D ) = italic_Z by Claim (1), so q\u011f\ufffd\u2018\ufffdqitalic_q divides |D/Z|\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd|D/Z|| italic_D / italic_Z |. Hence q\u011f\ufffd\u2018\ufffdqitalic_q does not divides |Cq\u00e2\ufffd\u00a2UG/Cq|subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffd|C_{q}U^{G}/C_{q}|| italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT |. If Cq\u00e2\u02c6\u00a9UG=1subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00ba1C_{q} U^{G}=1italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT \u00e2\u02c6\u00a9 italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT = 1, then UG\u00e2\u2030\u0192Cq\u00e2\ufffd\u00a2UG/Cqsimilar-to-or-equalssuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdU^{G} C_{q}U^{G}/C_{q}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT \u00e2\u2030\u0192 italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT is a non-abelian P\u011f\ufffd\u2018\u0192Pitalic_P-group, contrary to Claim (12), so Cq\u00e2\u2030\u00a4UGsubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00baC_{q} U^{G}italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT. Then Cqsubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdC_{q}italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT is a Sylow q\u011f\ufffd\u2018\ufffdqitalic_q-subgroup of UGsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00baU^{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT. Hence UG=Cq\u00e2\u2039\u0160(R\u00e2\u2039\u0160U)superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00baright-normal-factor-semidirect-productsubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdright-normal-factor-semidirect-product\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u02c6U^{G}=C_{q} U)italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT = italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT \u00e2\u2039\u0160 ( italic_R \u00e2\u2039\u0160 italic_U ), where R\u00e2\u2039\u0160U\u00e2\u2030\u0192UG/Cqsimilar-to-or-equalsright-normal-factor-semidirect-product\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u02c6superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdR U U^{G}/C_{q}italic_R \u00e2\u2039\u0160 italic_U \u00e2\u2030\u0192 italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT / italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT is a non-abelian P\u011f\ufffd\u2018\u0192Pitalic_P-group. Let C=CUG\u00e2\ufffd\u00a2(Cq)\u011f\ufffd\ufffd\u00b6subscript\u011f\ufffd\ufffd\u00b6superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdC=C_{U^{G}}(C_{q})italic_C = italic_C start_POSTSUBSCRIPT italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ( italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ). Then U\u00e2\u2030\u00a4C\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b6U Citalic_U \u00e2\u2030\u00a4 italic_C by Claim (11) and so, by Lemma 2.10(1), R\u00e2\u2039\u0160U=UR\u00e2\u2039\u0160U\u00e2\u2030\u00a4Cright-normal-factor-semidirect-product\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u02c6superscript\u011f\ufffd\u2018\u02c6right-normal-factor-semidirect-product\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00b6R U=U^{R U} Citalic_R \u00e2\u2039\u0160 italic_U = italic_U start_POSTSUPERSCRIPT italic_R \u00e2\u2039\u0160 italic_U end_POSTSUPERSCRIPT \u00e2\u2030\u00a4 italic_C. Hence Cq\u00e2\u2030\u00a4Z\u00e2\ufffd\u00a2(UG)subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00baC_{q} Z(U^{G})italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_Z ( italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT ). Therefore UG=Cq\u00c3\u2014(R\u00e2\u2039\u0160U)superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00basubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdright-normal-factor-semidirect-product\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u02c6U^{G}=C_{q} U)italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT = italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT \u00c3\u2014 ( italic_R \u00e2\u2039\u0160 italic_U ), where R\u00e2\u2039\u0160Uright-normal-factor-semidirect-product\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u02c6R Uitalic_R \u00e2\u2039\u0160 italic_U is characterisric in UGsuperscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00baU^{G}italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT and so it is normal in G\u011f\ufffd\ufffd\u00baGitalic_G. But then UG=R\u00e2\u2039\u0160U\u00e2\u2030 Cq\u00e2\u2039\u0160(R\u00e2\u2039\u0160U)superscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\ufffd\u00baright-normal-factor-semidirect-product\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u02c6right-normal-factor-semidirect-productsubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\ufffdright-normal-factor-semidirect-product\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u02c6U^{G}=R U C_{q} U)italic_U start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT = italic_R \u00e2\u2039\u0160 italic_U \u00e2\u2030 italic_C start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT \u00e2\u2039\u0160 ( italic_R \u00e2\u2039\u0160 italic_U ), a contradiction. The theorem is proved. Proof of Theorem F. In view of Example 1.2(i), Teorem F is a special case of Theorem E, where \u00cf\u0192={\u00e2\u201e\u2122}\u011f\ufffd\u0153\ufffd\u00e2\u201e\u2122 = { blackboard_P }. 1. First Consider the special case of Theorem E where \u00cf\u0192=\u00cf\u01921\u00e2\ufffd\u00a2\u00cf\u20ac={{p1},\u00e2\u20ac\u00a6,{pn},\u00cf\u20ac\u00e2\u20ac\u00b2}\u011f\ufffd\u0153\ufffdsuperscript\u011f\ufffd\u0153\ufffd1\u011f\ufffd\u0153\u2039subscript\u011f\ufffd\u2018\ufffd1\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203asuperscript\u011f\ufffd\u0153\u2039\u00e2\u20ac\u00b2 = italic_\u00cf\u0192 start_POSTSUPERSCRIPT 1 italic_\u00cf\u20ac end_POSTSUPERSCRIPT = { { italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT } , \u00e2\u20ac\u00a6 , { italic_p start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } , italic_\u00cf\u20ac start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT } and \u00cf\u20ac={p1,\u00e2\u20ac\u00a6,pn}\u011f\ufffd\u0153\u2039subscript\u011f\ufffd\u2018\ufffd1\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a = { italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_p start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } (see Example 1.2(iii)). In this case we say that G\u011f\ufffd\ufffd\u00baGitalic_G is a Q\u00e2\ufffd\u00a21\u00e2\ufffd\u00a2\u00cf\u20ac\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e1\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\u2021Q1 Titalic_Q 1 italic_\u00cf\u20ac italic_T-group if 1\u00e2\ufffd\u00a2\u00cf\u20ac1\u011f\ufffd\u0153\u20391 italic_\u00cf\u20ac-quasinormality is a transitive relation on G\u011f\ufffd\ufffd\u00baGitalic_G, and we also say in this case that \u00e2\u20ac\ufffdG\u011f\ufffd\ufffd\u00baGitalic_G satisfies \u011f\ufffd\ufffd\ufffd1\u00e2\ufffd\u00a2\u00cf\u20ac\u00e2\ufffd\u00a2(p,q)subscript\u011f\ufffd\ufffd\ufffd1\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd{ Q}_{1 start_POSTSUBSCRIPT 1 italic_\u00cf\u20ac ( italic_p , italic_q ) end_POSTSUBSCRIPT\u00e2\u20ac\ufffd instead of \u00e2\u20ac\ufffdG\u011f\ufffd\ufffd\u00baGitalic_G satisfies \u011f\ufffd\ufffd\ufffd\u00cf\u0192\u00e2\ufffd\u00a2(p,q)subscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd{ Q}_{ start_POSTSUBSCRIPT italic_\u00cf\u0192 ( italic_p , italic_q ) end_POSTSUBSCRIPT\u00e2\u20ac\ufffd. Observe that G\u011f\ufffd\ufffd\u00baGitalic_G satisfies \u011f\ufffd\ufffd\ufffd1\u00e2\ufffd\u00a2\u00cf\u20ac\u00e2\ufffd\u00a2(p,q)subscript\u011f\ufffd\ufffd\ufffd1\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd{ Q}_{1 start_POSTSUBSCRIPT 1 italic_\u00cf\u20ac ( italic_p , italic_q ) end_POSTSUBSCRIPT if whenever N\u011f\ufffd\u2018\ufffdNitalic_N is a soluble normal subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G and P/N\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\ufffdP/Nitalic_P / italic_N is a normal non-abelian P\u011f\ufffd\u2018\u0192Pitalic_P-subgroup of type (p,q)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd(p,q)( italic_p , italic_q ) of G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N, where p,q\u00e2\u02c6\u02c6\u00cf\u20ac\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u0153\u2039\u00e2\u20ac\u00b2p,q , italic_q \u00e2\u02c6\u02c6 italic_\u00cf\u20ac start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT, every subgroup of P/N\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\ufffdP/Nitalic_P / italic_N is modular in G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N. Therefore we get from Theorem E the following result. Corollary 4.1. A group G\u011f\ufffd\ufffd\u00baGitalic_G is a Q\u00e2\ufffd\u00a21\u00e2\ufffd\u00a2\u00cf\u20ac\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e1\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\u2021Q1 Titalic_Q 1 italic_\u00cf\u20ac italic_T-group if and only if G\u011f\ufffd\ufffd\u00baGitalic_G has a perfect normal subgroup D\u011f\ufffd\ufffd\u00b7Ditalic_D such that: (i) G/D\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7G/Ditalic_G / italic_D is a soluble Q\u00e2\ufffd\u00a21\u00e2\ufffd\u00a2\u00cf\u20ac\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e1\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\u2021Q1 Titalic_Q 1 italic_\u00cf\u20ac italic_T-group, (ii) if D\u00e2\u2030 1\u011f\ufffd\ufffd\u00b71D 1italic_D \u00e2\u2030 1, G\u011f\ufffd\ufffd\u00baGitalic_G has a Robinson complex (D,Z\u00e2\ufffd\u00a2(D);U1,\u00e2\u20ac\u00a6,Uk)\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02dc(D,Z(D);U_{1}, italic_D , italic_Z ( italic_D ) ; italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) and (iii) for any set {i1,\u00e2\u20ac\u00a6,ir}\u00e2\u0160\u2020{1,\u00e2\u20ac\u00a6,k}subscript\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u01781\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u02dc italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT } \u00e2\u0160\u2020 { 1 , \u00e2\u20ac\u00a6 , italic_k }, where 1\u00e2\u2030\u00a4r<k1\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u02dc1 r<k1 \u00e2\u2030\u00a4 italic_r < italic_k, the groups G\u011f\ufffd\ufffd\u00baGitalic_G and G/Ui1\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2\u00e2\u2039\u00af\u00e2\ufffd\u00a2Uir\u00e2\u20ac\u00b2\u011f\ufffd\ufffd\u00basuperscriptsubscript\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00b2\u00e2\u2039\u00afsuperscriptsubscript\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u0178\u00e2\u20ac\u00b2G/U_{i_{1}}^{ U_{i_{r}}^{ / italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u2039\u00af italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT satisfy \u011f\ufffd\ufffd\ufffdpsubscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\ufffd{ N}_{p}bold_N start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u00e2\u02c6\u02c6{2,3}\u00e2\u02c6\u00a9\u00cf\u20ac\u00e2\ufffd\u00a2(Z\u00e2\ufffd\u00a2(D))\u011f\ufffd\u2018\ufffd23\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7p \u00e2\u02c6\u02c6 { 2 , 3 } \u00e2\u02c6\u00a9 italic_\u00cf\u20ac ( italic_Z ( italic_D ) ), \u011f\ufffd\ufffd\ufffdpsubscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\ufffd{ P}_{p}bold_P start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u00e2\u02c6\u02c6\u00cf\u20ac\u00e2\ufffd\u00a2(D)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u2039\u011f\ufffd\ufffd\u00b7p \u00e2\u02c6\u02c6 italic_\u00cf\u20ac ( italic_D ), and \u011f\ufffd\ufffd\ufffd1\u00cf\u20ac(p,q){ Q}_{1 start_POSTSUBSCRIPT 1 italic_\u00cf\u20ac ( italic_p , italic_q end_POSTSUBSCRIPT ) for all pairs {p,q}\u00e2\u0160\u2020\u00cf\u20ac\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u0153\u2039\u00e2\u20ac\u00b2 italic_p , italic_q } \u00e2\u0160\u2020 italic_\u00cf\u20ac start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT with {p,q}\u00e2\u02c6\u00a9\u00cf\u20ac\u00e2\ufffd\u00a2(D)\u00e2\u2030 \u00e2\u02c6\u2026\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u2039\u011f\ufffd\ufffd\u00b7 italic_p , italic_q } \u00e2\u02c6\u00a9 italic_\u00cf\u20ac ( italic_D ) \u00e2\u2030 \u00e2\u02c6\u2026. 2. Now Consider the special case of Theorem E where \u00cf\u0192=\u00cf\u0192\u00cf\u20ac={\u00cf\u20ac,\u00cf\u20ac\u00e2\u20ac\u00b2}\u011f\ufffd\u0153\ufffdsuperscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u0153\u2039\u011f\ufffd\u0153\u2039superscript\u011f\ufffd\u0153\u2039\u00e2\u20ac\u00b2 = italic_\u00cf\u0192 start_POSTSUPERSCRIPT italic_\u00cf\u20ac end_POSTSUPERSCRIPT = { italic_\u00cf\u20ac , italic_\u00cf\u20ac start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT } (see Example 1.2(iv)). In this case we say that G\u011f\ufffd\ufffd\u00baGitalic_G is a Q\u00e2\ufffd\u00a2\u00cf\u20ac,\u00cf\u20ac\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\u2039superscript\u011f\ufffd\u0153\u2039\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u2021Q italic_\u00cf\u20ac , italic_\u00cf\u20ac start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT italic_T-group if \u00cf\u20ac,\u00cf\u20ac\u00e2\u20ac\u00b2\u011f\ufffd\u0153\u2039superscript\u011f\ufffd\u0153\u2039\u00e2\u20ac\u00b2 , italic_\u00cf\u20ac start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT-quasinormality is a transitive relation on G\u011f\ufffd\ufffd\u00baGitalic_G, and we also say in this case that G\u011f\ufffd\ufffd\u00baGitalic_G \u00e2\u20ac\ufffdsatisfies \u011f\ufffd\ufffd\ufffd\u00cf\u20ac,\u00cf\u20ac\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(p,q)subscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u0153\u2039superscript\u011f\ufffd\u0153\u2039\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd{ Q}_{ start_POSTSUBSCRIPT italic_\u00cf\u20ac , italic_\u00cf\u20ac start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ( italic_p , italic_q ) end_POSTSUBSCRIPT\u00e2\u20ac\ufffd instead of \u00e2\u20ac\ufffdG\u011f\ufffd\ufffd\u00baGitalic_G satisfies \u011f\ufffd\ufffd\ufffd\u00cf\u0192\u00e2\ufffd\u00a2(p,q)subscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd{ Q}_{ start_POSTSUBSCRIPT italic_\u00cf\u0192 ( italic_p , italic_q ) end_POSTSUBSCRIPT\u00e2\u20ac\ufffd. Observe that G\u011f\ufffd\ufffd\u00baGitalic_G satisfies \u011f\ufffd\ufffd\ufffd\u00cf\u20ac,\u00cf\u20ac\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(p,q)subscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u0153\u2039superscript\u011f\ufffd\u0153\u2039\u00e2\u20ac\u00b2\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd{ Q}_{ start_POSTSUBSCRIPT italic_\u00cf\u20ac , italic_\u00cf\u20ac start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ( italic_p , italic_q ) end_POSTSUBSCRIPT if whenever N\u011f\ufffd\u2018\ufffdNitalic_N is a soluble normal subgroup of G\u011f\ufffd\ufffd\u00baGitalic_G and P/N\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\ufffdP/Nitalic_P / italic_N is a normal non-abelian P\u011f\ufffd\u2018\u0192Pitalic_P-subgroup of type (p,q)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd(p,q)( italic_p , italic_q ) of G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N, where p,q\u00e2\u02c6\u02c6\u00cf\u20ac0\u00e2\u02c6\u02c6{\u00cf\u20ac,\u00cf\u20ac\u00e2\u20ac\u00b2}\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u0153\u20390\u011f\ufffd\u0153\u2039superscript\u011f\ufffd\u0153\u2039\u00e2\u20ac\u00b2p,q , italic_q \u00e2\u02c6\u02c6 italic_\u00cf\u20ac start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 { italic_\u00cf\u20ac , italic_\u00cf\u20ac start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT }, every subgroup of P/N\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\ufffdP/Nitalic_P / italic_N is modular in G/N\u011f\ufffd\ufffd\u00ba\u011f\ufffd\u2018\ufffdG/Nitalic_G / italic_N. Therefore we get from Theorem E the following result. Corollary 4.2. A group G\u011f\ufffd\ufffd\u00baGitalic_G is a Q\u00e2\ufffd\u00a2\u00cf\u20ac,\u00cf\u20ac\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\u2039superscript\u011f\ufffd\u0153\u2039\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u2021Q italic_\u00cf\u20ac , italic_\u00cf\u20ac start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT italic_T-group if and only if G\u011f\ufffd\ufffd\u00baGitalic_G has a perfect normal subgroup D\u011f\ufffd\ufffd\u00b7Ditalic_D such that: (i) G/D\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7G/Ditalic_G / italic_D is a soluble Q\u00e2\ufffd\u00a2\u00cf\u20ac,\u00cf\u20ac\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u201e\u011f\ufffd\u0153\u2039superscript\u011f\ufffd\u0153\u2039\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u2021Q italic_\u00cf\u20ac , italic_\u00cf\u20ac start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT italic_T-group, (ii) if D\u00e2\u2030 1\u011f\ufffd\ufffd\u00b71D 1italic_D \u00e2\u2030 1, G\u011f\ufffd\ufffd\u00baGitalic_G has a Robinson complex (D,Z\u00e2\ufffd\u00a2(D);U1,\u00e2\u20ac\u00a6,Uk)\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02dc(D,Z(D);U_{1}, italic_D , italic_Z ( italic_D ) ; italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) and (iii) for any set {i1,\u00e2\u20ac\u00a6,ir}\u00e2\u0160\u2020{1,\u00e2\u20ac\u00a6,k}subscript\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u01781\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u02dc italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT } \u00e2\u0160\u2020 { 1 , \u00e2\u20ac\u00a6 , italic_k }, where 1\u00e2\u2030\u00a4r<k1\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u02dc1 r<k1 \u00e2\u2030\u00a4 italic_r < italic_k, the groups G\u011f\ufffd\ufffd\u00baGitalic_G and G/Ui1\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2\u00e2\u2039\u00af\u00e2\ufffd\u00a2Uir\u00e2\u20ac\u00b2\u011f\ufffd\ufffd\u00basuperscriptsubscript\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00b2\u00e2\u2039\u00afsuperscriptsubscript\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u0178\u00e2\u20ac\u00b2G/U_{i_{1}}^{ U_{i_{r}}^{ / italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u2039\u00af italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT satisfy \u011f\ufffd\ufffd\ufffdpsubscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\ufffd{ N}_{p}bold_N start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u00e2\u02c6\u02c6{2,3}\u00e2\u02c6\u00a9\u00cf\u20ac\u00e2\ufffd\u00a2(Z\u00e2\ufffd\u00a2(D))\u011f\ufffd\u2018\ufffd23\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7p \u00e2\u02c6\u02c6 { 2 , 3 } \u00e2\u02c6\u00a9 italic_\u00cf\u20ac ( italic_Z ( italic_D ) ), \u011f\ufffd\ufffd\ufffdpsubscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\ufffd{ P}_{p}bold_P start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u00e2\u02c6\u02c6\u00cf\u20ac\u00e2\ufffd\u00a2(D)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u2039\u011f\ufffd\ufffd\u00b7p \u00e2\u02c6\u02c6 italic_\u00cf\u20ac ( italic_D ), and \u011f\ufffd\ufffd\ufffd\u00cf\u20ac,\u00cf\u20ac\u00e2\u20ac\u00b2(p,q){ Q}_{ start_POSTSUBSCRIPT italic_\u00cf\u20ac , italic_\u00cf\u20ac start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ( italic_p , italic_q end_POSTSUBSCRIPT ) for all pairs {p,q}\u00e2\u02c6\u00a9\u00cf\u20ac\u00e2\ufffd\u00a2(D)\u00e2\u2030 \u00e2\u02c6\u2026\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u2039\u011f\ufffd\ufffd\u00b7 italic_p , italic_q } \u00e2\u02c6\u00a9 italic_\u00cf\u20ac ( italic_D ) \u00e2\u2030 \u00e2\u02c6\u2026. 3. In the case when \u00cf\u0192=\u00cf\u01921={{2},{3},{5}\u00e2\ufffd\u00a2\u00e2\u20ac\u00a6}\u011f\ufffd\u0153\ufffdsuperscript\u011f\ufffd\u0153\ufffd1235\u00e2\u20ac\u00a6 = italic_\u00cf\u0192 start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT = { { 2 } , { 3 } , { 5 } \u00e2\u20ac\u00a6 } (see Example 1.2(ii)) we get from Theorem E the following clarification of Theorem D. Corollary 4.3. G\u011f\ufffd\ufffd\u00baGitalic_G is a P\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2021PTitalic_P italic_T-group if and only if G\u011f\ufffd\ufffd\u00baGitalic_G has a normal perfect subgroup D\u011f\ufffd\ufffd\u00b7Ditalic_D such that: (i) G/D\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7G/Ditalic_G / italic_D is a soluble P\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2021PTitalic_P italic_T-group, and (i) if D\u00e2\u2030 1\u011f\ufffd\ufffd\u00b71D 1italic_D \u00e2\u2030 1, G\u011f\ufffd\ufffd\u00baGitalic_G has a Robinson complex (D,Z\u00e2\ufffd\u00a2(D);U1,\u00e2\u20ac\u00a6,Uk)\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02dc(D,Z(D);U_{1}, italic_D , italic_Z ( italic_D ) ; italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) and (iii) for any set {i1,\u00e2\u20ac\u00a6,ir}\u00e2\u0160\u2020{1,\u00e2\u20ac\u00a6,k}subscript\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u01781\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u02dc italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT } \u00e2\u0160\u2020 { 1 , \u00e2\u20ac\u00a6 , italic_k }, where 1\u00e2\u2030\u00a4r<k1\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u02dc1 r<k1 \u00e2\u2030\u00a4 italic_r < italic_k, G\u011f\ufffd\ufffd\u00baGitalic_G and G/Ui1\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2\u00e2\u2039\u00af\u00e2\ufffd\u00a2Uir\u00e2\u20ac\u00b2\u011f\ufffd\ufffd\u00basuperscriptsubscript\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00b2\u00e2\u2039\u00afsuperscriptsubscript\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u0178\u00e2\u20ac\u00b2G/U_{i_{1}}^{ U_{i_{r}}^{ / italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u2039\u00af italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT satisfy \u011f\ufffd\ufffd\ufffdpsubscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\ufffd{ N}_{p}bold_N start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u00e2\u02c6\u02c6{2,3}\u00e2\u02c6\u00a9\u00cf\u20ac\u00e2\ufffd\u00a2(Z\u00e2\ufffd\u00a2(D))\u011f\ufffd\u2018\ufffd23\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7p \u00e2\u02c6\u02c6 { 2 , 3 } \u00e2\u02c6\u00a9 italic_\u00cf\u20ac ( italic_Z ( italic_D ) ) and \u011f\ufffd\ufffd\ufffdpsubscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\ufffd{ P}_{p}bold_P start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u00e2\u02c6\u02c6\u00cf\u20ac\u00e2\ufffd\u00a2(D)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u2039\u011f\ufffd\ufffd\u00b7p \u00e2\u02c6\u02c6 italic_\u00cf\u20ac ( italic_D ). 4. In the paper [21], the following special case of Theorem F was proved. Corollary 4.4. A group G\u011f\ufffd\ufffd\u00baGitalic_G is an M\u00e2\ufffd\u00a2T\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2021MTitalic_M italic_T-group if and only if G\u011f\ufffd\ufffd\u00baGitalic_G has a perfect normal subgroup D\u011f\ufffd\ufffd\u00b7Ditalic_D such that: (i) G/D\u011f\ufffd\ufffd\u00ba\u011f\ufffd\ufffd\u00b7G/Ditalic_G / italic_D is an M\u011f\ufffd\u2018\u20acMitalic_M-group, (ii) if D\u00e2\u2030 1\u011f\ufffd\ufffd\u00b71D 1italic_D \u00e2\u2030 1, G\u011f\ufffd\ufffd\u00baGitalic_G has a Robinson complex (D,Z\u00e2\ufffd\u00a2(D);U1,\u00e2\u20ac\u00a6,Uk)\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u2018\u02c61\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02dc(D,Z(D);U_{1}, italic_D , italic_Z ( italic_D ) ; italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) and (iii) for any set {i1,\u00e2\u20ac\u00a6,ir}\u00e2\u0160\u2020{1,\u00e2\u20ac\u00a6,k}subscript\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u01781\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u02dc italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT } \u00e2\u0160\u2020 { 1 , \u00e2\u20ac\u00a6 , italic_k }, where 1\u00e2\u2030\u00a4r<k1\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u02dc1 r<k1 \u00e2\u2030\u00a4 italic_r < italic_k, G\u011f\ufffd\ufffd\u00baGitalic_G and G/Ui1\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2\u00e2\u2039\u00af\u00e2\ufffd\u00a2Uir\u00e2\u20ac\u00b2\u011f\ufffd\ufffd\u00basuperscriptsubscript\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00b2\u00e2\u2039\u00afsuperscriptsubscript\u011f\ufffd\u2018\u02c6subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u0178\u00e2\u20ac\u00b2G/U_{i_{1}}^{ U_{i_{r}}^{ / italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u2039\u00af italic_U start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT satisfy \u011f\ufffd\ufffd\ufffdpsubscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\ufffd{ N}_{p}bold_N start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u00e2\u02c6\u02c6\u00cf\u20ac\u00e2\ufffd\u00a2(Z\u00e2\ufffd\u00a2(D))\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7p \u00e2\u02c6\u02c6 italic_\u00cf\u20ac ( italic_Z ( italic_D ) ), \u011f\ufffd\ufffd\ufffdpsubscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\ufffd{ P}_{p}bold_P start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for all p\u00e2\u02c6\u02c6\u00cf\u20ac\u00e2\ufffd\u00a2(D)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u2039\u011f\ufffd\ufffd\u00b7p \u00e2\u02c6\u02c6 italic_\u00cf\u20ac ( italic_D ), and \u011f\ufffd\ufffd\u0152p,qsubscript\u011f\ufffd\ufffd\u0152\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd{ M}_{p,q}bold_M start_POSTSUBSCRIPT italic_p , italic_q end_POSTSUBSCRIPT for all pairs {p,q}\u00e2\u02c6\u00a9\u00cf\u20ac\u00e2\ufffd\u00a2(D)\u00e2\u2030 \u00e2\u02c6\u2026.\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u2039\u011f\ufffd\ufffd\u00b7 italic_p , italic_q } \u00e2\u02c6\u00a9 italic_\u00cf\u20ac ( italic_D ) \u00e2\u2030 \u00e2\u02c6\u2026 . Remark 4.5. Theorem F not only strengthens Corollary 4.4 but also gives a new proof of it.",
        "keywords": ""
    },
    {
        "id": 10,
        "title": "VR Isle Academy: A VR Digital Twin Approach for Robotic Surgical Skill Development",
        "abstract": "Abstract.Contemporary progress in the field of robotics, marked by improved\nefficiency and stability, has paved the way for the global adoption of\nsurgical robotic systems (SRS).\nWhile these systems enhance surgeons\u00e2\u20ac\u2122 skills by offering a more\naccurate and less invasive approach to operations, they come at a\nconsiderable cost.\nMoreover, SRS components often involve heavy machinery, making the\ntraining process challenging due to limited access to such equipment.\nIn this paper we introduce a cost-effective way to facilitate training\nfor a simulator of a SRS via a portable,\ndevice-agnostic, ultra realistic simulation with hand tracking and\nfeet tracking support.\nError assessment is accessible in both real-time and offline,\nwhich enables the monitoring and tracking of users\u00e2\u20ac\u2122 performance.\nThe VR application has been objectively evaluated by several untrained\ntesters showcasing significant reduction in error metrics as the\nnumber of training sessions increases.\nThis indicates that the proposed VR application denoted asVR Isle Academyoperates efficiently, improving the robot - controlling\nskills of the testers in an intuitive and immersive way towards\nreducing the learning curve at minimal cost.",
        "corpus": "Contemporary progress in the field of robotics, marked by improved efficiency and stability, has paved the way for the global adoption of surgical robotic systems (SRS). While these systems enhance surgeons\u00e2\u20ac\u2122 skills by offering a more accurate and less invasive approach to operations, they come at a considerable cost. Moreover, SRS components often involve heavy machinery, making the training process challenging due to limited access to such equipment. In this paper we introduce a cost-effective way to facilitate training for a simulator of a SRS via a portable, device-agnostic, ultra realistic simulation with hand tracking and feet tracking support. Error assessment is accessible in both real-time and offline, which enables the monitoring and tracking of users\u00e2\u20ac\u2122 performance. The VR application has been objectively evaluated by several untrained testers showcasing significant reduction in error metrics as the number of training sessions increases. This indicates that the proposed VR application denoted as VR Isle Academy operates efficiently, improving the robot - controlling skills of the testers in an intuitive and immersive way towards reducing the learning curve at minimal cost. In recent years, the trajectory of medical training has significantly shifted, incorporating the latest technological advancements. However, this transition is not extensively adopted in universities or other institutions that focus on medical training, primarily due to the limited availability of market products and the high cost of the required training equipment. To this day, due to the aforementioned reasons, the majority of surgical training courses still adhere to a pattern of the 16th-century training procedure\u00c2 (Kostylev, 2000) where the trainees simply observe the expert-surgeon/tutor perform surgery. Contemporary advancements in the field of robotics have established robotic surgical systems as a viable option for performing highly precise minimally invasive operations enabling the surgeon to operate while seated. Some of the surgical robotic systems that are out in the market are the da Vinci surgical system (https://www.intuitive.com/en-us/products-and-services/da-vinci), Senhance surgical system (https://www.asensus.com/) and Flex robotic system (https://novusarge.com/en/medical-products/flex-robotic-system/). The da Vinci Surgical System (Intuitive, 2024) has is one of the most widely used robotic surgical systems (Peters et\u00c2 al., 2018). This system has been used for many different operations such as cardiac, colorectal, general, gynecologic, head and neck, thoracic, and urologic surgeries\u00c2 (Peters et\u00c2 al., 2018). In 2021, 6500 da Vinci Surgical system were installed in 67 different countries and 55.000 doctors were trained to use it\u00c2 (int, 2021; Xue and Liu, 2022). The cost of acquiring and maintaining the above Surgical System is significant. Due to cost considerations of acquiring it and the low amount of systems around the world, various companies have capitalized on private training courses tailored for doctors and surgeons. The field of Virtual Reality (VR) has undergone major advancements with powerful VR headsets being able to render entire worlds in real-time. This has introduced a new market for VR, in medical training. VR training offers an immersive experience for the trainees who enhance their hard-skills inside the virtual world and gain experience by training their hard-skills. Researchers across the globe have directed their efforts towards enhancing the scientific domain of VR medical training by introducing innovative solutions to address existing challenges, such as those highlighted in (Liao et\u00c2 al., 2022), (Chiang et\u00c2 al., 2013). Recognizing the necessity for a more convenient, affordable, and portable approach to utilize SRS, we suggest an advanced VR Ultra Realistic training simulation for surgical robotic systems. Figure\u00c2 1a illustrates the user utilizing the machine that controls the robotic arms, with figure\u00c2 1b depicting the view from the simulated training scenario. Figures\u00c2 1c and \u00c2 1d respectively demonstrate a user being trained in the same scenario using our application along with his view within VR. This VR simulation democratizes the training of these systems with a \u00e2\u20ac\u0153device-agnostic\u00e2\u20ac\ufffd strategy by reducing the cost of training and smoothing out the learning curve. The incorporation of feet tracking enhances user immersion, providing an authentic training experience for a surgical robotic system. The main contribution of this work is to present a complete digital-twin of the SRS training process. To the best of our knowledge, VR Isle Academy is the first approach that provides the full training experience entirely in VR. In this paper, we selected da Vinci as the reference point due to its renowned reputation within the global community of surgeons. However, the work accomplished can be adapted to replicate any SRS system and not just the mechanics and training scenarios of the reference SRS. By leveraging available tools, we\u00e2\u20ac\u2122ve developed a VR simulation enabling trainees to undergo SRS training conveniently, irrespective of location or time constraints. This addresses the challenge posed by the limited availability of SRS training devices in certain geographical areas, thereby saving both time and expenses associated with traditional training methods. A Digital Twin is a virtual representation, mirroring a physical object or process in the digital realm with a high-fidelity resemblance. The term was publicly introduced by Michael Grieves for a product lifecycle management\u00c2 (Batty, 2018). In the modern age, digital twins are extensively utilized across various sectors including power generation equipment, structures, manufacturing operations, automotive industry, healthcare services, and urban planning\u00c2 (IBM, 2024). Specifically, in domains such as SRS training, digital twins offer opportunities to simulate either real-life procedures, like laparoscopic surgery using the SRS, or typical training scenarios utilized for doctor training in SRS procedures. Within the framework of our project, we\u00e2\u20ac\u2122ve developed a digital twin of the SRS training simulator, which can simulate real surgical operations when necessary. Numerous efforts have been made to expedite the training and education process in the medical field using VR. Recently, the cost of acquiring and maintaining commercial VR head-mounted displays (HMDs) has decreased. Furthermore, the contemporary advancements in HMD technology significantly enhance the overall performance of standalone applications. To this end, VR technology has been widely adopted for facilitating medical training not only for students but also for health care professionals. Several research papers and examples have demonstrated that VR training in the medical field reduces malpractices, training time, and the learning curve\u00c2 (Cevallos et\u00c2 al., 2022; Blumstein et\u00c2 al., 2020; McKinney et\u00c2 al., 2022; Kenanidis et\u00c2 al., 2023). To facilitate the development of medical training scenarios, several software development kits (SDK) have been released. MAGES SDK\u00c2 (Zikas et\u00c2 al., 2023) is an innovative SDK that empowers developers with numerous tools to efficiently create fast and effective medical training scenarios. Paul Zikas et al. (Zikas et\u00c2 al., 2023) highlight the latest advancements in the aforementioned SDK, including 5G edge-cloud remote rendering, a physics dissection layer, real-time simulation of organic tissues as soft-bodies within 10 ms, a highly realistic cutting and tearing algorithm, neural network assessment for user profiling, and a VR recorder for recording, replaying, and debriefing training simulations from any perspective. Fundamental Core\u00c2 (fun, 2017) is an all-in-one SDK for Unity game engine. The developer has the capability to establish a scoring system for real-time results at the end of a playthrough. Additionally, they provide a ready-to-use multiplayer service enabling users to connect and train together, complete with voice communication. Lastly, the SDK is device-agnostic and compatible with various VR headsets. The da Vinci machine, a Surgical Robotic System developed by Intuitive (https://intuitive.com), stands as the most widely utilized SRS globally. This surgical system provides the surgeon with an advanced set of instruments for conducting robotic-assisted minimally invasive surgery. It consists of a surgeon\u00e2\u20ac\u2122s console, the four robotic arms that are scissors, scalpel, 3D cameras and forceps that are connected and moved from the surgeon\u00e2\u20ac\u2122s console and the vision cart which makes the connection between the surgeon\u00e2\u20ac\u2122s console and the robotic arms. Moreover, the surgeon is provided with a superior vision, through the 3D real-time high-definition view with a magnifier that can reach up to 10 times more than the human eye can see. Moreover, the ergonomic design of the surgeon\u00e2\u20ac\u2122s console allows the surgeon to operate while seated for extended periods, ensuring high efficiency in incisions. The design also provides the surgeon with the capability to utilize hand controllers and foot pedals for the machine\u00e2\u20ac\u2122s various functionalities. Lastly, the machine offers various functionalities triggered by pedals, masters, or the touch screen. The Camera Pedal allows adjustment of the position and orientation of the camera attached to a robotic arm. The Clutch Pedal is used to extend or shorten the robotic arm. Four energy pedals control the electro-surgical instruments. The 30-degree view pedal toggles between different camera views. Lastly, the red circle indicates the output of the cameras. The current bibliography includes numerous VR training simulations incorporating advanced cognitive and psychomotor techniques aimed at maximizing educational advantages for trainees, exemplified by references such as (Zikas et\u00c2 al., 2022) and (Kenanidis et\u00c2 al., 2023). However, despite this proliferation, simulations tailored for training in SRS within XR environments remain relatively scarce. Sketchy Neurons (https://sketchyneurons.com/) have created a VR game called Minimally Invasive (https://store.steampowered.com/app/2331420/Minimally_Invasive/) that uses a surgical robotic system. The concept of the game is that the user is a transplant surgeon and will have to burn, slice and operate aliens. They claim to have realistic physics and that the tools that are used are developed by actual surgeons. In the VR game, you can train on how to use and operate the robotic arms. They have created a menu where you can select to train and learn how to move and operate the robotic arms. The user will encounter six scenarios designed to teach functionalities similar to those of a clutch and camera. While they have embraced a device agnostic approach by incorporating SteamVR (https://store.steampowered.com/app/250820/SteamVR/), it\u00e2\u20ac\u2122s worth noting that the game requires tethering, which significantly reduces portability. Moreover, the application lacks realism by not imposing hand restrictions on the user, as opposed to a real SRS. Lastly, the physics appears to be implemented in a manner that lacks realism. Surgical Robot Simulator (https://store.steampowered.com/app/1727070/Surgical_Robot_Simulator/) is another VR serious game that incorporates the fundamentals of an SRS. The game provides tutorials on controller usage and offers a range of scenarios to engage with. A notable feature of this game is the utilization of deformation algorithms, allowing users to cut and manipulate deformable meshes. Despite its realistic graphics and the mesh deformation algorithm, the control scheme for manipulating forceps and robotic arms is neither optimal nor intuitive. Users can only control the movement and rotation of the robotic arms, while the rotation of the forceps is adjusted via the thumbstick. This configuration makes it challenging to intuitively and seamlessly manipulate the medical tool of the robot. Xiaoyu Cai et al. (Cai et\u00c2 al., 2023) proposed a robotic minimally invasive surgical simulator based on VR digital. In their research they used Pimax (https://pimax.com/) for the VR headset and two 3DSystems (https://www.3dsystems.com/haptics-devices/touch) Touch devices and two UR5 robots (https://www.universal-robots.com/). While they have successfully linked the virtual and physical realms, there are still certain elements they are missing. Primarily, the application lacks portability, as it necessitates the presence of the robotic arm, touch devices, and the large machine designed to simulate the SRS. Furthermore, they do not incorporate any pedals, whether virtual or physical, to activate essential functions such as the clutch and camera. Finally, their solution is not cost-effective, mainly due to the necessary equipment required for the system to function effectively. Marco Ferro et al. (Ferro et\u00c2 al., 2019) proposed a portable da Vinci simulator in VR using cheap haptic interfaces and an Oculus Rift (https://www.oculus.com) to replicate the master console of the da Vinci. Despite its affordability, the system lacks portability due to the use of two styluses and a tethered connection to a desktop PC. Additionally, immersion is constrained, with users confined to a training scene, while clutch functionality is implemented through stylus\u00e2\u20ac\u2122 buttons. Unity (https://unity.com/) is a cross-platform game engine that can be used to create two-dimensional and three-dimensional games. The engine offers a primary scripting API in C#. We used a variety of external plugins in order to create this digital twin environment. The core plugin we used in order to create each training scenario is MAGES SDK, a robust tool enabling the creation of immersive XR simulations. From this kit, we used the analytics engine in order to capture the events needed to provide the user with realtime and offline feedback, and scores depending on their performance. Also, the VR editor facilitates the quick and straightforward development of scenarios. Using scenegraph, a virtual editor that lets you create action nodes and modify existing ones in order to form a training scenario, we were able to create some of the basic scenarios of a SRS. More about them in the section 3.3. Action nodes correspond to a certain task that has to be completed in VR. The developer can either use one of the predefined action types, such as insert action, remove action, use action, or create his own action type. Although our implementation is Unity-based, our approach can be leveraged and implemented into any modern game engine. The surgical robotic system employed in the VR environment consists of two parts, which are commonly coined as master and slave\u00c2 (Low and Phee, 2004). The master platform is controlled by the user with two-joystick-like controls (Fig.\u00c2 3) and two pedals that can be utilized for changing functionalities when necessary. On the other hand, the slave is located in a different area within the scene and consists of two 6-Degrees of Freedom (DoFs) robotic arms. Each robotic arm is equipped with a 1-DoF two-jaw gripper end effector (the tool mounted at the end of the robotic arm) featuring multiple box collider (Fig.\u00c2 3), enhancing the realism and physics accuracy of haptic interactions with objects of various shapes within the scene. The master platform was acquired from\u00c2 (ope, 2023) and it was modified appropriately to improve rendering speed and the overall efficiency of the model. The robotic arm was designed entirely by our team while drawing inspiration from the specifications of the da Vinci surgical robot (https://www.intuitive.com/en-us/products-and-services/da-vinci), the most widely utilized robotic system for minimally invasive surgeries\u00c2 (Xue and Liu, 2022). Moreover, we aimed to replicate the surgeon\u00e2\u20ac\u2122s console, allowing users to customize the head height of the machine and adjust the position of the pedals to optimize ergonomic posture. Users can also re-calibrate the trackers to easily configure their height. These operations can be performed conveniently through the virtual tablet on the console. In our application, we simulated eleven scenarios basic resembling those found in a modern SRS. These scenarios are designed to familiarize the user with the control of the robotic arms, the clutch pedal, the camera pedal, and the 30-degree camera. The purpose of these activities is to provide the user with an interactive introduction to the surgical system\u00e2\u20ac\u2122s features. More precisely, some exercises try to mix various functionalities in a single scenario, while other lessons concentrate on a single one, such as the camera function in the Camera 0 scenario. For example, in the Sea Spikes exercises the user must learn how to manage delicate wrist movements while combining the camera and clutch functionalities effectively. Through a User-Interface (UI) menu (Fig. 7), the users can choose to train in any one of the 12 scenarios. Instructions (Fig. 4) detailing the objective of the exercise and the user\u00e2\u20ac\u2122s responsibilities are provided for each scenario. For instance, in Wrist Articulation 1, users are instructed to touch the ball inside the glass cube, without breaking the exterior glass. The implementation of the exercises was carried out using the scenegraph framework from the MAGES SDK. In this framework, exercises can be seen as Actions that users have to perform. Exercises that require repetition, such as Wrist Articulation 1 or Camera 0, are implemented as one action that is repeated X\u011f\ufffd\u2018\u2039Xitalic_X times, where X\u011f\ufffd\u2018\u2039Xitalic_X is the amount of total iterations the scenario requires. To exemplify, in Wrist Articulation 1, the users have to perform two actions (in this case, place the instruments on a specific position and touch the glowing ball) ten times, but on a different angle. Lastly, more scenarios can be seamlessly added to the application in order to enhance the variety of the training options. In this section, we elucidate the scoring system we include in our application, used for the qualitative assessment of the users\u00e2\u20ac\u2122 performance. Through error detection and analytic metrics for each exercise, the users can monitor their progress and improve their skills. Each exercise contains a list of efficiency and penalty scores used to assess the overall score of the session. The scoring factors and analytics metrics of VR Isle Academy were designed and implemented based on the corresponding factors of a modern SRS, with a focus on retaining the different weight and importance of each metric to the final score of each exercise. The main focus of VR Isle Academy regarding the scoring system is to retain the importance of each metric when providing user performance feedback. In order to extract information regarding the scoring factors and their importance, an iterative procedure was followed, where we carefully examined the scores and their breakdown in the actual simulation for each and every exercise. Each metric score is calculated using a weight factor. This weight factor varies from metric to metric. For instance, the \u00e2\u20ac\ufffddrops\u00e2\u20ac\ufffd metric which represents the times an object held by the instruments fell on the environment, has a bigger weight factor than the \u00e2\u20ac\ufffdexcessive force\u00e2\u20ac\ufffd metric, which measures the times excessive force was applied by the instruments to an object, while the \u00e2\u20ac\ufffdtower detach\u00e2\u20ac\ufffd metric fails the exercise immediately. The total score of an action is formed as such: As can be observed, the analytic metrics are split into two main categories: Efficiency Metrics and Penalty Scores. The first category includes two metrics; \u00e2\u20ac\ufffdtotal time\u00e2\u20ac\ufffd, representing the total time needed to complete the exercise, and \u00e2\u20ac\ufffdeconomy of motion\u00e2\u20ac\ufffd, which is the travel distance of the instruments during the exercise. Both metrics have an initial score of fifty (50) points. When the duration for completing the scenario exceeds a predetermined threshold or the user makes unnecessary movements (thus increasing the total distance), points are deducted. For the implementation of the scoring system, we used the analytics framework from the MAGES SDK. We mainly utilized the custom scoring factors that monitor data from objects. For instance, in order to compute the \u00e2\u20ac\ufffdeconomy of motions metric\u00e2\u20ac\ufffd, we summarize the total changes of both position and rotation for each bone in our Inverse Kinematic (IK) chain. More details about the IK solver will be discussed in Section 4.1. Upon exercise completion a detailed breakdown of the score is presented to the user that also includes the penalty deducted points through a User Interface (see Fig. 8-Top). Furthermore, MAGES automatically uploads analytics data for each exercise to a web browser portal (see Fig. 8-Bottom) after finishing a training scenario. Users can log in using their credentials and gain access to a detailed log of each training session that showcases their analytics. The primary objective of this section is to present the control framework designed to guide the robot in accurately tracking the user\u00e2\u20ac\u2122s movements in an intuitive way. The user holds the VR controllers and by moving them, he can translate and rotate the two machine controllers within the virtual reality environment. These machine controllers, which will be referred to as \u00e2\u20ac\u0153masters\u00e2\u20ac\ufffd, directly control the robotic arms in the operation room. Each robot arm\u00e2\u20ac\u2122s end effector (EE) should achieve the corresponding desired pose (as extracted by the masters) accurately in real-time without significant delay. To this end, the computational complexity of the code is of pivotal importance when developing such a framework. First, the 6-DoF pose (position and orientation) of each master is mapped into the desired pose for the corresponding EE (left and right). The mathematical expressions in this section will be formulated for one master and one EE since the left and right arms are considered equivalent. To prevent gimbal locks and other issues associated with representing rotations using Euler angles, rotation matrices are employed to express rotations, while transformation matrices are utilized for poses. Let \u011f\ufffd\u2018\u00bbWM\u00e2\u02c6\u02c6S\u00e2\ufffd\u00a2E\u00e2\ufffd\u00a2(3)superscriptsubscript\u011f\ufffd\u2018\u00bb\u011f\ufffd\u2018\u0160\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2020\u011f\ufffd\ufffd\u00b83 SE(3)bold_italic_T start_POSTSUBSCRIPT italic_W end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT \u00e2\u02c6\u02c6 italic_S italic_E ( 3 ) be the pose of the master with respect to an inertial frame, or, world frame. S\u00e2\ufffd\u00a2E\u00e2\ufffd\u00a2(3)\u011f\ufffd\u2018\u2020\u011f\ufffd\ufffd\u00b83SE(3)italic_S italic_E ( 3 ) is the Special Euclidean group in three dimensions, while \u011f\ufffd\u2018\u00bbWMsuperscriptsubscript\u011f\ufffd\u2018\u00bb\u011f\ufffd\u2018\u0160\u011f\ufffd\u2018\u20ac start_POSTSUBSCRIPT italic_W end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT is a 4\u00c3\u20144444 44 \u00c3\u2014 4 homogeneous transformation matrix represents the translation and rotation from world frame (W)\u011f\ufffd\u2018\u0160(W)( italic_W ) to the master frame (M)\u011f\ufffd\u2018\u20ac(M)( italic_M ) and it is defined as: where \u011f\ufffd\u2018\u00b9WM\u00e2\u02c6\u02c6S\u00e2\ufffd\u00a2O\u00e2\ufffd\u00a2(3)superscriptsubscript\u011f\ufffd\u2018\u00b9\u011f\ufffd\u2018\u0160\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2020\u011f\ufffd\u2018\u201a3 SO(3)bold_italic_R start_POSTSUBSCRIPT italic_W end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT \u00e2\u02c6\u02c6 italic_S italic_O ( 3 ) is the 3\u00c3\u20143333 33 \u00c3\u2014 3 rotation matrix which belongs to the Special Orthogonal group, \u011f\ufffd\u2019\u2018\u00e2\u02c6\u02c6\u00e2\u201e\ufffd3\u011f\ufffd\u2019\u2018superscript\u00e2\u201e\ufffd3 \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT the translation part, \u011f\ufffd\u2019\u2018=[x,y,z]T\u011f\ufffd\u2019\u2018superscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u2021 = [ italic_x , italic_y , italic_z ] start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT and \u011f\ufffd\u0178\ufffd=[0,\u00e2\u20ac\u201e0,\u00e2\u20ac\u201e0]00\u00e2\u20ac\u201e0\u00e2\u20ac\u201e0 = [ 0 , 0 , 0 ]. At each iteration, the orientation of the master is mapped to the EE\u00e2\u20ac\u2122s frame to extract the desired orientation (Rd)subscript\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u2018(R_{d})( italic_R start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ): where, RW\u00e2\ufffd\u00a2tMsuperscriptsubscript\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u0160\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u20acR_{Wt}^{M}italic_R start_POSTSUBSCRIPT italic_W italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT is the current orientation of the master at time t\u011f\ufffd\u2018\u00a1titalic_t, (RW\u00e2\ufffd\u00a20M)Tsuperscriptsuperscriptsubscript\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u01600\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2021(R_{W0}^{M})^{T}( italic_R start_POSTSUBSCRIPT italic_W 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT is the transpose (or inverse) of the initial orientation of the master and, RW\u00e2\ufffd\u00a20E\u00e2\ufffd\u00a2Esuperscriptsubscript\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u01600\u011f\ufffd\ufffd\u00b8\u011f\ufffd\ufffd\u00b8R_{W0}^{EE}italic_R start_POSTSUBSCRIPT italic_W 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_E italic_E end_POSTSUPERSCRIPT is the initial orientation of the EE. For computing the desired position of the EE, \u011f\ufffd\u2019\u2018d:=[xd,yd,zd]assignsubscript\u011f\ufffd\u2019\u2018\u011f\ufffd\u2018\u2018subscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2018subscript\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u2018subscript\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT := [ italic_x start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT , italic_z start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ], with respect to its own initial position, the following formula is utilized: where \u011f\ufffd\u2019\u20180E\u00e2\ufffd\u00a2Esuperscriptsubscript\u011f\ufffd\u2019\u20180\u011f\ufffd\ufffd\u00b8\u011f\ufffd\ufffd\u00b8 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_E italic_E end_POSTSUPERSCRIPT is the initial position of the EE, \u011f\ufffd\u2019\u2018tMsuperscriptsubscript\u011f\ufffd\u2019\u2018\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u20ac start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT is the current position of the master, \u011f\ufffd\u2019\u20180Msuperscriptsubscript\u011f\ufffd\u2019\u20180\u011f\ufffd\u2018\u20ac start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT is the initial position of the master and finally \u00ce\u00b1\u011f\ufffd\u203a\u00bc which denotes the translation sensitivity multiplier. Moreover, \u00ce\u00b1\u011f\ufffd\u203a\u00bc is a hyperparameter that specifies the amount of change in the position of the EE for a certain displacement of the master. Given that this implementation is specifically tailored for surgical systems, enhancing the overall accuracy requires reducing the movement of the EE to considerably less than that of the master\u00e2\u20ac\u2122s displacement (\u00ce\u00b1\u00e2\u2030\u00aa1)much-less-than\u011f\ufffd\u203a\u00bc1 1 italic_\u00ce\u00b1 \u00e2\u2030\u00aa 1 ). At every time step, after extracting the desired pose of the EE using equations (2) and (3), the corresponding control inputs (u\u00e2\u02c6\u02c6\u00e2\u201e\ufffd6\u011f\ufffd\u2018\u00a2superscript\u00e2\u201e\ufffd6u \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT) that achieve this pose are calculated using Inverse Kinematics (IK). To this end, we have developed a numerical-approximation IK solver that is utilized to determine the control inputs for each fully-actuated manipulator as follows. Consider the forward kinematics equation \u011f\ufffd\u2019\u2122=\u011f\ufffd\u2019\u2021\u00e2\ufffd\u00a2(\u011f\ufffd\u0153\u00bd)\u011f\ufffd\u2019\u2122\u011f\ufffd\u2019\u2021\u011f\ufffd\u0153\u00bd = bold_italic_f ( bold_italic_\u00ce\u00b8 ), where \u011f\ufffd\u2019\u2021:\u00e2\u201e\ufffd6\u00e2\u2020\u2019\u00e2\u201e\ufffd6:\u011f\ufffd\u2019\u2021\u00e2\u2020\u2019superscript\u00e2\u201e\ufffd6superscript\u00e2\u201e\ufffd6 : blackboard_R start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT \u00e2\u2020\u2019 blackboard_R start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT is the forward kinematics function, \u011f\ufffd\u2019\u2122\u00e2\u02c6\u02c6\u00e2\u201e\ufffd6\u011f\ufffd\u2019\u2122superscript\u00e2\u201e\ufffd6 \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT is the pose of the EE and \u011f\ufffd\u0153\u00bd\u00e2\u02c6\u02c6\u00e2\u201e\ufffd6\u011f\ufffd\u0153\u00bdsuperscript\u00e2\u201e\ufffd6 \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT are the joint angles of the robot. The three wrist joint angles are depicted in Fig.\u00c2 9. By deploying the Newton-Raphson method to solve the equation \u011f\ufffd\u2019\u02c6\u00e2\ufffd\u00a2(\u011f\ufffd\u0153\u00bdd)=\u011f\ufffd\u2019\u2122d\u00e2\u02c6\u2019\u011f\ufffd\u2019\u2021\u00e2\ufffd\u00a2(\u011f\ufffd\u0153\u00bdd)=0\u011f\ufffd\u2019\u02c6subscript\u011f\ufffd\u0153\u00bd\u011f\ufffd\u2018\u2018subscript\u011f\ufffd\u2019\u2122\u011f\ufffd\u2018\u2018\u011f\ufffd\u2019\u2021subscript\u011f\ufffd\u0153\u00bd\u011f\ufffd\u2018\u20180 ( bold_italic_\u00ce\u00b8 start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ) = bold_italic_x start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT - bold_italic_f ( bold_italic_\u00ce\u00b8 start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ) = 0, we extract the desired joint angles \u011f\ufffd\u0153\u00bddsubscript\u011f\ufffd\u0153\u00bd\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT that will result the desired pose for the EE \u011f\ufffd\u2019\u2122dsubscript\u011f\ufffd\u2019\u2122\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT by using the 1s\u00e2\ufffd\u00a2tsuperscript1\u011f\ufffd\u2018 \u011f\ufffd\u2018\u00a11^{st}1 start_POSTSUPERSCRIPT italic_s italic_t end_POSTSUPERSCRIPT order Taylor expansion\u00c2 (Lynch and Park, 2017): where, \u011f\ufffd\u0153\u00bdtsubscript\u011f\ufffd\u0153\u00bd\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is the current state of the robot, \u011f\ufffd\u2019\u2122dsubscript\u011f\ufffd\u2019\u2122\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT and \u011f\ufffd\u2019\u2122tsubscript\u011f\ufffd\u2019\u2122\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT are the desired and current pose of the EE respectively. \u011f\ufffd\u2018\u00b1\u00e2\u02c6\u20191\u00e2\ufffd\u00a2(\u011f\ufffd\u0153\u00bdd)superscript\u011f\ufffd\u2018\u00b11subscript\u011f\ufffd\u0153\u00bd\u011f\ufffd\u2018\u2018 start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( bold_italic_\u00ce\u00b8 start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ) is the inverse Jacobian matrix that maps changes from the task space into joint space. Ultimately, after computing \u011f\ufffd\u0153\u00bddsubscript\u011f\ufffd\u0153\u00bd\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT, we apply it to Unity\u00e2\u20ac\u2122s articulation drive component (https://docs.unity3d.com/Manual/class-ArticulationBody.html), which utilizes the information to extract the necessary forces for a smooth transition from the current to the desired joint angles. All SRS machinery is typically controlled via hand movements of the user through a controller-like system, as depicted in Figure 2. Similarly, this approach can be adopted in the corresponding VR digital-twin, utilizing the HMD controller. However in order to increase the system\u00e2\u20ac\u2122s portability whilst enhancing the intuitiveness of controlling the robotic arms (Huang et\u00c2 al., 2021), we opt to explore replicating controller movements through hand tracking technology. This technology could enhance the training experience, particularly because the pitcher-like movement of the actual SRS cannot be replicated with a commercially standard VR controller. Therefore, hand gestures could be readily identified using hand tracking. In VR Isle Academy, we explored hand tracking with Wave SDK on the HTC Vive XR Elite headset and the XR Hands (https://docs.unity3d.com/Packages/com.unity.xr.hands@1.1/manual/index.html) with the OpenXR (https://www.khronos.org/openxr/) loader on the Meta Quest 2/3 headsets. We aimed to replicate users\u00e2\u20ac\u2122 interactions and hand poses on the surgeon\u00e2\u20ac\u2122s console of an SRS, which led to the integration of hand tracking as can be observed in Fig. 10. Notably, the Wave SDK doesn\u00e2\u20ac\u2122t offer a straightforward method for pinch-based grabbing, in contrast to Unity\u00e2\u20ac\u2122s XR Hands, which include a built-in interaction mechanism. Notably, hand tracking, by relying solely on onboard VR sensors, has limitations. For instance, the user\u00e2\u20ac\u2122s hands might exceed the Field of View (FOV) of the VR cameras which results in loss of tracking. Another significant issue is self-occlusion in instances that the user engages in intricate hand poses. This complication led to the VR system being unable to accurately recognize when the user was pinching, consequently preventing the forceps from closing in the digital twin. While we successfully addressed the FOV problem by incorporating two HTC Vive Wrist Trackers on the user\u00e2\u20ac\u2122s wrists, the persistent self occlusion issue prompted. The hand tracking feature reserved solely for specific scenarios where pinch gesture is not required (such as Wrist Articulation). As a result, the pinch-like gesture that an SRS user would perform is instead performed via trigger buttons by the VR trainee. Our primary objective was to implement a foot tracking solution to interact with physical pedals within the VR, which in turn would trigger specific functionalities of the surgical robot. Initially, HTC Vive Trackers 3.0 were considered, but their reliance on external lighthouse cameras made them less suitable for our standalone application and their setup was not as straightforward as desired. Consequently, we opted for the HTC Vive Ultimate Trackers (https://www.vive.com/us/accessory/vive-ultimate-tracker/), primarily due to their compatibility with standalone VR system such as the HTC Vive XR Elite, and particularly for Android applications. HTC Vive Ultimate Trackers are an enhancement of the standard model. They are distinguished by the inclusion of two 3D cameras, which significantly refine the mapping of the user\u00e2\u20ac\u2122s surroundings. This addition allows for a more nuanced interaction within virtual environments. The Wave Tracker Manager from the Essence package is utilized in our application. It contains class references for each tracker, including the tracker ID. The manager provides two key functionalities: activating the initial start tracker, triggering the tracker interface for direct communication when the API starts, and enabling the use of XR Device to retrieve tracker data from UnityEngine. XR. InputDevice (https://docs.unity3d.com/ScriptReference/XR.InputDevice.html). This class is part of Unity\u00e2\u20ac\u2122s XR input subsystem, managing input devices in XR applications, defining an XR input device, and handling input features and haptic feedback. The script checks for instances where trackers may become stuck, specifically when they have a valid rotation but no positional data, issuing warnings to the user. It also verifies tracker connections based on their specific ID within the application. Once communication is established between the trackers and the headset, we implement the rotation and position data from the trackers onto the feet of the Full-Body avatar, ensuring an ongoing synchronization with the user\u00e2\u20ac\u2122s movements. Mini-map in video games is a small heads-up display (HUD) map which is usually placed at the corners of the screen to help the player navigate inside the virtual world. Usually, the mini-map contains topographical information regarding key objectives and world features. The utilization of feet trackers enables the user to literally press the pedals inside the virtual world. However, such action requires some form of feedback that will notify the user when the pedal has been pressed successfully. However, a physical form of feedback (vibration) is unavailable in HTC Vive Ultimate Trackers. To this end, we propose a visual feedback scheme by utilizing the minimap. We created a User-Interface (UI) that represents the placement of the pedals and two UI elements, one for each foot (Fig. 11). The mini-map is placed on the left side of the machine\u00e2\u20ac\u2122s screen (Fig. 12). For the pedals, the user can see the Clutch, Camera, Switch and all the energy types. These pedals are static, they cannot change position or orientation. From the other half, the user\u00e2\u20ac\u2122s feet UIs change position and scale. when the user moves his feet, the UI will change position. Then, by pressing one of the buttons, the UI icon of the particular pedal will turn black and an audible \u00e2\u20ac\ufffdclick\u00e2\u20ac\ufffd sound will be triggered in order to inform the user that he has pressed a pedal. Moreover, our approach solves another issue that corresponds to the height of the user\u00e2\u20ac\u2122s feet. If the user raises his leg, the feet UI will scale-up, signifying the foot displacement with the respect to the ground. To assess the effectiveness of our application and the impact on facilitating the medical training procedure, we conducted experiments involving 4 testers. The testers are medical students that do not possess any prior knowledge on operating an SRS. Each tester played 4 scenarios, repeating them 3 times. The order of scenarios was Wrist Articulation 1, Clutch, Camera 0, Sea Spikes 1, and Roller Coaster 1. Wrist Articulation 1 is the easiest scenario, whereas Roller Coaster 1 is the most challenging. The first three scenarios aim to familiarize the user with the core functionalities of the VR Isle Academy, namely, the control of the robotic arms, the clutch pedal and the camera movement. The remaining two scenarios involve a combination of robotic arms and camera movements, requiring users to execute precise actions. In Fig. 13, it is noticeable that the users achieved a higher score as they progress the training scenarios. This scenario is relatively easy, involving the task of learning how to manoeuvre the forceps correctly with minimal wrist movements. In Fig. 14, a distinction is evident between play 1 and play 2. This is attributed to the scenario\u00e2\u20ac\u2122s combination of correct wrist movement and pedal functionalities, making it challenging to grasp in a single attempt. The testers found it easy and intuitive to operate the surgeon\u00e2\u20ac\u2122s console for various training scenarios. The more they played, the easier it became for them to use. The most challenging concept to grasp was the feet trackers. Initially, users reported difficulty localizing their feet and whether they were pressing a pedal. This might stem from the fact that HTC Vive Ultimate trackers do not provide haptic feedback; hence, the mini-map and sound served as the only source of feedback. Upon familiarization, the users improved at controlling the trackers, getting accustomed to the mini-map. Even though the testers we selected are aspiring doctors, their background may not be fully aligned with the performance they achieved in the training scenarios. The ability to control a robotic arm should be intuitive and easy regardless of the user\u00e2\u20ac\u2122s background. Lastly, users who have actually tried the VR Isle Academy prior to using the real machine have reported an intuitive transition between the two. The required training time with an instructor was significantly reduced and their score was higher than the average. VR Isle Academy is a cost-effective solution that enables unsupervised training on operating an advanced SRS. Whether utilizing trackers, VR controllers, or Hand Tracking, the user enjoys the freedom to train in various settings. Thus, we minimized the need of using an explicit, bulky device. Also, the availability of the application is 24/7. Also, there\u00e2\u20ac\u2122s no need to schedule a slot or incur additional costs for a teaching service; the user can independently learn how to operate a Surgical Robotic System (SRS). Moreover, the advancements in VR tracking technology, especially with the introduction of HTC Vive Trackers and HTC Vive Ultimate Trackers, have substantially augmented the depth and breadth of virtual reality applications. These developments have not only heightened the immersive quality of VR but also expanded its practical applications across diverse fields. The ongoing evolution of VR technology promises further enhancements in tracking precision and user engagement. Even as users strive to familiarize themselves with tracker usage, the inclusion of a mini-map depicting the position and orientation of the feet has proven highly beneficial. This approach effectively addresses the feedback-related challenges by providing visual and auditory cues, enabling users to orient themselves correctly and press the intended pedal. The accurate error detection and comprehensive analytics are pivotal in such simulations. Surgeons undergoing training in this VR digital twin will benefit significantly from robust error detection mechanisms and detailed analytics. The user can check his analytics in real-time, while using the VR headset, or offline, by accessing a portal page. Although we explored the Hand Tracking approach, we found it less suitable. The ergonomic design of the machine often led to hands going beyond the FOV of the VR cameras. Additionally, self-occlusion occurred when adopting unnatural hand poses. This presented challenges as the application couldn\u00e2\u20ac\u2122t accurately detect when the user was \u00e2\u20ac\ufffdtapping\u00e2\u20ac\ufffd or \u00e2\u20ac\ufffdclosing\u00e2\u20ac\ufffd their fingers, impacting the simulation\u00e2\u20ac\u2122s fidelity. While we addressed the FOV issue by incorporating wrist trackers from HTC Vive, the problem of self-occlusion persisted. Although readily available tools were utilized for developing VR Isle Academy, the novelty lies in their effective integration. The combination of different features and techniques provides the users with a unique, immersive educational experience and value. Development will continue, introducing an additional twelve scenarios aimed at training users in utilizing the energy pedals, the switch pedal, and a pedal facilitating the transition between two robotic arms. Additionally, there will be diversification in the types of forceps, incorporating both mono-polar and bi-polar options, enabling the utilization of different energy sources. Currently, the sole method of employing the trackers independently is through the Wave SDK. However, there are plans to ensure compatibility of the Vive Ultimate Trackers with OpenXR. Preparations have been made, having already executed a port of the VR application to OpenXR for other HMDs like Meta Quest 2 and Meta Quest 3. Finally, controlled clinical trials involving surgeons will be conducted to assess the fidelity and resemblance between the real and the digital twin SRS. Two groups will be formed. Both groups will use the real SRS while only one of them will have been trained using VR Isle Academy. Subsequently, we will compare the efficiency and time taken by each user, comparing the usage of our application and an SRS versus using only an SRS.",
        "keywords": "Digital Twin , Medical Training , Virtual Reality\n, Inverse Kinematics , Surgical Robotic System"
    },
    {
        "id": 11,
        "title": "Navigating the Future of Federated Recommendation Systems with Foundation Models",
        "abstract": "AbstractIn recent years, the integration of federated learning (FL) and recommendation systems (RSs), known as Federated Recommendation Systems (FRSs), has attracted attention for preserving user privacy by keeping private data on client devices. However, FRS faces inherent limitations such as data heterogeneity and scarcity, due to the privacy requirements of FL and the typical data sparsity issues of RSs.\nFoundation models (FMs), such as diffusion models (DMs) and large language models (LLMs), which are widely recognized for producing high-quality content in the image and NLP domains, focus on understanding and mimicking the underlying distribution of the training data. Unlike discriminative models, which learn the boundaries between categories, FMs aim to learn the entire probability distribution of the input data. Thus, the achievements of FMs inspire the design of FRS and suggest a promising research direction: integrating foundation models to address the above limitations.\nIn this study, we conduct a comprehensive review of FRSs with FMs. Specifically, we: 1) summarise the common approaches of current FRSs and FMs; 2) review the challenges posed by FRSs and FMs; 3) discuss potential future research directions; and 4) introduce some common benchmarks and evaluation metrics in the FRS field.\nWe hope that this survey provides the necessary background and guidance to explore this interesting and emerging topic.",
        "corpus": "In recent years, the integration of federated learning (FL) and recommendation systems (RSs), known as Federated Recommendation Systems (FRSs), has attracted attention for preserving user privacy by keeping private data on client devices. However, FRS faces inherent limitations such as data heterogeneity and scarcity, due to the privacy requirements of FL and the typical data sparsity issues of RSs. Foundation models (FMs), such as diffusion models (DMs) and large language models (LLMs), which are widely recognized for producing high-quality content in the image and NLP domains, focus on understanding and mimicking the underlying distribution of the training data. Unlike discriminative models, which learn the boundaries between categories, FMs aim to learn the entire probability distribution of the input data. Thus, the achievements of FMs inspire the design of FRS and suggest a promising research direction: integrating foundation models to address the above limitations. In this study, we conduct a comprehensive review of FRSs with FMs. Specifically, we: 1) summarise the common approaches of current FRSs and FMs; 2) review the challenges posed by FRSs and FMs; 3) discuss potential future research directions; and 4) introduce some common benchmarks and evaluation metrics in the FRS field. We hope that this survey provides the necessary background and guidance to explore this interesting and emerging topic. In the digital age, the exponential growth of information has created a need for systems that navigate, filter, and personalize data for individual users. Recommendation Systems (RS) nowadays become crucial tools for filtering online information and helping users discover products, content, and services that align with their preferences [1]. However, the systems traditionally rely heavily on centralized data collection and processing, posing significant privacy risks and operational bottlenecks. The importance of user privacy has never been greater, particularly with stringent data protection regulations such as the General Data Protection Regulation [2] in Europe, which emphasises the need to store user data on theirs local devices, instead of uploading it to central servers. As a novel approach to address these privacy concerns, Google introduced Federated Learning (FL) [3] as a framework designed to train models across decentralized devices, while keeping data localized. This paradigm shift in data processing leverages the computational capabilities of individual devices for local data analysis. Specifically, FL alternates between local model training at the user end and global parameter aggregation from these models on a central server. The integration of FL with RS becomes essential for safeguarding user privacy in recommendation services, which has given rise to the burgeoning field of Federated Recommendation Systems (FRS) [4]. In this field, typically each client consists of a single user\u2019s device. Therefore, unless specified otherwise in this paper, the terms \u2019user,\u2019 \u2019client,\u2019 and \u2019device\u2019 all refer to an individual user. FRS recently have shown promising results in many areas, such as service providing [5, 6], daily scheduling [7], driving planing [8, 9] and more, significantly impacting different facets of daily life. Similar to FL, FRS is required to keep user data local to protect user privacy. However, in most cases, each client typically contains only the data of one user\u2019s accessed item, which is extremely small compared to the total number of items, creating a serious data sparsity problem. In addition, different users have different behaviours and preferences, which can lead to data heterogeneity. The presence of both issues can lead to sub-optimal models and reduced effectiveness. More recently, the emergence of a novel paradigm for the construction of artificial intelligence (AI) systems has garnered considerable interest in the wake of the remarkable success of ChatGPT [10] and Stable Diffusion [11] in the tasks of language understanding [12, 13, 14, 15] and image generation [16, 17], which we refer to as Foundation Models (FM) [18]. As shown in Fig. 1, this paradigm is built by using self-supervised optimization of training goals to determine how to update model parameters based on model predictions on the large amount of unlabelled training data. This process is referred to as pre-training. Language models, e.g. BERT [19]and RoBERT [20], are usually trained using the next token prediction goal, which refers to the extent to which the model is able to predict the next token in the sequence. One of the most successful examples of language models is ChatGPT, which is based on GPT-3.5. By training on large amounts of text data, it aligns the capabilities of large language models with human intent [21]. Vision models like ViT [22] are typically trained using either contrast learning or diffusion training targets. For contrast learning [23, 24], images are randomly augmented before evaluating the similarity of the model representations. For diffusion models [25, 26], noise is added to the images and the model is gradually de-noised by the target. There are also multi-modal training targets, some of which separate images and text during training, while others consider both. The foundation model, once trained, is used as a plug-in in combination with adaptations to achieve results for a wide variety of downstream tasks. CLIP [27] and DALL\u00b7E [28] are two multimodal AI models developed by OpenAI. CLIP focuses on understanding images through natural language, while DALL\u00b7E focuses on generating images based on text descriptions. While both models are trained on large datasets of images and text, CLIP is primarily used for image retrieval and classification, while DALL\u00b7E excels at generating new images that match text descriptions [29]. As FM is frequently trained using a substantial quantity of data from multiple sources, they are capable of incorporating a considerable amount of additional knowledge when performing a specific downstream task. This feature enables FM to provide diverse training data for task-specific models in downstream task scenarios, thus effectively alleviating the problem of data scarcity. Given these considerations, the application of FM to FRS is not only a viable approach but also holds significant research potential. Such integration will drive innovation in FRS. Although the application of FM to FRS has the potential to be highly beneficial, it must be acknowledged that this field is still in its nascent stages, with an insufficient understanding of the challenges, viable methods, and directions for development. This paper aims to bridge this knowledge gap through an in-depth analysis of the integration of FM and FRS. The article provides a comprehensive examination of the motivations and challenges associated with integrating these two paradigms, with a particular focus on several representative technologies. Additionally, it outlines future development trends and their applications. By elucidating the intersection of FRS and FM, this study aims to promote further exploration and innovation within this emerging field, thereby facilitating its rapid advancement. Paper Organization. The reminder is structured to provide a thorough examination of the current research landscape, technical challenges, application cases, and future directions of FRS. The organization is as follows: Sec. II outlines the existing surveys within the field of FRS, and distinctly highlights our novel contributions, setting our survey apart from the current literature. Sec. III introduce foundational knowledge in the field of FRS and FM, including definitions, basic architectures, and current scenario classifications. Sec. IV introduces the potential applications and functions of FM according to the three classical phases of FRS. Sec. V delves into the main technical challenges faced by FRS with FM, including data heterogeneity, model aggregation difficulties, and privacy concerns, as well as current methods and their limitations in addressing these challenges. Sec. VII showcases applications of FRS across various domains, such as e-commerce, lifestyle and healthcare, discussing the outcomes and challenges of these real-world implementations. Sec. VIII summarizes the datasets and evaluation methods commonly used in FRS with FM, explaining how to quantify the recommendation performances. Sec. VI explores future research directions in FRS with FM, including unresolved issues and emerging research areas, providing guidance and inspiration for researchers in the field. Sec. IX concludes the survey with a summary of key findings and perspectives, offering insights into the trends and potential future of FRS. In the field of FRSs, various studies have converged on methodologies, privacy preservation, and challenges, albeit with distinct focal points. Yang et al. [30] discuss the practical implementation and evaluation of federated recommendation systems, with a focus on system architecture and algorithmic efficiency. Alamgir et al. [31] provides a comprehensive overview of federated recommendation systems, highlighting techniques, prevailing challenges, and future directions. Javeed et al. [32] focus on the security and privacy concerns in personalized recommendation systems and propose targeted solutions to these challenges. Finally, Sun et al. [33] conduct a survey that compares existing federated recommendation research, highlighting the strengths and limitations of various approaches. All studies emphasize the critical importance of privacy protection and the challenges posed by data heterogeneity and model aggregation. This body of work enhances our understanding of FRSs and provides a foundation for future research to address their inherent challenges. Although a number of surveys [34, 35, 36, 37, 38, 39] focusing on FL with FM already exist, our paper is the first survey work in our current knowledge that focuses on combining FRS with FM. Contribution. This survey aims to provide a clear theoretical framework for applying FM to FRS and to elaborate on their principles and methods of application. By analyzing existing technologies, this paper strives to drive innovation in integrating the pre-training capabilities of FM into FRS. The article discusses in detail the technical challenges and practical issues faced when integrating FM, such as privacy protection, data heterogeneity, communication efficiency, and model generalization capabilities. It also identifies current research gaps and future directions, aiming to guide subsequent academic research and technological development. Additionally, through application studies, this paper demonstrates how to apply the integration of FM with FRS in practical scenarios, thereby deepening the integration of theory and practice. A Federated Recommendation System is a technology that uses distributed algorithms for personalized information filtering. It aims to improve the accuracy of information filtering and the effectiveness of personalized services, while maintaining user privacy. FRS facilitate collaborative learning by pooling analysis and learning capabilities across multiple clients (e.g. users or locations), without the need for direct exchange of raw user data. Fig. 3 illustrates that this type of system typically involves three processes: client model update, communication, and global aggregation. The client model update allows users to train their models locally on their devices using their own data and then upload the updated intermediate parameters to the server. The server performs global aggregation on the parameters sent by all participants, integrating the unique information from each of them. The aggregated parameters are then distributed to the next round of participants, initiating a new training round. The process of uploading and distributing is collectively referred to as communication. These approaches effectively preserves privacy and security. As illustrated in Fig. 5, FRS can be categorized based on different criteria [40, 41]. According to used data distribution, FRS can be divided into Horizontal FRS, Vertical FRS, and Transfer FRS. Each type addresses different data collaboration and learning scenarios. Specifically: Horizontal FRS deals with situations where the feature spaces are similar across different entities, but the sample spaces differ, as shown in Fig. 2a. For instance, two customers who shop at the same store may purchase some of the same products. The horizontal method aggregates model updates from various sources to train recommendation models without sharing raw user data. This approach enhances the accuracy and efficiency of recommendation systems while safeguarding user privacy. Horizontal FRS is currently the most common type, with many studies [42, 43, 44] based on the assumption of this data distribution. Vertical FRS is applied when the feature spaces differ but the sample spaces are similar. This scenario is common when different entities possess different types of data about the same users. An example would be a bank and an online retailer holding distinct perspectives on the same customers, i.e., the bank has credit history while the retailer has shopping history. Vertical FRS [45, 46, 47, 48] trains recommendation models by securely integrating different data features between parties, utilizing richer user information for more accurate personalized recommendations and ensuring data privacy and security. Transfer FRS utilizes principles of transfer learning [49] to transfer knowledge from one domain to another. This type is suited for scenarios with significant differences in both feature and sample spaces across parties. Transfer learning allows the system to leverage data and knowledge from the source domain to enhance recommendation performance in the target domain, even when the target domain lacks sufficient data for independent model training. Transfer FRS [50, 51] is particularly beneficial for emerging markets or user groups with limited data, drawing insights from related domains. As shown in Fig. 4, FRS can be categorized into centralized, semi-decentralized and decentralized based on their communication architecture. Each type addresses privacy and scalability in different ways: Centralized FRS operates within a FL framework where a central server orchestrates the learning process. User devices (or clients) locally compute updates based on their data and send these updates to the server. The server aggregates these updates to improve the global model, which is then distributed back to the users. While this approach improves privacy by not requiring the sharing of raw data, it still relies on a central authority to manage the model. It effectively addresses privacy concerns by allowing the model to learn from decentralized data sources without centralizing the data itself. This architecture is typically used to overcome data silo issues and improve the performance of RSs without compromising user privacy and data security. Due to its simplicity and intuitive nature, this architecture has become the dominant framework within the field of FRS. There is a great deal of work [52, 43, 44] based on it currently. Semi-decentralized FRS introduces an intermediate layer between the central server and the users, such as edge servers or devices that can perform additional computational or storage tasks. This setup aims to reduce the communication overhead and latency associated with sending updates to a central server, especially in large-scale applications. A specific example is the Semi-decentralized Federated Ego Graph Learning (SemiDFEGL) framework [53], which improves scalability and reduces communication costs by introducing new device-to-device collaborations. It augments local subgraphs with predicted interacted item nodes to exploit high-order collaborative information between users and items in a privacy-preserving manner, which is particularly useful for recommendations based on collaborative filtering and graph neural networks. Decentralized FRS, which employs peer-to-peer communication architecture [54], distributes the learning process completely to all participating devices, without the need for a central server for model aggregation. This approach maximizes privacy and data ownership, but presents challenges in coordinating model updates and ensuring model convergence. Zheng et al. [55] proposed a FRS model called DGREC by adopting a decentralized graph neural network, which constructs a local intra-item hypergraph and a global inter-user graph for each user, allowing users to freely choose whether to disclose their interactions. Li et al. [56] introduced DFedRec, which uses a privacy-aware client-level structured graph to share model parameters only with relevant neighboring users, thereby reducing communication costs and protecting user privacy. Each of these architectures offers a trade-off between privacy, communication efficiency and the degree of decentralization. Centralized systems simplify model aggregation, but rely on a central authority. Semi-decentralized systems aim to balance efficiency and privacy with an intermediate layer, while decentralized systems offer the highest level of privacy at the cost of more complex model coordination. The rapid increase in the performance of computer hardwares, e.g., GPUs, the increasing maturity of transformer architectures, and the public availability of large amounts of training data have been three key factors in the emergence of FM [18]. According to the work of Stanford HAI [18], we have the following definition of FM: A foundation model is defined as any model trained on extensive data (typically using large-scale self-supervised learning) that is capable of adapting to a wide range of downstream tasks, for instance, through fine-tuning. In recent years, the scale and scope of FM have greatly expanded our imagination of potential applications. Such models typically have billions or even trillions of parameters, allowing them to learn more complex patterns and knowledge. They can be adapted to new tasks through fine-tuning or zero-sample learning. For instance, the GPT-3 model [57], comprising 175 billion parameters, is capable of adapting and perform various tasks with the aid of natural language prompts, despite the fact that a significant proportion of these tasks have not been explicitly trained. FM is distinguished by two key characteristics: 1) Emergence, which refers to the implicit induction of system behavior from examples, as opposed to explicit design; and 2) Homogenization, which indicates that the method of constructing machine learning systems tends to be unified across a wide range of applications. Although FM is based on standard deep learning and transfer learning, their scale brings new emergent abilities, and their effectiveness in many tasks has motivated homogenization. While homogenization provides strong leverage, it also requires caution, as defects in foundation models can be inherited by all downstream adapted models. Moreover, despite the broad deployment prospects of foundation models, due to their emergent properties, our understanding of how they work, when they fail, and what they can actually do is still quite limited. As shown in Fig. 6, similar to FRS, FM can also be classified based on data type or functionality. Specifically, based on the type of data used during training, FM is mainly divided into followings [18]: Language FM: These types of FM mainly deal with textual data and are trained on large textual datasets to understand and generate language. They are very effective in natural language processing (NLP) tasks such as machine translation, text summarization, and sentiment analysis. Typical language models include BERT [19], GPT-3 [57], and T5 [58], which typically use deep transformer architectures that are able to capture complex linguistic regularities and demonstrate excellent performance on multilingual tasks. Vision FM: Vision FM focuses on processing and understanding image data. These models are able to perform tasks such as object recognition, image segmentation, and visual reasoning by learning large amounts of image data. For example, DINOv2 [59] and SAM [60] are basic models trained specifically for visual tasks, and using self-supervised learning methods, these models learn valid visual representations without labelling the data. Multimodal FM: Multimodal models can simultaneously process and understand multiple types of data, such as text and images. Such models can excel in cross-modal tasks such as image captioning and visual quizzing by integrating information from different modalities. CLIP [27] and DALL\u00b7E [28] are representative of such models that are able to understand the relationship between an image and its corresponding textual descriptions, demonstrating flexibility and robustness in handling multiple data types. Functionally, FMs are generally categorized into two types [18, 61]: Discriminative FM: The main task of discriminative FM is to distinguish or predict specific outputs from given input data. These models are generally based on the BERT family and are more concerned with learning decision boundaries from the data to perform classification, regression, or other predictive tasks. Generative FM: The core goal of generative FM is to learn the distribution of the data and be able to generate new data samples. These models, such as GPT-3, DALL\u00b7E, etc., are able to capture the underlying structure of the data and thus generate new instances that are similar but different from the training data. Generative FM has a wide range of applications in areas such as text generation and image generation. Fig. 1 illustrates a commonly used technique for pre-trained models, known as the Adapter. This technique adds new lightweight layers while maintaining the original parameters of the pre-trained model, enabling fine-tuning and extension for specific tasks. This approach is suitable for multi-task learning and tasks performed in resource-limited environments. Adapters, such as LoRA [62] and QLoRA [63], have found wide applications in natural language processing [62] and computer vision tasks. As described earlier in Fig. 3, a typical FRS typically consists of three stages: client model update, communication, and global aggregation. Integration with FM should also occur at these three stages. In FRS, the clients have the following characteristics: As previously described, the data needed for model training in FRS, such as user information and interaction history, are privacy-sensitive and are therefore required to stay on the user\u2019s device, creating data silos. Moreover, each user\u2019s data is minimal compared to the total dataset, and each user only accesses a small portion of the item set, leading to data sparsity. The data on the client is influenced by user preferences, such as user behavior and product preferences. The resulting data distribution often does not meet the independent and identically distributed (IID) assumption, leading to the challenge of data heterogeneity. Additionally, user devices are generally consumer products like mobile phones and personal computers, characterized by unstable communication and limited computational resources. This requires that the computational load of the models deployed on the client and the amount of information exchanged with the server be kept as low as possible. FM is typically pre-trained on large, diverse datasets, acquiring a broad range of features and knowledge. This pre-training endows them with prior knowledge that allows for rapid adaptation to specific client data through fine-tuning. Consequently, these models can learn general feature representations, providing a certain level of adaptability to different data distributions. Therefore, clients can effectively fine-tune the model with a minimal amount of local data, achieving good performance on specific downstream tasks. Additionally, by fine-tuning foundation models locally, sensitive data does not need to leave the device, thereby enhancing data privacy. However, it is important to note that when FM is applied to data significantly different from the training distribution, performance degradation may occur. This issue, known as out-of-distribution generalization, represents a challenging aspect that FMs need to overcome. Moreover, if biases exist in the training dataset, FMs might learn and amplify these biases, leading to unfair outcomes across different data distributions. Although fine-tuning FMs requires significantly fewer resources than training from scratch, it usually still demands substantial computational resources for effective fine-tuning and updating. This requirement could limit their application on resource-constrained clients, particularly in FRS, where each user represents a client, thus potentially restricting the deployment of FM due to limited computational resources. Communicate Efficiency. Similar to FL, FFRS involves significant data transfer between numerous clients and a central server, making communication efficiency a critical factor in the duration of the entire learning process. To enhance communication efficiency, model compression techniques such as quantization or sparsification of model parameters can be utilized to reduce the volume of data transmitted. Periodic averaging is another strategy that reduces communication overhead by decreasing the frequency of model parameter uploads. FM, due to its parameter sharing and hierarchical features, allow clients to transmit only fine-tuned parameter updates rather than the entire model\u2019s parameters. This approach can significantly reduce communication overhead while maintaining or even enhancing the model\u2019s performance on specific tasks. Similarly, since foundation models have already learned rich feature representations during the pre-training phase, they can adapt more quickly to new tasks. This means that in FRS, clients may achieve satisfactory performance with fewer iterations, thus reducing the frequency of communication. Client Selection. In each iteration of FRS, considering resource limitations and privacy concerns, the central server may choose to communicate only with a subset of clients. Research indicates that clients should not participate in consecutive training rounds as attackers could potentially infer information about the client from transmitted gradients or model parameters. Client selection strategy determines which clients will participate in the current round based on various factors such as computational power, network stability, data diversity, and quality. Client selection can also be conducted through random sampling or based on statistical characteristics of the data to ensure the model learns from diverse data sources, enhancing its generalization ability. Since FM already possesses a broad knowledge base and generalization capabilities, when selecting clients for model training, greater emphasis can be placed on data compatibility and coverage. Specifically, priority can be given to clients that can provide data types less represented or missing in the pre-training phase, thereby supplementing and enhancing the model\u2019s performance in these areas. For instance, clients whose data can significantly improve the model\u2019s performance on specific tasks can be considered more valuable. Incentive mechanisms can be set up to encourage the participation of these high-value data providers in the training process. However, it is important to ensure that the same client does not participate in consecutive training rounds to minimize the risk of privacy breaches. Privacy Protection. A major advantage of federated learning is the ability to train models without compromising user privacy, making privacy protection a primary consideration in designing communication protocols. Privacy risks are mitigated by transmitting model updates, such as gradients or parameters, instead of raw data from clients to the server. Additionally, technologies like homomorphic encryption, secure multi-party computation (SMC), or differential privacy can further enhance privacy protection during communication. Global aggregation in FRS integrates model parameters independently trained by various clients to form a unified global model. This process not only enhances the accuracy and generalization of the recommendation system but also strengthens the system\u2019s robustness by protecting client data privacy, optimizing resource usage, ensuring model synchronization and fairness, thereby improving recommendation performance and efficient resource utilization without compromising user privacy. The Typical Average scheme, proposed with FedAvg [3], is the most common aggregation strategy where the server computes a simple arithmetic average of the model updates received from client devices. It\u2019s popular due to its simplicity and effectiveness in many scenarios In the Weighted Average strategy, model updates are weighted based on certain criteria such as the volume of data on each client or the reliability of the data source, allowing more significant contributions to have a proportionally greater impact on the global model. This approach can be more effective than the typical average scheme, especially in non-IID data environments, where data distribution varies significantly across devices When integrating FM, exploring new aggregation technologies becomes particularly important to address the challenges posed by the scale and complexity of the models. Beyond the traditional weighted average method, some emerging aggregation strategies have shown potential in managing these challenges. For instance, the technique called Model Soups enhances model accuracy and robustness by averaging the weights of models that have been fine-tuned with different hyperparameters. Additionally, aggregation strategies based on the Mixture of Experts (MoE) utilize multiple specialized sub-models, each optimized for specific tasks or data types. These strategies dynamically adjust model weights based on data-driven methods, allowing for flexible adjustment of the aggregation process in response to real-time data changes, thus improving the overall model performance and adaptability. These emerging technologies not only improve the effectiveness of aggregation but also better address the challenges from large-scale distributed data, making them valuable aggregation strategies worth further research and application in the field. Additionally, leveraging machine learning techniques to dynamically adjust aggregation methods based on real-time data quality and integrity assessments could improve both the robustness and efficiency of FRS. The integration of generative models into federated recommendation systems heralds a new frontier in personalized content delivery, promising to enhance user experiences with tailored suggestions while respecting privacy concerns. However, this promising union is not without its complexities. As we venture further into this domain, a myriad of challenges emerges, each posing unique hurdles that must be carefully navigated. These challenges span the spectrum from data heterogeneity and privacy concerns to communication overheads and resource-intensive computations. Understanding and addressing these issues is paramount to the successful deployment and operation of federated recommendation systems that are both effective and secure. In this section, we delve into each of these challenges, exploring their implications and discussing potential strategies for overcoming them. The diversity in user-generated data can complicate the generative model\u2019s ability to identify a common representation that accurately reflects all users\u2019 preferences. This challenge necessitates the development of robust mechanisms capable of handling varied data inputs and providing nuanced, precise recommendations. Techniques such as transfer learning and multi-task learning can be employed to better adapt to the heterogeneity of data. The collection of user data is essential for refining recommendation algorithms, but it also poses significant privacy and security risks. While federated learning offers a solution by processing data locally, generative models must be carefully designed to prevent the leakage of sensitive information through their generated outputs. Privacy-preserving methods like differential privacy and secure multi-party computation can be integrated to enhance data security. Membership inference attacks aim to determine whether specific data samples were used in training a model. Such attacks can reveal the presence of sensitive data, for example, by disclosing whether a patient\u2019s medical records were used to train a disease prediction model. Under the FL setting, attackers might use model updates obtained from various participants to infer which data were used for training. Particularly in FRS with FM settings, the complexity and depth of the models make membership inference attacks more covert, thereby complicating defense efforts. Data reconstruction attacks aim to rebuild or approximate the actual data used in training. This is typically achieved through optimization techniques such as model inversion and gradient matching, where attackers attempt to generate data samples similar to the training data by accessing the model\u2019s outputs or gradients. Under the FL setting, although the original data does not leave the owner\u2019s device, aggregated updates may still leak sufficient information to enable attackers to reconstruct the original data. Particularly when large-scale foundation models are used, this risk may be exacerbated due to the models\u2019 high capacity for data representation. In FL, poisoning attacks represent a security threat aimed at disrupting or manipulating the learning process and outcomes through malicious modifications to data or model parameters. These attacks primarily take two forms: data poisoning attacks and model poisoning attacks. Specifically: Untargeted Attacks: Untargeted attacks aim to disrupt the entire training process, causing the global model to fail to converge or significantly degrade in performance. These attacks are typically executed by injecting noisy data or incorrect information into the model training process. In a FL environment, attackers might submit model updates containing erroneous gradients or parameter updates, thereby disturbing the learning process of the aggregated global model. The challenge of these attacks lies in the ability of the attackers to pass the poisoned data through the FL system\u2019s normal aggregation process without detection. Targeted Attacks: In contrast, targeted attacks aim to cause the model to produce incorrect outputs for specific inputs, without affecting the model\u2019s performance on most other inputs. This type of attack is usually carried out by injecting a small amount of carefully designed poisoned samples into the training data. These samples contain specific triggers that, when encountered by the model, lead to predetermined incorrect outputs. This attack method is particularly covert in FL, as attackers can embed these triggers during local training, and these modifications may only affect a small part of the model, making them difficult to detect in the global model. Federated systems necessitate ongoing communication between users and servers to synchronize model updates. The large parameter size of generative models can significantly increase the demand for communication resources. To address this, efficient communication protocols and model compression techniques can be utilized to reduce the bandwidth required for updates. The scarcity of user data is a significant challenge, particularly for new or less active users, as it can hinder the model\u2019s ability to learn accurate preferences. To combat this, data augmentation strategies and synthetic data generation can be employed to enrich the training data and improve model generalization. Generative models are computationally demanding, requiring substantial storage and processing capabilities. This can be particularly challenging in resource-constrained environments, such as mobile devices. Optimizing model architectures and leveraging distributed computing can help alleviate the strain on resources. The quality of synthetic data generated by generative models is crucial. Low-quality synthetic data can negatively impact the model\u2019s performance if used in training. Ensuring the synthetic data closely resembles real data distributions is essential for maintaining the integrity of the recommendation system. Generative models within federated recommendation systems must be robust against data anomalies and capable of maintaining stable performance even when faced with shifts in data distribution. This requires the implementation of robust learning algorithms that can adapt to changes in the data landscape without significant degradation in performance. This section discusses applications that highlight the great potential of generative models in federated recommender systems. These applications not only have the potential to improve recommendation quality, but also to provide personalised services while protecting user privacy. As technology continues to advance, we can expect generative models to play an increasingly important role in future FRSs. Generative models such as VAEs and GANs can be used to generate personalized user profiles within federated recommendation systems. These models can capture latent features of user preferences and generate recommendations that reflect these characteristics, providing more accurate personalized suggestions. Privacy is paramount in federated recommendation systems. Generative models can protect user data privacy by generating representations of user preferences locally and then only sending these representations to a central server for recommendations, without disclosing raw user data. Diffusion models and large language models can be used to generate additional training data, which is particularly useful in federated learning environments where data sparsity is often an issue. By generating synthetic data, the diversity of the training set can be increased, enhancing the performance of the recommendation system. Federated recommendation systems allow multiple organizations to share in the training of a recommendation model without sharing user data. Generative models can be used within this framework to generate cross-domain recommendations, sharing generated latent user features across different organizations rather than raw data. For new users or new items, traditional recommendation systems face the so-called \u201dcold start\u201d problem. Generative models can predict the latent features of these new entities and generate initial recommendations, quickly initiating the recommendation process. Large language models can be used to generate explanations for recommendations, helping users understand why a particular piece of content is recommended. This is crucial for increasing user trust and acceptance of recommendation systems. Generative models can quickly produce recommendations, which is useful for recommendation scenarios that require real-time feedback, such as news recommendations or real-time event recommendations. By generating a diverse range of recommendations, generative models can help reduce biases in recommendation systems, providing more equitable recommendation outcomes. In federated recommendation systems, generative models can be used to simulate various user behaviors and preferences, thereby testing and improving the robustness of the recommendation system. Combining multiple types of data such as images, text, and audio, generative models can be used to create multimodal recommendations, such as recommending travel destinations that combine images with textual descriptions. eHealthcare systems leverage modern technology to enhance the quality and efficiency of medical services, such as remote diagnosis and patient monitoring. Federated recommendation systems allow different medical institutions to share insights from patient data without sharing the data itself, which is crucial for protecting sensitive health information. Generative models use this data to provide doctors and patients with personalized treatment plans and health advice, improving diagnostic accuracy and treatment outcomes. Thus, federated recommendation systems combined with generative models can integrate patient health data across institutions to create complex treatment pathways and simulate disease progression, enabling doctors to better predict patients\u2019 responses to specific treatments and provide more precise medical services. In manufacturing, automation and intelligent technologies significantly enhance production efficiency and safety. Federated recommendation systems foster technological collaboration between different enterprises by sharing non-sensitive data, accelerating product design and optimization processes. This not only shortens product development cycles but also protects corporate trade secrets. Generative models can design new mechanical parts or product prototypes by simulating different design variables, quickly proposing multiple design solutions; they can also help predict machine failures, perform maintenance in advance, and reduce downtime, thereby enhancing production efficiency. Federated recommendation systems combined with generative models enable the sharing of improvements and innovations while maintaining data privacy between companies. Analyzing consumer behavior helps businesses deeply understand customer needs. Federated recommendation systems can integrate data from different service providers while protecting user privacy, achieving personalized services. Generative models provide personalized recommendations based on this data, enhancing user experience. For example, in travel recommendation systems, models generate customized travel itineraries based on users\u2019 historical preferences. By simulating different consumer behavior patterns, businesses can predict market trends, adjust service strategies, and enhance competitiveness. Federated recommendation systems combined with generative models analyze user behavior data from different service providers to generate service plans that meet individual needs, promoting personalized service development. Applying recommendation systems to online shopping and retail provides a personalized shopping experience. Federated recommendation systems in the retail and e-commerce sectors analyze consumer shopping habits to generate personalized product recommendations, increasing users\u2019 purchasing desire and satisfaction. Retailers and e-commerce platforms can use generative models to predict consumer buying behavior, thereby offering more accurate product recommendations, optimizing inventory, and enhancing sales efficiency. Federated recommendation systems combined with generative models allow retailers and e-commerce platforms to consider market conditions comprehensively, predicting consumer buying behavior and providing more precise product recommendations, optimizing inventory, and enhancing sales efficiency. In the financial sector, recommendation systems use data analysis and prediction models to optimize financial services, applicable for credit assessments, stock market analysis, etc., offering clients tailored financial products. Federated recommendation systems ensure transaction data privacy while offering clients tailored financial products. Generative models can simulate market behaviors, predicting stock prices or financial product returns. These models help financial institutions formulate more accurate investment strategies while reducing risks. In finance, federated recommendation systems combined with generative models help financial institutions protect client privacy while simulating market changes and user behavior, offering advice on investment products and credit strategies, thereby enhancing clients\u2019 investment returns and satisfaction. In smart city applications, systems need to process and analyze large-scale urban data. From optimizing traffic flow to devising public safety strategies, federated recommendation systems can help city planners use resident data without directly sharing it to recommend strategies for improving public services and infrastructure, enhancing urban management efficiency and improving residents\u2019 quality of life. Additionally, using generative models to simulate the effects of different strategies can find optimal solutions for managing and allocating urban resources. For example, by simulating traffic flow, models can predict congestion and propose solutions, improving urban traffic efficiency. Federated recommendation systems combined with generative models can help city planners optimize resource allocation and management efficiency without sharing resident data. Social platforms facilitate interpersonal communication and information sharing online, using recommendation systems to suggest content to users, such as friends or topics of interest, to increase user engagement. Federated recommendation systems can enhance user engagement and satisfaction while protecting user privacy. Generative models can generate personalized content recommendations, enhancing user engagement and satisfaction while ensuring the protection of user privacy, increasing platform attractiveness and user retention. In the field of education, using recommendation systems can improve teaching methods by making appropriate recommendations based on students\u2019 progress and abilities, providing a personalized learning experience. Generative models can generate personalized learning materials and courses based on students\u2019 progress and interests. These customized learning resources can enhance students\u2019 learning efficiency and interest. Federated recommendation systems combined with generative models can generate personalized learning paths based on students\u2019 feedback and learning history. By simulating teaching scenarios and student learning processes, these systems can provide resources that better meet individual learning needs. In FRS, the datasets used can be categorized into two types based on user feedback: explicit feedback and implicit feedback, as shown in Fig. 7. Explicit feedback includes direct responses from users about their preferences. This typically includes ratings (such as a 1-5 scale), user comments, and like/dislike statements. Such data is clear and provides straightforward insights into user preferences, making it highly valuable for training recommendation models. Common datasets with explicit feedback include the following shown in Table ?????????I: Amazon Reviews111https://cseweb.ucsd.edu/ jmcauley/datasets.html#amazon_reviews: The Amazon Reviews dataset is a large-scale dataset that contains product information across various categories such as Books, CDs, and Music. It includes reviews (ratings, text, helpfulness votes) and product metadata (description, category information, price, brand, and image features). There are three updated versions of this dataset from the years 2014 [64, 65], 2018 [66], and 2023 [67]. MovieLens Datasets222https://grouplens.org/datasets/movielens/: The MovieLens datasets [68], initially released in 1998, capture individuals\u2019 stated movie preferences. These preferences are recorded as tuples, with each tuple showing a person\u2019s rating (from 0 to 5 stars) for a movie at a specific time. Users enter these ratings through the MovieLens website, which provides personalized movie suggestions based on these ratings. Yelp Datasets333https://www.yelp.com/dataset: This dataset is a subset of Yelp\u2019s business, review, and user data. It was initially developed for the Yelp Dataset Challenge, which allows students to study or analyze Yelp data and present their insights. In total, there are four versions of the Yelp datasets. Anime444https://www.kaggle.com/datasets/CooperUnion/anime-recommendations-database: This dataset collects user preference data from the MyAnimeList website. It contains information from 73,516 users on 12,294 anime titles. Users can add anime to their completed list and rate them, and this dataset compiles these ratings. Book Crossing555https://grouplens.org/datasets/book-crossing/: The Book-Crossing dataset is a well-structured collection of data collected by Cai-Nicolas Ziegler in a 4-week crawl from the Book-Crossing community. This dataset primarily comprises user interactions that include book ratings, ranging from 0 to 10. Douban666https://www.kaggle.com/datasets/utmhikari/doubanmovieshortcomments: The Douban Movie dataset is a Chinese website where internet users can post their opinions and comments about films. This dataset contains over 2 million short comments on 28 movies from the Douban Movie website. Epinions777https://cseweb.ucsd.edu/ jmcauley/datasets.html#social_data [69]: This dataset was collected from Epinions.com, a popular online consumer review site. It includes trust relationships between users and covers a period from January 2001 to November 2013. Goodreads888https://www.kaggle.com/datasets/jealousleopard/goodreadsbooks: This dataset includes reviews from the book review website Goodreads, along with various attributes describing the books. Importantly, the dataset captures different levels of user interaction, from adding books to a shelf, to rating them, to reading them. Jester999https://eigentaste.berkeley.edu/dataset/: The Jester dataset focuses exclusively on jokes. Users of the Jester online platform rate jokes and these ratings are then used to personalize joke recommendations for them. Netflix101010https://www.kaggle.com/datasets/netflix-inc/netflix-prize-data: Netflix provided a training dataset consisting of 100,480,507 ratings from 480,189 users for 17,770 films. Each rating is represented as a set of four elements: \u00a1user, movie, rating date, rating score\u00bf. The user and the movie are identified by integer IDs, and the rating scores range from 1 to 5 stars, also as integers. Yahoo Music111111https://webscope.sandbox.yahoo.com/catalog.php?datatype=r: The Yahoo Music dataset is known for its large scale and diversity. It contains a large collection of user ratings on different musical elements such as tracks, albums, artists and genres. This dataset was used in the KDD-Cup 2011 competition, where participants were asked to analyse user preferences in music based on these ratings. Implicit feedback, on the other hand, is derived from user actions that indirectly indicate preferences, such as bookmarks, video/music play history, or click-throughs. Although implicit feedback does not directly express user likes or dislikes, it is rich and captures user behaviour more comprehensively. MIND121212https://msnews.github.io/ [70]: The MIND dataset, sourced from the Microsoft News website, is a large-scale collection of approximately 160,000 English news articles and over 15 million user interaction records. It has been designed to advance research in news recommendation systems. It includes detailed textual content for each story and anonymized user interaction data to ensure privacy. Tenrec131313https://github.com/yuangh-x/2022-NIPS-Tenrec [71]: The Tenrec dataset is a comprehensive benchmark dataset for RSs, featuring user interactions from two recommendation platforms across four dataset files: QK-video and QB-video for video actions, and QK-article and QB-article for article actions. Adressa141414https://reclab.idi.ntnu.no/dataset/ [72]: The Adressa dataset is a corpus of Norwegian news articles related to anonymous users. It is a collaborative project between the Norwegian University of Science and Technology and Adressavisen. The objective is to gain insight into the nature of news articles and their readers. Foursquare151515https://sites.google.com/site/yangdingqi/home/foursquare-dataset [73]: This dataset comprises check-in data from New York City, collected over a period of approximately ten months (from 12 April 2012 to 16 February 2013). It encompasses 227,428 check-ins in New York City, with each check-in recorded with its timestamp, GPS coordinates, and detailed venue category. Gowalla161616https://snap.stanford.edu/data/loc-gowalla.html [74]: Gowalla is a location-based social networking website where users can post their whereabouts by checking in. The dataset comprises data collected from the public API, which represents an undirected friendship network with 196,591 nodes and 950,327 connections. Additionally, it records 6,442,890 check-ins made by these users between February 2009 and October 2010. Last.FM171717https://grouplens.org/datasets/hetrec-2011/ [75]: The Last.FM dataset represents a valuable resource that has been extensively utilized in the field of music information retrieval and RSs. It captures detailed information regarding music listening events from users. Each listening event is further enhanced with user demographics and specific descriptors that reflect their music tastes and consumption behaviours. Pinterest181818https://github.com/edervishaj/pinterest-recsys-dataset [76]: The Pinterest dataset represents a valuable resource for a variety of research and analytical purposes. It encompasses a diverse range of data, including images, user features, interests, and user interactions. Steam191919https://github.com/kang205/SASRec [77]: The Steam dataset is a collection of information about games published on the Steam platform. It includes details such as game names, release dates, genres, developers, publishers, and other relevant information. TaFeng202020https://www.kaggle.com/datasets/chiranjivdas09/ta-feng-grocery-dataset: The TaFeng dataset is a comprehensive collection of supermarket shopping data, including detailed transaction records from the Ta Feng supermarket in Taiwan, covering a period from November 2000 to February 2001. The dataset comprises a variety of data points, including customer demographics, product categories, and detailed item descriptions along with quantities purchased. Tmall212121https://tianchi.aliyun.com/dataset/53[78]: The Tmall dataset is a comprehensive collection from Tmall, comprising anonymized user shopping records over a six-month period up to and including the \u201dDouble 11\u201d event. It should be noted that the data is selectively sampled to address privacy concerns. Both types of feedback play a critical role in the development of FRSs, providing diverse insights into user preferences that help improve the accuracy and relevance of the recommendations provided. In the field of FRSs, the use of evaluation metrics is fundamental to assessing and refining the performance of our algorithms. Metrics serve as a quantitative lens through which we can observe how closely the system\u2019s suggestions match users\u2019 actual interests and preferences. For predicting how well a system can estimate user preferences, there are several metrices measuring the prediction errors to judge the accuracy of the predictions, such as Mean Absolute Error (MAE), Mean Squared Error (MSE) and Root Mean Squared Error (RMSE). When it comes to classifying items, i.e., determining whether a user will like a product or not, we look at metrics such as Precision, Recall, Hit Ratio (HR), F1 Score, Accuracy and AUC. These tell us how correctly the RS is classifying items, and the F1 score helps us balance the Precision and Recall. Then to measure the item ranking ability, which is about listing recommendations in the right order, Average Precision (AP) and Mean Average Precision (MAP) are key to this, as they assess the quality of the order of recommendations. Metrics such as Mean Reciprocal Rank (MRR), Normalized Mutual Rank (NMR) and Normalised Discounted Cumulative Gain (NDCG) also contribute by assessing how well the top recommended items are ranked. On a broader scale, we consider recommendation-centric metrics such as Diversity, which ensures that a variety of items are suggested, and Coverage, which measures how many items from the catalogue are recommended. There are also some user-centric metrics include Novelty, which measures how new or surprising the recommendations are, and Degree of Agreement (DOA), which quantifies the level of concordance between the ranking of items produced by a recommendation system and the ranking preferred by the user. Moreover, business metrics such as Click-Through Rate (CTR) are critical to assessing the system\u2019s impact on user engagement and the company\u2019s bottom line, and Conversion Rate (CVR) measures how efficient an algorithm is at providing recommendations that lead to user purchases. There also are some metrics for measuring other functionality. For example, Gini Index evaluates the fairness of recommendation distribution, with lower values indicating more equitable distribution across items. Furthermore, in the generative recommendation scenario, FMs such as DMs and LLMs can generate items that have never appeared in historical data and recommend them to users. In this case, how to evaluate the generative recommendation capability of these generative FMs remains an open question. This study comprehensively examines the integration of FRSs with FMs, a direction that has gained attention for its ability to protect user privacy. The article begins by summarizing common approaches of FRSs and FMs, then delves into the challenges faced during integration. To address these challenges, the paper proposes various strategies including using transfer learning and multitask learning techniques to adapt to data diversity, employing privacy-preserving methods like differential privacy and secure multi-party computation, and reducing communication overhead through model compression and efficient communication protocols. This work also discusses the future research directions directions indicating that FRSs can provide more accurate personalized recommendations while better protecting user privacy. Additionally, the paper showcases applications of FRS in various fields, demonstrating their potential and value in the real world. Through this study, we aim to provide theoretical guidance for integrating FRS with FM, directing future research and technological advancements to collectively advance this field.",
        "keywords": "Index Terms: \nFederated Recommendation System, Foundation Model, Privacy Preserving, Security,"
    },
    {
        "id": 12,
        "title": "Evaluating Transfer Learning in Deep Learning Models for Classification on a Custom Wildlife Dataset: Can YOLOv8 Surpass Other Architectures?",
        "abstract": "AbstractBiodiversity plays a crucial role in maintaining the balance of the ecosystem. However, poaching and unintentional human activities contribute to the decline in the population of many species. Hence, active monitoring is required to preserve these endangered species. Current human-led monitoring techniques are prone to errors and are labor-intensive. Therefore, we study the application of deep learning methods like Convolutional Neural Networks (CNNs) and transfer learning, which can aid in automating the process of monitoring endangered species. For this, we create our custom dataset utilizing trustworthy online databases like iNaturalist and ZooChat. To choose the best model for our use case, we compare the performance of different architectures like DenseNet, ResNet, VGGNet, and YOLOv8 on the custom wildlife dataset. Transfer learning reduces training time by freezing the pre-trained weights and replacing only the output layer with custom, fully connected layers designed for our dataset. Our results indicate that YOLOv8 performs better, achieving a training accuracy of 97.39\u00c2\u00a0% and an F1 score of 96.50\u00c2\u00a0%, surpassing other models. Our findings suggest that integrating YOLOv8 into conservation efforts could revolutionize wildlife monitoring with its high accuracy and efficiency, potentially transforming how endangered species are monitored and protected worldwide.",
        "corpus": "Biodiversity plays a crucial role in maintaining the balance of the ecosystem. However, poaching and unintentional human activities contribute to the decline in the population of many species. Hence, active monitoring is required to preserve these endangered species. Current human-led monitoring techniques are prone to errors and are labor-intensive. Therefore, we study the application of deep learning methods like Convolutional Neural Networks (CNNs) and transfer learning, which can aid in automating the process of monitoring endangered species. For this, we create our custom dataset utilizing trustworthy online databases like iNaturalist and ZooChat. To choose the best model for our use case, we compare the performance of different architectures like DenseNet, ResNet, VGGNet, and YOLOv8 on the custom wildlife dataset. Transfer learning reduces training time by freezing the pre-trained weights and replacing only the output layer with custom, fully connected layers designed for our dataset. Our results indicate that YOLOv8 performs better, achieving a training accuracy of 97.39\u00c2 % and an F1 score of 96.50\u00c2 %, surpassing other models. Our findings suggest that integrating YOLOv8 into conservation efforts could revolutionize wildlife monitoring with its high accuracy and efficiency, potentially transforming how endangered species are monitored and protected worldwide. *joint first authors. Convolutional Neural Network (CNN), Endangered Species Detection, Image Classification, Transfer Learning, YOLO. Each living creature in our world plays a vital role in maintaining the balance of the ecosystem. However, activities like poaching and illegal trade, reduction of prey base, habitat loss and degradation, and human-wildlife conflict have led to a rapid decline in the number of some species, including critically endangered ones [11]. Currently, wildlife monitoring is done using camera traps that capture the images of animals, which are then analyzed and studied by humans. This is time-consuming, tedious, and prone to errors. The introduction of various deep learning techniques and their use in computer vision shows optimistic results. Convolutional Neural Networks (CNNs), introduced by LeCun et al. in 1998 [14], have been a significant milestone in image classification tasks [22, 26, 12]. In these networks, images are fed through convolutional and pooling layers for feature extraction, followed by fully connected layers. Transfer learning, highlighted by Pan and Yang [18], is fine-tuning pre-trained models on large datasets for specified tasks that significantly reduce training time with increased performance. Densely connected convolutional networks, popularized by Huang et al. in 2017 [8], and residual networks, put forward by He et al. in 2016 [7], are deep and complex networks that facilitate effective feature extraction. However, VGGNet, proposed by Simonyan and Zisserman in 2014 [25], is somewhat computationally expensive, although its results are excellent in some cases.YOLOv8 is an evolution in Redmon et al.\u00e2\u20ac\u2122s object detection and has shown remarkable results in various computer vision tasks [20]. El Abbadi et al. achieved a classification accuracy of 97.5% using a deep convolutional neural network model for the automated classification of vertebrate animals, thereby demonstrating the effectiveness of deep learning in animal recognition tasks [6]. Similarly, Villa et al. demonstrated in their study that very deep convolutional neural networks achieved 88.9% accuracy in a balanced dataset and 35.4% in an unbalanced one for automatic species identification in camera-trap images, marking a notable advancement in non-intrusive wildlife monitoring [27]. In 2020 Ibraheam et al. reported in their paper that their deep learning-based system achieved 99.8% accuracy in distinguishing between animals and humans, and 97.6% in identifying specific animal species, significantly improving safety in wildlife-human and wildlife-vehicle encounters [9]. Brust et al. have illustrated that ResNet50 outperformed VGG16 and Inception v3 on a wildlife image dataset, with the highest accuracy of 90.3\u00c2 %. It provided insights into the strengths and weaknesses of different CNN architectures for wildlife classification [3]. Similarly, Beery et al. 2018 validated the same on a challenging dataset of wildlife images with occlusions, varying lighting conditions, and motion blur. They found the Faster R-CNN model achieved the highest accuracy of 88.7\u00c2 %, indicating the importance of model robustness in real-world applications [2]. Similarly, Yilmaz et al. in 2021 demonstrated that the YOLOv4 algorithm achieved a high classification accuracy of 92.85\u00c2 % for cattle breed detection [29], emphasizing its effectiveness in wildlife classification tasks. M. Kumar et al. found that YOLOv4 was the most effective of the several deep learning-based models, including SSD and YOLOv5, achieving an accuracy of 95.43\u00c2 % in their bird classification task [13]. Hung Nguyen et al. achieved 96.6\u00c2 % accuracy in detecting animal images and 90.4\u00c2 % accuracy in species identification using deep learning, highlighting its potential for automatically monitoring wildlife [17]. This paper answers some of the burning questions regarding selecting deep learning models for practical wildlife conservation tasks, such as which models provide the best accuracy and efficiency, how YOLOv8 compares to DenseNet, ResNet, and VGGNet, and what challenges and limitations exist in applying these models to wildlife conservation. Our results show that YOLOv8 is best suited for automated wildlife monitoring with much better accuracy and efficiency than models such as DenseNet, ResNet, and VGGNet. This work will supply essential guidance to researchers and practitioners on the choice of appropriate models for endangered species conservation. Addressing these research questions is crucial as the current methodologies for wildlife monitoring are labor-intensive and error-prone. This work aims to fill this gap by systematically evaluating different deep learning models and providing essential guidance to researchers and practitioners on the choice of appropriate models for endangered species conservation. In this paper, we begin by reviewing related works and current methodologies in wildlife conservation. In Section 2, we describe our dataset and the preprocessing steps involved and a detailed overview of the methodologies employed in our study. Following this, Section 3 elaborates on the performance and evaluation metrics used for our machine learning models. In Section 4, we present and discuss the experimental results. Finally, we conclude in Section 5 with a summary of our findings and suggestions for future work. Our dataset includes 23 each carefully selected based on its conservation status and the need for monitoring. These species cover many endangered animals, including mammals, reptiles, and amphibians as shown in table 1. Our study began by collecting the data from different sources on the internet. Each class is represented by 50 filtered images, resulting in 1150 images in our dataset. We maintained a balanced dataset to reduce the bias towards any particular species and to perform the balanced model training. The internet houses a huge amount of data, but finding and gathering useful ones is still challenging. To collect images of various animal species, we utilized online repositories like iNaturalist and ZooChat [10, 30]. The good thing about using such sites is their authenticity and fair use policy. For the same reason, we did not use the images shown in regular Google searches or try to automate the process. We divided the preprocessing of the image data into the following steps. We preprocessed all the images utilized for our study to have an aspect ratio of 1:1 and a resolution of 400 x 400. We added padding whenever required, ensuring we did not lose any information from the images during resizing. We normalized every image to increase accuracy and speed up the model\u00e2\u20ac\u2122s convergence. It also reduced the variance in the training data. We split the dataset into train (80\u00c2 %) and val (20\u00c2 %) sets. We used the split-folders Python package to split the dataset while maintaining the original distribution [4]. Babu et al.\u00e2\u20ac\u2122s study examines the impact of image data splitting on the performance of machine learning models [1]. For better generalization, we increased the diversity of data by applying different augmentation techniques, as suggested by Shorten and Khoshgoftaar in 2019 [24]. While their survey offered valuable insights into the importance of data augmentation for enhancing the model\u00e2\u20ac\u2122s performance, we customized the specific methods to our dataset and requirements through numerous experiments. Table 2 displays the final set of parameters for data augmentation. Convolutional Neural Networks are a special kind of neural network designed to work with grid data like images. They learn by extracting the features from input data via convolution and pooling operations followed by fully connected layers [14]. CNNs have played a pivotal role in the advancement of computer vision and related tasks. They are especially effective in performing tasks such as image recognition, object detection, and classification [5, 16, 23]. Transfer learning is an approach to deep learning that enables researchers and developers to use the previously trained model in a huge dataset and implement it in downstream tasks [22]. It is especially useful when we have limited data to train the model. Also, it significantly reduces the training time because the feature extraction part remains unchanged. However, it may fail when there is a significant mismatch between the target domain task and the source task. These are some of the models we used to compare transfer learning with our dataset. Figure 3 shows the corresponding architecture of these models. DenseNet: DenseNet was introduced by Gao Huang and colleagues in 2017 [26]. It connects each layer with all other layers densely, meaning each layer receives input from the preceding layers. By efficiently cutting the parameters\u00e2\u20ac\u2122 requirements and boosting the network\u00e2\u20ac\u2122s ability by reusing the features extracted, it allows for a deeper network. However, the dense connectivity may lead to increased computational cost and memory consumption. ResNet: ResNet was introduced by Kaiming He et al. in 2016 [12]. It utilizes residual blocks, which are shortcut connections that bypass one or multiple layers. It also allows the network to learn residual functions instead of direct mapping. This architecture supports very deep networks without degradation problems. VGG: VGG was introduced by Karen Simonyan and Andrew Zisserman in 2014 [18]. It is known for its simplicity and depth, achieved by stacking small 3*3 convolutional layers, increasing the model\u00e2\u20ac\u2122s depth and parameters. The max pooling layers follow the convolutional layers to handle the volume size and end with the fully connected layers. YOLOv8: YOLOv8 is built upon the object detection framework introduced by Joseph Redmon, with contributions from many researchers over successive versions. It enhances speed and accuracy through an advanced backbone architecture, refined loss functions, and anchor-free detections [21]. Figure 4 shows the architecture of the YOLOv8. We loaded the pre-trained models(DenseNet, ResNet and VGG, ) with their respective weights, made these weights untrainable(frozen), and replaced the last layer with custom, fully connected layers corresponding to the number of classes in our dataset. We added a GlobalAveragePooling2D layer to reduce the feature maps\u00e2\u20ac\u2122 spatial dimensions and prevent overfitting. This layer is followed by a Dense layer with 128 neurons and activated by ReLU to introduce non-linearity and learn more complex features. Finally, we added a Dense layer with 23 units activated by softmax to match the number of classes in our dataset, enabling the model to output the class probabilities, as shown in Figure 5. We then trained the models using Adam as the optimizer and cross-entropy as the loss function for 100 epochs with a batch size of 32 images. Meanwhile, we used a validation set to monitor the progress to avoid plateauing and adjusting the learning rate dynamically. We experimented with multiple sets of hyperparameters, including learning rates, optimizers, batch sizes, and schedulers, thereby selecting the most favorable settings of hyperparameters that showed optimal performance. Table 3 lists the final set of hyperparameters. Categorical Cross Entropy: Categorical Cross Entropy (CCE) is used for multi-class classification tasks. It measures the difference between the true class labels and the predicted class probabilities. The formula sums the negative log-likelihood of the true class\u00e2\u20ac\u2122s predicted probability across all classes. We have used CCE as our loss function. Binary Cross Entropy for One Neuron: Binary Cross Entropy (BCE) is used for binary classification tasks. The binary cross-entropy loss measures the dissimilarity between predicted probability distributions and the ground truth labels. The formula is the negative log-likelihood of the predicted probability if the true label is 1 and 1 minus the predicted probability if the true label is 0. The BCE is utilized in each output layer neuron and used in the YOLOv8 classification task. AdamW Optimizer: AdamW stands for Adaptive Moment Estimation with Weight Decay. It is an extension of the Adam optimizer, including weight decay, to improve generalization by preventing overfitting. AdamW adjusts the learning rate based on the gradients\u00e2\u20ac\u2122 first and second moments and consists of a weight decay term to penalize large weights. Where: \u00ce\u02dctsubscript\u00ce\u02dc\u00f0\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is the parameter at time step t\u00f0\ufffd\u2018\u00a1titalic_t \u00ce\u00b1\u00f0\ufffd\u203a\u00bc is the learning rate mtsubscript\u00f0\ufffd\u2018\u0161\u00f0\ufffd\u2018\u00a1m_{t}italic_m start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is the biased first-moment estimate \u00f0\ufffd\ufffd\u2022tsubscript\u00f0\ufffd\ufffd\u2022\u00f0\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is the biased second raw moment estimate \u00cf\u00b5italic-\u00cf\u00b5 is a small constant to prevent division by zero weight_decay is the weight decay term [24]. The performance of our models is not examined by accuracy alone. In addition to accuracy, other metrics like f1-score, precision, recall, and loss were employed for the evaluation. Precision is an indicator of the accuracy of model predictions i.e., the ratio of the true positive predictions to the total number of positive predictions made by the model. The recall is an indicator of the model\u00e2\u20ac\u2122s ability to identify all the relevant classes i.e., ratio of true positive predictions to the total number of actual positive instances. The F1 score provides the single value for the evaluation of the model and is the harmonic mean of precision and recall. The loss gives insights into how well the model\u00e2\u20ac\u2122s prediction matches the true outcomes and is the difference between the predicted values and the actual values. Our study evaluated multiple deep-learning models for identifying endangered animal species from wildlife images. The results show the varying performance across the models. YOLOv8 outperformed the other models, and the DenseNet and Resnet models also did well, as their results were close to those of YOLOv8. In contrast, the VGG and Vanilla CNN models faced significant challenges. Table 4 shows the performances of different models. DenseNet: DenseNet architectures showed strong performance across all metrics. DenseNet 169 achieved a training accuracy of 98.27% and a validation accuracy of 93.91%. Also, it had F1 scores of 95.22% in training and 93.95% in validation. Impressively, DenseNet 201 outperformed by a slightly better training accuracy of 98.80% and had F1-scores of 96.36% in training and 92.22% in validation, though its validation accuracy was somewhat lower at 92.17%. Figure 7 shows training and validation set loss curves decreasing rapidly, finally reaching a plateau, indicating good learning and model convergence. The relatively smooth curve showed a minimal gap in Figure 7, indicating good generalization and no significant overfitting. ResNet: The ResNets architecture also showed promising results. Resnet 101 V2 reached a training accuracy of 98.74% and a validation accuracy of 92.17%. Its F1 scores were 97.36% in training and 92.09% in validation, showing robust performance. Resnet 152 V2 showed a training accuracy of 98.20% and a validation accuracy of 93.04%, with high F1-scores of 95.79% in training and 93.22% in validation. The training and validation data loss plunged drastically initially and finally tended towards low values, similar to DenseNet169, as shown in Figure 9. The very close train and validation loss curves indicated that the model generalized well without overfitting\u00e2\u20ac\u201da similar trend in the training and validation accuracy from Figure 9. VGG: In contrast, the VGG architectures underperformed significantly compared to DenseNet and ResNet models. VGG 16 and VGG 19 showed much lower training accuracies (46.00% and 32.67%, respectively) and validation accuracies (33.91% and 33.04%, respectively). Their F1 scores were also considerably lower, with VGG 16 at 42.89% for training and 28.65% for validation and VGG 19 at 29.82% for training and 31.19% for validation. The training loss decreased steadily, while the validation loss followed a different pattern, decreasing even slower and with apparent variance, as shown in Figure 11. There was a visible gap between training and validation loss, showing the possible overfitting phenomenon, i.e., a model fitting much better with the training set than the validation set. Also, Figure 11 shows oscillations in the training and validation accuracies. YOLOv8: The YOLOV8 model achieved an accuracy of 97.39% in training and 99.13% in validation with a shallow loss of 0.01175, which showed that despite being known for detection purposes, it surprisingly worked well for our classification task. The F1 score was 96.5% in training and 99.12% in validation. Figure 13 shows that the loss decreased rapidly and plateaued early in training, which shows the model\u00e2\u20ac\u2122s effectiveness for fast convergence during transfer learning. Unlike the loss, the accuracy oscillated slightly before it finally plateaued near 50 epochs, as indicated in Figure 13. CNN: We validated different architectures for the vanilla CNN with the same dataset. However, we did not get satisfactory results. Since our dataset contained images of species across 23 classes, simple, shallow CNN could not converge effectively. Nevertheless, we tried adjusting various parameters like the number of layers, regularization techniques, loss functions, and augmentations. Despite these efforts, the performance metrics remained mediocre. Our experimental analysis shows the metrics of various deep-learning models in identifying endangered animals on our custom endangered wildlife dataset, as shown in Figure 14. The dataset was carefully created from reputable online databases, ensuring the species\u00e2\u20ac\u2122 authenticity and relevance. Our motto was to train a model that could recognize vulnerable species and assist in their proper monitoring. Furthermore, the other side of our study involved finding the best available architecture for this task. We experimented with various such architectures and analyzed their performance under different metrics. We found that newer version of all the models showed stronger performance. VGG was the oldest among our models, so it performed poorly. Its accuracy was way below the vanilla CNN. Conversely, DenseNet and ResNet offered significantly better performance, so we can easily use them for related tasks. Also, we noted that these networks\u00e2\u20ac\u2122 newer and deeper versions did not provide any impactful difference across various metrics. In addition, we implemented transfer learning and did not train them from scratch, benchmarking their ease of use in downstream tasks like ours. We had to freeze the feature extraction layers and only trained the last few fully connected layers. Doing this saved the time and computing required without compromising their performance. Alongside standard CNN models like ResNet, DenseNet, and VGGNet, specially designed for classification tasks, we also experimented with YOLOv8. YOLOs are primarily designed and used as go-to models for detection and segmentation tasks. To our great surprise, the metrics surpassed other standard classification models. Thus, YOLO might work well for classification tasks for custom datasets in similar niches. Why does YOLOv8 perform the best? YOLOv8\u00e2\u20ac\u2122s superior performance might be due to its advanced architecture, which combines efficient feature extraction with fast processing capabilities by integrating components like CSPNet (Cross Stage Partial Networks) and PANet (Path Aggregation Network) [28, 15]. CSPNet reduces the computational cost while maintaining accuracy. It divides the feature map into two parts and merges them through the cross-stage hierarchy. On the other hand, PANet enhances the information flow between various layers, which is excellent for object detection across multi-scales. But, this proved beneficial for classification tasks, too. Even more importantly, the multiscale capability of YOLOv8 allows handling images with object sizes that can have significant variations and differing resolutions. It also has advanced augmentations, such as mosaic augmentation, which places four training images into one with diverse contexts in one image and hence helps the model generalize better to varying lighting and environmental conditions in training. All these features, together, carry out fast processing and effective feature extraction. To sum up, we performed experimental analysis on transfer learning of various deep-learning CNN architectures on our custom dataset containing images of endangered mammals from Nepal. Our findings featured the superior performance of YOLOv8 compared to other models like DenseNet, ResNetV2, and VGG. It demonstrated higher accuracy, precision, and recall, making it practical for our and similar classification tasks. Although lagging by a narrow margin, other models like ResNet and DenseNet also performed well and competed neck and neck with YOLOv8. Transfer learning proved beneficial, drastically reducing training time and data required while maintaining high performance, which is crucial for tasks with limited data availability. In the future, we will explore the ensemble methods that combine the strengths of multiple CNN architectures potentially enhancing classification accuracy and robustness, especially in diverse and challenging environmental conditions. We will also incorporate real-time monitoring capabilities in the future to provide feedback for conservation and take timely action in preventing the loss of endangered species. Hence, this study shows the reliance and robustness of deep-learning models in monitoring wildlife. This research received no external funding. The authors declare that there is no conflict of interest regarding the publication of this paper. The authors thank their supervisor, Dr. Mansi Bhavsar, for their invaluable guidance and support. Both authors contributed equally to this work.",
        "keywords": ""
    },
    {
        "id": 13,
        "title": "Bonus-malus Systems vs Delays in Claim Settlements: Analysis of Ruin Probabilities",
        "abstract": "AbstractOur paper explores a discrete-time risk model with time-varying premiums, investigating two types of correlated claims: main claims and by-claims. Settlement of the by-claims can be delayed for one time period, representing real-world insurance practices. We examine two premium principles based on reported and settled claims, using recursively computable finite-time ruin probabilities to evaluate the performance of time-varying premiums. Our findings suggest that, under specific assumptions, a higher probability of by-claim settlement delays leads to lower ruin probabilities. Moreover, a stronger correlation between main claims and their associated by-claims results in higher ruin probabilities. Lastly, the premium adjustment principles based on settled claims experience contribute to higher ruin probabilities compared to those based on reported claims experience, assuming all other factors remain constant. Notably, this difference becomes more pronounced when there is a high likelihood of by-claim delays.Keywords:Discrete-time risk model; Finite-time ruin; Recursive computation; Bonus-malus; Delayed claim",
        "corpus": "Our paper explores a discrete-time risk model with time-varying premiums, investigating two types of correlated claims: main claims and by-claims. Settlement of the by-claims can be delayed for one time period, representing real-world insurance practices. We examine two premium principles based on reported and settled claims, using recursively computable finite-time ruin probabilities to evaluate the performance of time-varying premiums. Our findings suggest that, under specific assumptions, a higher probability of by-claim settlement delays leads to lower ruin probabilities. Moreover, a stronger correlation between main claims and their associated by-claims results in higher ruin probabilities. Lastly, the premium adjustment principles based on settled claims experience contribute to higher ruin probabilities compared to those based on reported claims experience, assuming all other factors remain constant. Notably, this difference becomes more pronounced when there is a high likelihood of by-claim delays. Keywords: Discrete-time risk model; Finite-time ruin; Recursive computation; Bonus-malus; Delayed claim Due to the nature of the insurance business, certain insurers often need to deal with the issue of delayed claim settlements. Many factors prevent insurers from settling claims promptly after the claims are lodged. One of the main causes of delayed claims settlement is the investigation time insurers spend on verifying and assessing the reported claims. A typical example is casualty insurance. According to the usual claiming process of casualty insurance policies, after the policyholders notify the insurance company of the incident that causes loss or damage to their property, the surveyor/loss assessor will detect the reported damage to evaluate the repair/replacement cost. This process may also involve the police department and some third parties, so it may require a lot of time, which results in delayed claims settlement. Another cause of delayed claims settlement is delayed claim reporting. This issue occurs when the policyholder reports a previously incurred insurable loss to the insurer after their insurance policy has expired. In insurance terminology, this type of claim is known as incurred-but-not-reported claims or simply IBNR claims. As the name says, these claims are not reported in a timely manner which certainly delays the whole process of dealing with the claims. In term of the solvency risk, the delayed claims have a significant impact on the loss modelling by actuaries, since the timing of settled claims are inconsistent with the incident occurrence times. It may lead to the underestimation/ overestimation of claim experience in the time period under consideration which will reduce the effectiveness of the insolvency measures developed by usual loss models. Therefore, researchers and practitioners derived methods to deal with delayed or IBNR claims. A well-known approach to dealing with the IBNR claims is the chain ladder method (CLM). It uses the run-off triangles to help insurance companies estimate their required claim reserves involving IBNR losses. In ruin theory, risk models with delayed claims are developed to complement the classical risk model. This type of generalisation relaxes the assumption that claims settlements and claim reporting occur in the same financial period. As a result, the risk models with delayed claims are better connected with real-life insurance practice and attracted much attention from researchers in the literature. Regarding the relevant literature, Waters and Papatriandafylou (1985) derived the upper bounds for the ruin probability of a risk process with delayed claims settlement. Yuen and Guo (2001) studied the ruin probabilities for time-correlated claims in the compound binomial risk model. They introduced the principle of delayed claims in their model by defining the term \u00e2\u20ac\u02dcmain claims\u00e2\u20ac\u2122, which refers to the initial claims that induce another type of claims, so-called by-claims, with different severity distributions and time occurrence. According to their models, the main claims and by-claims are assumed to be independent, which is a restrictive assumption. Some similar models can be found in Wu and Yuen (2004), which is an extension of Yuen and Guo (2001) by considering the interaction of the dependent classes of business in the models. Xiao and Guo (2007) studied the joint distribution of the surplus immediately prior to ruin and deficit at ruin in the compound binomial risk model with time-correlated claims and its relationship with the classical compound binomial risk model. Moreover, Trufin et al. (2011) and Ahn et al. (2018) studied the ruin probability with IBNR claims. Yuen et al. (2005) applied the martingale theory to obtain the expression for the ultimate ruin probability with the corresponding Lundberg exponent of its non-delayed risk model. Zou and Xie (2010) considered the case that the claims number process follows the Erlang(2) process and derived the explicit expression for the survival probability when both the main claims amount and by-claims amount are exponentially distributed. Dassios and Zhao (2013) obtained an asymptotic expression for the ruin probability with delayed claims by exploiting the non-homogenous Poisson model. Besides, the studies of an approximation of the ruin probability with delayed claims can also be found in Gao et al. (2019) and Yang and Li (2019). For the dividend problem in the risk models with time-delayed claims, Wu and Li (2012) studied the expected present value of dividend payments up to the time of ruin by considering a constant dividend barrier, whereas Zhou et al. (2013) studied a similar problem and assumed that the premium income is governed by the binomial process. Liu and Zhang (2015) considered a randomized dividend strategy for the study of the expected present value of dividend payments up to the time of ruin. Further, the literature concerning the penalty function in the risk models with time-delayed claims can be found in Yuen et al. (2013), Zhu et al. (2014), Liu and Bao (2015), Xie and Zou (2017), Wat et al. (2018), Deng et al. (2018), Zou and Xie (2019) and Liu et al. (2020). In this paper, we will extend the study of Yuen and Guo (2001) by assuming that periodic premiums are adjustable and are controlled by previous claims experience. This extension is inspired by the well-known principle in the non-life insurance business, the so-called Bonus-Malus system, which allows the insurers to determine renewal premium levels based on the historical claims experience of the policyholders under consideration. The traditional bonus-malus systems are at the granular level, i.e. at the policyholder level, which ignores the overall financial status of the insurance company. To address the issue, we adopt the portfolio-dependent premium correction framework that is considered crudely, i.e. on the portfolio level or higher, which enables us to incorporate it into the risk models and to study the corresponding ruin probabilities. As a result, the proposed models in this study can be used to evaluate the risk of ruin for insurers who have to face both delayed claim settlements and varying premiums in their everyday business, such as automobile insurance companies. Studies of risk models with varying premiums can be found in various papers in the literature. For example, Trufin and Loisel (2013) studied the discrete-time risk models with premiums adjusted to the claims by B\u00c3\u00bchlmann credibility. Another model in a discrete-time setting can be found in Wu et al. (2015), who used a two-state Markov Chain model to express the ultimate ruin probabilities in terms of both recursive formulae and explicit forms. The related literature regarding the continuous-time setting can be found in Li et al. (2015a) and Constantinescu et al. (2016). In the study of Li et al. (2015a), the premiums were assumed to be adjusted according to the historical claims number, whereas the study of Constantinescu et al. (2016) assumed that the premiums are adjusted according to the change in the inter-arrival time distribution between claims. Additionally, Osatakul and Wu (2021) studied the risk models with claim-dependent premiums and also considered the external environment for their models. Further studies concerning the risk models with varying premiums can also be found in Afonso et al. (2010), Li et al. (2015b), Kucerovsk\u00c3\u00bd and Najafabadi (2017), Afonso et al. (2017) and Afonso et al. (2020) for the continuous-time setting, and Dufresne (1988) and Wagner (2001) for the discrete-time setting. In this paper, we inherit the assumptions regarding main claims and by-claims from Wu and Li (2012), which weakened the assumptions in Yuen and Guo (2001) by allowing the dependence between main claims and by-claims. It is worth mentioning that if premiums are to be adjusted by the settled claim experience, then the underlying premium status process would display an in-homogeneous nature, because the transition probability between any two premium levels vary from time to time due to the uncertainty in the settled claims. This property differs from the homogeneity property of the premium status process should the premiums be adjusted by the reported claim experience. This interesting contrast makes our discussions in this paper more realistic. This paper aims to answer to following questions: What is the impact of the probability of claims settlement delays on the ruin probabilities? What is the impact of the correlation between the main claims and by-claims on the ruin probabilities? Which of the premium adjustment strategies should be implemented by the insurers? In our study, we propose four premium adjustment principles: adjusting by aggregate reported claims, by aggregate settled claims, by reported number of claims and by settled number of claims. This paper is organised as follows. Section 2 presents the models and assumptions of our study. Section 3 to 6 presents results for the finite-time ruin probabilities under each of the above four premium adjustment principles respectively. Numerical examples showcasing our theoretical results in this paper are given in Section 7 with detailed discussions. Concluding remarks and potential future research are given in Section 8. We first define a surplus process of discrete times, denoted by Uksubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02dcU_{k}italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT, as where U0\u00e2\u02c6\u02c6\u00e2\u201e\u2022:={0,1,2,\u00e2\u20ac\u00a6}subscript\u011f\ufffd\u2018\u02c60\u00e2\u201e\u2022assign012\u00e2\u20ac\u00a6U_{0} start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_N := { 0 , 1 , 2 , \u00e2\u20ac\u00a6 } is the initial surplus, Stsubscript\u011f\ufffd\u2018\u2020\u011f\ufffd\u2018\u00a1S_{t}italic_S start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is the total amount of settled claims during the t\u011f\ufffd\u2018\u00a1titalic_tth unit time period payable at time t\u011f\ufffd\u2018\u00a1titalic_t, and Ctsubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\u00a1C_{t}italic_C start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is the premium of the t\u011f\ufffd\u2018\u00a1titalic_tth period received at the beginning of the period. In this paper we aim to study varying premiums. Let \u011f\ufffd\ufffd\u0153:={c1,c2,\u00e2\u20ac\u00a6,cl}assign\u011f\ufffd\ufffd\u0153subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2122 := { italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_c start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT } be the set of premium levels and \u011f\ufffd\u201c\u203a={1,2,\u00e2\u20ac\u00a6,l}\u011f\ufffd\u201c\u203a12\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u2122 = { 1 , 2 , \u00e2\u20ac\u00a6 , italic_l }. Without losing generality, we let c1<\u00e2\u20ac\u00a6<cl\u00e2\u02c6\u02c6\u00e2\u201e\u2022+:={1,2,\u00e2\u20ac\u00a6}subscript\u011f\ufffd\u2018\ufffd1\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2122superscript\u00e2\u201e\u2022assign12\u00e2\u20ac\u00a6c_{1}<...<c_{l} start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < \u00e2\u20ac\u00a6 < italic_c start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT := { 1 , 2 , \u00e2\u20ac\u00a6 }. As we mentioned previously, there are two types of reported individual claims, i.e. main claims and the associated by-claims. They are denoted by Xtsubscript\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1X_{t}italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT and Ytsubscript\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a1Y_{t}italic_Y start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT respectively for t\u00e2\u02c6\u02c6\u00e2\u201e\u2022+\u011f\ufffd\u2018\u00a1superscript\u00e2\u201e\u2022t \u00e2\u02c6\u02c6 blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT. In this paper, we only consider a very simple case where there is at most one main claim in any time period, and one main claim generates at most one by-claim. Both {Xt}t\u00e2\u02c6\u02c6\u00e2\u201e\u2022+subscriptsubscript\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a1superscript\u00e2\u201e\u2022 italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_t \u00e2\u02c6\u02c6 blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT end_POSTSUBSCRIPT and {Yt}t\u00e2\u02c6\u02c6\u00e2\u201e\u2022+subscriptsubscript\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a1superscript\u00e2\u201e\u2022 italic_Y start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_t \u00e2\u02c6\u02c6 blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT end_POSTSUBSCRIPT are independent and identically distributed (i.i.d.) sequences of random variables with common probability mass function (p.m.f.) fX\u00e2\ufffd\u00a2(x),x\u00e2\u02c6\u02c6\u00e2\u201e\u2022subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a5\u00e2\u201e\u2022f_{X}(x),x start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT ( italic_x ) , italic_x \u00e2\u02c6\u02c6 blackboard_N, and fY\u00e2\ufffd\u00a2(y),y\u00e2\u02c6\u02c6\u00e2\u201e\u2022subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a6\u00e2\u201e\u2022f_{Y}(y),y start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ( italic_y ) , italic_y \u00e2\u02c6\u02c6 blackboard_N, respectively. On the other hand, Xtsubscript\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1X_{t}italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT and Ytsubscript\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a1Y_{t}italic_Y start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT are assumed to be correlated with common joint p.m.f. fX\u00e2\ufffd\u00a2Y\u00e2\ufffd\u00a2(x,y)subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a6f_{XY}(x,y)italic_f start_POSTSUBSCRIPT italic_X italic_Y end_POSTSUBSCRIPT ( italic_x , italic_y ), x,y\u00e2\u02c6\u02c6\u00e2\u201e\u2022\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a6\u00e2\u201e\u2022x,y , italic_y \u00e2\u02c6\u02c6 blackboard_N. Not surprisingly, one can see that fX\u00e2\ufffd\u00a2Y\u00e2\ufffd\u00a2(0,y)=0subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u01520\u011f\ufffd\u2018\u00a60f_{XY}(0,y)=0italic_f start_POSTSUBSCRIPT italic_X italic_Y end_POSTSUBSCRIPT ( 0 , italic_y ) = 0 for y\u00e2\u2030 0\u011f\ufffd\u2018\u00a60y 0italic_y \u00e2\u2030 0. Assume that main claims are always settled at the end of the reporting time period, which is not the case for by-claims. When a by-claim Yksubscript\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u02dcY_{k}italic_Y start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT occurs, there is a probability 0\u00e2\u2030\u00a4q\u00e2\u2030\u00a410\u011f\ufffd\u2018\ufffd10 q 10 \u00e2\u2030\u00a4 italic_q \u00e2\u2030\u00a4 1 that its settlement will be delayed to the end of the (k+1)\u011f\ufffd\u2018\u02dc1(k+1)( italic_k + 1 )th period. Further, the settlement delays of Yk,k=1,2,\u00e2\u20ac\u00a6,formulae-sequencesubscript\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u02dc12\u00e2\u20ac\u00a6Y_{k},k=1,2, start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_k = 1 , 2 , \u00e2\u20ac\u00a6 , are independent of each other. Thus, the aggregate claim amount settled in time period t\u011f\ufffd\u2018\u00a1titalic_t is For a given time horizon n\u00e2\u02c6\u02c6\u00e2\u201e\u2022+\u011f\ufffd\u2018\u203asuperscript\u00e2\u201e\u2022n \u00e2\u02c6\u02c6 blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, the finite-time ruin probability of Uksubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02dcU_{k}italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT with initial premium level cisubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013c_{i}italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, for i\u00e2\u02c6\u02c6\u011f\ufffd\u201c\u203a\u011f\ufffd\u2018\u2013\u011f\ufffd\u201c\u203ai \u00e2\u02c6\u02c6 bold_caligraphic_L, is defined as where the subscript u\u011f\ufffd\u2018\u00a2uitalic_u represents the condition U0=usubscript\u011f\ufffd\u2018\u02c60\u011f\ufffd\u2018\u00a2U_{0}=uitalic_U start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = italic_u. We have \u00cf\u02c6i\u00e2\ufffd\u00a2(u,n)=1subscript\u011f\ufffd\u0153\u201c\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u203a1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_u , italic_n ) = 1 for u<0,n\u00e2\u2030\u00a50formulae-sequence\u011f\ufffd\u2018\u00a20\u011f\ufffd\u2018\u203a0u<0,n 0italic_u < 0 , italic_n \u00e2\u2030\u00a5 0 and \u00cf\u02c6i\u00e2\ufffd\u00a2(u,0)=0subscript\u011f\ufffd\u0153\u201c\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a200 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_u , 0 ) = 0 for u\u00e2\u2030\u00a50\u011f\ufffd\u2018\u00a20u 0italic_u \u00e2\u2030\u00a5 0 by convention. Remark We assume that there is no delayed by-claim from the time period before the initial time 0. Then, S1subscript\u011f\ufffd\u2018\u20201S_{1}italic_S start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT can only be X1subscript\u011f\ufffd\u2018\u20391X_{1}italic_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT or X1+Y1subscript\u011f\ufffd\u2018\u20391subscript\u011f\ufffd\u2018\u01521X_{1}+Y_{1}italic_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_Y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. Next we shall develop some recursive algorithm to compute the finite-time ruin probabilities under the above proposed risk framework. To enable our derivations, we define the following auxiliary surplus process with an up-front delayed by-claim where Y0>0subscript\u011f\ufffd\u2018\u015200Y_{0}>0italic_Y start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT > 0 is the up-front delayed by-claim and other notations are exactly the same as those in model (2.1). Assume that Y0subscript\u011f\ufffd\u2018\u01520Y_{0}italic_Y start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT is independent of all other random components in model (2.4) and follows the p.m.f. fY\u00e2\ufffd\u00a2(y)subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a6f_{Y}(y)italic_f start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ( italic_y ). The corresponding n\u011f\ufffd\u2018\u203anitalic_n-period finite time ruin probability with initial premium level cisubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013c_{i}italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, i\u00e2\u02c6\u02c6\u011f\ufffd\u201c\u203a\u011f\ufffd\u2018\u2013\u011f\ufffd\u201c\u203ai \u00e2\u02c6\u02c6 bold_caligraphic_L, is defined as Again, \u00cf\u02c6i\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(u;z,n)=1superscriptsubscript\u011f\ufffd\u0153\u201c\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u203a1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_u ; italic_z , italic_n ) = 1 for u<0,n\u00e2\u2030\u00a50formulae-sequence\u011f\ufffd\u2018\u00a20\u011f\ufffd\u2018\u203a0u<0,n 0italic_u < 0 , italic_n \u00e2\u2030\u00a5 0 and \u00cf\u02c6i\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(u;z,0)=0superscriptsubscript\u011f\ufffd\u0153\u201c\u011f\ufffd\u2018\u2013\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a700 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_u ; italic_z , 0 ) = 0 for u\u00e2\u2030\u00a50\u011f\ufffd\u2018\u00a20u 0italic_u \u00e2\u2030\u00a5 0 by convention. In the following sections, we shall consider four different premium changing principles, i.e. premiums adjusted according to aggregate reported claims, premiums adjusted according to aggregate settled claims, premiums adjusted according to the reported claim frequency, and premiums adjusted according to the settled claim frequency, respectively. The premium changing rule considered in this section allows the next periodic premium to be determined based on the current premium level as well as the total reported claims in the current time period. In our previous model setting, we can see that the total reported claims in time period k\u011f\ufffd\u2018\u02dckitalic_k is Xk+Yksubscript\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u02dcsubscript\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u02dcX_{k}+Y_{k}italic_X start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT + italic_Y start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT. Whether the settlement of Yksubscript\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u02dcY_{k}italic_Y start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT is delayed or not does not have impact on the next periodic premium level. We define a bonus-malus system \u00ce\u201d=(\u011f\ufffd\ufffd\u201c,\u011f\ufffd\ufffd\u0153,i)\u00ce\u201d\u011f\ufffd\ufffd\u201c\u011f\ufffd\ufffd\u0153\u011f\ufffd\u2018\u2013 = ( bold_T , bold_c , italic_i ), where i\u00e2\u02c6\u02c6\u011f\ufffd\u201c\u203a\u011f\ufffd\u2018\u2013\u011f\ufffd\u201c\u203ai \u00e2\u02c6\u02c6 bold_caligraphic_L is the state of initial premium level; \u011f\ufffd\ufffd\u201c={ti\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(s)}i,j\u00e2\u02c6\u02c6\u011f\ufffd\u201c\u203a;s\u00e2\u02c6\u02c6\u00e2\u201e\u2022\u011f\ufffd\ufffd\u201csubscriptsubscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018 formulae-sequence\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u201c\u203a\u011f\ufffd\u2018 \u00e2\u201e\u2022 = { italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ( italic_s ) } start_POSTSUBSCRIPT italic_i , italic_j \u00e2\u02c6\u02c6 bold_caligraphic_L ; italic_s \u00e2\u02c6\u02c6 blackboard_N end_POSTSUBSCRIPT denotes a general set of time-homogeneous rules for premium variations. For any s\u00e2\u02c6\u02c6\u00e2\u201e\u2022\u011f\ufffd\u2018 \u00e2\u201e\u2022s \u00e2\u02c6\u02c6 blackboard_N and k\u00e2\u02c6\u02c6\u00e2\u201e\u2022+\u011f\ufffd\u2018\u02dcsuperscript\u00e2\u201e\u2022k \u00e2\u02c6\u02c6 blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, ti\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(s)=1subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018 1t_{ij}(s)=1italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ( italic_s ) = 1 if the total reported claim amount s\u011f\ufffd\u2018 sitalic_s in time period k\u011f\ufffd\u2018\u02dckitalic_k leads to the transition from premium level Ck=cisubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\u02dcsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013C_{k}=c_{i}italic_C start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT to Ck+1=cjsubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\u02dc1subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2014C_{k+1}=c_{j}italic_C start_POSTSUBSCRIPT italic_k + 1 end_POSTSUBSCRIPT = italic_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT and ti\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(s)=0subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018 0t_{ij}(s)=0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ( italic_s ) = 0 otherwise. For any k\u00e2\u02c6\u02c6\u00e2\u201e\u2022+\u011f\ufffd\u2018\u02dcsuperscript\u00e2\u201e\u2022k \u00e2\u02c6\u02c6 blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, the probability that the premium level moves from level cisubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013c_{i}italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT in time period k\u011f\ufffd\u2018\u02dckitalic_k to level cjsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2014c_{j}italic_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT in time period k+1\u011f\ufffd\u2018\u02dc1k+1italic_k + 1 is defined by Using (3.6), one can obtain a one-step transition probability matrix for the premium level Markov process Before we present our first main result, we would like to show a simple relationship between the two finite-time ruin probabilities defined before, which will benefit our following discussions. When premiums are adjusted according to aggregate reported claims, the finite-time ruin probabilities \u00cf\u02c6\u011f\ufffd\u0153\u201c and \u00cf\u02c6\u00e2\u20ac\u00b2superscript\u011f\ufffd\u0153\u201c\u00e2\u20ac\u00b2 start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT satisfy the following relationship, for n\u00e2\u02c6\u02c6\u00e2\u201e\u2022+\u011f\ufffd\u2018\u203asuperscript\u00e2\u201e\u2022n \u00e2\u02c6\u02c6 blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, Proof. Because the premiums are adjusted according to the total reported claims, the up-front delayed claim Y0subscript\u011f\ufffd\u2018\u01520Y_{0}italic_Y start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT has no impact on how the next premium is going to change. When 0<z\u00e2\u2030\u00a4u0\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u00a20<z u0 < italic_z \u00e2\u2030\u00a4 italic_u, it can be seen from (2.3) that Uk\u00e2\u20ac\u00b2subscriptsuperscript\u011f\ufffd\u2018\u02c6\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u02dcU^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT with initial surplus u\u011f\ufffd\u2018\u00a2uitalic_u is equivalent to Uksubscript\u011f\ufffd\u2018\u02c6\u011f\ufffd\u2018\u02dcU_{k}italic_U start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT with initial surplus u\u00e2\u02c6\u2019z\u00e2\u2030\u00a50\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a70u-z 0italic_u - italic_z \u00e2\u2030\u00a5 0. So the first case of (3.10) holds. When z>u+ci,\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013z>u+c_{i},italic_z > italic_u + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , the delayed by-claim is large enough to cause ruin, no matter whether there is any new claim in time period 1. \u00e2\u2013\u00a1\u00e2\u2013\u00a1 Before we present our first main result, we introduce an auxiliary function that is used to simplify our main results given within the rest of this paper: Our first main result is given below. Given initial surplus u\u00e2\u2030\u00a50\u011f\ufffd\u2018\u00a20u 0italic_u \u00e2\u2030\u00a5 0 and initial premium level cisubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013c_{i}italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, i\u00e2\u02c6\u02c6\u011f\ufffd\u201c\u203a\u011f\ufffd\u2018\u2013\u011f\ufffd\u201c\u203ai \u00e2\u02c6\u02c6 bold_caligraphic_L, the finite-time ruin probability with premiums adjusted according to aggregate reported claims without the up-front delayed by-claim satisfies the following recursive formula, for n\u00e2\u02c6\u02c6\u00e2\u201e\u2022+\u011f\ufffd\u2018\u203asuperscript\u00e2\u201e\u2022n \u00e2\u02c6\u02c6 blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, where \u00cf\u02c6i\u00e2\ufffd\u00a2(u,1)=(1\u00e2\u02c6\u2019q)\u00e2\ufffd\u00a2\u00e2\u02c6\u2018y=1\u00e2\u02c6\ufffd\u00ce\u00bey\u00e2\ufffd\u00a2(u+ci)+\u00e2\u02c6\u2018x=u+ci+1\u00e2\u02c6\ufffdfX\u00e2\ufffd\u00a2(x)subscript\u011f\ufffd\u0153\u201c\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a211\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u00a61subscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013superscriptsubscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20131subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a5 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_u , 1 ) = ( 1 - italic_q ) \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_y = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\ufffd end_POSTSUPERSCRIPT italic_\u00ce\u00be start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ( italic_u + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) + \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_x = italic_u + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\ufffd end_POSTSUPERSCRIPT italic_f start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT ( italic_x ). Proof. From (2.3), we have where the three major terms within the second equality represent all possibilities of the main claim and by-claim within the first time period. The first term is the scenario that the main claim in the first time period is large enough to cause ruin at time 1. It does not matter whether there is a by-claim or not in this case. The second term covers three scenarios: no claims within the first time period at all, i.e. X1=Y1=0subscript\u011f\ufffd\u2018\u20391subscript\u011f\ufffd\u2018\u015210X_{1}=Y_{1}=0italic_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_Y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0; only a small by-claim without any by-claims, i.e. X1=x,Y1=0formulae-sequencesubscript\u011f\ufffd\u2018\u20391\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\u015210X_{1}=x,Y_{1}=0italic_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_x , italic_Y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0, 1\u00e2\u2030\u00a4x\u00e2\u2030\u00a4u+ci1\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20131 x u+c_{i}1 \u00e2\u2030\u00a4 italic_x \u00e2\u2030\u00a4 italic_u + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT; a small main claim and a small by-claim satisfying X1+Y1\u00e2\u2030\u00a4u+cisubscript\u011f\ufffd\u2018\u20391subscript\u011f\ufffd\u2018\u01521\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013X_{1}+Y_{1} u+c_{i}italic_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_Y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_u + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, where 1\u00e2\u2030\u00a4x\u00e2\u2030\u00a4u+ci1\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20131 x u+c_{i}1 \u00e2\u2030\u00a4 italic_x \u00e2\u2030\u00a4 italic_u + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, 1\u00e2\u2030\u00a4y\u00e2\u2030\u00a4u+ci\u00e2\u02c6\u2019x1\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a51 y u+c_{i}-x1 \u00e2\u2030\u00a4 italic_y \u00e2\u2030\u00a4 italic_u + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - italic_x. Allowing x=0\u011f\ufffd\u2018\u00a50x=0italic_x = 0 when 1\u00e2\u2030\u00a4y\u00e2\u2030\u00a4u+ci\u00e2\u02c6\u2019x1\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a51 y u+c_{i}-x1 \u00e2\u2030\u00a4 italic_y \u00e2\u2030\u00a4 italic_u + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - italic_x does not hurt as we have made it clear early in Section 2 that fX\u00e2\ufffd\u00a2Y\u00e2\ufffd\u00a2(0,y)=0subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u01520\u011f\ufffd\u2018\u00a60f_{XY}(0,y)=0italic_f start_POSTSUBSCRIPT italic_X italic_Y end_POSTSUBSCRIPT ( 0 , italic_y ) = 0 for y\u00e2\u2030 0\u011f\ufffd\u2018\u00a60y \u00e2\u2030 0. The third term represents the scenario that there is a small main claim within the first time period paired with a large by-claim satisfying X1+Y1\u00e2\u2030\u00a5u+ci+1subscript\u011f\ufffd\u2018\u20391subscript\u011f\ufffd\u2018\u01521\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20131X_{1}+Y_{1} u+c_{i}+1italic_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_Y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030\u00a5 italic_u + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + 1, where 1\u00e2\u2030\u00a4x\u00e2\u2030\u00a4u+ci1\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20131 x u+c_{i}1 \u00e2\u2030\u00a4 italic_x \u00e2\u2030\u00a4 italic_u + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, y\u00e2\u2030\u00a5u+ci\u00e2\u02c6\u2019x+1\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a51y u+c_{i}-x+1italic_y \u00e2\u2030\u00a5 italic_u + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - italic_x + 1. The two possibilities that the by-claim is settled within this time period or delayed to the next time period are considered separately, where the non-delay case leads to ruin at time 1. Considering the above scenarios and applying the given rule of premium adjustments for the second time period yield Note that we have Uk\u00e2\u20ac\u00b2subscriptsuperscript\u011f\ufffd\u2018\u02c6\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u02dcU^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT in the fourth term of both equalities because there is a delayed by-claim Y1subscript\u011f\ufffd\u2018\u01521Y_{1}italic_Y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT at the beginning of the second time period. From (2.3) and (2.5), we have One can also verify that \u00e2\u2013\u00a1\u00e2\u2013\u00a1 Remark. From the definition of \u00ce\u00bey\u00e2\ufffd\u00a2(n+y)subscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u00a6 start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ( italic_n + italic_y ), one can show that Also, \u00e2\u02c6\u2018x=u+ci+1\u00e2\u02c6\ufffdfX\u00e2\ufffd\u00a2(x)=1\u00e2\u02c6\u2019\u00e2\u02c6\u2018x=0u+cifX\u00e2\ufffd\u00a2(x)superscriptsubscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20131subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a51superscriptsubscript\u011f\ufffd\u2018\u00a50\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a5 start_POSTSUBSCRIPT italic_x = italic_u + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\ufffd end_POSTSUPERSCRIPT italic_f start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT ( italic_x ) = 1 - \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_x = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_u + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_f start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT ( italic_x ). Therefore, in the recursive formula given in Theorem 1, there is only one infinite summation left which requires extra attention when use it for computational purposes. To use the recursive formula obtained in Theorem 1, we need to find a way to determine \u00cf\u02c6i\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(0;z,n)subscriptsuperscript\u011f\ufffd\u0153\u201c\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u20130\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u203a start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( 0 ; italic_z , italic_n ), 0<z\u00e2\u2030\u00a4u+ci0\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20130<z u+c_{i}0 < italic_z \u00e2\u2030\u00a4 italic_u + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, n\u00e2\u02c6\u02c6\u00e2\u201e\u2022+\u011f\ufffd\u2018\u203asuperscript\u00e2\u201e\u2022n \u00e2\u02c6\u02c6 blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT. The finite-time ruin probability with premiums adjusted according to aggregate reported claims and an up-front delayed by-claim z\u011f\ufffd\u2018\u00a7zitalic_z satisfies the following recursive formula, for 0<z\u00e2\u2030\u00a4u+ci0\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20130<z u+c_{i}0 < italic_z \u00e2\u2030\u00a4 italic_u + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and n\u00e2\u02c6\u02c6\u00e2\u201e\u2022+\u011f\ufffd\u2018\u203asuperscript\u00e2\u201e\u2022n \u00e2\u02c6\u02c6 blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, where \u00cf\u02c6i\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(0;z,1)=(1\u00e2\u02c6\u2019q)\u00e2\ufffd\u00a2\u00e2\u02c6\u2018y=1\u00e2\u02c6\ufffd\u00ce\u00bey\u00e2\ufffd\u00a2(ci\u00e2\u02c6\u2019z)+\u00e2\u02c6\u2018x=ci\u00e2\u02c6\u2019z+1\u00e2\u02c6\ufffdfX\u00e2\ufffd\u00a2(x)subscriptsuperscript\u011f\ufffd\u0153\u201c\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u20130\u011f\ufffd\u2018\u00a711\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u00a61subscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a7superscriptsubscript\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a71subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a5 )+ start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( 0 ; italic_z , 1 ) = ( 1 - italic_q ) \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_y = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\ufffd end_POSTSUPERSCRIPT italic_\u00ce\u00be start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ( italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - italic_z ) + \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_x = italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - italic_z + 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\ufffd end_POSTSUPERSCRIPT italic_f start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT ( italic_x ). Proof. For u<z\u00e2\u2030\u00a4u+ci\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013u<z u+c_{i}italic_u < italic_z \u00e2\u2030\u00a4 italic_u + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, the same method in the proof of Theorem 1 can be used to derive a recursive formula for \u00cf\u02c6i\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(u;z,n+1)subscriptsuperscript\u011f\ufffd\u0153\u201c\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u203a1 start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_u ; italic_z , italic_n + 1 ). Using (3.10), (3.12) can be obtained by replacing \u00cf\u02c6i\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(u;z,n)subscriptsuperscript\u011f\ufffd\u0153\u201c\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u203a start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_u ; italic_z , italic_n ) with \u00cf\u02c6i\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(0;z\u00e2\u02c6\u2019u,n)subscriptsuperscript\u011f\ufffd\u0153\u201c\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u20130\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u203a start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( 0 ; italic_z - italic_u , italic_n ) in the formula. \u00e2\u2013\u00a1\u00e2\u2013\u00a1 Previously, we have discussed the first case of varying premiums based on the total reported claims. In contrast, we shall consider another case where for k\u00e2\u02c6\u02c6\u00e2\u201e\u2022+\u011f\ufffd\u2018\u02dcsuperscript\u00e2\u201e\u2022k \u00e2\u02c6\u02c6 blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, the premium Ck+1subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\u02dc1C_{k+1}italic_C start_POSTSUBSCRIPT italic_k + 1 end_POSTSUBSCRIPT is determined by Cksubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\u02dcC_{k}italic_C start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT and the total settled claims in time period k\u011f\ufffd\u2018\u02dckitalic_k, i.e. Sksubscript\u011f\ufffd\u2018\u2020\u011f\ufffd\u2018\u02dcS_{k}italic_S start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT. Other model assumptions are the same as the previous case. It is worth noting that in this case of premium correction, the underlying Markov process governing the periodic premium levels is not time-homogeneous anymore since the distribution of aggregate settled claims Stsubscript\u011f\ufffd\u2018\u2020\u011f\ufffd\u2018\u00a1S_{t}italic_S start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT takes different forms over time, see (2.2) for details. Further, Lemma 1 does not hold in this case either as having a by-claim delayed from previous time period or not does matter when determining future premiums. However, we can still follow the main idea in previous section to obtain the following main result. Given initial surplus u\u00e2\u2030\u00a50\u011f\ufffd\u2018\u00a20u 0italic_u \u00e2\u2030\u00a5 0 and initial premium level cisubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013c_{i}italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, i\u00e2\u02c6\u02c6\u011f\ufffd\u201c\u203a\u011f\ufffd\u2018\u2013\u011f\ufffd\u201c\u203ai \u00e2\u02c6\u02c6 bold_caligraphic_L, the finite-time ruin probability with premiums adjusted according to aggregate settled claims without the up-front delayed by-claim satisfies the following recursive formula, for n\u00e2\u02c6\u02c6\u00e2\u201e\u2022+\u011f\ufffd\u2018\u203asuperscript\u00e2\u201e\u2022n \u00e2\u02c6\u02c6 blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, where \u00cf\u02c6i\u00e2\ufffd\u00a2(u,1)=\u00e2\u02c6\u2018x=u+ci+1\u00e2\u02c6\ufffdfX\u00e2\ufffd\u00a2(x)+(1\u00e2\u02c6\u2019q)\u00e2\ufffd\u00a2\u00e2\u02c6\u2018y=1\u00e2\u02c6\ufffd\u00ce\u00bey\u00e2\ufffd\u00a2(u+ci)subscript\u011f\ufffd\u0153\u201c\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a21superscriptsubscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20131subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a51\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u00a61subscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013 y=1}^{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_u , 1 ) = \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_x = italic_u + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\ufffd end_POSTSUPERSCRIPT italic_f start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT ( italic_x ) + ( 1 - italic_q ) \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_y = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\ufffd end_POSTSUPERSCRIPT italic_\u00ce\u00be start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ( italic_u + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ). Proof. From (2.3), we have The scenarios listed in the third equality are the same as those in the second equality within the proof of Theorem 1. Then we have Note that the rule of premium adjustments applied above is different from the rule proposed in Section 3. Here only the settled claims are counted when analysing the aggregate claims for the premium adjustment purposes. Similar to Theorem 1, one can verify that the result for \u00cf\u02c6i\u00e2\ufffd\u00a2(u,1)subscript\u011f\ufffd\u0153\u201c\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a21 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_u , 1 ) is just a special case of n=1\u011f\ufffd\u2018\u203a1n=1italic_n = 1. \u00e2\u2013\u00a1\u00e2\u2013\u00a1 To use the recursive formula obtained in Theorem 2, we need to find a way to determine \u00cf\u02c6i\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(u;z,n)subscriptsuperscript\u011f\ufffd\u0153\u201c\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u203a start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_u ; italic_z , italic_n ), 0<z\u00e2\u2030\u00a4ci0\u011f\ufffd\u2018\u00a7subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20130<z c_{i}0 < italic_z \u00e2\u2030\u00a4 italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, n\u00e2\u02c6\u02c6\u00e2\u201e\u2022+\u011f\ufffd\u2018\u203asuperscript\u00e2\u201e\u2022n \u00e2\u02c6\u02c6 blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT. The finite-time ruin probability with premiums adjusted according to aggregate settled claims and an up-front delayed by-claim z\u011f\ufffd\u2018\u00a7zitalic_z satisfies the following recursive formula, for 0<z\u00e2\u2030\u00a4u+ci0\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20130<z u+c_{i}0 < italic_z \u00e2\u2030\u00a4 italic_u + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and n\u00e2\u02c6\u02c6\u00e2\u201e\u2022+\u011f\ufffd\u2018\u203asuperscript\u00e2\u201e\u2022n \u00e2\u02c6\u02c6 blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, where \u00cf\u02c6i\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(u;z,1)=\u00e2\u02c6\u2018x=u\u00e2\u02c6\u2019z+ci+1\u00e2\u02c6\ufffdfX\u00e2\ufffd\u00a2(x)+(1\u00e2\u02c6\u2019q)\u00e2\ufffd\u00a2\u00e2\u02c6\u2018y=1\u00e2\u02c6\ufffd\u00ce\u00bey\u00e2\ufffd\u00a2(u\u00e2\u02c6\u2019z+ci)subscriptsuperscript\u011f\ufffd\u0153\u201c\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a71superscriptsubscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a7subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20131subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a51\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u00a61subscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a7subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013 }(x)+(1-q) start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_u ; italic_z , 1 ) = \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_x = italic_u - italic_z + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\ufffd end_POSTSUPERSCRIPT italic_f start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT ( italic_x ) + ( 1 - italic_q ) \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_y = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\ufffd end_POSTSUPERSCRIPT italic_\u00ce\u00be start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ( italic_u - italic_z + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ). Proof. Using (4.13), (4.14) can be obtained by adding z\u011f\ufffd\u2018\u00a7zitalic_z into the premium rule function ti\u00e2\ufffd\u00a2jsubscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014t_{ij}italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT and replacing u\u011f\ufffd\u2018\u00a2uitalic_u by u\u00e2\u02c6\u2019z\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a7u-zitalic_u - italic_z in (4.13). \u00e2\u2013\u00a1\u00e2\u2013\u00a1 In this section, we shall switch the premium correction trigger from aggregate claim experience to claim frequency experience. We still denote the bonus-malus system by \u00ce\u201d=(\u011f\ufffd\ufffd\u201c,\u011f\ufffd\ufffd\u0153,i)\u00ce\u201d\u011f\ufffd\ufffd\u201c\u011f\ufffd\ufffd\u0153\u011f\ufffd\u2018\u2013 = ( bold_T , bold_c , italic_i ), where i\u00e2\u02c6\u02c6\u011f\ufffd\u201c\u203a\u011f\ufffd\u2018\u2013\u011f\ufffd\u201c\u203ai \u00e2\u02c6\u02c6 bold_caligraphic_L; \u011f\ufffd\ufffd\u201c={ti\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(k)}i,j\u00e2\u02c6\u02c6\u011f\ufffd\u201c\u203a;k\u00e2\u02c6\u02c6\u00e2\u201e\u2022\u011f\ufffd\ufffd\u201csubscriptsubscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u02dcformulae-sequence\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u201c\u203a\u011f\ufffd\u2018\u02dc\u00e2\u201e\u2022 = { italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ( italic_k ) } start_POSTSUBSCRIPT italic_i , italic_j \u00e2\u02c6\u02c6 bold_caligraphic_L ; italic_k \u00e2\u02c6\u02c6 blackboard_N end_POSTSUBSCRIPT denotes a general set of time-homogeneous rules with input k\u011f\ufffd\u2018\u02dckitalic_k being the number of claims. For any k\u00e2\u02c6\u02c6\u00e2\u201e\u2022\u011f\ufffd\u2018\u02dc\u00e2\u201e\u2022k \u00e2\u02c6\u02c6 blackboard_N and n\u00e2\u02c6\u02c6\u00e2\u201e\u2022+\u011f\ufffd\u2018\u203asuperscript\u00e2\u201e\u2022n \u00e2\u02c6\u02c6 blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, ti\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(k)=1subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u02dc1t_{ij}(k)=1italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ( italic_k ) = 1 if the total number of claims in time period n\u011f\ufffd\u2018\u203anitalic_n leads to the transition from premium level Cn=cisubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013C_{n}=c_{i}italic_C start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT to Cn+1=cjsubscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\u203a1subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2014C_{n+1}=c_{j}italic_C start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT = italic_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT and ti\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2(k)=0subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u02dc0t_{ij}(k)=0italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ( italic_k ) = 0 otherwise. Now we consider the first type of claim frequency, i.e. the total number of reported claims. Let NtXsubscriptsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1N^{X}_{t}italic_N start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT denote the number of main claims in t\u011f\ufffd\u2018\u00a1titalic_t-th time period. According to the assumption in section 2, we have \u00e2\u201e\u2122\u00e2\ufffd\u00a2(NtX=0)=fX\u00e2\ufffd\u00a2(0)\u00e2\u201e\u2122subscriptsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a10subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u20390 ( italic_N start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0 ) = italic_f start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT ( 0 ) and \u00e2\u201e\u2122\u00e2\ufffd\u00a2(NtX=1)=1\u00e2\u02c6\u2019fX\u00e2\ufffd\u00a2(0)\u00e2\u201e\u2122subscriptsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a111subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u20390 ( italic_N start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 1 ) = 1 - italic_f start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT ( 0 ). Similarly, the number of by-claims in time period t\u011f\ufffd\u2018\u00a1titalic_t is denoted by NtYsubscriptsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a1N^{Y}_{t}italic_N start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, where \u00e2\u201e\u2122\u00e2\ufffd\u00a2(NtY=0)=fY\u00e2\ufffd\u00a2(0)\u00e2\u201e\u2122subscriptsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a10subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u01520 ( italic_N start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0 ) = italic_f start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ( 0 ) and \u00e2\u201e\u2122\u00e2\ufffd\u00a2(NtY=1)=1\u00e2\u02c6\u2019fY\u00e2\ufffd\u00a2(0)\u00e2\u201e\u2122subscriptsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a111subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u01520 ( italic_N start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 1 ) = 1 - italic_f start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ( 0 ). We assume that NtYsubscriptsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a1N^{Y}_{t}italic_N start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is observable at time t\u011f\ufffd\u2018\u00a1titalic_t no matter if the settlement of Ytsubscript\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a1Y_{t}italic_Y start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT will be delayed or not, so the total number of reported claims in time period t\u011f\ufffd\u2018\u00a1titalic_t is NtX+NtYsubscriptsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1subscriptsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a1N^{X}_{t}+N^{Y}_{t}italic_N start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_N start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT. For any time period t\u011f\ufffd\u2018\u00a1titalic_t, t\u00e2\u02c6\u02c6\u00e2\u201e\u2022+\u011f\ufffd\u2018\u00a1superscript\u00e2\u201e\u2022t \u00e2\u02c6\u02c6 blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, there are only three cases of reported number of claims: NtX=0subscriptsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a10N^{X}_{t}=0italic_N start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0 and NtY=0subscriptsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a10N^{Y}_{t}=0italic_N start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0; NtX=1subscriptsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a11N^{X}_{t}=1italic_N start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 1 and NtY=0subscriptsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a10N^{Y}_{t}=0italic_N start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0; NtX=1subscriptsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a11N^{X}_{t}=1italic_N start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 1 and NtY=1subscriptsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a11N^{Y}_{t}=1italic_N start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 1. Using a similar method as the one used in Section 3, we obtain the following main result: Given initial surplus u\u00e2\u2030\u00a50\u011f\ufffd\u2018\u00a20u 0italic_u \u00e2\u2030\u00a5 0 and initial premium level cisubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013c_{i}italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, i\u00e2\u02c6\u02c6\u011f\ufffd\u201c\u203a\u011f\ufffd\u2018\u2013\u011f\ufffd\u201c\u203ai \u00e2\u02c6\u02c6 bold_caligraphic_L, the finite-time ruin probability with premiums adjusted according to reported number of claims without the up-front delayed by-claim satisfies the following recursive formula, for n\u00e2\u02c6\u02c6\u00e2\u201e\u2022+\u011f\ufffd\u2018\u203asuperscript\u00e2\u201e\u2022n \u00e2\u02c6\u02c6 blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, where \u00cf\u02c6i\u00e2\ufffd\u00a2(u,1)=(1\u00e2\u02c6\u2019q)\u00e2\ufffd\u00a2\u00e2\u02c6\u2018y=1\u00e2\u02c6\ufffd\u00ce\u00bey\u00e2\ufffd\u00a2(u+ci)+\u00e2\u02c6\u2018x=u+ci+1\u00e2\u02c6\ufffdfX\u00e2\ufffd\u00a2(x)subscript\u011f\ufffd\u0153\u201c\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a211\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u00a61subscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013superscriptsubscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20131subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a5 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_u , 1 ) = ( 1 - italic_q ) \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_y = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\ufffd end_POSTSUPERSCRIPT italic_\u00ce\u00be start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ( italic_u + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) + \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_x = italic_u + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\ufffd end_POSTSUPERSCRIPT italic_f start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT ( italic_x ). Proof. It is not hard to see that the formula (5.15) can be obtained by replacing the premium rule ti\u00e2\ufffd\u00a2jsubscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014t_{ij}italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT in (3.11) with the new version defined at the beginning of this section. Since there are only three cases of total number of reported claims in each time period, one can get (5.15) straightforwardly. \u00e2\u2013\u00a1\u00e2\u2013\u00a1 The finite-time ruin probability with premiums adjusted according to reported claims number and an up-front delayed by-claim z\u011f\ufffd\u2018\u00a7zitalic_z satisfies the following recursive formula, for 0<z\u00e2\u2030\u00a4ci0\u011f\ufffd\u2018\u00a7subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20130<z c_{i}0 < italic_z \u00e2\u2030\u00a4 italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and n\u00e2\u02c6\u02c6\u00e2\u201e\u2022+\u011f\ufffd\u2018\u203asuperscript\u00e2\u201e\u2022n \u00e2\u02c6\u02c6 blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, where \u00cf\u02c6i\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(0;z,1)=(1\u00e2\u02c6\u2019q)\u00e2\ufffd\u00a2\u00e2\u02c6\u2018y=1\u00e2\u02c6\ufffd\u00ce\u00bey\u00e2\ufffd\u00a2(ci\u00e2\u02c6\u2019z)+\u00e2\u02c6\u2018x=ci\u00e2\u02c6\u2019z+1\u00e2\u02c6\ufffdfX\u00e2\ufffd\u00a2(x)subscriptsuperscript\u011f\ufffd\u0153\u201c\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u20130\u011f\ufffd\u2018\u00a711\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u00a61subscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a7superscriptsubscript\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a71subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a5 c_{i}-z)}+ start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( 0 ; italic_z , 1 ) = ( 1 - italic_q ) \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_y = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\ufffd end_POSTSUPERSCRIPT italic_\u00ce\u00be start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ( italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - italic_z ) + \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_x = italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - italic_z + 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\ufffd end_POSTSUPERSCRIPT italic_f start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT ( italic_x ). Proof. Again, the formula (5.16) can be obtained by plugging in the reported claims number in the new premium rule function ti\u00e2\ufffd\u00a2jsubscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014t_{ij}italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT that replaces the one in (3.12). \u00e2\u2013\u00a1\u00e2\u2013\u00a1 In this section, we consider the second type of claim frequency, i.e. the total number of settled claims in a given time period. For time period t\u00e2\u02c6\u02c6\u00e2\u201e\u2022+\u011f\ufffd\u2018\u00a1superscript\u00e2\u201e\u2022t \u00e2\u02c6\u02c6 blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, let MtXsubscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1M^{X}_{t}italic_M start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT denote the number of main claims in this time period; let MtYsubscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a1M^{Y}_{t}italic_M start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT denote the number of settled by-claims incurred in the current period; let MtZsubscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1M^{Z}_{t}italic_M start_POSTSUPERSCRIPT italic_Z end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT denote the number of settled by-claims incurred in precious time period. Based on the assumptions in Section 2, we know that all of these count random variables can only take a value either 0 or 1. The values of MtZsubscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1M^{Z}_{t}italic_M start_POSTSUPERSCRIPT italic_Z end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT and MtXsubscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1M^{X}_{t}italic_M start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT have unique interpretations, but the value 0 for MtYsubscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a1M^{Y}_{t}italic_M start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT leads to multiple possibilities. To be more specific, MtY=0subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a10M^{Y}_{t}=0italic_M start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0 means either no by-claim incurred in time period t\u011f\ufffd\u2018\u00a1titalic_t or the settlement of the incurred by-claim is delayed to next time period. This implies that Mt+1Z=1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a111M^{Z}_{t+1}=1italic_M start_POSTSUPERSCRIPT italic_Z end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT = 1 gives MtY=0subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a10M^{Y}_{t}=0italic_M start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0, but not vice versa. Here we assume that the premium Ct+1subscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\u00a11C_{t+1}italic_C start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT, t\u00e2\u02c6\u02c6\u00e2\u201e\u2022+\u011f\ufffd\u2018\u00a1superscript\u00e2\u201e\u2022t \u00e2\u02c6\u02c6 blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, is determined according to the total number of settled claims in time period t\u011f\ufffd\u2018\u00a1titalic_t, i.e. MtX+MtY+MtZsubscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1M^{X}_{t}+M^{Y}_{t}+M^{Z}_{t}italic_M start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_M start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_M start_POSTSUPERSCRIPT italic_Z end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, which can take an integer value from 0 to 3: MtZ=0subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a10M^{Z}_{t}=0italic_M start_POSTSUPERSCRIPT italic_Z end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0, MtX=0subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a10M^{X}_{t}=0italic_M start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0, MtY=0subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a10M^{Y}_{t}=0italic_M start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0 \u00e2\u2021\u2019\u00e2\u2021\u2019 MtX+MtY+MtZ=0subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a10M^{X}_{t}+M^{Y}_{t}+M^{Z}_{t}=0italic_M start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_M start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_M start_POSTSUPERSCRIPT italic_Z end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0; MtZ=0subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a10M^{Z}_{t}=0italic_M start_POSTSUPERSCRIPT italic_Z end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0, MtX=1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a11M^{X}_{t}=1italic_M start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 1, MtY=0subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a10M^{Y}_{t}=0italic_M start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0 \u00e2\u2021\u2019\u00e2\u2021\u2019 MtX+MtY+MtZ=1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a11M^{X}_{t}+M^{Y}_{t}+M^{Z}_{t}=1italic_M start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_M start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_M start_POSTSUPERSCRIPT italic_Z end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 1; MtZ=0subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a10M^{Z}_{t}=0italic_M start_POSTSUPERSCRIPT italic_Z end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0, MtX=1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a11M^{X}_{t}=1italic_M start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 1, MtY=1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a11M^{Y}_{t}=1italic_M start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 1 \u00e2\u2021\u2019\u00e2\u2021\u2019 MtX+MtY+MtZ=2subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a12M^{X}_{t}+M^{Y}_{t}+M^{Z}_{t}=2italic_M start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_M start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_M start_POSTSUPERSCRIPT italic_Z end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 2; MtZ=1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a11M^{Z}_{t}=1italic_M start_POSTSUPERSCRIPT italic_Z end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 1, MtX=0subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a10M^{X}_{t}=0italic_M start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0, MtY=0subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a10M^{Y}_{t}=0italic_M start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0 \u00e2\u2021\u2019\u00e2\u2021\u2019 MtX+MtY+MtZ=1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a11M^{X}_{t}+M^{Y}_{t}+M^{Z}_{t}=1italic_M start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_M start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_M start_POSTSUPERSCRIPT italic_Z end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 1; MtZ=1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a11M^{Z}_{t}=1italic_M start_POSTSUPERSCRIPT italic_Z end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 1, MtX=1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a11M^{X}_{t}=1italic_M start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 1, MtY=0subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a10M^{Y}_{t}=0italic_M start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0 \u00e2\u2021\u2019\u00e2\u2021\u2019 MtX+MtY+MtZ=2subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a12M^{X}_{t}+M^{Y}_{t}+M^{Z}_{t}=2italic_M start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_M start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_M start_POSTSUPERSCRIPT italic_Z end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 2; MtZ=1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a11M^{Z}_{t}=1italic_M start_POSTSUPERSCRIPT italic_Z end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 1, MtX=1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a11M^{X}_{t}=1italic_M start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 1, MtY=1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a11M^{Y}_{t}=1italic_M start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 1 \u00e2\u2021\u2019\u00e2\u2021\u2019 MtX+MtY+MtZ=3subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a1subscriptsuperscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a13M^{X}_{t}+M^{Y}_{t}+M^{Z}_{t}=3italic_M start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_M start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_M start_POSTSUPERSCRIPT italic_Z end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 3. Similar to Section 4, there is lack of time-homogeneity in the underlying Markov process for premiums. Taking into account the complications illustrated above on the total number of settled claims, we obtain the following result for the finite-time ruin probabilities. Given initial surplus u\u00e2\u2030\u00a50\u011f\ufffd\u2018\u00a20u 0italic_u \u00e2\u2030\u00a5 0 and initial premium level cisubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013c_{i}italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, i\u00e2\u02c6\u02c6\u011f\ufffd\u201c\u203a\u011f\ufffd\u2018\u2013\u011f\ufffd\u201c\u203ai \u00e2\u02c6\u02c6 bold_caligraphic_L, the finite-time ruin probability with premiums adjusted according to settled claims number without the up-front delayed by-claim satisfies the following recursive formula, for n\u00e2\u02c6\u02c6\u00e2\u201e\u2022+\u011f\ufffd\u2018\u203asuperscript\u00e2\u201e\u2022n \u00e2\u02c6\u02c6 blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, where \u00cf\u02c6i\u00e2\ufffd\u00a2(u,1)=\u00e2\u02c6\u2018x=u+ci+1\u00e2\u02c6\ufffdfX\u00e2\ufffd\u00a2(x)+(1\u00e2\u02c6\u2019q)\u00e2\ufffd\u00a2\u00e2\u02c6\u2018y=1\u00e2\u02c6\ufffd\u00ce\u00bey\u00e2\ufffd\u00a2(u+ci)subscript\u011f\ufffd\u0153\u201c\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a21superscriptsubscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20131subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a51\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u00a61subscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013 y=1}^{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_u , 1 ) = \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_x = italic_u + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\ufffd end_POSTSUPERSCRIPT italic_f start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT ( italic_x ) + ( 1 - italic_q ) \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_y = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\ufffd end_POSTSUPERSCRIPT italic_\u00ce\u00be start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ( italic_u + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ). Proof. Similar to the proof of Theorem 3, (6.17) can be obtained by replacing the function ti\u00e2\ufffd\u00a2jsubscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014t_{ij}italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT in (4.13) with the new one defined at the beginning of Section 5. Then we plug in the total number of settled claims in ti\u00e2\ufffd\u00a2jsubscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014t_{ij}italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT according to the values of X\u011f\ufffd\u2018\u2039Xitalic_X and Y\u011f\ufffd\u2018\u0152Yitalic_Y. \u00e2\u2013\u00a1\u00e2\u2013\u00a1 The finite-time ruin probability with premiums adjusted according to settled claims number and an up-front delayed by-claim z\u011f\ufffd\u2018\u00a7zitalic_z satisfies the following recursive formula, for 0<z\u00e2\u2030\u00a4u+ci0\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u00a2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20130<z u+c_{i}0 < italic_z \u00e2\u2030\u00a4 italic_u + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and n\u00e2\u02c6\u02c6\u00e2\u201e\u2022+\u011f\ufffd\u2018\u203asuperscript\u00e2\u201e\u2022n \u00e2\u02c6\u02c6 blackboard_N start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, where \u00cf\u02c6i\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(u;z,1)=\u00e2\u02c6\u2018x=u\u00e2\u02c6\u2019z+ci+1\u00e2\u02c6\ufffdfX\u00e2\ufffd\u00a2(x)+(1\u00e2\u02c6\u2019q)\u00e2\ufffd\u00a2\u00e2\u02c6\u2018y=1\u00e2\u02c6\ufffd\u00ce\u00bey\u00e2\ufffd\u00a2(u\u00e2\u02c6\u2019z+ci)subscriptsuperscript\u011f\ufffd\u0153\u201c\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a71superscriptsubscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a7subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20131subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a51\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u00a61subscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a7subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013 }(x)+(1-q) start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_u ; italic_z , 1 ) = \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_x = italic_u - italic_z + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\ufffd end_POSTSUPERSCRIPT italic_f start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT ( italic_x ) + ( 1 - italic_q ) \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_y = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\ufffd end_POSTSUPERSCRIPT italic_\u00ce\u00be start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ( italic_u - italic_z + italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ). Proof. Using (6.17), (6.18) can be obtained by adding 1111 into the premium rule function ti\u00e2\ufffd\u00a2jsubscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014t_{ij}italic_t start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT and replacing u\u011f\ufffd\u2018\u00a2uitalic_u by u\u00e2\u02c6\u2019z\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a7u-zitalic_u - italic_z in (6.17). \u00e2\u2013\u00a1\u00e2\u2013\u00a1 In this section we shall provide some numerical examples to illustrate the theoretical results obtained under the previously discussed four premium adjustment principles and to further study the commonality and dissimilarity of the four principles. Since we have been focusing on the finite-time ruin probabilities in this paper, we shall adopt the finite-time ruin probabilities with a fixed term (say 20) as the proxy to achieve the aforementioned goals. The possible behaviours of finite-time ruin probabilities under each principle when the term changes are not covered here, mainly due to the significantly increased computational costs involved in the completion of the task. The first numerical example we give in this section applies the premium correction principle allowing premiums to be adjusted according to aggregate reported claims. As mentioned previously in section 2.1, the aggregate claims are assumed to be reported at the end of each policy period even when the settlement of by-claims is delayed. We shall examine three hypothetical scenarios for the degree of correlation between the main claim X\u011f\ufffd\u2018\u2039Xitalic_X and the by-claim Y\u011f\ufffd\u2018\u0152Yitalic_Y in this example: low correlation, moderate correlation and high correlation. For each scenario, two cases of claim settlement delay are considered: q=0.2\u011f\ufffd\u2018\ufffd0.2q=0.2italic_q = 0.2 or q=0.8\u011f\ufffd\u2018\ufffd0.8q=0.8italic_q = 0.8. We propose the following joint distributions of X\u011f\ufffd\u2018\u2039Xitalic_X and Y\u011f\ufffd\u2018\u0152Yitalic_Y: high correlation case: where \u011f\ufffd\u201d\u00bc\u00e2\ufffd\u00a2(X)\u011f\ufffd\u201d\u00bc\u011f\ufffd\u2018\u2039 ( italic_X )=5, \u011f\ufffd\u201d\u00bc\u00e2\ufffd\u00a2(Y)\u011f\ufffd\u201d\u00bc\u011f\ufffd\u2018\u0152 ( italic_Y )=5 and the correlation coefficient \u00cf\ufffdX\u00e2\ufffd\u00a2Ysubscript\u011f\ufffd\u0153\u0152\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u0152 start_POSTSUBSCRIPT italic_X italic_Y end_POSTSUBSCRIPT=1; low correlation case: where \u011f\ufffd\u201d\u00bc\u00e2\ufffd\u00a2(X)\u011f\ufffd\u201d\u00bc\u011f\ufffd\u2018\u2039 ( italic_X )=5, \u011f\ufffd\u201d\u00bc\u00e2\ufffd\u00a2(Y)\u011f\ufffd\u201d\u00bc\u011f\ufffd\u2018\u0152 ( italic_Y )=5 and \u00cf\ufffdX\u00e2\ufffd\u00a2Ysubscript\u011f\ufffd\u0153\u0152\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u0152 start_POSTSUBSCRIPT italic_X italic_Y end_POSTSUBSCRIPT=0.1443; moderate correlation case: we let where \u011f\ufffd\u201d\u00bc\u00e2\ufffd\u00a2(X)\u011f\ufffd\u201d\u00bc\u011f\ufffd\u2018\u2039 ( italic_X )=5, \u011f\ufffd\u201d\u00bc\u00e2\ufffd\u00a2(Y)\u011f\ufffd\u201d\u00bc\u011f\ufffd\u2018\u0152 ( italic_Y )=5 and so \u00cf\ufffdX\u00e2\ufffd\u00a2Ysubscript\u011f\ufffd\u0153\u0152\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u0152 start_POSTSUBSCRIPT italic_X italic_Y end_POSTSUBSCRIPT=0.5401. According to the above assumptions, we can see that X\u011f\ufffd\u2018\u2039Xitalic_X follows the same marginal geometric distribution in all three cases, i.e. fX\u00e2\ufffd\u00a2(x)=(16)\u00e2\ufffd\u00a2(56)xsubscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a516superscript56\u011f\ufffd\u2018\u00a5f_{X}(x)= start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT ( italic_x ) = ( divide start_ARG 1 end_ARG start_ARG 6 end_ARG ) ( divide start_ARG 5 end_ARG start_ARG 6 end_ARG ) start_POSTSUPERSCRIPT italic_x end_POSTSUPERSCRIPT, x\u00e2\u2030\u00a50\u011f\ufffd\u2018\u00a50x 0italic_x \u00e2\u2030\u00a5 0. However, the three marginal distributions of Y\u011f\ufffd\u2018\u0152Yitalic_Y differ from each other, which are listed below, for y\u00e2\u2030\u00a50\u011f\ufffd\u2018\u00a60y 0italic_y \u00e2\u2030\u00a5 0, where I{y=0}subscript\u011f\ufffd\ufffd\u00bc\u011f\ufffd\u2018\u00a60I_{ start_POSTSUBSCRIPT { italic_y = 0 } end_POSTSUBSCRIPT is an indicator function taking 1 when y=0\u011f\ufffd\u2018\u00a60y=0italic_y = 0 and 0 otherwise. The set of premium levels is assumed to be c={c1,\u00e2\u20ac\u00a6,c5}={11,12,14,16,18}csubscript\u011f\ufffd\u2018\ufffd1\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\ufffd51112141618 = { italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_c start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT } = { 11 , 12 , 14 , 16 , 18 } and the initial premium of new policyholders C1subscript\u011f\ufffd\ufffd\u00b61C_{1}italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is c3subscript\u011f\ufffd\u2018\ufffd3c_{3}italic_c start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT that is 140% of the expected aggregate reported claims \u011f\ufffd\u201d\u00bc\u00e2\ufffd\u00a2(X+Y)\u011f\ufffd\u201d\u00bc\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u0152 ( italic_X + italic_Y ) (i.e. a safety loading factor of 40%). Under our assumption, the premium levels range from 110%percent110110 % to 180%percent180180 % of the expected aggregate reported claims. We propose the following rules of premium adjustment: If the reported aggregate claims in the current period is no more than 3, then the premium level for the next period will move to the lower premium level or stay in the lowest one, i.e. for s\u00e2\u2030\u00a43\u011f\ufffd\u2018 3s 3italic_s \u00e2\u2030\u00a4 3, t11\u00e2\ufffd\u00a2(s)=1,ti,i\u00e2\u02c6\u20191\u00e2\ufffd\u00a2(s)=1,i\u00e2\u2030\u00a52formulae-sequencesubscript\u011f\ufffd\u2018\u00a111\u011f\ufffd\u2018 1formulae-sequencesubscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018 1\u011f\ufffd\u2018\u20132t_{11}(s)=1,t_{i,i-1}(s)=1,i 2italic_t start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT ( italic_s ) = 1 , italic_t start_POSTSUBSCRIPT italic_i , italic_i - 1 end_POSTSUBSCRIPT ( italic_s ) = 1 , italic_i \u00e2\u2030\u00a5 2; If the reported aggregate claims in the current period is more than 3 but no more than 14, then the premium level for the next period will remain in the current level, i.e. for 3<s\u00e2\u2030\u00a4143\u011f\ufffd\u2018 143<s 143 < italic_s \u00e2\u2030\u00a4 14, ti\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2(s)=1,1\u00e2\u2030\u00a4i\u00e2\u2030\u00a45formulae-sequencesubscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018 11\u011f\ufffd\u2018\u20135t_{ii}(s)=1,1 i 5italic_t start_POSTSUBSCRIPT italic_i italic_i end_POSTSUBSCRIPT ( italic_s ) = 1 , 1 \u00e2\u2030\u00a4 italic_i \u00e2\u2030\u00a4 5; If the reported aggregate claims in the current period is more than 14, then the premium level for the next period will move to the higher premium level or stay in the highest one, i.e. for s>14\u011f\ufffd\u2018 14s>14italic_s > 14, t55\u00e2\ufffd\u00a2(s)=1,ti,i+1\u00e2\ufffd\u00a2(s)=1,i\u00e2\u2030\u00a44formulae-sequencesubscript\u011f\ufffd\u2018\u00a155\u011f\ufffd\u2018 1formulae-sequencesubscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018 1\u011f\ufffd\u2018\u20134t_{55}(s)=1,t_{i,i+1}(s)=1,i 4italic_t start_POSTSUBSCRIPT 55 end_POSTSUBSCRIPT ( italic_s ) = 1 , italic_t start_POSTSUBSCRIPT italic_i , italic_i + 1 end_POSTSUBSCRIPT ( italic_s ) = 1 , italic_i \u00e2\u2030\u00a4 4. According to the above transition rules, we can calculate the transition probabilities among the premium levels based on (3.6). Let \u011f\ufffd\ufffd\ufffdTHsubscriptsuperscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\ufffd\u00bb\u011f\ufffd\u2018\u2021 start_POSTSUPERSCRIPT italic_H end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT, \u011f\ufffd\ufffd\ufffdTMsubscriptsuperscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2021 start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT and \u011f\ufffd\ufffd\ufffdTLsubscriptsuperscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\u2021 start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT denote the transition matrix in each of the above correlation cases respectively, then we have The corresponding long-term stationary distribution of the premium levels are: The long-term expected premium per time period is 13.26, 13.65 and 14.07 in the high, moderate, and low correlation scenario, respectively. Using (3.11) and (3.12), we calculate \u00cf\u02c63\u00e2\ufffd\u00a2(u,20)subscript\u011f\ufffd\u0153\u201c3\u011f\ufffd\u2018\u00a220 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_u , 20 ), 0\u00e2\u2030\u00a4u\u00e2\u2030\u00a41000\u011f\ufffd\u2018\u00a21000 u 1000 \u00e2\u2030\u00a4 italic_u \u00e2\u2030\u00a4 100, with the initial premium c3subscript\u011f\ufffd\u2018\ufffd3c_{3}italic_c start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT and the results are summarised in Table LABEL:tab1 and Figure 1. Note that the notations H\u00e2\ufffd\u00a21\u011f\ufffd\ufffd\u00bb1H1italic_H 1, M\u00e2\ufffd\u00a21\u011f\ufffd\u2018\u20ac1M1italic_M 1 and L\u00e2\ufffd\u00a21\u011f\ufffd\ufffd\u00bf1L1italic_L 1 denote the scenarios of high, moderate and low correlation between X\u011f\ufffd\u2018\u2039Xitalic_X and Y\u011f\ufffd\u2018\u0152Yitalic_Y when q=0.2\u011f\ufffd\u2018\ufffd0.2q=0.2italic_q = 0.2, and the notations H\u00e2\ufffd\u00a22\u011f\ufffd\ufffd\u00bb2H2italic_H 2, M\u00e2\ufffd\u00a22\u011f\ufffd\u2018\u20ac2M2italic_M 2 and L\u00e2\ufffd\u00a22\u011f\ufffd\ufffd\u00bf2L2italic_L 2 correspond to the scenarios when q=0.8\u011f\ufffd\u2018\ufffd0.8q=0.8italic_q = 0.8. The first observation, a trivial one, from Table LABEL:tab1 and Figure 1 is that \u00cf\u02c63\u00e2\ufffd\u00a2(u,20)subscript\u011f\ufffd\u0153\u201c3\u011f\ufffd\u2018\u00a220 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_u , 20 ) decreases when u\u011f\ufffd\u2018\u00a2uitalic_u increases. Moreover, we notice that the correlation level between main claim X\u011f\ufffd\u2018\u2039Xitalic_X and by-claim Y\u011f\ufffd\u2018\u0152Yitalic_Y does affect the finite-time ruin probability. Under our previous assumptions, after fixing u\u011f\ufffd\u2018\u00a2uitalic_u and q\u011f\ufffd\u2018\ufffdqitalic_q, the higher is the correlation, the higher is the risk of ruin. Although the same premium adjustment rules are applicable for all three correlation scenarios, the joint distribution of X\u011f\ufffd\u2018\u2039Xitalic_X and Y\u011f\ufffd\u2018\u0152Yitalic_Y differentiates the transition probabilities among premium levels as well as the stationary distribution of individual premium levels. The previously calculated \u00cf\u20acHsuperscript\u011f\ufffd\u0153\u2039\u011f\ufffd\ufffd\u00bb start_POSTSUPERSCRIPT italic_H end_POSTSUPERSCRIPT, \u00cf\u20acMsuperscript\u011f\ufffd\u0153\u2039\u011f\ufffd\u2018\u20ac start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT and \u00cf\u20acLsuperscript\u011f\ufffd\u0153\u2039\u011f\ufffd\ufffd\u00bf start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT show that the high correlation case has the highest long-term probability to reach low premium levels and the lowest long-term probability for high premium levels. It implies that in long-run, in scenario H\u011f\ufffd\ufffd\u00bbHitalic_H, the insurer is expected to receive less total premium income than the other two scenarios, which results in the highest finite-time ruin probabilities among the three scenarios. Similar arguments can be made to explain the ordering between cases M\u011f\ufffd\u2018\u20acMitalic_M and L\u011f\ufffd\ufffd\u00bfLitalic_L. In addition, the differences, in terms of percentages, among the finite-time ruin probabilities under the three scenarios increase when the initial surplus u\u011f\ufffd\u2018\u00a2uitalic_u increases. For example, \u00cf\u02c63H\u00e2\ufffd\u00a21\u00e2\ufffd\u00a2(0,20)subscriptsuperscript\u011f\ufffd\u0153\u201c\u011f\ufffd\ufffd\u00bb13020 start_POSTSUPERSCRIPT italic_H 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( 0 , 20 ) is only about 5.4% higher than \u00cf\u02c63M\u00e2\ufffd\u00a21\u00e2\ufffd\u00a2(0,20)subscriptsuperscript\u011f\ufffd\u0153\u201c\u011f\ufffd\u2018\u20ac13020 start_POSTSUPERSCRIPT italic_M 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( 0 , 20 ) and around 12.9% higher than \u00cf\u02c63L\u00e2\ufffd\u00a21\u00e2\ufffd\u00a2(0,20)subscriptsuperscript\u011f\ufffd\u0153\u201c\u011f\ufffd\ufffd\u00bf13020 start_POSTSUPERSCRIPT italic_L 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( 0 , 20 ). But \u00cf\u02c63H\u00e2\ufffd\u00a21\u00e2\ufffd\u00a2(100,20)subscriptsuperscript\u011f\ufffd\u0153\u201c\u011f\ufffd\ufffd\u00bb1310020 start_POSTSUPERSCRIPT italic_H 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( 100 , 20 ) is about three times \u00cf\u02c63M\u00e2\ufffd\u00a21\u00e2\ufffd\u00a2(100,20)subscriptsuperscript\u011f\ufffd\u0153\u201c\u011f\ufffd\u2018\u20ac1310020 start_POSTSUPERSCRIPT italic_M 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( 100 , 20 ) and around 68 times \u00cf\u02c63L\u00e2\ufffd\u00a21\u00e2\ufffd\u00a2(100,20)subscriptsuperscript\u011f\ufffd\u0153\u201c\u011f\ufffd\ufffd\u00bf1310020 start_POSTSUPERSCRIPT italic_L 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( 100 , 20 ). This makes sense because when u\u011f\ufffd\u2018\u00a2uitalic_u is small, if ruin occurs then it is more likely to occur within the first few periods. As a result, there is only limited time for the main factors, which vary the finite-time ruin probabilities among these scenarios, to take effect. The same initial premium assumption under all three scenarios also contributed to the small differences in percentage among the finite-time ruin probabilities when u\u011f\ufffd\u2018\u00a2uitalic_u is small. On the contrary, when u\u011f\ufffd\u2018\u00a2uitalic_u is large, if ruin occurs then ruin is more likely to occur in the long run. The dissimilar premium evolving patterns under the three scenarios have plenty of time to drive the underlying surplus processes to different directions, which lead to divergent finite-time ruin probabilities. Last but not least, it is evident from Figure 1 that with all other factors being the same, an increase in q\u011f\ufffd\u2018\ufffdqitalic_q from 0.2 to 0.8 shifted the finite-time ruin probabilities downwards. This is reasonable since when the settlement of by-claims is more likely to be delayed, the insurers can receive more premium income that helps to settle the claims. However, this effect reduces when u\u011f\ufffd\u2018\u00a2uitalic_u is larger, because delaying by-claims for one time unit would not make a big difference for the worst cases (i.e. getting bankrupted with a large initial capital). This example examines the premium adjustment principle that was discussed in Section 4. This principle is worth exploring because that, in certain circumstances, the total settled claim amounts might better reflect the claims experiences of policyholders than the total reported claim amounts in a given time window due to the fact that in real practice reported claims come with uncertainties in the scale and timing of the real settlements. Therefore, the reported claims are only initial guesses and may not provide accurate information to represent the policyholders\u00e2\u20ac\u2122 historical claim experience. In this paper, for the purpose of simplification, we assumed that the reported and settled by-claims amounts are always equal and the length of delay is always 1. Although these restrictive assumptions are not entirely realistic, they serve as good starting points that could motivate more realistic models in future studies. We assume the same claim distributions and premium levels as those in previous example, whilst the transition rules of premium levels are modified as: If the settled aggregate claims in the current period is no more than 3, the premium level for the next period will move to the lower premium level or stay in the lowest one; If the settled aggregate claims in the current period is more than 3 but no more than 14, the premium level for the next period will remain in the current premium level; If the settled aggregate claims in the current period is more than 14, the premium level for the next period will move to the higher premium level or stay in the highest one. By the non-homogeneity nature exhibited under the new rules, there is no constant one-step transition matrix among the premium levels anymore. On the contrary, the one-step transition matrix varies over time and depends on the number of by-claims settled in each given time period. However, we can still study 20-period finite-time ruin probabilities using the recursive formulae (4.13) and (4.14). The results are given in Table LABEL:tab2 and Figure 2. We adopt the same notation to denote the scenarios under consideration. As shown in Table LABEL:tab2 and Figure 2, consistent observations are evident in this aggregate settled claims principle comparing with the aggregate reported claims case. Further, the differences between the two q\u011f\ufffd\u2018\ufffdqitalic_q cases in each correlation scenario also behave interestingly differently. In the high correlation scenario, there is a big gap between the two ruin probability curves showing that a high chance of delaying the highly correlated by-claims results in a big reduction in the risk of ruin comparing from the case of low chance of delay. On the contrary, when the correlation between main claims and by-claims is low and u\u011f\ufffd\u2018\u00a2uitalic_u is not small, whether delaying the by-claims or not seem not having a significant impact on the finite-time ruin probabilities. A reasonable interpretation is that when the correlation is low, the main difference between the two cases of q\u011f\ufffd\u2018\ufffdqitalic_q is that the by-claims settled in each time period are likely to be delayed ones or freshly incurred ones. Since the correlation between the main claims and by-claims is low, the distributions of aggregate settled claims in each period are similar in both cases. Therefore, except the first time period, the surplus process should behave similarly within all remaining time periods in both q\u011f\ufffd\u2018\ufffdqitalic_q cases that lead to similar finite-time ruin probabilities. Moreover, we generate comparison results, shown in Figure 3 and Figure 4, regarding \u00cf\u02c63\u00e2\ufffd\u00a2(u,20)subscript\u011f\ufffd\u0153\u201c3\u011f\ufffd\u2018\u00a220 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_u , 20 ) in this and the previous numerical examples. The superscripts R\u011f\ufffd\u2018\u2026Ritalic_R and S\u011f\ufffd\u2018\u2020Sitalic_S denote the premium adjustment principle by reported aggregate claims and by settled aggregate claims respectively. As seen in Figure 3, the two premium correction principles lead to marginal differences in the finite-time ruin probabilities in the case of q=0.2\u011f\ufffd\u2018\ufffd0.2q=0.2italic_q = 0.2, because when q\u011f\ufffd\u2018\ufffdqitalic_q is small, the aggregate reported claims in each period are likely to be the same as the aggregate settled claims. Therefore, the periodic premiums are highly likely to follow the same pattern in both cases, which result in similar finite-time ruin probabilities. On the other hand, according to Figure 4, when q=0.8\u011f\ufffd\u2018\ufffd0.8q=0.8italic_q = 0.8 the trends of finite-time ruin probabilities in the two cases differ significantly from one another. However, the differences increase when the correlation between the main claims and by-claims becomes weaker, and they tend to diminish when u\u011f\ufffd\u2018\u00a2uitalic_u increases. Moreover, when q=0.8\u011f\ufffd\u2018\ufffd0.8q=0.8italic_q = 0.8 the differences among the three correlation scenarios under the aggregate settled claims principle are generally smaller than those in the aggregate reported claims case. A possible interpretation is that when q\u011f\ufffd\u2018\ufffdqitalic_q is high, after the first couple of time periods, the aggregate settled claims in each period is highly likely to be the summation of a main claim X\u011f\ufffd\u2018\u2039Xitalic_X of the current period and a by-claim Y\u011f\ufffd\u2018\u0152Yitalic_Y delayed from the previous period (if any), whilst the aggregate reported claims in each period is a current main claim plus a current by-claim (if any). Due to the independence assumption between main claims and by-claims in different time periods, the within-period correlation between main and by-claims becomes between-period correlation in the aggregate settled claims case, which likely contributes to the above observation. A consistent finding in both q\u011f\ufffd\u2018\ufffdqitalic_q cases is that the finite-time ruin probabilities under the aggregated settled claims principle are generally higher than the corresponding ones in the aggregate reported claims case. It implies that if the information regarding reported claims is accurate, then the insurers better adopt the aggregate reported claims principle to adjust their periodic premiums, or they will face a higher insolvency risk otherwise. In the following sections, we shall provide two examples designed to examine the finite-time ruin probabilities with premiums adjustment principles that focus on the claim frequency information. In this example, we assume that the claim distributions and the set of premium levels are the same as the previous examples. The rules of premium corrections are: If the number of reported claims in the current period is 0, then the premium level for the next period will move to the lower premium level or stay in the lowest one; If the number of reported claims in the current period is 1, then the premium level for the next period will remain in the current premium level; If the number of reported claims in the current period is more than 1, then the premium level for the next period will move to the higher premium level or stay in the highest one. Next, we shall explore the impact of the correlation between main claims and by-claims as well as the impact of q\u011f\ufffd\u2018\ufffdqitalic_q on the finite-time ruin probabilities. Under the new premium adjustment rules given above, the correlation between the number of main claims NtXsubscriptsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1N^{X}_{t}italic_N start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT and by-claims NtYsubscriptsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a1N^{Y}_{t}italic_N start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT are calculated instead of the correlation between X\u011f\ufffd\u2018\u2039Xitalic_X and Y\u011f\ufffd\u2018\u0152Yitalic_Y. We find that the correlation between NtXsubscriptsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1N^{X}_{t}italic_N start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT and NtYsubscriptsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a1N^{Y}_{t}italic_N start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT generated by the claims distribution fX\u00e2\ufffd\u00a2YH\u00e2\ufffd\u00a2(x,y)subscriptsuperscript\u011f\ufffd\u2018\u201c\u011f\ufffd\ufffd\u00bb\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a6f^{H}_{XY}(x,y)italic_f start_POSTSUPERSCRIPT italic_H end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_X italic_Y end_POSTSUBSCRIPT ( italic_x , italic_y ), fX\u00e2\ufffd\u00a2YM\u00e2\ufffd\u00a2(x,y)subscriptsuperscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a6f^{M}_{XY}(x,y)italic_f start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_X italic_Y end_POSTSUBSCRIPT ( italic_x , italic_y ) and fX\u00e2\ufffd\u00a2YL\u00e2\ufffd\u00a2(x,y)subscriptsuperscript\u011f\ufffd\u2018\u201c\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a6f^{L}_{XY}(x,y)italic_f start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_X italic_Y end_POSTSUBSCRIPT ( italic_x , italic_y ) is \u00cf\ufffdNX,NY=1subscript\u011f\ufffd\u0153\u0152superscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2039superscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u01521 start_POSTSUBSCRIPT italic_N start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT , italic_N start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT end_POSTSUBSCRIPT = 1, \u00cf\ufffdNX,NY=0.8272subscript\u011f\ufffd\u0153\u0152superscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2039superscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u01520.8272 start_POSTSUBSCRIPT italic_N start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT , italic_N start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT end_POSTSUBSCRIPT = 0.8272 and \u00cf\ufffdNX,NY=0.7071subscript\u011f\ufffd\u0153\u0152superscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2039superscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u01520.7071 start_POSTSUBSCRIPT italic_N start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT , italic_N start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT end_POSTSUBSCRIPT = 0.7071, respectively. These surprisingly high correlations between number of claims are rooted in the model assumptions made in Section 2, i.e. one main claim generates at most one by-claim and no main claim means no by-claim. Similar to the example in Section 7.1, we can calculate the transition matrix among premium levels as follows: The corresponding long-term stationary distribution of the premium levels are: The long-term expected premiums in each correlation scenario is 17.50, 17.46 and 17.40 in the H, M and L scenario, respectively. It is worth noting that given the very different joint distributions of X\u011f\ufffd\u2018\u2039Xitalic_X and Y\u011f\ufffd\u2018\u0152Yitalic_Y in the three correlation scenarios, the corresponding long-term expected premiums are very similar under the current premium correction principle. By (5.15) and (5.16), we obtain results for \u00cf\u02c63\u00e2\ufffd\u00a2(u,20)subscript\u011f\ufffd\u0153\u201c3\u011f\ufffd\u2018\u00a220 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_u , 20 ) that are summarized in Table LABEL:tab3 and Figure 5. The notations in Table LABEL:tab3 are defined in the same way as in Table LABEL:tab1 and LABEL:tab2. Again, Table LABEL:tab3 and Figure 5 show us some similar trends to those shown in Table LABEL:tab1 & LABEL:tab2 and Figure 1 & 2. First, \u00cf\u02c63\u00e2\ufffd\u00a2(u,20)subscript\u011f\ufffd\u0153\u201c3\u011f\ufffd\u2018\u00a220 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_u , 20 ) decreases when u\u011f\ufffd\u2018\u00a2uitalic_u increases and the correlation level between NXsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2039N^{X}italic_N start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT and NYsuperscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0152N^{Y}italic_N start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT is positively related to the ruin probabilities. When fixing u\u011f\ufffd\u2018\u00a2uitalic_u and q\u011f\ufffd\u2018\ufffdqitalic_q, the higher the correlation, the higher is the ruin probability. Additionally, the decrease in q\u011f\ufffd\u2018\ufffdqitalic_q from 0.8 to 0.2 also causes a lift in the finite time ruin probabilities in all correlation scenarios. There are two inconsistencies between this example and the previous ones: Firstly, the scales of difference in \u00cf\ufffdX,Ysubscript\u011f\ufffd\u0153\u0152\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u0152 start_POSTSUBSCRIPT italic_X , italic_Y end_POSTSUBSCRIPT and \u00cf\u02c63\u00e2\ufffd\u00a2(u,20)subscript\u011f\ufffd\u0153\u201c3\u011f\ufffd\u2018\u00a220 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_u , 20 ) among all correlation scenarios in Section 7.1 and 7.2 are larger than the corresponding differences in this example. An interpretation is that, as given at the beginning of this section, the differences among the three \u00cf\ufffdNX,NYsubscript\u011f\ufffd\u0153\u0152superscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2039superscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0152 start_POSTSUBSCRIPT italic_N start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT , italic_N start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT end_POSTSUBSCRIPT values are much smaller than the differences among the three \u00cf\ufffdX,Ysubscript\u011f\ufffd\u0153\u0152\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u0152 start_POSTSUBSCRIPT italic_X , italic_Y end_POSTSUBSCRIPT values, which makes the three correlation scenarios less distinct from one another. Secondly, the relationship between \u00cf\ufffdNX,NYsubscript\u011f\ufffd\u0153\u0152superscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2039superscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0152 start_POSTSUBSCRIPT italic_N start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT , italic_N start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT end_POSTSUBSCRIPT and the long-term expected premium in this example is opposite to that in Section 7.1. To be more specific, in Section 7.1, lower \u00cf\ufffdX,Ysubscript\u011f\ufffd\u0153\u0152\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u0152 start_POSTSUBSCRIPT italic_X , italic_Y end_POSTSUBSCRIPT leads to higher long-term expected premiums, whereas in this example, lower \u00cf\ufffdNX,NYsubscript\u011f\ufffd\u0153\u0152superscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2039superscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0152 start_POSTSUBSCRIPT italic_N start_POSTSUPERSCRIPT italic_X end_POSTSUPERSCRIPT , italic_N start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT end_POSTSUBSCRIPT gives lower long-term expected premiums. A likely justification of this difference is the change of premium correction objectives from aggregate claim experience to claim frequencies. In our last numerical example, we shall duplicate the model assumptions but change the premiums adjustment rules following the settled claims number premium principle. The transition rules of premiums are: If the number of settled claims in the current period is 0, then the premium level for the next period will move to the lower premium level or stay in the lowest one; If the number of settled claims in the current period is 1, then the premium level for the next period will remain in the current premium level; If the number of settled claims in the current period is more than 1, the premium level for the next period will move to the higher premium level or stay in the highest one. We use (6.17) and (6.18) to calculate \u00cf\u02c63\u00e2\ufffd\u00a2(u,20)subscript\u011f\ufffd\u0153\u201c3\u011f\ufffd\u2018\u00a220 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_u , 20 ) and the results are summarised in Table LABEL:tab4 and Figure 6, adopting the same notations. Table LABEL:tab4 and Figure 6 show very similar trends to our findings from Table LABEL:tab3 and Figure 5. Again, we generate two comparison graphs, Figure 7 and Figure 8, between the two claim frequency premium principles for q=0.2\u011f\ufffd\u2018\ufffd0.2q=0.2italic_q = 0.2 and q=0.8\u011f\ufffd\u2018\ufffd0.8q=0.8italic_q = 0.8 respectively. The superscript R\u011f\ufffd\u2018\u2026Ritalic_R denotes the reported claims number principle and S\u011f\ufffd\u2018\u2020Sitalic_S denotes the settled claims number one. From Figure 7 and Figure 8, we can see that when q=0.2\u011f\ufffd\u2018\ufffd0.2q=0.2italic_q = 0.2, the finite-time ruin probabilities in this example is slightly higher than the results in section 7.3 for fixed u\u011f\ufffd\u2018\u00a2uitalic_u and the correlation level. On the other hand, when q=0.8\u011f\ufffd\u2018\ufffd0.8q=0.8italic_q = 0.8, the gaps between the finite-time ruin probabilities of this example and those of 7.3 are larger. This is because when q=0.2\u011f\ufffd\u2018\ufffd0.2q=0.2italic_q = 0.2, the by-claim settlements are unlikely to be delayed. Therefore, it is more likely that both main claims and their associated by-claims to be settled in the same time periods, which makes the reported claims number principle and the settled claims number one to work similarly. On the contrary, when q=0.8\u011f\ufffd\u2018\ufffd0.8q=0.8italic_q = 0.8, the settled claims number in the first time period is likely to be one since there is no up-front delayed by-claim, while the by-claim\u00e2\u20ac\u2122s settlement (if any) is likely to be delayed. Therefore, the settled claims number principle would determine the second premium according to the number of main claims in period one, whereas both the number of main claims and by-claims in period one will be used by the reported claims number principle. As a result, it is likely that the second premium under the reported claims number principle will be higher than the one under the settled claims number principle, which varies the whole sequence of future premiums and results in lower ruin probabilities in the former case. In this paper, we studied a discrete-time risk model with claim-dependent premiums and time-delayed by-claims. Our main goal is to evaluate the impact of the correlation between the main claims and by-claims and the probability of delaying by-claim settlements on the finite-time ruin probabilities under the proposed premium adjustment principles: the aggregate reported claims principle, the aggregate settled claims principle, the reported claims number principle and the settled claims number principle. Under certain assumptions, we found in our numerical studies that a higher probability of delaying the by-claim settlements would result in lower finite-time ruin probabilities. Moreover, the higher correlation between the main claims and by-claims also leads to higher finite-time ruin probabilities. Lastly, the premium adjustment principles based on settled claims experience (aggregate settled claims or settled claims number) account for higher finite-time ruin probabilities, compared with the principles based on the reported claims experience, given all other factors are the same. This difference is more remarkable when the probability of by-claim delays is high. According to these main findings in our study, the insurers should remain on high alert if a high correlation between the main claims and their associated by-claims is evident or the chance of getting delays in claim settlements is low because both situations could lead to increased insolvency risk. Further, the premium adjustment principles based on the reported claims experience could be a safer choice than the principles based on settled claims experience, especially in the high probability of delayed by-claim settlement cases. However, there are some limitations in this study that could be addressed in future research. Firstly, the numerical results of this study only assumed a positive correlation between the main claims and by-claims, but in real life, the correlation can also be negative. Secondly, this paper assumed that by-claim settlements could only be delayed by one time period, which is not realistic in real practice. As an extension, a multiple-period delay could be taken into consideration. Finally, our study assumed that there were at most one main claim and one by-claim incurring in each period and the settled claim amounts are always equal to the reported ones. Some more realistic models allowing general main claim and/or by-claim counts, as well as unequal amounts in reporting and settlement might be worth studying in future research.",
        "keywords": ""
    },
    {
        "id": 14,
        "title": "Handling Numeric Expressions in Automatic Speech Recognition",
        "abstract": "AbstractThis paper addresses the problem of correctly formatting numeric expressions in automatic speech recognition (ASR) transcripts. This is challenging since the expected transcript format depends on the context, e.g., 1945 (year) vs. 19:45 (timestamp).\nWe compare cascaded and end-to-end approaches to recognize and format numeric expression, such as years, timestamps, currency amounts, and quantities.\nFor the end-to-end approach we employed a data generation strategy using a large language model (LLM) together with a text to speech (TTS) model to generate adaptation data.\nThe results on our test dataset show that while approaches based on LLMs perform well on recognizing formatted numeric expressions, adapted end-to-end models offer competitive performance with the advantage of lower latency and inference cost.",
        "corpus": "This paper addresses the problem of correctly formatting numeric expressions in automatic speech recognition (ASR) transcripts. This is challenging since the expected transcript format depends on the context, e.g., 1945 (year) vs. 19:45 (timestamp). We compare cascaded and end-to-end approaches to recognize and format numeric expression, such as years, timestamps, currency amounts, and quantities. For the end-to-end approach we employed a data generation strategy using a large language model (LLM) together with a text to speech (TTS) model to generate adaptation data. The results on our test dataset show that while approaches based on LLMs perform well on recognizing formatted numeric expressions, adapted end-to-end models offer competitive performance with the advantage of lower latency and inference cost. Index Terms: numeric expression formatting, automatic speech recognition. In the last decade, ASR systems improved tremendously in terms of word error rate (WER) due to more data, more computation power and better architectures [1, 2, 3]. These systems are normally trained with labeled ASR data, i.e., human transcribed speech or human correct automatically transcribed speech. The way how numeric expressions are transcribed - using numeric literals, e.g., 1945, or number words, e.g., nineteen forty-five - can vary between different datasets of sometimes even within a dataset. Furthermore, dependent on the usage of the ASR system, different transcript formats might be preferred. For example when a video conference call is automatically subtitled using an ASR system, the readers might prefer numeric literals since they are shorter and easier to read. On the other hand, transcripts of an ASR system containing numeric expressions should be formatted dependent on the context the numeric expressions occur in. For example the number word nineteen forty-five should be formatted as 1945 if it represents a year, as 19:45 if it represents a timestamp, as $19.45 if it represents a currency amount and as 1,945 if quantity is meant. Often numeric expression formatting is not reflected in the WER because numeric expression formats get normalized before calculating the WER. However, proper formatting of numeric expressions is important because it heavily improves readability of the transcript. Therefore, in this work, we tackle the problem of properly formatting numeric expressions in ASR transcripts. For this, we 1) created a test set containing the numeric expression types year, timestamp, currency amount and quantity, 2) propose a strategy using a LLM together with a TTS model to get synthetic data with which an end-to-end ASR system can be adapted (see figure 1 and section 3.1), and 3) compare cascaded and end-to-end approaches to recognize the numeric expression types (see sections 3.2 and 4). We show that while approaches based on LLMs perform well on recognizing formatted numeric expressions, adapted end-to-end models offer competitive performance with the advantage of lower latency and inference cost. Until a few years ago, most ASR systems were trained to output lowercase transcripts without punctuation [4]. For this the transcripts of the training data got normalized. To get a transcript which contains casing and punctuation, inverse text normalization [5] was applied. This was done by applying a text segmentation model [6] after the transcription. For the text segmentation step auto regressive models similar to models used in machine translation can be used. To minimize the training-test mismatch in the input distribution such a text segmentation model should to be trained on hypotheses specific to some ASR model. Therefore, when changing the ASR model also the text segmentation model should be changed. The lately introduced LLMs [7, 8, 9] can also be used as a text segmentation model, i.e. to reformat the ASR hypotheses. LLMs are pre-trained on a lot of text to predict the next token and then adapted to e.g. answer questions. In-context learning [10] can be used to increase the performance without changing the weights of the LLM by providing examples how questions should be answered. On the other hand, ASR systems lately moved more and more towards end-to-end approaches where the transcript already contains casing and punctuation [3]. This has the advantage that only one model has to be executed decreasing latency and reducing maintenance effort. Furthermore, end-to-end approaches search for a global optimum and with enough training data this works well [3]. The drawback is that the formatting of numeric expressions in the transcript can not be easily changed with text-only data and the question is how to get ASR data with suitable numeric expression formatting. We use a TTS model for synthetic data generation (see next section). Other works [11, 12] have shown that it is possible to use synthetic TTS data to improve ASR performance. To adapt and test the numeric expression formatting of our models (see 3.2) we created a numeric expression dataset (see figure 1). For this, we first used gpt3.5-turbo from OpenAI to generate sentences containing the different numeric expression types we consider written down as number words. This is done by a prompt like (the actually used prompt is a little more complex e.g. to make the LLM not output enumeration) Generate {n} diverse [German (optional)] sentences containing a {numeric expression type} written down using number words. With half of the executed prompts we generated English sentences and with the other half German sentences. Then, we used the TTS model tts-1-hd from OpenAI (with voice randomly chosen) to generate audio. For this it was crucial to have the numeric expressions transcribed as number words since the TTS model did not produce correct output using numeric literals e.g. $19.45. Third, we prompted the LLM to convert the number words to numeric literals in the wanted format (see table 1). This is done by a prompt like Convert the {numeric expression type} in the sentences to numeric literals. The output of this step is used a labels for the utterances. To get a high quality dataset we applied some filtering using simple rules, e.g., output sentences of the third step not containing numeric literals were ignored. The created data was then split in training, development and test sets. We noticed that the numeric expressions created by the LLM sometimes repeated. Therefore, we split the data such that the numeric expressions contained in the three sets were chosen to be pairwise disjoint (see table 2). Then, the test set was read by human annotators to collect real audio samples. We noticed that for the end-to-end approach (see section 4) the performance on the timestamps was worse than the cascaded approaches. Therefore, we evaluated if more data generation could help and created more training data (Training-larger) containing timestamps with gpt-4o. This is done by a prompt like Generate a [German (optional)] sentence containing the timestamp {timestamp} written down using number words. For {timestamp} we iterate over many possibilities, e.g. for English one o\u2019clock, quarter past one, half past one, quarter to one, two minutes past one, two minutes to one. For German we use equivalent translations. The seconds and third step of the data generation are the same as before. To evaluate the general performance of our model, we report the WER on the Common voice [13] test sets in English and German. We filtered the test sets by excluding utterances containing numeric expressions because the numeric expressions contained in the labels are written down using number words and we tuned our models to output numeric literals. The English and German test sets each contain 2,000 utterances and 3.3 hours of audio. We compare cascaded and end-to-end approaches for numeric expression formatting (see figure 2). For the cascaded approach we use a trained ASR model and reformat the output using a text segmentation model. For the end-to-end approach we adapt the trained ASR model by fine-tuning on the training set of our numeric expressions dataset (see section 3.1). We use Whisper [3] (whisper-large-v2) as our baseline ASR model and for the text segmentation model we compare using a mbart-based model [14] (mbart-large-50) and LLMs. We adapted the pretrained mbart model in two steps since we only have limited data for the second step. First, we fine-tuned it to predict the transcript labels of the Common voice training sets (excluding utterances containing numeric expressions similar to the test sets) given the ASR hypothesis generated by our baseline ASR model. This model we denote by mbart baseline. Second, we fine-tuned the model on the numeric expressions dataset to format numeric expressions correctly. This is done by using the sentences where numeric expressions are written down as number words as input and the corresponding sentences where numeric expressions are written down as numeric literals as labels. This model we denote by mbart numeric expressions. For both steps we froze the embedding of the model since this yielded better performance than not freezing it. For the LLM we use GPT3.5 (gpt-3.5-turbo) or GPT 4 [15] (gpt4-turbo and gpt-4o) with in-context learning using one example for each numeric expression type (9 examples in total). The results can be seen in table 3 (WER) and table 4 (accuracy of the different numeric expression types). We see that ASR + mbart baseline slightly improves the WER on the Commonvoice test sets due to the learned correction of the ASR hypothesis. However, the performance (WER and accuracy) on the numeric expressions test sets heavily decreased since the model was not trained to predict numeric literals. The model ASR + mbart numeric expressions performs better and outperforms the ASR only model on the numeric expressions test sets, while there is not much difference on the Common voice test sets. However, the model struggles to format the timestamps (and currency amounts) correctly, e.g., the ASR hypothesis \u201dThe library opens at 10 o\u2019clock, but it\u2019s best to arrive early.\u201d is converted to \u201dThe library opens at 17:00, but it\u2019s best to arrive early.\u201d This is probably due to the limited amount of numeric expressions data. Using more data did help a bit but the accuracy on e.g. timestamps is still less than 40%. Using a LLM as text segmentation model sometimes (gpt3.5-turbo: 9.7%, gpt4-turbo: 1.4%, gpt-4o: 2.7%) does not follow the prompt, e.g., when the input sentence is a question, it is answered. This leads to a completely different transcript and increases in the WER. To circumvent this problem we compute the WER between input and output of the LLM and if the WER is larger than a threshold (0.5) we ignore to LLM output and return the input instead. With this, the LLMs clearly outperform the mbart-based model both in terms of WER and accuracy. The advantage of the LLMs is that they got trained on a lot more data. Most errors are caused by the LLM not following the prompt, e.g., in the sentence \u201dThe bus leaves at five past seven.\u201d the timestamps is not changed to 7:05. Furthermore, the most recently published LLMs perform better. Using an LLM which follows the prompt better would probably yield a bit better scores. It is quite expensive to reformat each hypothesis using an LLM (\u2248 $15 for evaluating the ASR + gpt-4o approach on the 4.000 Common voice test sets sentences), especially if the goal is to provide the transcription to lots of customers. Therefore, we experimented adapting the ASR model end-to-end. The results show similar WER performance as the LLM-based approaches, however the WER on the German numeric expressions test set is a bit better. The improvement is due to the fact that for most of the timestamp data the baseline ASR model outputs e.g. for an audio containing \u201dIch habe bis f\u00fcnfzehn Uhr f\u00fcnfundvierzig Zeit.\u201d a transcript \u201dIch habe bis 15.45 Uhr Zeit\u201d. The conversion by the LLM does not remove the \u201dUhr\u201d which is counted as an error. The fine-tuned ASR model does not output this \u201dUhr\u201d. The accuracy of the fine-tuned ASR model with more data on the numeric expressions is better than the approaches ASR + gpt3.5-turbo / gpt4-turbo and only a bit worse than ASR + gpt-4o. The largest difference is on the timestamp numeric expressions. For example the audio containing \u201dThe deadline is at thirty minutes past three.\u201d was transcribed \u201dThe deadline is 03:30.\u201d While this could be correct, a deadline is more likely not to be within the night and the better world knowledge helps the LLMs here to output \u201d15:30\u201d. With our data generation strategy it is easy to add more formatting rules, e.g., new currency symbols, by performing more augmenting data and adapting the model. The main limitation for the cascaded approach using an LLM is the ability of the LLM to follow the prompt correctly. This is expected to be handled even better for newer LLMs getting trained. For the fine-tuned ASR model the limitation is getting diverse data containing suitable numeric expression formatting. We also tried adapting the ASR model using batch weighting [16] and/or a factorization-based approach [2] together with the common voice training dataset. While the performance on the Common voice test sets improved, which is expected since the training and test datasets are more similar, the performance on the numeric expression formatting was slightly worse. Furthermore, we tried freezing the encoder or only adapting the final projection layer during the adaptation with the numeric expressions data. For both, the performance on the numeric expressions test data was slightly worse compared to not freezing any weights. In this paper, we tackled the problem of correctly formatting numeric expressions in ASR transcripts. Our experiments revealed that LLMs, particularly the latest models, deliver strong performance in recognizing and formatting numeric expressions. On the other hand, end-to-end models adapted with synthetic ASR data provide competitive performance. This research was supported in part by a grant from Zoom Video Communications, Inc. The authors gratefully acknowledge the support.",
        "keywords": ""
    },
    {
        "id": 15,
        "title": "Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy",
        "abstract": "AbstractEarly detection of Cerebral Palsy (CP) is crucial for effective intervention and monitoring. This paper tests the reliability and applicability of Explainable AI (XAI) methods using a deep learning method that predicts CP by analyzing skeletal data extracted from video recordings of infant movements. Specifically, we use XAI evaluation metrics \u00e2\u20ac\u201d namely faithfulness and stability \u00e2\u20ac\u201d to quantitatively assess the reliability of Class Activation Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this specific medical application. We utilize a unique dataset of infant movements and apply skeleton data perturbations without distorting the original dynamics of the infant movements. Our CP prediction model utilizes an ensemble approach, so we evaluate the XAI metrics performances for both the overall ensemble and the individual models. Our findings indicate that both XAI methods effectively identify key body points influencing CP predictions and that the explanations are robust against minor data perturbations. Grad-CAM significantly outperforms CAM in the RISv metric, which measures stability in terms of velocity. In contrast, CAM performs better in the RISb metric, which relates to bone stability, and the RRS metric, which assesses internal representation robustness. Individual models within the ensemble show varied results, and neither CAM nor Grad-CAM consistently outperform the other, with the ensemble approach providing a representation of outcomes from its constituent models. Both CAM and Grad-CAM also perform significantly better than random attribution, supporting the robustness of these XAI methods. Our work demonstrates that XAI methods can offer reliable and stable explanations for CP prediction models. Future studies should further investigate how the explanations can enhance our understanding of specific movement patterns characterizing healthy and pathological development.",
        "corpus": "Early detection of Cerebral Palsy (CP) is crucial for effective intervention and monitoring. This paper tests the reliability and applicability of Explainable AI (XAI) methods using a deep learning method that predicts CP by analyzing skeletal data extracted from video recordings of infant movements. Specifically, we use XAI evaluation metrics \u00e2\u20ac\u201d namely faithfulness and stability \u00e2\u20ac\u201d to quantitatively assess the reliability of Class Activation Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this specific medical application. We utilize a unique dataset of infant movements and apply skeleton data perturbations without distorting the original dynamics of the infant movements. Our CP prediction model utilizes an ensemble approach, so we evaluate the XAI metrics performances for both the overall ensemble and the individual models. Our findings indicate that both XAI methods effectively identify key body points influencing CP predictions and that the explanations are robust against minor data perturbations. Grad-CAM significantly outperforms CAM in the RISv metric, which measures stability in terms of velocity. In contrast, CAM performs better in the RISb metric, which relates to bone stability, and the RRS metric, which assesses internal representation robustness. Individual models within the ensemble show varied results, and neither CAM nor Grad-CAM consistently outperform the other, with the ensemble approach providing a representation of outcomes from its constituent models. Both CAM and Grad-CAM also perform significantly better than random attribution, supporting the robustness of these XAI methods. Our work demonstrates that XAI methods can offer reliable and stable explanations for CP prediction models. Future studies should further investigate how the explanations can enhance our understanding of specific movement patterns characterizing healthy and pathological development. Index Terms\u00e2\u20ac\u201d\u00e2\u20ac\u2030 explainable AI, CAM, Grad-CAM, skeleton data, Cerebral Palsy Cerebral Palsy (CP) is the most common motor disability in children, and it is essential to detect it early for effective early intervention and surveillance [1]. Machine learning based technologies are increasingly being explored in the early detection of CP due to its potential for more accurate, accessible, and timely diagnoses. Specifically, deep learning methods have shown great potential in medical diagnostics due to their ability to detect complex patterns in large sets of data. For instance, McCay et al.\u00c2 developed a deep learning framework that classifies infant movements from RGB videos using extracted pose-based features to identify Fidgety Movements (FMs) [2]. Similarly, Groos et al.\u00c2 introduced a method leveraging deep learning to predict CP from skeletal data captured in spontaneous infant movements, validated across a multi-center cohort [3]. Additionally, Zhang et al.\u00c2 designed CP-AGCN, a graph convolutional network (GCN) that uses skeletal data from RGB videos and a frequency-binning module to classify CP risks in infants [4]. Gao et al. implemented a deep learning model to automate early CP detection by analyzing FMs in video sequences [5]. There are several data modalities that can be analyzed for early CP prediction such as in the sensor fusion approach proposed by Kulvicius et al.\u00c2 [6], but this paper focuses on analyzing skeletal data extracted from video recordings via pose estimation, noting its broader applicability to areas such as abnormal gait detection [7], Parkinson\u00e2\u20ac\u2122s disease gait assessment [8], fall detection [9], and other health-related applications. Despite its promising potential, the use of AI in medical diagnostics introduces new challenges, including the widely discussed problem of explainability and transparency. Deep learning models\u00e2\u20ac\u2122 inherent lack of interpretability \u00e2\u20ac\u201c commonly referred to as the \u00e2\u20ac\u02dcblack box\u00e2\u20ac\u2122 challenge \u00e2\u20ac\u201c is problematic in a medical setting, where clear explanations for diagnoses is a requirement. To build trust in AI-driven diagnostic tools among clinicians and patients, and facilitate possible implementation in clinical use, it is crucial to understand the predictions made by these tools. This need for transparency and trust aligns with the requirements of the EU\u00e2\u20ac\u2122s recently implemented AI regulation, the AI Act, which classifies applications that could affect the life, safety, and health of people as high-risk [10], and thereby requires these applications to provide explanations before they are allowed for deployment. Prechtl\u00e2\u20ac\u2122s General Movements Assessment (GMA) is a highly reliable diagnostic tool for early detection of CP and is based upon medical experts observing normal versus abnormal movement patterns [11], yet it faces several challenges. These include the requirement for training the clinicians performing GMA to achieve proficiency in assessment techniques, the subjective nature of visual analysis which can lead to variability in interpretations, the time-intensive process of manually analyzing movements, and long-term costs associated with training and qualifying medical experts [12]. Using AI can potentially address these issues by automating the detection process of abnormal movement patterns, thereby reducing the burden on the limited number of trained GMA experts, while providing objective and consistent analysis, and significantly reducing the time needed for assessments. However, it is crucial that this does not compromise the interpretability that clinicians value in Prechtl\u00e2\u20ac\u2122s GMA, ensuring that the insights offered by AI systems are sufficiently explained and thus complementary and understandable from a clinician\u00e2\u20ac\u2122s perspective. To aid healthcare providers in understanding AI diagnoses, Explainable AI (XAI) methods can be used. For instance, in medical imaging, XAI has facilitated cancer detection [13]. In the CP prediction space, Sakkos et al. introduced a deep learning framework using RGB videos, with visualization showing segmented body parts with movement abnormalities and their contribution to the classification result [14]. Reflecting on the boom of automated solutions for Prechtl\u00e2\u20ac\u2122s GMA and the growing trend of incorporating XAI in diverse medical applications, and in anticipation of the legal requirements when deploying AI-assisted medical diagnostic tools, our study aims to bridge a crucial gap: despite the evident progress, the application of XAI in skeleton-based CP diagnosis remains understudied. To assess the trustworthiness of the explanations generated by these methods, we advocate for the use of metrics that objectively evaluate the reliability of the explanations. This is crucial because AI-based analysis of skeletal data could extend to several other previously mentioned high-stakes applications, beyond CP prediction. However, the application of domain-specific knowledge across such a broad spectrum of potential uses could become cumbersome. Therefore, we also suggest adopting the metrics evaluated in this study as foundational benchmarks for assessing XAI techniques, and then supplementing them with specialized domain knowledge to enhance and confirm their validity further. This study explores the applicability of Class Activation Mapping (CAM) and Gradient-Weighted Class Activation Mapping (Grad-CAM), which are widely used XAI methods in Convolutional Neural Network (CNN) models, to Graph Convolutional Network (GCN)-based models for Cerebral Palsy (CP) prediction. Specifically, we investigate whether these XAI methods can effectively differentiate between important and unimportant body points influencing CP predictions. Additionally, we assess the stability of explanations when the input data undergo minor perturbations. The contributions of our study are: An objective evaluation framework to assess the reliability of different XAI methods used in a specific medical application, which is skeleton-based early detection of CP from infants\u00e2\u20ac\u2122 spontaneous movements. The comparative analysis of different XAI methods (CAM and Grad-CAM), providing insight into their effectiveness in the context of early CP detection, which can potentially be used in other high-stakes applications. Showing the possible use of XAI methods to guide further research in early CP diagnosis. For example, it can potentially be used to discover specific infant movement patterns that are correlated with later CP status that might be complementary information for GMA experts focusing on gestalt infant movements. The evaluation of these XAI methods for this specific application is the first step towards determining the most reliable explanations that can provide valuable insights into specific infant movements. The application of XAI evaluation metrics to an ensemble of models for CP prediction, providing insight into the collective robustness of the aggregated ensemble and individual model explanations against minor perturbations. The following section discusses the various XAI methods implemented for the skeleton-based CP prediction model. These methods will subsequently be assessed using the XAI evaluation metrics. CAM was originally introduced as a method for identifying important pixels in an image [15] as determined by a CNN model. It projects the model\u00e2\u20ac\u2122s output layer weights onto a convolutional layer\u00e2\u20ac\u2122s feature maps (usually from the final layer), creating a heatmap that highlights the areas influencing the network\u00e2\u20ac\u2122s predictions, CAM can be generalized and applied to other convolution-based models if the weights after Global Average Pooling (GAP) for a specific c\u00e2\ufffd\u00a2l\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2s\u00e2\ufffd\u00a2s\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018 \u011f\ufffd\u2018 classitalic_c italic_l italic_a italic_s italic_s and the nth feature map Fnsuperscript\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u203aF^{n}italic_F start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT are multiplied, as shown in Equation\u00c2 (1). For example, in human activity recognition (HAR) using 3D skeleton graphs as input to a GCN, important body points in the skeleton data can be highlighted, as shown by Song et al. with their work on EfficientGCN [16]. CAM has several weaknesses, such as the lack of flexibility in model architecture due to the need for a GAP layer and a Fully Connected (FC) layer for classification. Gradient-weighted Class Activation Mapping (Grad-CAM) [17] addresses this by using gradients entering the FC layer instead of weights, calculated via thus making it adaptable to various CNN architectures. Since the introduction of Grad-CAM, many other CAM-based methods have been introduced to further improve the original CAM. Similarly to CAM, Grad-CAM has been shown to be applicable to GCN-based HAR using skeleton data, as illustrated by Das et al. [18]. In our previous work [19], we explored various metrics proposed in [20] to evaluate explanations from different XAI methods within the context of skeleton-based HAR. Building on these foundations, this paper aims to extend these evaluation techniques to a specific medical application, which is skeleton-based CP prediction. The following subsections give a brief overview of the applied metrics, illustrating their applicability and relevance in a specific medical use-case. Consider X\u011f\ufffd\u2018\u2039Xitalic_X as the original input data, with its corresponding explanation eXsubscript\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u2039e_{X}italic_e start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT, and let f\u00e2\ufffd\u00a2(\u00e2\u2039\u2026)\u011f\ufffd\u2018\u201c\u00e2\u2039\u2026f( ( \u00e2\u2039\u2026 ) denote the model\u00e2\u20ac\u2122s output, representing CP risk. Then, X\u00e2\u20ac\u00b2superscript\u011f\ufffd\u2018\u2039\u00e2\u20ac\u00b2X^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT is the perturbed version of X\u011f\ufffd\u2018\u2039Xitalic_X, and eX\u00e2\u20ac\u00b2subscriptsuperscript\u011f\ufffd\u2018\u2019\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u2039e^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT stands for its corresponding explanation following the perturbation. Top-k\u011f\ufffd\u2018\u02dckitalic_k refers to the most important features in the input data, while non-top-k\u011f\ufffd\u2018\u02dckitalic_k refers to the remaining, less important features. Fidelity or faithfulness [21, 22, 23] checks whether an explanation accurately identifies the features that influence a model\u00e2\u20ac\u2122s predictions. The Prediction Gap on Important features (PGI) in Equation\u00c2 (3) quantifies the prediction change when key features are altered, while the Prediction Gap on Unimportant features (PGU) in Equation\u00c2 (4) measures the change when minor features are modified. Ideally, when important features are perturbed, there should be a significant change in the model prediction. Conversely, perturbing unimportant features should have little effect on the prediction. By this logic, a good XAI method should identify both important and unimportant features in a way that results in a high PGI and a low PGU. Stability or robustness [24, 25], measures how much an explanation changes relative to changes in the model\u00e2\u20ac\u2122s input, output, or internal representation when the original input data undergo minor perturbations, as shown in Equations\u00c2 (5)\u00e2\u20ac\u201c(7). Relative Input Stability (RIS) includes three components for each of the model\u00e2\u20ac\u2122s multiple input streams: position, velocity, and bone, referred to as RISp, RISv, and RISb, respectively. ROS refers to Relative Output Stability and RRS refers to Relative Representation Stability. To better understand these concepts in relation to the variables in the model, please refer to Fig.\u00c2 1(a), which illustrates the main architecture of the network. \u00e2\u201e\u2019Xsubscript\u00e2\u201e\u2019\u011f\ufffd\u2018\u2039 start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT in Equation\u00c2 (7) denotes the model\u00e2\u20ac\u2122s internal representation, which in our study is the logits from the layer preceding the softmax activation function. A stability score of zero is ideal, as it means that visually imperceptible perturbations do not change the explanation at all. The dataset used in this study originates from Groos et al.\u00c2 [3], and is made up of 557 infants at elevated risk of perinatal brain injury, gathered from 13 different hospitals in Norway, Belgium, India, and the US. In compliance with Prechtl\u00e2\u20ac\u2122s GMA tool protocols, the infants were filmed during the FM period occurring between 9 and 18 weeks\u00e2\u20ac\u2122 corrected age. Using the CP decision tree from the Surveillance of Cerebral Palsy in Europe [26], a pediatrician determined their CP statuses at 12 months corrected age or older. Of the 557 videos, 75% were allocated for model training and validation, while the remaining 25% formed the test set which is used in this paper. Of the 139 videos in the test set, 21 are true CP cases and 118 are true No CP cases. For the XAI metrics testing, extracted skeleton tracker data from the original videos were used instead of the videos themselves. Given the long testing times for computing XAI metrics (approximately 1 hour per 5-second window on an RTX3090 GPU), random 5-second window samples were taken from the tracker data, proportional to the video length. For example, only one 5-second window sample was taken from the shortest videos. Moreover, since testing for s\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2l\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2y\u011f\ufffd\u2018 \u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a6stabilityitalic_s italic_t italic_a italic_b italic_i italic_l italic_i italic_t italic_y metric requires that the true label matches the predicted label, only correctly predicted data were used, resulting in 15 CP and 111 No CP cases. From these, 24 random 5-second windows were selected from CP data and 136 from No CP data, maintaining the original CP to No-CP ratio. Additionally, windows at the beginning or end of the videos were avoided to reduce noise, and non-overlapping 5-second windows were chosen to avoid redundant data. The same deep learning-based CP prediction model from the Groos et al. study [3] was evaluated for the XAI metrics. This model uses a GCN architecture to process infants\u00e2\u20ac\u2122 biomechanical movement properties, namely positions, velocities, and bones (distances between body keypoints). The GCN architecture was optimized through an automatic search, which created 70 distinct model instances, each trained on different sections of the dataset. Refinement of the model involved hyperparameter tuning and an automatic Neural Architecture Search (NAS) approach, exploring various architectural designs and configurations. The final Ensemble-NAS-GCN model combines predictions from the 70 GCN instances, as illustrated in Fig. 1(b), where the model number represents a unique architecture and the portion number denotes the specific training/validation fold used for that model. Details about each of the 10 GCN model architectures can be found in the Appendix Table 3. Each model instance analyzes 5-second windows, with the CP risk determined as the median prediction across the ensemble. Similarly, for each 5-second window, the XAI attribution scores (i.e. CAM or Grad-CAM) from all 70 GCN instances were collected and unified by calculating the median score for each body point. There were no alterations made to the CP prediction pipeline except for capturing intermediate variables, such as model weights and gradients needed for the XAI metric evaluation. As demonstrated in our previous work [19], skeleton joints can be perturbed by converting Cartesian coordinates to spherical coordinates. This is performed using the equations below, where d\u00e2\ufffd\u00a2x\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u00a5dxitalic_d italic_x and d\u00e2\ufffd\u00a2y\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u00a6dyitalic_d italic_y represent the perturbation magnitudes along the x\u011f\ufffd\u2018\u00a5xitalic_x- and y\u011f\ufffd\u2018\u00a6yitalic_y-axes respectively, P\u011f\ufffd\u2018\u0192Pitalic_P is the original point, P\u00e2\u20ac\u00b2superscript\u011f\ufffd\u2018\u0192\u00e2\u20ac\u00b2P^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT is the new perturbed point, x\u00e2\u20ac\u00b2superscript\u011f\ufffd\u2018\u00a5\u00e2\u20ac\u00b2x^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT and y\u00e2\u20ac\u00b2superscript\u011f\ufffd\u2018\u00a6\u00e2\u20ac\u00b2y^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT are the new coordinates, x\u011f\ufffd\u2018\u00a5xitalic_x and y\u011f\ufffd\u2018\u00a6yitalic_y are the original coordinates, and \u00ce\u00b8\u011f\ufffd\u0153\u0192 is the randomly generated azimuthal angle: Equations\u00c2 (5),\u00c2 (6),\u00c2 (7) require that the perturbed input data X\u00e2\u20ac\u00b2superscript\u011f\ufffd\u2018\u2039\u00e2\u20ac\u00b2X^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT remains close to the original data X\u011f\ufffd\u2018\u2039Xitalic_X, which also maintains accurate human kinematics and preserving the integrity of model predictions. To achieve this, r\u011f\ufffd\u2018\u0178ritalic_r is set to 1% of the median height of the infant across all frames in a 5-second window. The infant coordinate data are in pixels and height is calculated as the Euclidean distance between the head and left ankle. The values d\u00e2\ufffd\u00a2x\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u00a5dxitalic_d italic_x and d\u00e2\ufffd\u00a2y\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u00a6dyitalic_d italic_y are computed once for each joint and applied consistently across all video frames, producing a perturbed 2D point. The first step is to obtain the explanation for the original unperturbed data. The skeleton tracker data is fed into the CP prediction pipeline after Data Preprocess stage as shown in Fig. 1(a). Each model in the ensemble generates its own explanation according to Equations (1) and (2), as shown in Fig. 1(b)). These individual explanations are combined by calculating the median values, representing the overall explanation for the ensemble. Similarly, individual model output predictions are combined by taking the median value, representing the ensemble\u00e2\u20ac\u2122s output prediction. This process yields the terms f\u00e2\ufffd\u00a2(X)\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2039f(X)italic_f ( italic_X ), eXsubscript\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u2039e_{X}italic_e start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT, and X\u011f\ufffd\u2018\u2039Xitalic_X. The term \u00e2\u201e\u2019Xsubscript\u00e2\u201e\u2019\u011f\ufffd\u2018\u2039 start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT is derived by collecting internal representations from the final FC layer before the softmax function of each model and flattening them into a single array. Next, the body keypoints are ranked by importance from highest to lowest, and the top-k and non top-k joints are identified as determined by the ensemble\u00e2\u20ac\u2122s explanations. A sample visualization of these attribution scores, translated into color-coded importance indicators, is shown in Fig. 2, where green indicates low scores, yellow indicates moderate scores, orange indicates high scores, and red indicates very high scores relative to a threshold of 0.3. Perturbed varieties of the original data are generated as outlined in the previous section. Each 5-second window undergoes n=50\u011f\ufffd\u2018\u203a50n=50italic_n = 50 perturbations at a specified magnitude r\u011f\ufffd\u2018\u0178ritalic_r. The top-k body points (where k = 1 to 19) are systematically perturbed n\u011f\ufffd\u2018\u203anitalic_n times and then fed into the model to calculate PGI, then the remaining points are perturbed to compute PGU. Stability metrics are also computed using the explanations for the n\u011f\ufffd\u2018\u203anitalic_n perturbations and the resulting intermediate values in the ensemble. We use the Area Under the Curve (AUC) to combine the calculated metric scores across all k values for each video into a single score. We then compute the mean and standard deviation of these AUCs in all videos to obtain the overall metric values. Since the metrics are unitless, the results are also compared against a random method that assigns feature attribution scores randomly, which represents the worst performance for an XAI method when subjected to a perturbation magnitude r\u011f\ufffd\u2018\u0178ritalic_r. To compare the ensemble\u00e2\u20ac\u2122s XAI metrics performance with individual models, we conducted the same test on each model architecture. The ensemble consists of 70 model instances across 10 unique architectures, each trained on 7 different folds. Model 9, portion 5 achieved the highest AUC-ROC score in the test set, and thus portion 5 was used to represent each architecture in the tests. The same test pipeline is implemented as described above, except that the intermediate values for the metrics were derived from the individual models rather than the ensemble. Note that each model and the ensemble have unique sets of top-k and non top-k body points identified, resulting in distinct perturbed skeleton data, requiring separate tests. Using our hardware setup with RTX3090 GPU, the calculation for the ensemble took approximately 163 hours for CAM, 238 hours for Grad-CAM, and 120 hours for random method. The calculation for CAM, Grad-CAM, and random methods combined took approximately 24 hours for each model. The results for the individual models can be found in the Appendix Tables 1 and 2. Lastly, we conducted an unpaired t-test to determine the statistical significance of the differences in metric results between CAM and Grad-CAM. For completeness, we also performed t-tests comparing CAM versus random attribution and Grad-CAM versus random attribution, expecting significant statistical differences in both tests. A line plot is used to comparatively show the metrics performance of each XAI method in Fig. 3, which shows the relative performances for each metric based on their positions on the horizontal axis. The exact numerical results with confidence intervals are shown in the Appendix Tables 1 and 2. PGI results indicate that the ensemble\u00e2\u20ac\u2122s predictions are influenced by key features identified by the two XAI methods (i.e. the change in output probability f\u00e2\ufffd\u00a2(X)\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2039f(X)italic_f ( italic_X ) increases when important nodes are perturbed), with a significant difference compared to the random attribution at p<0.005\u011f\ufffd\u2018\ufffd0.005p<0.005italic_p < 0.005 for both CAM versus random and Grad-CAM versus random. There was no significant difference in PGI and PGU between CAM and Grad-CAM. Overall, the faithfulness tests indicate that XAI methods effectively distinguish important from unimportant body points influencing predictions. The plots of RISp, RISv, RISb, ROS, and RRS in Fig. 3 immediately show us that random explanations cause significant changes in the stability results, with p<0.005\u011f\ufffd\u2018\ufffd0.005p<0.005italic_p < 0.005 for both CAM versus random and Grad-CAM versus random. This indicates that both XAI methods are less susceptible to large explanation changes with small input perturbations. Most notably, Grad-CAM offers a highly significant improvement (with p<8.507\u00c3\u201410\u00e2\u02c6\u20197\u011f\ufffd\u2018\ufffd8.507superscript107p<8.507 10^{-7}italic_p < 8.507 \u00c3\u2014 10 start_POSTSUPERSCRIPT - 7 end_POSTSUPERSCRIPT) of input stability compared to CAM for RISv of the ensamble model. In contrast, CAM offers a significantly better input stability (with p<0.05\u011f\ufffd\u2018\ufffd0.05p<0.05italic_p < 0.05) compared to Grad-CAM for RISb and RRS. The result for the stability and faithfullness metric for the different GCN models in ensemble can be found in the Appendix Tables 1 and 2. This study evaluated the reliability and robustness of two XAI techniques, CAM and Grad-CAM, within a deep learning ensemble model. The faithfulness metrics show both methods are effective in identifying important and unimportant body points influencing CP predictions, while stability tests demonstrate robustness against minor data perturbations. Specifically, CAM significantly outperformed Grad-CAM in RISb and RRS, while Grad-CAM excelled in RISv. The choice of XAI method depends on the specific application and key metrics. For instance, to identify potential movement biomarkers for CP related to joint velocity, Grad-CAM is recommended for its superior RISv performance. This also suggests exploring the velocity input branch for possible CP movement biomarkers, which aligns with previous studies [27, 28, 29, 30] where a velocity parameter is used in classical machine learning assessments of CP. If similar explanations for body points are found in multiple 5-second windows, Grad-CAM offers better insight into body point velocity due to its stable explanations despite input variations. Conversely, for quick explanations (i.e. for visual inspection purposes), CAM is preferable due to its faster calculation time. Individual models in the ensemble show varied results in metrics tests, while the ensemble provides a combined outcome from its constituent models. In our previous work [19], we applied metrics tests to a single GCN-based model, limiting generalizability. This study has evaluated XAI metrics in both an ensemble and the individual models composing it, revealing that neither CAM nor Grad-CAM consistently outperforms the other in all metrics. Overall, our findings demonstrate that both XAI methods can provide reliable and stable explanations in CP prediction models. By finding patterns and doing further studies into the explanations, these could potentially supplement GMA observers with specialized domain knowledge, contributing to more interpretable and trustworthy AI diagnostics. The study\u00e2\u20ac\u2122s insights into the comparative performance of CAM and Grad-CAM can also guide future research in improving AI explainability in other high-stakes medical applications. As a next step, it is crucial to introduce more XAI metrics that incorporate domain-specific knowledge to further validate the relevance and accuracy of the explanations provided. It is also necessary to perform clinical interpretations on the explanations to enhance the practical utility of the models. Architectural choice 1 2 3 4 5 6 7 8 9 10 No. modules of input br. 3 3 2 2 2 2 3 3 2 2 Width of input br. 10 10 12 10 8 6 8 6 12 12 Block type in initial mod. Bottl. Basic Basic Basic Bottl. Basic Basic MBC. Bottl. Basic Residual type in initial mod. None Den. None Block Den. Den. Mod. Block Den. Den. No. tmp. scales in input br. 1 3 2 2 3 2 2 1 2 2 No. levels of main br. 3 1 3 2 2 2 2 2 2 1 No. modules of main br. levels 3 2 1 1 3 3 2 3 1 1 Width of first level of main br. 12 12 12 10 12 12 10 12 8 12 No. tmp. scales in main br. 1 2 2 3 2 1 2 1 1 1 Pooling layer type Gl. Gl. Gl. Sp. Sp. Gl. Gl. Gl. Gl. Sp. Graph convolution type DA 2 DA 4+2 SC DA 4 SC DA 4 DA 2 DA 2 DA 4 SC Block type Basic MBC. Basic Basic Bottl. Bottl. Basic Basic Bottl. Basic Bottl. factor 4 2 2 2 2 2 4 4 4 4 Residual type None Block Den. None None Block None Den. Block None SE type None Outer Inner None Outer None None Outer Outer None SE ratio - 2 2 4 2 4 4 4 4 4 SE ratio type - Abs. Abs. Abs. - Abs. - Abs. Abs. - Attention type Ch. - - - Ch. - Ch. - Ch. - Nonlinearity type ReLU Sw. ReLU Sw. Sw. ReLU ReLU Sw. ReLU Sw. Tmp. kernel size 9 7 9 7 9 7 9 7 9 7 AUC 0.949 0.942 0.938 0.943 0.937 0.956 0.953 0.953 0.932 0.947",
        "keywords": ""
    },
    {
        "id": 16,
        "title": "Spatio-Temporal Communication Compression for Distributed Prime-Dual Optimization",
        "abstract": "AbstractIn this paper, for the problem of distributed computing, we propose a general spatio-temporal compressor and discuss its compression methods. This compressor comprehensively considers both temporal and spatial information, encompassing many existing specific compressors. We use the average consensus algorithm as a starting point and further studies distributed optimization algorithms, the Prime-Dual algorithm as an example, in both continuous and discrete time forms. We find that under stronger additional assumptions, the spatio-temporal compressor can be directly applied to distributed computing algorithms, while its default form can also be successfully applied through observer-based differential compression methods, ensuring the linear convergence of the algorithm when the objective function is strongly convex. On this basis, we also discuss the acceleration of the algorithm, filter-based compression methods in the literature, and the addition of randomness to the spatio-temporal compressor. Finally, numerical simulations illustrate the generality of the spatio-temporal compressor, compare different compression methods, and verify the algorithm\u00e2\u20ac\u2122s performance in the convex objective function scenario.",
        "corpus": "In this paper, for the problem of distributed computing, we propose a general spatio-temporal compressor and discuss its compression methods. This compressor comprehensively considers both temporal and spatial information, encompassing many existing specific compressors. We use the average consensus algorithm as a starting point and further studies distributed optimization algorithms, the Prime-Dual algorithm as an example, in both continuous and discrete time forms. We find that under stronger additional assumptions, the spatio-temporal compressor can be directly applied to distributed computing algorithms, while its default form can also be successfully applied through observer-based differential compression methods, ensuring the linear convergence of the algorithm when the objective function is strongly convex. On this basis, we also discuss the acceleration of the algorithm, filter-based compression methods in the literature, and the addition of randomness to the spatio-temporal compressor. Finally, numerical simulations illustrate the generality of the spatio-temporal compressor, compare different compression methods, and verify the algorithm\u00e2\u20ac\u2122s performance in the convex objective function scenario. keywords Communication compression; distributed optimization; linear convergence; spatio-temporal compressors; average consensus. Distributed intelligent systems, such as drone swarms, smart grids, and cyber-physical systems, have been extensively researched across disciplines such as control, signal processing, and machine learning [1, 2, 3, 4]. The mathematical representation of a distributed system involves a network connecting multiple agents, where each node symbolizes an individual agent, and the edges depict communication lines between these nodes. When distributed systems are required to implement tasks such as cluster optimization and collaborative control, it requires the foundational functionality of distributed computing. In this process, each node stores localized information and communicates messages with connected nodes through the network, and collaboratively solves a mathematical problem [1]. This paper focuses on addressing distributed optimization problems, where each node possesses a function, aiming to identify solutions that collectively minimize the sum of network node functions through constant communication across the network. Extensive research has been devoted to the study of distributed optimization algorithms, primarily rooted in the consensus algorithm. The goal of this algorithm is to foster consistency in the states across nodes within the network. A combination of the consensus algorithm with the classical gradient descent method in optimization problems, coupled with stability tactics, results in the distributed subgradient algorithm (DSG), achieving sublinear convergence under a strongly convex global cost function [5, 6]. To address distributed optimization problems with faster rate requirements, more sophisticated algorithms have been introduced. The distributed gradient tracking algorithm (DGT) incorporates an additional state to trace the gradient of the objective function [7, 8], akin to integral action [9]. For diverse equivalent forms of distributed optimization problems, various Lagrangian functions have been proposed, giving rise to multiple algorithms based on the saddle point dynamic method. Examples include the Wang-Eila algorithm in [10] and primal dual algorithm in [11], distinct in communication states. In practical implementation, the network bandwidth for communication in distributed systems is limited and numerous communication compression strategies have been developed to handle such issues. In [12, 13, 14, 15], the idea of quantifying the communication is combined with DSG and DGT algorithms. Specifically, [12] introduced adaptive quantization and [13] applied random quantization, where the quantizer codebook changes when approaching the solution. In [15], the authors developed a dynamic encoding and decoding scheme for quantization. In addition to quantization, there are also several other types of compressors capable of reducing communication bits by synthesizing concepts from quantization, sparsity, and randomization [16, 17, 18, 19]. These compressors exclusively focus on the spatial dimension, encompassing the information within transmitted messages. Notably, the compressor in [20] incorporates temporal dimensions, utilizing information across time. Other research aims to identify commonalities among specific compressors, thereby proposing a generalized definition of compressors [21, 22, 23]. This definition allows any function that satisfies these properties to be considered as a compressor and applied to algorithms. Our goal is to propose such a definition, characterized by properties that simultaneously consider both temporal and spatial dimensions. In addition, how to combine the compressors with distributed optimization algorithms has become a noteworthy area of study. This is because refining the application method can facilitate the successful integration of more general compressors and enhance the overall effectiveness of the algorithm. Beyond the direct application of compressors to the communication state, there exist intriguing techniques, as direct application often poses challenges to stability [24, 25]. For instance, [12, 19] incorporate a weighted sum of the updated value and the original value into the original value, while [13, 26] compress the difference between iterations rather than the original value. In the work of [15, 27], the difference is scaled and then compressed, with the results communicated after a reverse reduction, further ensuring the convergence of the algorithm. [16, 28] adopts a differential compression method based on filtering, and through additional equivalent transformations, ensures that only compressed values are exchanged between nodes. The proposal of a compressor application method based on observers is also a main focus of this paper. Our research in this paper contributes in two aspects: proposing a general compressor definition and exploring its application methods. Firstly, we propose an unified spatio-tempral compressor theory for communication compression in distributed optimization. Such ST compressor uses a constructive exponential stability perspective from nonlinear systems, and various static communication compressors in the literature are categorized into it. We discuss the compression method of direct compression and our proposed observer-based compression, and establish convergence conditions for a class of distributed Prime-Dual optimization algorithms with explicit convergence rates. Our results and analysis are presented to the large class of ST communication compression, without replying on the specific form of a particular compressor. We also discuss the extensions to accelerated algorithm and stochastic compressor. Finally, we validate the above conclusions through simulation experiments. The paper is structured as follows. Section 2 formulates the distributed optimization problem of interest and proposes the spatio-temporal compressor of both original form and stronger form for message communication. In Section 3, we start from the distributed consensus to illustrate the stronger conditions required when applying this compressor directly, as well as the successful combination with observer-based compression methods. In Section 4, we respectively discuss the applicability of these two compression methods to the Prime-Dual flow and discuss several extension. In Section 5, we discretize the Flows based on Euler method, discuss its acceleration method, and introduce randomness to our compressor. Numerical simulations are presented to show the effectiveness of the proposed approaches in Section 6. Finally, a brief conclusion is made in Section 7. All technical proofs are collected in the Appendices. Notation. In this paper, \u00e2\u02c6\u00a5\u00e2\u2039\u2026\u00e2\u02c6\u00a5 \u00e2\u2039\u2026 \u00e2\u02c6\u00a5 denotes Euclidean norm. The notation \u011f\ufffd\u0178\ufffdn\u00e2\ufffd\u00a2(\u011f\ufffd\u0178\ufffdn)subscript1\u011f\ufffd\u2018\u203asubscript0\u011f\ufffd\u2018\u203a start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( bold_0 start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ), \u011f\ufffd\ufffd\u02c6nsubscript\u011f\ufffd\ufffd\u02c6\u011f\ufffd\u2018\u203a start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT and {\u011f\ufffd\ufffd\ufffd1,\u00e2\u20ac\u00a6,\u011f\ufffd\ufffd\ufffdm}subscript\u011f\ufffd\ufffd\ufffd1\u00e2\u20ac\u00a6subscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\u0161 e}_{1},...,{ e}_{m} bold_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , bold_e start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT } denote the column one (zero) vector, identity matrix and base vectors in \u00e2\u201e\ufffddsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018 start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, respectively. The expression diag\u00e2\ufffd\u00a2(x1,\u00e2\u20ac\u00a6,xn)diagsubscript\u011f\ufffd\u2018\u00a51\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u203a ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) is a diagonal matrix with the i\u011f\ufffd\u2018\u2013iitalic_i-th diagonal element being xisubscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2013x_{i}italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. The symbol \u00e2\u0160\u2014tensor-product denotes the Kronecker product. For differential function, \u00e2\u02c6\u2021(\u00e2\u2039\u2026)\u00e2\u02c6\u2021\u00e2\u2039\u2026 ( \u00e2\u2039\u2026 ) denotes its gradient. \u00e2\ufffd\u00a2 denotes Hadamard product. In this paper, we consider a network of agents indexed by V={1,2\u00e2\ufffd\u00a2\u00e2\u20ac\u00a6\u00e2\ufffd\u00a2n}V12\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u203a = { 1 , 2 \u00e2\u20ac\u00a6 italic_n }, where each agent i\u00e2\u02c6\u02c6V\u011f\ufffd\u2018\u2013Vi \u00e2\u02c6\u02c6 roman_V holds a cost function fi:\u00e2\u201e\ufffdd\u00e2\u2020\u2019\u00e2\u201e\ufffd:subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2013\u00e2\u2020\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018\u00e2\u201e\ufffdf_{i}: start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \u00e2\u2020\u2019 blackboard_R, and aims to solve the following distributed optimization problem Particularly, each local cost function fisubscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2013f_{i}italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is assumed to fulfill the following requirements. The following properties are satisfied. The global cost function f\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1):=\u00e2\u02c6\u2018i=1nfi\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1)assign\u011f\ufffd\u2018\u201c\u011f\ufffd\ufffd\u00b1superscriptsubscript\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2013\u011f\ufffd\ufffd\u00b1f( ( bold_x ) := \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( bold_x ) is strongly convex, i.e., there exists \u00ce\u00bc>0\u011f\ufffd\u0153\u20210 > 0 such that f\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b2)\u00e2\u2030\u00a5f\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1)+\u00e2\u02c6\u2021f\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1)T\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b2\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00b1)+\u00ce\u00bc2\u00e2\ufffd\u00a2\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b2\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00b1\u00e2\u20ac\u20132\u011f\ufffd\u2018\u201c\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u201c\u011f\ufffd\ufffd\u00b1\u00e2\u02c6\u2021\u011f\ufffd\u2018\u201csuperscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2021\u011f\ufffd\ufffd\u00b2\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u0153\u20212superscriptnorm\u011f\ufffd\ufffd\u00b2\u011f\ufffd\ufffd\u00b12f( f( f( )+ ( bold_y ) \u00e2\u2030\u00a5 italic_f ( bold_x ) + \u00e2\u02c6\u2021 italic_f ( bold_x ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ( bold_y - bold_x ) + divide start_ARG italic_\u00ce\u00bc end_ARG start_ARG 2 end_ARG \u00e2\u02c6\u00a5 bold_y - bold_x \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT for all \u011f\ufffd\ufffd\u00b1,\u011f\ufffd\ufffd\u00b2\u00e2\u02c6\u02c6\u00e2\u201e\ufffdd\u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b2superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018 , bold_y \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT. Each local gradient \u00e2\u02c6\u2021fi\u00e2\u02c6\u2021subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2013 f_{i}\u00e2\u02c6\u2021 italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is globally Lipschitz continuous, i.e., there exists Lf>0subscript\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\u201c0L_{f}>0italic_L start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT > 0 such that \u00e2\u20ac\u2013\u00e2\u02c6\u2021fi\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1)\u00e2\u02c6\u2019\u00e2\u02c6\u2021fi\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b2)\u00e2\u20ac\u2013\u00e2\u2030\u00a4Lf\u00e2\ufffd\u00a2\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b1\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00b2\u00e2\u20ac\u2013norm\u00e2\u02c6\u2021subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2013\u011f\ufffd\ufffd\u00b1\u00e2\u02c6\u2021subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2013\u011f\ufffd\ufffd\u00b2subscript\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\u201cnorm\u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b2 f_{i}( f_{i}( L_{f} \u00e2\u02c6\u2021 italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( bold_x ) - \u00e2\u02c6\u2021 italic_f start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( bold_y ) \u00e2\u02c6\u00a5 \u00e2\u2030\u00a4 italic_L start_POSTSUBSCRIPT italic_f end_POSTSUBSCRIPT \u00e2\u02c6\u00a5 bold_x - bold_y \u00e2\u02c6\u00a5 for all \u011f\ufffd\ufffd\u00b1,\u011f\ufffd\ufffd\u00b2\u00e2\u02c6\u02c6\u00e2\u201e\ufffdd\u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b2superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018 , bold_y \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT. \u00e2\u2013\u00a1\u00e2\u2013\u00a1 If Assumption 1 holds, then the considered optimization problem (1) turns out a strongly convex optimization problem, allowing an optimal solution s\u00e2\u02c6\u2014\u00e2\u0160\u2020\u00e2\u201e\ufffddsuperscript\u011f\ufffd\u2018 \u00e2\u02c6\u2014superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018s^{ start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT \u00e2\u0160\u2020 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT such that \u00e2\u02c6\u2021f\u00e2\ufffd\u00a2(s\u00e2\u02c6\u2014)=0\u00e2\u02c6\u2021\u011f\ufffd\u2018\u201csuperscript\u011f\ufffd\u2018 \u00e2\u02c6\u20140 f(s^{ italic_f ( italic_s start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT ) = 0 and f\u00e2\ufffd\u00a2(s\u00e2\u02c6\u2014)=f\u00e2\u02c6\u2014\u011f\ufffd\u2018\u201csuperscript\u011f\ufffd\u2018 \u00e2\u02c6\u2014superscript\u011f\ufffd\u2018\u201c\u00e2\u02c6\u2014f(s^{ ( italic_s start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT ) = italic_f start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT, where f\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018\u201c\u00e2\u02c6\u2014f^{ start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT is the optimal value. As each agent has the information of only local cost function, to solve such a distributed optimization problem (1), a communication network is usually required for transmitting messages. Denote the communication graph G=(V,E)GVE = ( roman_V , roman_E ), where EE denotes the set of edges. Let [ai\u00e2\ufffd\u00a2j]\u00e2\u02c6\u02c6Rn\u00c3\u2014ndelimited-[]subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014superscriptR\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u203a[a_{ij}] n}[ italic_a start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ] \u00e2\u02c6\u02c6 roman_R start_POSTSUPERSCRIPT italic_n \u00c3\u2014 italic_n end_POSTSUPERSCRIPT denote the weight matrix complying with graph GG i.e., ai\u00e2\ufffd\u00a2j>0subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140a_{ij}>0italic_a start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT > 0 if (j,i)\u00e2\u02c6\u02c6E\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u2013E(j,i) italic_j , italic_i ) \u00e2\u02c6\u02c6 roman_E and ai\u00e2\ufffd\u00a2j=0subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140a_{ij}=0italic_a start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 0 if (j,i)\u00e2\u02c6\u2030E\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u2013E(j,i) italic_j , italic_i ) \u00e2\u02c6\u2030 roman_E. Then denote by \u011f\ufffd\ufffd\u2039\u011f\ufffd\ufffd\u2039 the Laplacian matrix of graph GG satisfying [\u011f\ufffd\ufffd\u2039]i\u00e2\ufffd\u00a2j=\u00e2\u02c6\u2019ai\u00e2\ufffd\u00a2jsubscriptdelimited-[]\u011f\ufffd\ufffd\u2039\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014[ bold_L ] start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = - italic_a start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT for all i\u00e2\u2030 j\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014i jitalic_i \u00e2\u2030 italic_j, and [\u011f\ufffd\ufffd\u2039]i\u00e2\ufffd\u00a2i=\u00e2\u02c6\u2018j=1nai\u00e2\ufffd\u00a2jsubscriptdelimited-[]\u011f\ufffd\ufffd\u2039\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2013superscriptsubscript\u011f\ufffd\u2018\u20141\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014[ bold_L ] start_POSTSUBSCRIPT italic_i italic_i end_POSTSUBSCRIPT = \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_a start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT for all i\u00e2\u02c6\u02c6V\u011f\ufffd\u2018\u2013Vi \u00e2\u02c6\u02c6 roman_V. Denote the neighbor set of agent i\u011f\ufffd\u2018\u2013iitalic_i as NisubscriptN\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, satisfying j\u00e2\u02c6\u02c6Ni\u011f\ufffd\u2018\u2014subscriptN\u011f\ufffd\u2018\u2013j \u00e2\u02c6\u02c6 roman_N start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT if and only if [\u011f\ufffd\ufffd\u2039]i\u00e2\ufffd\u00a2j\u00e2\u2030 0subscriptdelimited-[]\u011f\ufffd\ufffd\u2039\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140[ 0[ bold_L ] start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT \u00e2\u2030 0 for all i,j\u00e2\u02c6\u02c6V\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014Vi,j , italic_j \u00e2\u02c6\u02c6 roman_V. For simplicity, we make the following assumption on the communication graph. The graph GG is undirected, connected and time-invariant. The above Assumption 2 indicates that the Laplacian matrix \u011f\ufffd\ufffd\u2039\u011f\ufffd\ufffd\u2039 is symmetric positive semi-definite, with [\u011f\ufffd\ufffd\u2039]i\u00e2\ufffd\u00a2j=[\u011f\ufffd\ufffd\u2039]j\u00e2\ufffd\u00a2isubscriptdelimited-[]\u011f\ufffd\ufffd\u2039\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscriptdelimited-[]\u011f\ufffd\ufffd\u2039\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u2013[ bold_L ] start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = [ bold_L ] start_POSTSUBSCRIPT italic_j italic_i end_POSTSUBSCRIPT, \u011f\ufffd\ufffd\u2039\u011f\ufffd\u0178\ufffdn=\u011f\ufffd\u0178\ufffdnsubscript\u011f\ufffd\ufffd\u2039\u011f\ufffd\u0178\ufffd\u011f\ufffd\u2018\u203asubscript0\u011f\ufffd\u2018\u203a start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = bold_0 start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT and its eigenvalues \u00ce\u00bbisubscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, i\u00e2\u02c6\u02c6V\u011f\ufffd\u2018\u2013Vi \u00e2\u02c6\u02c6 roman_V in an ascending order satisfying 0=\u00ce\u00bb1<\u00ce\u00bb2\u00e2\u2030\u00a4\u00e2\u20ac\u00a6\u00e2\u2030\u00a4\u00ce\u00bbn0subscript\u011f\ufffd\u0153\u20201subscript\u011f\ufffd\u0153\u20202\u00e2\u20ac\u00a6subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u203a0= = italic_\u00ce\u00bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < italic_\u00ce\u00bb start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 \u00e2\u20ac\u00a6 \u00e2\u2030\u00a4 italic_\u00ce\u00bb start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT by [1]. We let \u011f\ufffd\ufffd\u2019\u00e2\u02c6\u02c6\u00e2\u201e\ufffdn\u00c3\u2014(n\u00e2\u02c6\u20191)\u011f\ufffd\ufffd\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u203a1 \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_n \u00c3\u2014 ( italic_n - 1 ) end_POSTSUPERSCRIPT be a matrix whose rows are eigenvectors corresponding to nonzero eigenvalues of \u011f\ufffd\ufffd\u2039\u011f\ufffd\ufffd\u2039 satisfying With the communication graph GG several distributed optimization algorithms have been developed in the literature [7, 8, 9, 10, 11] to compute the solution s\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018 \u00e2\u02c6\u2014s^{ start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT for (1). In this paper, we mainly focus on the distributed Prime-Dual algorithm, which enables to achieve exponential convergence and further generalizations to the case with optimization constraints [29, 30]. A common distributed Prime-Dual flow for (1) takes the form [11] where \u00ce\u00b2,\u00ce\u00b7>0\u011f\ufffd\u203a\u00bd\u011f\ufffd\u0153\u201a0 , italic_\u00ce\u00b7 > 0 are parameters to be fixed and the initial condition \u00e2\u02c6\u2018i=1n\u011f\ufffd\ufffd\u00afi\u00e2\ufffd\u00a2(0)=\u011f\ufffd\u0178\ufffddsuperscriptsubscript\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\ufffd\u00af\u011f\ufffd\u2018\u20130subscript0\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT bold_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( 0 ) = bold_0 start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT. In this paper, we are particularly interested in the Spatio-Temporal (ST) compressors. Given a uniformly linearly bounded mapping \u011f\ufffd\ufffd\u201a:\u00e2\u201e\ufffdd\u00c3\u2014\u00e2\u201e\ufffd+\u00e2\u2020\u2019\u00e2\u201e\ufffdd:\u011f\ufffd\ufffd\u201a\u00e2\u2020\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018subscript\u00e2\u201e\ufffdsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018 : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \u00c3\u2014 blackboard_R start_POSTSUBSCRIPT + end_POSTSUBSCRIPT \u00e2\u2020\u2019 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, i.e., there exists a Lc>0subscript\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\ufffd0L_{c}>0italic_L start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT > 0 such that \u00e2\u20ac\u2013\u011f\ufffd\ufffd\u201a\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e,t)\u00e2\u20ac\u2013\u00e2\u2030\u00a4Lc\u00e2\ufffd\u00a2\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b1e\u00e2\u20ac\u2013norm\u011f\ufffd\ufffd\u201asubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\ufffdnormsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019 L_{c} bold_C ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) \u00e2\u02c6\u00a5 \u00e2\u2030\u00a4 italic_L start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT \u00e2\u02c6\u00a5 bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT \u00e2\u02c6\u00a5 for all \u011f\ufffd\ufffd\u00b1e\u00e2\u02c6\u02c6\u00e2\u201e\ufffddsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT and any t\u00e2\u02c6\u02c6\u00e2\u201e\ufffd+\u011f\ufffd\u2018\u00a1subscript\u00e2\u201e\ufffdt \u00e2\u02c6\u02c6 blackboard_R start_POSTSUBSCRIPT + end_POSTSUBSCRIPT. Then we have the following statements. The mapping \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a is said to be a ST compressor in continuous time, if the induced continuous-time non-autonomous system \u011f\ufffd\ufffd\u00b1\u00cb\u2122e=\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u201a\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e,t)subscript\u00cb\u2122\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\ufffd\u201asubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1 start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT = - bold_C ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) is uniformly globally exponentially stable at the origin. The mapping \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a is said to be a ST compressor in discrete time, if the induced discrete time non-autonomous system \u011f\ufffd\ufffd\u00b1e\u00e2\ufffd\u00a2(t+1)=\u011f\ufffd\ufffd\u00b1e\u00e2\ufffd\u00a2(t)\u00e2\u02c6\u2019\u00ce\u00ba0\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u201a\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e,t)subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a11subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u0153\u20260\u011f\ufffd\ufffd\u201asubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t + 1 ) = bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ) - italic_\u00ce\u00ba start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT bold_C ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) is uniformly globally exponentially stable at the origin for some stepsize \u00ce\u00ba0>0subscript\u011f\ufffd\u0153\u202600 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT > 0. \u00e2\u2013\u00a1\u00e2\u2013\u00a1 In the following, a stronger version of the spatio-temporal compressors, i.e., the Strongly Spatio-Temporal (SST) compressors, is introduced. Given a uniformly globally Lipschitz mapping \u011f\ufffd\ufffd\u201a:\u00e2\u201e\ufffdd\u00c3\u2014\u00e2\u201e\ufffd+\u00e2\u2020\u2019\u00e2\u201e\ufffdd:\u011f\ufffd\ufffd\u201a\u00e2\u2020\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018subscript\u00e2\u201e\ufffdsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018 : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \u00c3\u2014 blackboard_R start_POSTSUBSCRIPT + end_POSTSUBSCRIPT \u00e2\u2020\u2019 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, i.e., there exists a Lc>0subscript\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\ufffd0L_{c}>0italic_L start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT > 0 such that \u00e2\u20ac\u2013\u011f\ufffd\ufffd\u201a\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e,t)\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u201a\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e\u00e2\u20ac\u00b2,t)\u00e2\u20ac\u2013\u00e2\u2030\u00a4Lc\u00e2\ufffd\u00a2\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b1e\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00b1e\u00e2\u20ac\u00b2\u00e2\u20ac\u2013norm\u011f\ufffd\ufffd\u201asubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1\u011f\ufffd\ufffd\u201asuperscriptsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\ufffdnormsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019superscriptsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u00e2\u20ac\u00b2 L_{% c} bold_C ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) - bold_C ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT , italic_t ) \u00e2\u02c6\u00a5 \u00e2\u2030\u00a4 italic_L start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT \u00e2\u02c6\u00a5 bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT - bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u02c6\u00a5 for all \u011f\ufffd\ufffd\u00b1e,\u011f\ufffd\ufffd\u00b1e\u00e2\u20ac\u00b2\u00e2\u02c6\u02c6\u00e2\u201e\ufffddsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019superscriptsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u00e2\u20ac\u00b2superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT and any t\u00e2\u02c6\u02c6\u00e2\u201e\ufffd+\u011f\ufffd\u2018\u00a1subscript\u00e2\u201e\ufffdt \u00e2\u02c6\u02c6 blackboard_R start_POSTSUBSCRIPT + end_POSTSUBSCRIPT. Then we have the following statements. The mapping \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a is said to be a SST compressor in continuous time, if the induced continuous-time non-autonomous system \u011f\ufffd\ufffd\u00b1\u00cb\u2122e=\u00e2\u02c6\u2019k\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u201a\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e,t)subscript\u00cb\u2122\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u02dc\u011f\ufffd\ufffd\u201asubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1 start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT = - italic_k bold_C ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) is uniformly globally exponentially stable at the origin for any k>0\u011f\ufffd\u2018\u02dc0k>0italic_k > 0. The mapping \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a is said to be a SST compressor in discrete time, if there exists \u00ce\u00ba0\u00e2\u02c6\u2014>0superscriptsubscript\u011f\ufffd\u0153\u20260\u00e2\u02c6\u20140 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT > 0 such that the induced discrete time non-autonomous system \u011f\ufffd\ufffd\u00b1e\u00e2\ufffd\u00a2(t+1)=\u011f\ufffd\ufffd\u00b1e\u00e2\ufffd\u00a2(t)\u00e2\u02c6\u2019\u00ce\u00ba0\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u201a\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e,t)subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a11subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u0153\u20260\u011f\ufffd\ufffd\u201asubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t + 1 ) = bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ) - italic_\u00ce\u00ba start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT bold_C ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) is uniformly globally exponentially stable at the origin for any stepsize \u00ce\u00ba0\u00e2\u02c6\u02c6(0,\u00ce\u00ba0\u00e2\u02c6\u2014)subscript\u011f\ufffd\u0153\u202600superscriptsubscript\u011f\ufffd\u0153\u20260\u00e2\u02c6\u2014 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 ( 0 , italic_\u00ce\u00ba start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT ). \u00e2\u2013\u00a1\u00e2\u2013\u00a1 It is clear that the mapping \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a satisfying either of both Definitions 1 and 2, needs to vanish at the origin, i.e., \u011f\ufffd\ufffd\u201a\u00e2\ufffd\u00a2(0,t)\u00e2\u2030\u00a10\u011f\ufffd\ufffd\u201a0\u011f\ufffd\u2018\u00a10 0bold_C ( 0 , italic_t ) \u00e2\u2030\u00a1 0 uniformly in t\u011f\ufffd\u2018\u00a1titalic_t. This immediately shows that the uniformly globally Lipschitz property in Definition 2 implies the uniformly linearly bounded property. Besides, the exponential stability of the induced non-autonomous \u011f\ufffd\ufffd\u00b1esubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT-systems in Definition 2 is more restrictive than Definition 1. In view of both points, the notion of the SST compressor in Definition 2, is stronger than that of Definition 1. In the literature there are also some other classes of compressors, that are indeed special cases of our (strong) ST compressors. The scalarized compressor \u011f\ufffd\ufffd\u201a1:\u00e2\u201e\ufffdd\u00c3\u2014\u00e2\u201e\ufffd+\u00e2\u2020\u2019\u00e2\u201e\ufffdd:subscript\u011f\ufffd\ufffd\u201a1\u00e2\u2020\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018subscript\u00e2\u201e\ufffdsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \u00c3\u2014 blackboard_R start_POSTSUBSCRIPT + end_POSTSUBSCRIPT \u00e2\u2020\u2019 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT satisfies \u011f\ufffd\ufffd\u201a1\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e,t)=\u011f\ufffd\u203a\u2122\u00e2\ufffd\u00a2(t)\u00e2\ufffd\u00a2\u011f\ufffd\u203a\u2122\u00e2\ufffd\u00a2(t)T\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b1esubscript\u011f\ufffd\ufffd\u201a1subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1\u011f\ufffd\u203a\u2122\u011f\ufffd\u2018\u00a1\u011f\ufffd\u203a\u2122superscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2021subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) = bold_italic_\u00cf\u02c6 ( italic_t ) bold_italic_\u00cf\u02c6 ( italic_t ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT, where the compression vector \u011f\ufffd\u203a\u2122:\u00e2\u201e\ufffd+\u00e2\u2020\u2019\u00e2\u201e\ufffdd:\u011f\ufffd\u203a\u2122\u00e2\u2020\u2019subscript\u00e2\u201e\ufffdsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018 : blackboard_R start_POSTSUBSCRIPT + end_POSTSUBSCRIPT \u00e2\u2020\u2019 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT is uniformly bounded and persistently excited, i.e., either of the followings holds For continuous time, For discrete time, for some constants \u00ce\u00b11,\u00ce\u00b12,T1>0subscript\u011f\ufffd\u203a\u00bc1subscript\u011f\ufffd\u203a\u00bc2subscript\u011f\ufffd\u2018\u202110 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u00ce\u00b1 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT > 0 (see [20]). \u00e2\u2013\u00a1\u00e2\u2013\u00a1 The contractive compressor \u011f\ufffd\ufffd\u201a2:\u00e2\u201e\ufffdd\u00e2\u2020\u2019\u00e2\u201e\ufffdd:subscript\u011f\ufffd\ufffd\u201a2\u00e2\u2020\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \u00e2\u2020\u2019 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT satisfies for some \u00cf\u2020\u00e2\u02c6\u02c6(0,1]\u011f\ufffd\u0153\u201801 \u00e2\u02c6\u02c6 ( 0 , 1 ] and p>0\u011f\ufffd\u2018\ufffd0p>0italic_p > 0 (see [16, 19, 31], with the expectation operator removed). By [16], the following \u011f\ufffd\ufffd\u201a2\u00e2\ufffd\u00a2asubscript\u011f\ufffd\ufffd\u201a2\u011f\ufffd\u2018\ufffd start_POSTSUBSCRIPT 2 italic_a end_POSTSUBSCRIPT and \u011f\ufffd\ufffd\u201a2\u00e2\ufffd\u00a2bsubscript\u011f\ufffd\ufffd\u201a2\u011f\ufffd\u2018\ufffd start_POSTSUBSCRIPT 2 italic_b end_POSTSUBSCRIPT are specific examples of \u011f\ufffd\ufffd\u201a2subscript\u011f\ufffd\ufffd\u201a2 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, and \u011f\ufffd\ufffd\u201a2\u00e2\ufffd\u00a2csubscript\u011f\ufffd\ufffd\u201a2\u011f\ufffd\u2018\ufffd start_POSTSUBSCRIPT 2 italic_c end_POSTSUBSCRIPT is a specific example of \u011f\ufffd\ufffd\u201a2subscript\u011f\ufffd\ufffd\u201a2 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT with p=1\u011f\ufffd\u2018\ufffd1p=1italic_p = 1 and \u00cf\u2020=34\u011f\ufffd\u0153\u201834 = divide start_ARG 3 end_ARG start_ARG 4 end_ARG: Greedy (Top-k) sparsifier [32] \u011f\ufffd\ufffd\u201a2\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e)=\u00e2\u02c6\u2018s=1k[\u011f\ufffd\ufffd\u00b1e]is\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\ufffdissubscript\u011f\ufffd\ufffd\u201a2\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019superscriptsubscript\u011f\ufffd\u2018 1\u011f\ufffd\u2018\u02dcsubscriptdelimited-[]subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018 subscript\u011f\ufffd\ufffd\ufffdsubscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018 e}_% {i_{s}}bold_C start_POSTSUBSCRIPT 2 italic_a end_POSTSUBSCRIPT ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ) = \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_s = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT [ bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ] start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT end_POSTSUBSCRIPT bold_e start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT end_POSTSUBSCRIPT where i1,\u00e2\u20ac\u00a6,iksubscript\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dci_{1},...,i_{k}italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_i start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT are the indices of largest t\u011f\ufffd\u2018\u00a1titalic_t coordinates in the absolute value of \u011f\ufffd\ufffd\u00b1esubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT. Standard uniform quantizer [16] \u011f\ufffd\ufffd\u201a2\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e)=\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b1e\u00e2\u20ac\u2013\u00e2\u02c6\ufffd2\u00e2\ufffd\u00a2sgn\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e),subscript\u011f\ufffd\ufffd\u201a2\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019subscriptnormsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u20192sgnsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019 sgn}( start_POSTSUBSCRIPT 2 italic_b end_POSTSUBSCRIPT ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ) = divide start_ARG \u00e2\u02c6\u00a5 bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT \u00e2\u02c6\u00a5 start_POSTSUBSCRIPT \u00e2\u02c6\ufffd end_POSTSUBSCRIPT end_ARG start_ARG 2 end_ARG roman_sgn ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ) , where sgn\u00e2\ufffd\u00a2(\u00e2\u2039\u2026)sgn\u00e2\u2039\u2026 ( \u00e2\u2039\u2026 ) denotes the element-wise sign. Saturated quantizer where i=1,2\u00e2\ufffd\u00a2\u00e2\u20ac\u00a6,d\u011f\ufffd\u2018\u201312\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u2018i=1,2...,ditalic_i = 1 , 2 \u00e2\u20ac\u00a6 , italic_d, \u00ce\u201d\u00e2\u02c6\u02c6\u00e2\u201e\ufffd\u00ce\u201d\u00e2\u201e\ufffd \u00e2\u02c6\u02c6 blackboard_R denotes the quantization precision and \u00e2\u0152\u0160\u00e2\u2039\u2026\u00e2\u0152\u2039\u00e2\u2039\u2026 \u00e2\u2039\u2026 \u00e2\u0152\u2039 denotes the the floor sign. \u00e2\u2013\u00a1\u00e2\u2013\u00a1 The following statements are true. The scalarized compressor \u011f\ufffd\ufffd\u201a1subscript\u011f\ufffd\ufffd\u201a1 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT belongs to the SST compressor. The contractive compressor \u011f\ufffd\ufffd\u201a2subscript\u011f\ufffd\ufffd\u201a2 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT belongs to the ST compressor. \u00e2\u2013\u00a1\u00e2\u2013\u00a1 A specific example of discrete time cases of \u011f\ufffd\ufffd\u201a1subscript\u011f\ufffd\ufffd\u201a1 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, denoted by \u011f\ufffd\ufffd\u201a1\u00e2\ufffd\u00a2asubscript\u011f\ufffd\ufffd\u201a1\u011f\ufffd\u2018\ufffd start_POSTSUBSCRIPT 1 italic_a end_POSTSUBSCRIPT, can be derived by letting \u011f\ufffd\u203a\u2122\u00e2\ufffd\u00a2(t)=\u011f\ufffd\ufffd\ufffdi\u011f\ufffd\u203a\u2122\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\u2013 ( italic_t ) = bold_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT with i=1+(t\u00e2\ufffd\u00a2mod\u00e2\ufffd\u00a2d)\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\u00a1mod\u011f\ufffd\u2018\u2018i=1+(t d)italic_i = 1 + ( italic_t roman_mod italic_d ) for t\u00e2\u02c6\u02c6\u00e2\u201e\u2022\u011f\ufffd\u2018\u00a1\u00e2\u201e\u2022t \u00e2\u02c6\u02c6 blackboard_N. In addition to the above mentioned compressors, there are also some other forms of compressors that satisfy Definition 2. For example, \u011f\ufffd\ufffd\u201a1\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e,t)=\u00ce\u00b8\u00e2\ufffd\u00a2(t)\u00e2\ufffd\u00a2\u011f\ufffd\u203a\u2122\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e,t)subscript\u011f\ufffd\ufffd\u201a1subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1\u011f\ufffd\u0153\u0192\u011f\ufffd\u2018\u00a1\u011f\ufffd\u203a\u2122subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) = italic_\u00ce\u00b8 ( italic_t ) bold_italic_\u00cf\u02c6 ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) where \u011f\ufffd\u203a\u2122\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e,t)\u011f\ufffd\u203a\u2122subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1 ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) is a scalarized mapping and \u00ce\u00b8\u00e2\ufffd\u00a2(t)\u00e2\ufffd\u00a2\u011f\ufffd\u203a\u2122\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e,t)\u011f\ufffd\u0153\u0192\u011f\ufffd\u2018\u00a1\u011f\ufffd\u203a\u2122subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1 ( italic_t ) bold_italic_\u00cf\u02c6 ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) is strongly P\u011f\ufffd\u2018\u0192Pitalic_P-monotonic (see [33]). \u00e2\u2013\u00a1\u00e2\u2013\u00a1 We stress that when the compressor \u011f\ufffd\ufffd\u201a\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e,t)\u011f\ufffd\ufffd\u201asubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1 ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) is used, we do not mean to using \u011f\ufffd\ufffd\u201a\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e,t)\u011f\ufffd\ufffd\u201asubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1 ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) to encode \u011f\ufffd\ufffd\u00b1esubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT for communication and then transmitting the whole vector of \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a directly. Instead, the \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a represents the communication information, whose transmission can be implemented requiring less bandwidths than directly transmitting \u011f\ufffd\ufffd\u00b1esubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT of d\u011f\ufffd\u2018\u2018ditalic_d dimensions, leading to the so-called communication compression. For example, if the scalarized compressor \u011f\ufffd\ufffd\u201a1subscript\u011f\ufffd\ufffd\u201a1 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is adopted, the actual communication message at each round is a scalar \u011f\ufffd\u203a\u2122\u00e2\ufffd\u00a2(t)\u00e2\u0160\u00a4\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b1e\u00e2\ufffd\u00a2(t)\u011f\ufffd\u203a\u2122superscript\u011f\ufffd\u2018\u00a1topsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1 ( italic_t ) start_POSTSUPERSCRIPT \u00e2\u0160\u00a4 end_POSTSUPERSCRIPT bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ) with each agent holding a common \u011f\ufffd\u203a\u2122\u00e2\ufffd\u00a2(t)\u011f\ufffd\u203a\u2122\u011f\ufffd\u2018\u00a1 ( italic_t ), while for the standard uniform quantizer \u011f\ufffd\ufffd\u201a2\u00e2\ufffd\u00a2bsubscript\u011f\ufffd\ufffd\u201a2\u011f\ufffd\u2018\ufffd start_POSTSUBSCRIPT 2 italic_b end_POSTSUBSCRIPT, the actual communication message consists of a scalar \u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b1e\u00e2\u20ac\u2013\u00e2\u02c6\ufffdsubscriptnormsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019 bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT \u00e2\u02c6\u00a5 start_POSTSUBSCRIPT \u00e2\u02c6\ufffd end_POSTSUBSCRIPT and a vector sgn\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e)sgnsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019 ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ). In view of this, with a bit abuse of notation, we insist on saying the mapping \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a to be a compressor throughout the paper. \u00e2\u2013\u00a1\u00e2\u2013\u00a1 In contrast with the conventional compressors, e.g., the contractive compressor, the ST compressor exhibits two distinctive features. Firstly, it synthesizes information from both the time and space domains, broadening its applicability and expanding the design possibilities. Secondly, its key characteristic is elucidated through a non-autonomous system, which can simplify the design procedure while providing the flexibility to incorporate control-related tools into distributed optimization. Distributed consensus is a fundamental algorithm that acts as a subroutine in numerous distributed optimization problems. In view of this, in this section we investigate how to combine the ST compressors with the consensus algorithm, which motivates the subsequent developments of distributed optimization algorithms with ST compressors. Moreover, due to its convenience of analysis, we focus on the continuous-time distributed consensus, taking the form where \u011f\ufffd\ufffd\u00b1i,c\u00e2\u02c6\u02c6\u00e2\u201e\ufffddsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffdsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT italic_i , italic_c end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT denotes the message transmitted by agent i\u00e2\u02c6\u02c6V\u011f\ufffd\u2018\u2013Vi \u00e2\u02c6\u02c6 roman_V. It is clear that over the graph GG under Assumption 2, each node state exponentially reaches consensus at the average \u011f\ufffd\ufffd\u00b1\u00e2\u02c6\u2014:=1n\u00e2\ufffd\u00a2\u00e2\u02c6\u2018j=0n\u011f\ufffd\ufffd\u00b1j\u00e2\ufffd\u00a2(0)assignsuperscript\u011f\ufffd\ufffd\u00b1\u00e2\u02c6\u20141\u011f\ufffd\u2018\u203asuperscriptsubscript\u011f\ufffd\u2018\u20140\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u20140{ start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT := divide start_ARG 1 end_ARG start_ARG italic_n end_ARG \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_j = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT bold_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ( 0 ). An intuitive design of compressed consensus algorithm is to directly replace the transmitted message \u011f\ufffd\ufffd\u00b1isubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT by the compressed one, i.e., \u011f\ufffd\ufffd\u00b1i,c=\u011f\ufffd\ufffd\u201a\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1i,t)subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u201asubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_i , italic_c end_POSTSUBSCRIPT = bold_C ( bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_t ) in (4), leading to the following distributed consensus flow with direct compression (DC-DC) as Then a natural question arises: given a ST compressor \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a whether or when the DC-DC flow (5) maintains the exponential convergence to the average. Before we answer such a question, we make the following observation on the SST compressor. Given a SST compressor \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a in continuous time, it is clear that the system where \u011f\ufffd\ufffd\u00b2e\u00e2\u02c6\u02c6\u00e2\u201e\ufffd(n\u00e2\u02c6\u20191)\u00e2\ufffd\u00a2dsubscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u203a1\u011f\ufffd\u2018\u2018{ start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT ( italic_n - 1 ) italic_d end_POSTSUPERSCRIPT, \u00ce\u203a:=diag\u00e2\ufffd\u00a2(\u00ce\u00bb2,\u00e2\u20ac\u00a6,\u00ce\u00bbn)\u00e2\u0160\u2014\u011f\ufffd\ufffd\u02c6dassign\u00ce\u203atensor-productdiagsubscript\u011f\ufffd\u0153\u20202\u00e2\u20ac\u00a6subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\ufffd\u02c6\u011f\ufffd\u2018\u2018 := roman_diag ( italic_\u00ce\u00bb start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_\u00ce\u00bb start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) \u00e2\u0160\u2014 bold_I start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT and \u011f\ufffd\u2019\ufffd\u00e2\u02c6\u2019\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b2,t):=[\u011f\ufffd\ufffd\u201aT\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b21,t),\u00e2\u20ac\u00a6,\u011f\ufffd\ufffd\u201aT\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b2n\u00e2\u02c6\u20191,t)]Tassignsuperscript\u011f\ufffd\u2019\ufffd\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u00a1superscriptsuperscript\u011f\ufffd\ufffd\u201a\u011f\ufffd\u2018\u2021subscript\u011f\ufffd\ufffd\u00b21\u011f\ufffd\u2018\u00a1\u00e2\u20ac\u00a6superscript\u011f\ufffd\ufffd\u201a\u011f\ufffd\u2018\u2021subscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u203a1\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2021 }^{T}( start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT ( bold_y , italic_t ) := [ bold_C start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ( bold_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_t ) , \u00e2\u20ac\u00a6 , bold_C start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ( bold_y start_POSTSUBSCRIPT italic_n - 1 end_POSTSUBSCRIPT , italic_t ) ] start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT, is uniformly globally exponentially stable at the zero equilibrium. By the converse Lyapunov Theorem for exponential stability [34, Theorem 4.14], this implies the existence of a Lyapunov function Ve:\u00e2\u201e\ufffd(n\u00e2\u02c6\u20191)\u00e2\ufffd\u00a2d\u00c3\u2014\u00e2\u201e\ufffd+\u00e2\u2020\u2019\u00e2\u201e\ufffd+:subscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2019\u00e2\u2020\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u203a1\u011f\ufffd\u2018\u2018subscript\u00e2\u201e\ufffdsubscript\u00e2\u201e\ufffdV_{e}: start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT : blackboard_R start_POSTSUPERSCRIPT ( italic_n - 1 ) italic_d end_POSTSUPERSCRIPT \u00c3\u2014 blackboard_R start_POSTSUBSCRIPT + end_POSTSUBSCRIPT \u00e2\u2020\u2019 blackboard_R start_POSTSUBSCRIPT + end_POSTSUBSCRIPT such that for some c1,c2,c3,c4>0subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd3subscript\u011f\ufffd\u2018\ufffd40c_{1},c_{2},c_{3},c_{4}>0italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT > 0. With this in mind, and defining \u011f\ufffd\u2022\u0160:=\u011f\ufffd\ufffd\u2019\u00e2\u0160\u2014\u011f\ufffd\ufffd\u02c6dassign\u011f\ufffd\u2022\u0160tensor-product\u011f\ufffd\ufffd\u2019subscript\u011f\ufffd\ufffd\u02c6\u011f\ufffd\u2018\u2018 := bold_S \u00e2\u0160\u2014 bold_I start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT and \u011f\ufffd\u2019\ufffd\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1,t):=[\u011f\ufffd\ufffd\u201aT\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b11,t),\u00e2\u20ac\u00a6,\u011f\ufffd\ufffd\u201aT\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1n,t)]Tassign\u011f\ufffd\u2019\ufffd\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1superscriptsuperscript\u011f\ufffd\ufffd\u201a\u011f\ufffd\u2018\u2021subscript\u011f\ufffd\ufffd\u00b11\u011f\ufffd\u2018\u00a1\u00e2\u20ac\u00a6superscript\u011f\ufffd\ufffd\u201a\u011f\ufffd\u2018\u2021subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2021 }( ( bold_x , italic_t ) := [ bold_C start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ( bold_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_t ) , \u00e2\u20ac\u00a6 , bold_C start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ( bold_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_t ) ] start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT, we are ready to propose the following theorem for Flow (5), answering the question by showing that an extra condition on the communication network GG and the SST compressor \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a is still required to maintain an exponential convergence to the average. Let Assumption 2 hold, then for the DC-DC Flow (5) with a SST compressor in continuous time \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a if there holds for \u00ce\u00b4<c3c4\u00e2\ufffd\u00a2\u00ce\u00bbn\u011f\ufffd\u203a\u00bfsubscript\u011f\ufffd\u2018\ufffd3subscript\u011f\ufffd\u2018\ufffd4subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u203a < divide start_ARG italic_c start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG start_ARG italic_c start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_\u00ce\u00bb start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_ARG, then there holds for some \u00ce\u00b3>0\u011f\ufffd\u203a\u00be0 > 0. \u00e2\u2013\u00a1\u00e2\u2013\u00a1 From the extra condition (7), it can be seen that not only the SST compressor \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a but also the network graph (see \u011f\ufffd\u2022\u0160\u011f\ufffd\u2022\u0160 play a role of determining the exponential convergence property of the DC-DC flow (5) in general. Moreover, by taking a linear form of SST compressor \u011f\ufffd\ufffd\u201a\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e,t)=M\u00e2\ufffd\u00a2(t)\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b1e\u011f\ufffd\ufffd\u201asubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019 ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) = italic_M ( italic_t ) bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT, e.g. the scalarized compressor \u011f\ufffd\ufffd\u201a1subscript\u011f\ufffd\ufffd\u201a1 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, we note that the extra condition (7) reduces to which holds for all (\u011f\ufffd\ufffd\u00b1,t)\u00e2\u02c6\u02c6\u00e2\u201e\ufffdn\u00e2\ufffd\u00a2d\u00c3\u2014\u00e2\u201e\ufffd+\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2018subscript\u00e2\u201e\ufffd( bold_x , italic_t ) \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_n italic_d end_POSTSUPERSCRIPT \u00c3\u2014 blackboard_R start_POSTSUBSCRIPT + end_POSTSUBSCRIPT, since (\u011f\ufffd\ufffd\u02c6n\u00e2\u02c6\u20191\u00e2\u0160\u2014M\u00e2\ufffd\u00a2(t))\u00e2\ufffd\u00a2\u011f\ufffd\u2022\u0160T\u00e2\u02c6\u2019\u011f\ufffd\u2022\u0160T\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u02c6n\u00e2\u02c6\u20191\u00e2\u0160\u2014M\u00e2\ufffd\u00a2(t))=0tensor-productsubscript\u011f\ufffd\ufffd\u02c6\u011f\ufffd\u2018\u203a1\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u00a1superscript\u011f\ufffd\u2022\u0160\u011f\ufffd\u2018\u2021superscript\u011f\ufffd\u2022\u0160\u011f\ufffd\u2018\u2021tensor-productsubscript\u011f\ufffd\ufffd\u02c6\u011f\ufffd\u2018\u203a1\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u00a10( M(t)) M(t))=0( bold_I start_POSTSUBSCRIPT italic_n - 1 end_POSTSUBSCRIPT \u00e2\u0160\u2014 italic_M ( italic_t ) ) blackboard_S start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT - blackboard_S start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ( bold_I start_POSTSUBSCRIPT italic_n - 1 end_POSTSUBSCRIPT \u00e2\u0160\u2014 italic_M ( italic_t ) ) = 0. This immediately implies that the linear SST compressor, e.g. the scalarized compressor \u011f\ufffd\ufffd\u201a1subscript\u011f\ufffd\ufffd\u201a1 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, is applicable to the DC-DC flow (5) with no need of any extra condition. In the previous subsection, it has been shown that the SST compressor can be directly applied, subject to an extra condition (7) which poses limitations on the range of feasible compressors and communication graphs. In this subsection, such limitations will be removed by proposing a new distributed compressed consensus, taking the form where \u00ce\u00b1>0\u011f\ufffd\u203a\u00bc0 > 0 is a gain parameter, and \u011f\ufffd\ufffd\u00b1j,ci\u00e2\ufffd\u00a2(0)=\u011f\ufffd\ufffd\u00b1i,cj\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(0),\u00e2\u02c6\u20acj,j\u00e2\u20ac\u00b2\u00e2\u02c6\u02c6Niformulae-sequencesubscriptsuperscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\ufffd0subscriptsuperscript\u011f\ufffd\ufffd\u00b1superscript\u011f\ufffd\u2018\u2014\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd0for-all\u011f\ufffd\u2018\u2014superscript\u011f\ufffd\u2018\u2014\u00e2\u20ac\u00b2subscriptN\u011f\ufffd\u2018\u2013 j,j^{ start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j , italic_c end_POSTSUBSCRIPT ( 0 ) = bold_x start_POSTSUPERSCRIPT italic_j start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_c end_POSTSUBSCRIPT ( 0 ) , \u00e2\u02c6\u20ac italic_j , italic_j start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u02c6\u02c6 roman_N start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, i\u00e2\u02c6\u02c6V\u011f\ufffd\u2018\u2013Vi \u00e2\u02c6\u02c6 roman_V. The proposed compressed consensus flow (8) is comprised of two sets of states for each agent i\u011f\ufffd\u2018\u2013iitalic_i. The state \u011f\ufffd\ufffd\u00b1isubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT denotes the estimate of consensus solution as in (4), while the states \u011f\ufffd\ufffd\u00b1j,cisubscriptsuperscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\ufffd{ start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j , italic_c end_POSTSUBSCRIPT are introduced to each agent i\u011f\ufffd\u2018\u2013iitalic_i to estimate its neighboring solution state \u011f\ufffd\ufffd\u00b1jsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2014 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, j\u00e2\u02c6\u02c6Ni\u011f\ufffd\u2018\u2014subscriptN\u011f\ufffd\u2018\u2013j \u00e2\u02c6\u02c6 roman_N start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. To have a better view of this, let first ignore the compressor and have \u011f\ufffd\ufffd\u00b1i,c=\u011f\ufffd\ufffd\u00b1i\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00b1i,cisubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013superscriptsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013{ start_POSTSUBSCRIPT italic_i , italic_c end_POSTSUBSCRIPT = bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - bold_x start_POSTSUBSCRIPT italic_i , italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT in (8). Then it is clear that the \u011f\ufffd\ufffd\u00b1j,cisubscriptsuperscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\ufffd{ start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j , italic_c end_POSTSUBSCRIPT acts as an observer to estimate \u011f\ufffd\ufffd\u00b1jsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2014 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT. Our proposed compression strategy is thus established by compressing the observation error \u011f\ufffd\ufffd\u00b1i\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00b1i,cisubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013superscriptsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - bold_x start_POSTSUBSCRIPT italic_i , italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT between the solution state \u011f\ufffd\ufffd\u00b1isubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and the corresponding observer state \u011f\ufffd\ufffd\u00b1i,cisuperscriptsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT italic_i , italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT of agent i\u011f\ufffd\u2018\u2013iitalic_i, as message for communication with neighbors. We are ready to propose the following theorem for Flow (8). Let Assumption 2 hold, then for the DC-OC flow (8) with the ST compressor \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a in continuous time, there exists \u00ce\u00b1\u00e2\u02c6\u2014>0superscript\u011f\ufffd\u203a\u00bc\u00e2\u02c6\u20140 start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT > 0 such that for all \u00ce\u00b1\u00e2\u2030\u00a4\u00ce\u00b1\u00e2\u02c6\u2014\u011f\ufffd\u203a\u00bcsuperscript\u011f\ufffd\u203a\u00bc\u00e2\u02c6\u2014 \u00e2\u2030\u00a4 italic_\u00ce\u00b1 start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT, there holds for some \u00ce\u00b3>0\u011f\ufffd\u203a\u00be0 > 0. \u00e2\u2013\u00a1\u00e2\u2013\u00a1 A rigorous proof of Theorem 2 is presented in Appendix C. Intuitively, from the perspective of control system, we stress that the corresponding system (8) can be regarded as an interconnection of two subsystems: \u011f\ufffd\ufffd\u00b1isubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT-subsystem and \u011f\ufffd\ufffd\u00b1j,cisubscriptsuperscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\ufffd{ start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j , italic_c end_POSTSUBSCRIPT-subsystem, with \u00ce\u00b1\u011f\ufffd\u203a\u00bc a low gain that is tuned to be small such that the supply functions of the two interconnected subsystems satisfy some small-gain condition for closed-loop exponential stability [34, Theorem 5.6]. In this subsection, we aim to present distributed compressed Prime-Dual optimization flow for the problem (1) by applying the SST compressor to directly compress the communication message in the conventional Prime-Dual optimization algorithms, as in Subsection 3.1. The proposed distributed Prime-Dual flow with direct compression takes the form where the initial condition \u00e2\u02c6\u2018i=1n\u011f\ufffd\ufffd\u00afi\u00e2\ufffd\u00a2(0)=\u011f\ufffd\u0178\ufffddsuperscriptsubscript\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\ufffd\u00af\u011f\ufffd\u2018\u20130subscript0\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT bold_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( 0 ) = bold_0 start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT. We are ready to propose the following theorem for Flow (9). Let Assumption 1 and 2 hold, and \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a be a SST compressor in continuous time, who also satisfies (7) with some \u00ce\u00b4>0\u011f\ufffd\u203a\u00bf0 > 0. Then there exists some \u00ce\u00b2,\u00ce\u00b7>0\u011f\ufffd\u203a\u00bd\u011f\ufffd\u0153\u201a0 , italic_\u00ce\u00b7 > 0 such that the flow (9) converges to the optimal solution s\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018 \u00e2\u02c6\u2014s^{ start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT exponentially, i.e., for some \u00ce\u00b3>0\u011f\ufffd\u203a\u00be0 > 0. \u00e2\u2013\u00a1\u00e2\u2013\u00a1 In this subsection, we propose compressed distributed Prime-Dual optimization flow by applying the ST compressor to compress the communication message in the conventional Prime-Dual optimization algorithms, based on distributed observer-based compressed consensus (8) in Subsection 3.2. The proposed distributed Prime-Dual flow in continuos form with observer-based compression takes the form where the initial condition is \u00e2\u02c6\u2018i=1n\u011f\ufffd\ufffd\u00afi\u00e2\ufffd\u00a2(0)=\u011f\ufffd\u0178\ufffddsuperscriptsubscript\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\ufffd\u00af\u011f\ufffd\u2018\u20130subscript0\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT bold_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( 0 ) = bold_0 start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT and for every i\u011f\ufffd\u2018\u2013iitalic_i, \u011f\ufffd\ufffd\u00b1j,ci\u00e2\ufffd\u00a2(0)=\u011f\ufffd\ufffd\u00b1i,cj\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(0),\u00e2\u02c6\u20acj,j\u00e2\u20ac\u00b2\u00e2\u02c6\u02c6Vformulae-sequencesubscriptsuperscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\ufffd0subscriptsuperscript\u011f\ufffd\ufffd\u00b1superscript\u011f\ufffd\u2018\u2014\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd0for-all\u011f\ufffd\u2018\u2014superscript\u011f\ufffd\u2018\u2014\u00e2\u20ac\u00b2V j,j^{ start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j , italic_c end_POSTSUBSCRIPT ( 0 ) = bold_x start_POSTSUPERSCRIPT italic_j start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_c end_POSTSUBSCRIPT ( 0 ) , \u00e2\u02c6\u20ac italic_j , italic_j start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u02c6\u02c6 roman_V.. We are ready to propose the following theorem for Flow (10). Let Assumptions 1 and 2 hold, and \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a be a ST compressor in continuous time. Then there exist \u00ce\u00b1,\u00ce\u00b2,\u00ce\u00b7>0\u011f\ufffd\u203a\u00bc\u011f\ufffd\u203a\u00bd\u011f\ufffd\u0153\u201a0 , italic_\u00ce\u00b2 , italic_\u00ce\u00b7 > 0 such that the flow (10) converges to the optimal solution s\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018 \u00e2\u02c6\u2014s^{ start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT exponentially, i.e., for some \u00ce\u00b3>0\u011f\ufffd\u203a\u00be0 > 0. \u00e2\u2013\u00a1\u00e2\u2013\u00a1 The theorems in this section only discuss the case of strongly convex object functions and demonstrate the exponential convergence of the flows. Since the convergence of the system is composed of the convergence of the Prime-Dual flow and the convergence to optimal solution of the compressor, and the Prime-Dual flow achieves asymptotic convergence to optimal solution for convex functions, it is not difficult to infer that both (9) and (10), and their discretization forms in next section, can achieve asymptotic convergence to optimal solution for convex functions. In practice, algorithms are always implemented in a discrete time form. In the following, we discretize Flow (9) based on Euler method, and derive the following discrete-time solver where the initial condition \u00e2\u02c6\u2018i=1n\u011f\ufffd\ufffd\u00afi\u00e2\ufffd\u00a2(t)=\u011f\ufffd\u0178\ufffddsuperscriptsubscript\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\ufffd\u00af\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a1subscript0\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT bold_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) = bold_0 start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT. Let Assumptions 1 and 2 hold, and \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a be a SST compressor in discrete time, who also satisfies (7) with some \u00ce\u00b4>0\u011f\ufffd\u203a\u00bf0 > 0. Then there exists some \u00ce\u00ba,\u00ce\u00ba0,\u00ce\u00b2,\u00ce\u00b7>0\u011f\ufffd\u0153\u2026subscript\u011f\ufffd\u0153\u20260\u011f\ufffd\u203a\u00bd\u011f\ufffd\u0153\u201a0 , italic_\u00ce\u00ba start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_\u00ce\u00b2 , italic_\u00ce\u00b7 > 0 such that DPD-DC (11) converges to the optimal solution s\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018 \u00e2\u02c6\u2014s^{ start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT linearly, i.e., for some \u00ce\u00b3\u00e2\u02c6\u02c6(0,1)\u011f\ufffd\u203a\u00be01 \u00e2\u02c6\u02c6 ( 0 , 1 ). \u00e2\u2013\u00a1\u00e2\u2013\u00a1 Next, we discretize Flow (10) based on Euler method, yielding the following discrete time algorithm where the initial condition is \u00e2\u02c6\u2018i=1n\u011f\ufffd\ufffd\u00afi\u00e2\ufffd\u00a2(t)=\u011f\ufffd\u0178\ufffddsuperscriptsubscript\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\ufffd\u00af\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a1subscript0\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT bold_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) = bold_0 start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT and for every i\u011f\ufffd\u2018\u2013iitalic_i, \u011f\ufffd\ufffd\u00b1i,cj\u00e2\ufffd\u00a2(0)=\u011f\ufffd\ufffd\u00b1i,cj\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(0),\u00e2\u02c6\u20acj,j\u00e2\u20ac\u00b2\u00e2\u02c6\u02c6Vformulae-sequencesubscriptsuperscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd0subscriptsuperscript\u011f\ufffd\ufffd\u00b1superscript\u011f\ufffd\u2018\u2014\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd0for-all\u011f\ufffd\u2018\u2014superscript\u011f\ufffd\u2018\u2014\u00e2\u20ac\u00b2V j,j^{ start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_c end_POSTSUBSCRIPT ( 0 ) = bold_x start_POSTSUPERSCRIPT italic_j start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_c end_POSTSUBSCRIPT ( 0 ) , \u00e2\u02c6\u20ac italic_j , italic_j start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u02c6\u02c6 roman_V. Let Assumption 1 and 2 hold, and \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a be a ST compressor in discrete time with some \u00ce\u00ba0>0subscript\u011f\ufffd\u0153\u202600 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT > 0. Then there exists some \u00ce\u00ba,\u00ce\u00b2,\u00ce\u00b7>0\u011f\ufffd\u0153\u2026\u011f\ufffd\u203a\u00bd\u011f\ufffd\u0153\u201a0 , italic_\u00ce\u00b2 , italic_\u00ce\u00b7 > 0 such that DPD-OC (12) converges to the optimal solution s\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018 \u00e2\u02c6\u2014s^{ start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT linearly. \u00e2\u2013\u00a1\u00e2\u2013\u00a1 When the ST compressor is enhanced to a SST compressor, it can be directly applied to distributed optimization algorithms as shown in DPD-DC (11), where the \u00e2\u02c6\u2019\u00e2\u02c6\u2018j=1n\u011f\ufffd\ufffd\u2039i\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u201a\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1i,t)subscriptsuperscript\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u20141subscript\u011f\ufffd\ufffd\u2039\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\ufffd\u201asubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a1- \u00e2\u02c6\u2018 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT bold_L start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT bold_C ( bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_t ) term ensures the convergence of system consensus. However, for the ST compressor, we need to ensure the convergence of the system through the method of compressing differences by observer, as shown in DPD-OC (12). Therefore, we consider the case of using the SST compressor for DPD-OC (12) and add the \u00e2\u02c6\u2019\u00e2\u02c6\u2018j=1n\u011f\ufffd\ufffd\u2039i\u00e2\ufffd\u00a2j\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u201a\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1i,t)subscriptsuperscript\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u20141subscript\u011f\ufffd\ufffd\u2039\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\ufffd\u201asubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a1- \u00e2\u02c6\u2018 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT bold_L start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT bold_C ( bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_t ) term to accelerate the convergence of the system consensus. We obtain the following solver where kp\u00e2\u2030\u00a50subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\ufffd0k_{p} 0italic_k start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT \u00e2\u2030\u00a5 0 is the proportional gain and the initial condition is \u00e2\u02c6\u2018i=1n\u011f\ufffd\ufffd\u00afi\u00e2\ufffd\u00a2(t)=\u011f\ufffd\u0178\ufffddsuperscriptsubscript\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\ufffd\u00af\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a1subscript0\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT bold_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) = bold_0 start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT and for every i\u011f\ufffd\u2018\u2013iitalic_i, \u011f\ufffd\ufffd\u00b1i,c\u00e2\ufffd\u00a21j\u00e2\ufffd\u00a2(0)=\u011f\ufffd\ufffd\u00b1i,c\u00e2\ufffd\u00a21j\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(0),\u00e2\u02c6\u20acj,j\u00e2\u20ac\u00b2\u00e2\u02c6\u02c6Vformulae-sequencesubscriptsuperscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd10subscriptsuperscript\u011f\ufffd\ufffd\u00b1superscript\u011f\ufffd\u2018\u2014\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd10for-all\u011f\ufffd\u2018\u2014superscript\u011f\ufffd\u2018\u2014\u00e2\u20ac\u00b2V j,j^{ } start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_c 1 end_POSTSUBSCRIPT ( 0 ) = bold_x start_POSTSUPERSCRIPT italic_j start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_c 1 end_POSTSUBSCRIPT ( 0 ) , \u00e2\u02c6\u20ac italic_j , italic_j start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u02c6\u02c6 roman_V. Let Assumption 1 and 2 hold, and \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a be a SST compressor in discrete time, who also satisfies (7) with some \u00ce\u00b4\u011f\ufffd\u203a\u00bf Then there exists some kp,\u00ce\u00ba,\u00ce\u00ba0,\u00ce\u00b2,\u00ce\u00b7>0subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u2026subscript\u011f\ufffd\u0153\u20260\u011f\ufffd\u203a\u00bd\u011f\ufffd\u0153\u201a0k_{p}, start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT , italic_\u00ce\u00ba , italic_\u00ce\u00ba start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_\u00ce\u00b2 , italic_\u00ce\u00b7 > 0 such that A-DPD-DC (13) converges to the optimal solution s\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018 \u00e2\u02c6\u2014s^{ start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT linearly. \u00e2\u2013\u00a1\u00e2\u2013\u00a1 The proof of Lemma 1 can be obtained with the proof of Theorem 5 in Appendix F and Theorem 6 in Appendix G. In numerical simulations, we can observe that under certain parameter conditions, this algorithm indeed converges noticeably faster than other algorithms. Observe (9) and (10), and we can see that they apply different compression methods to (2). There are many different compression methods documented in the literature. For example, let us discuss the combination of our ST compressor with a commonly used method [16]. This method introduces a distributed filter and a distributed integrator and compresses the state errors. The proposed distributed Prime-Dual flow with error state compression (DPD-ESC) takes the form. where \u00ce\u00ba\u011f\ufffd\u0153\u2026 \u00ce\u00ba0subscript\u011f\ufffd\u0153\u20260 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, \u00ce\u00b2,\u00ce\u00b7>0\u011f\ufffd\u203a\u00bd\u011f\ufffd\u0153\u201a0 , italic_\u00ce\u00b7 > 0 are parameters to be fixed. Similar theorems as those in previous context can be proved. For interested readers, the validity of the continuous form of the Algorithm above is proved in previous work [35]. It should be noticed that many literature on compressor assumption take into account the presence of randomness. Therefore, we extend the ST compressor to randomness and research its effectiveness in applications. In this section, we study the randomization of the ST compressor and the application of DPD-OC as a example. Introduce randomness to Definition 1, we obtain the definition of Stochastic Spatio-Temporal (StST) Compressor, with focus on discrete time. Given a linearly mean-square bounded mapping \u011f\ufffd\ufffd\u201a:\u00e2\u201e\ufffdd\u00c3\u2014\u00e2\u201e\ufffd+\u00e2\u2020\u2019\u00e2\u201e\ufffdd:\u011f\ufffd\ufffd\u201a\u00e2\u2020\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018subscript\u00e2\u201e\ufffdsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018 : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \u00c3\u2014 blackboard_R start_POSTSUBSCRIPT + end_POSTSUBSCRIPT \u00e2\u2020\u2019 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, i.e., there exists a Lc>0subscript\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\ufffd0L_{c}>0italic_L start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT > 0 such that \u011f\ufffd\u201d\u00bc\u00e2\ufffd\u00a2\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u201a\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e,t)\u00e2\u20ac\u20132\u00e2\u2030\u00a4Lc2\u00e2\ufffd\u00a2\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b1e\u00e2\u20ac\u20132\u011f\ufffd\u201d\u00bcsuperscriptnorm\u011f\ufffd\ufffd\u201asubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a12subscriptsuperscript\u011f\ufffd\ufffd\u00bf2\u011f\ufffd\u2018\ufffdsuperscriptnormsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u20192 L^{2}_{c} ^{2}blackboard_E \u00e2\u02c6\u00a5 bold_C ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT \u00e2\u2030\u00a4 italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT \u00e2\u02c6\u00a5 bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT for all \u011f\ufffd\ufffd\u00b1e\u00e2\u02c6\u02c6\u00e2\u201e\ufffddsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT and any t\u00e2\u02c6\u02c6\u00e2\u201e\ufffd+\u011f\ufffd\u2018\u00a1subscript\u00e2\u201e\ufffdt \u00e2\u02c6\u02c6 blackboard_R start_POSTSUBSCRIPT + end_POSTSUBSCRIPT. Then, \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a is said to be a StST compressor, if the induced non-autonomous system \u011f\ufffd\ufffd\u00b1e\u00e2\ufffd\u00a2(t+1)=\u011f\ufffd\ufffd\u00b1e\u00e2\ufffd\u00a2(t)\u00e2\u02c6\u2019\u00ce\u00ba0\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u201a\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e,t)subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a11subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u0153\u20260\u011f\ufffd\ufffd\u201asubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t + 1 ) = bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ) - italic_\u00ce\u00ba start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT bold_C ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) is uniformly globally exponentially stable at the origin in the mean-square sense111See [36] for the definition of mean square convergence, for some stepsize \u00ce\u00ba0>0subscript\u011f\ufffd\u0153\u202600 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT > 0. \u00e2\u2013\u00a1\u00e2\u2013\u00a1 The ST compressor is a special case of the StST compressor. Moreover, some compressor assumptions in literature belongs to the StST compressor. The stochastic contractive compressor \u011f\ufffd\ufffd\u201a3:\u00e2\u201e\ufffdd\u00e2\u2020\u2019\u00e2\u201e\ufffdd:subscript\u011f\ufffd\ufffd\u201a3\u00e2\u2020\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \u00e2\u2020\u2019 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT satisfies for some \u00cf\u2020\u00e2\u02c6\u02c6(0,1]\u011f\ufffd\u0153\u201801 \u00e2\u02c6\u02c6 ( 0 , 1 ] and p>0\u011f\ufffd\u2018\ufffd0p>0italic_p > 0. By [16], the followings are specific examples of \u011f\ufffd\ufffd\u201a3subscript\u011f\ufffd\ufffd\u201a3 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT: Unbiased l\u011f\ufffd\u2018\u2122litalic_l-bits quantizer [37] where \u00cf\u2030\u00c2\u00af\u00c2\u00af\u011f\ufffd\u0153\u201d start_ARG italic_\u00cf\u2030 end_ARG is a random perturbation vector uniformly sampled from [0,1]dsuperscript01\u011f\ufffd\u2018\u2018[0,1]^{d}[ 0 , 1 ] start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT. Compressor \u011f\ufffd\ufffd\u201a3subscript\u011f\ufffd\ufffd\u201a3 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT belongs to the StST compressor. \u00e2\u2013\u00a1\u00e2\u2013\u00a1 The proof of Proposition 2 is similar to that of Proposition b). in Appendix A and is omitted for simplicity. We apply the StST compressor to Algorithm (12) and propose the following theorem for DPD-OC. Let Assumption 1 and 2 hold, and \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a be a StST compressor with some \u00ce\u00ba0>0subscript\u011f\ufffd\u0153\u202600 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT > 0. Then for \u00ce\u00ba,\u00ce\u00b2,\u00ce\u00b7>0\u011f\ufffd\u0153\u2026\u011f\ufffd\u203a\u00bd\u011f\ufffd\u0153\u201a0 , italic_\u00ce\u00b2 , italic_\u00ce\u00b7 > 0, the mean square of \u011f\ufffd\ufffd\u00b1i\u00e2\ufffd\u00a2(t)subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) in the DPD-OC algorithm (12) converges to the optimal solution s\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018 \u00e2\u02c6\u2014s^{ start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT linearly. \u00e2\u2013\u00a1\u00e2\u2013\u00a1 In this subsection, we will verify that the compressors mentioned in this paper, \u011f\ufffd\ufffd\u201a1\u00e2\ufffd\u00a2asubscript\u011f\ufffd\ufffd\u201a1\u011f\ufffd\u2018\ufffd start_POSTSUBSCRIPT 1 italic_a end_POSTSUBSCRIPT, \u011f\ufffd\ufffd\u201a2\u00e2\ufffd\u00a2asubscript\u011f\ufffd\ufffd\u201a2\u011f\ufffd\u2018\ufffd start_POSTSUBSCRIPT 2 italic_a end_POSTSUBSCRIPT, \u011f\ufffd\ufffd\u201a2\u00e2\ufffd\u00a2bsubscript\u011f\ufffd\ufffd\u201a2\u011f\ufffd\u2018\ufffd start_POSTSUBSCRIPT 2 italic_b end_POSTSUBSCRIPT, \u011f\ufffd\ufffd\u201a2\u00e2\ufffd\u00a2csubscript\u011f\ufffd\ufffd\u201a2\u011f\ufffd\u2018\ufffd start_POSTSUBSCRIPT 2 italic_c end_POSTSUBSCRIPT, \u011f\ufffd\ufffd\u201a3\u00e2\ufffd\u00a2asubscript\u011f\ufffd\ufffd\u201a3\u011f\ufffd\u2018\ufffd start_POSTSUBSCRIPT 3 italic_a end_POSTSUBSCRIPT, satisfy the core property, i.e. the exponential stability of induced system, of ST compressor. Specifically, we let d=5\u011f\ufffd\u2018\u20185d=5italic_d = 5, k=2\u011f\ufffd\u2018\u02dc2k=2italic_k = 2 for \u011f\ufffd\ufffd\u201a2\u00e2\ufffd\u00a2asubscript\u011f\ufffd\ufffd\u201a2\u011f\ufffd\u2018\ufffd start_POSTSUBSCRIPT 2 italic_a end_POSTSUBSCRIPT, \u00ce\u201d=1\u00ce\u201d1 = 1 for \u011f\ufffd\ufffd\u201a2\u00e2\ufffd\u00a2csubscript\u011f\ufffd\ufffd\u201a2\u011f\ufffd\u2018\ufffd start_POSTSUBSCRIPT 2 italic_c end_POSTSUBSCRIPT and l=4\u011f\ufffd\u2018\u21224l=4italic_l = 4 for \u011f\ufffd\ufffd\u201a3\u00e2\ufffd\u00a2asubscript\u011f\ufffd\ufffd\u201a3\u011f\ufffd\u2018\ufffd start_POSTSUBSCRIPT 3 italic_a end_POSTSUBSCRIPT. The figures respectively demonstrate the exponential convergence system \u011f\ufffd\ufffd\u00b1\u00cb\u2122e=\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u201a\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e,t)subscript\u00cb\u2122\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\ufffd\u201asubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1 start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT = - bold_C ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) with different compressors, validating our conclusions. Other properties of the ST compressor can also be easily verified through theoretical analysis. Additionally, the satisfaction of these compressors with the conditions of the ST compressor in discrete form can also be verified through simulation, but it is omitted here. In this subsection, we consider a network of n\u011f\ufffd\u2018\u203anitalic_n nodes over a circle communication graph and dimension of local state is d\u011f\ufffd\u2018\u2018ditalic_d, where each edge is assigned with the same unit weight and each node holds a local function fi\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1i)=12\u00e2\ufffd\u00a2\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u2021iT\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b1i\u00e2\u02c6\u2019bi\u00e2\u20ac\u20132subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u201312superscriptnormsubscriptsuperscript\u011f\ufffd\ufffd\u2021\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20132f_{i}( start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = divide start_ARG 1 end_ARG start_ARG 2 end_ARG \u00e2\u02c6\u00a5 bold_H start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT with some randomly generated \u011f\ufffd\ufffd\u2021i\u00e2\u02c6\u02c6\u00e2\u201e\ufffddsubscript\u011f\ufffd\ufffd\u2021\u011f\ufffd\u2018\u2013superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT and bi\u00e2\u02c6\u02c6\u00e2\u201e\ufffdsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u00e2\u201e\ufffdb_{i} start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R. Assume that the linear equation \u011f\ufffd\ufffd\u2021\u00e2\ufffd\u00a2x=\u011f\ufffd\ufffd\u203a\u011f\ufffd\ufffd\u2021\u011f\ufffd\u2018\u00a5\u011f\ufffd\ufffd\u203a italic_x = bold_b has a unique solution s\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018 \u00e2\u02c6\u2014s^{ start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT, where \u011f\ufffd\ufffd\u2021=[\u011f\ufffd\ufffd\u20211\u00e2\ufffd\u00a2\u00e2\u20ac\u00a6\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u2021n]\u00e2\u0160\u00a4\u00e2\u02c6\u02c6\u00e2\u201e\ufffdn\u00c3\u2014d\u011f\ufffd\ufffd\u2021superscriptdelimited-[]subscript\u011f\ufffd\ufffd\u20211\u00e2\u20ac\u00a6subscript\u011f\ufffd\ufffd\u2021\u011f\ufffd\u2018\u203atopsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2018 d}bold_H = [ bold_H start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u20ac\u00a6 bold_H start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ] start_POSTSUPERSCRIPT \u00e2\u0160\u00a4 end_POSTSUPERSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_n \u00c3\u2014 italic_d end_POSTSUPERSCRIPT and \u011f\ufffd\ufffd\u203a=[b1\u00e2\ufffd\u00a2\u00e2\u20ac\u00a6\u00e2\ufffd\u00a2bn]\u00e2\u0160\u00a4\u00e2\u02c6\u02c6\u00e2\u201e\ufffdd\u011f\ufffd\ufffd\u203asuperscriptdelimited-[]subscript\u011f\ufffd\u2018\ufffd1\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203atopsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018 = [ italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u20ac\u00a6 italic_b start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ] start_POSTSUPERSCRIPT \u00e2\u0160\u00a4 end_POSTSUPERSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, then we can conclude that the functions fi\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1i)subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013f_{i}( start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) satisfy Assumption 1 with \u00ce\u00bc>0\u011f\ufffd\u0153\u20210 > 0 and optimal solution s\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018 \u00e2\u02c6\u2014s^{ start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT. Specifically, we let n=10\u011f\ufffd\u2018\u203a10n=10italic_n = 10, d=5\u011f\ufffd\u2018\u20185d=5italic_d = 5 and s\u00e2\u02c6\u2014=[2,\u00e2\u02c6\u20194,\u00e2\u02c6\u20194,2,\u00e2\u02c6\u20193]Tsuperscript\u011f\ufffd\u2018 \u00e2\u02c6\u2014superscript24423\u011f\ufffd\u2018\u2021s^{ start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT = [ 2 , - 4 , - 4 , 2 , - 3 ] start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT. Next, we will apply different compression methods to the compressors and compare their effects. We use the scalar compressor \u011f\ufffd\ufffd\u201a1\u00e2\ufffd\u00a2asubscript\u011f\ufffd\ufffd\u201a1\u011f\ufffd\u2018\ufffd start_POSTSUBSCRIPT 1 italic_a end_POSTSUBSCRIPT and greedy sparsifier compressor \u011f\ufffd\ufffd\u201a2\u00e2\ufffd\u00a2asubscript\u011f\ufffd\ufffd\u201a2\u011f\ufffd\u2018\ufffd start_POSTSUBSCRIPT 2 italic_a end_POSTSUBSCRIPT as examples. In this application, we integrate DPD-DC (11), A-DPD-OC (13), DPD-ESC (14) with \u011f\ufffd\ufffd\u201a1\u00e2\ufffd\u00a2asubscript\u011f\ufffd\ufffd\u201a1\u011f\ufffd\u2018\ufffd start_POSTSUBSCRIPT 1 italic_a end_POSTSUBSCRIPT, and integrate A-DPD-OC (13), DPD-ESC (14), with \u011f\ufffd\ufffd\u201a2\u00e2\ufffd\u00a2asubscript\u011f\ufffd\ufffd\u201a2\u011f\ufffd\u2018\ufffd start_POSTSUBSCRIPT 2 italic_a end_POSTSUBSCRIPT. Specifically, we let the parameters kp=10subscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\ufffd10k_{p}=10italic_k start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT = 10, \u00ce\u00ba0=1subscript\u011f\ufffd\u0153\u202601 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = 1, \u00ce\u00ba=0.002\u011f\ufffd\u0153\u20260.002 = 0.002, \u00ce\u00b1=1\u011f\ufffd\u203a\u00bc1 = 1, \u00ce\u00b2=10\u011f\ufffd\u203a\u00bd10 = 10, \u00ce\u00b7=5\u011f\ufffd\u0153\u201a5 = 5. The plot illustrates the sum of squared distances from the current \u011f\ufffd\ufffd\u00b1i\u00e2\ufffd\u00a2(t)subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) to s\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018 \u00e2\u02c6\u2014s^{ start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT, denoted as \u00e2\u02c6\u2018i=1n\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b1i\u00e2\ufffd\u00a2(t)\u00e2\u02c6\u2019s\u00e2\u02c6\u2014\u00e2\u20ac\u20132superscriptsubscript\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\u203asuperscriptnormsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a1superscript\u011f\ufffd\u2018 \u00e2\u02c6\u20142 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT \u00e2\u02c6\u00a5 bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) - italic_s start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT over time. We also simulated the Prime-Dual algorithm in discrete time without compressor under the same parameters for comparison. Notably, the algorithms exhibits exponential convergence to the optimal solution, verifying the theorems. Furthermore, we can observe that observer-based compression method has significant advantages on convergence rate under the same parameters. Next, we discuss the case where the objective function is convex but not strongly convex, while other settings is same as that in the previous subsection. We take the objective function from [38] as whose optimal solution is s\u00e2\u02c6\u2014=\u011f\ufffd\u0178\ufffddsuperscript\u011f\ufffd\u2018 \u00e2\u02c6\u2014subscript1\u011f\ufffd\u2018\u2018s^{ start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT = bold_1 start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT. The simulate results of DPD-DC (11) and DPD-OC (12) with \u011f\ufffd\ufffd\u201a1\u00e2\ufffd\u00a2asubscript\u011f\ufffd\ufffd\u201a1\u011f\ufffd\u2018\ufffd start_POSTSUBSCRIPT 1 italic_a end_POSTSUBSCRIPT, as an example, are shown. From the figure, we can see that the above algorithm can achieve asymptotic convergence to the optimal solution for convex function In this paper, we have introduced a type of spatio-temporal compressor that integrates both spatial and temporal characteristics, effectively compresses information by leveraging information from both the time and space domains. This class of compressors has covered several assumptions in literature on compressors. Our proposed compressor has been implemented in the Prime-Dual algorithm by direct compression and observer-based compression. In the future, we will investigate a broader spectrum of compressor types or enhanced algorithms tailored to the characteristics of this compressor, and to have extended its application to more classical distributed optimization algorithms, examining its universality across different algorithms. Proof of a). The proof of the statement in Definition 2 is obvious by recalling [39] that system \u011f\ufffd\ufffd\u00b1\u00cb\u2122e=\u00e2\u02c6\u2019k\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\ufffd\u00e2\ufffd\u00a2(t)\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\ufffd\u00e2\ufffd\u00a2(t)T\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b1esubscript\u00cb\u2122\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u02dc\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\u00a1\u011f\ufffd\ufffd\ufffdsuperscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2021subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019 start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT = - italic_k bold_italic_\u00cf\u02c6 ( italic_t ) bold_italic_\u00cf\u02c6 ( italic_t ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT is globally exponentially stable at the zero equilibrium for any k>0\u011f\ufffd\u2018\u02dc0k>0italic_k > 0 under the condition in continuous time cases, and \u011f\ufffd\ufffd\u00b1e\u00e2\ufffd\u00a2(t+1)=\u011f\ufffd\ufffd\u00b1e\u00e2\ufffd\u00a2(t)\u00e2\u02c6\u2019\u00ce\u00ba0\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\ufffd\u00e2\ufffd\u00a2(t)\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\ufffd\u00e2\ufffd\u00a2(t)T\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b1e\u00e2\ufffd\u00a2(t)subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a11subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u0153\u20260\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\u00a1\u011f\ufffd\ufffd\ufffdsuperscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2021subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1{ start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t + 1 ) = bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ) - italic_\u00ce\u00ba start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT bold_italic_\u00cf\u02c6 ( italic_t ) bold_italic_\u00cf\u02c6 ( italic_t ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ) is globally exponentially stable at the zero equilibrium for any \u00ce\u00ba0\u00e2\u2030\u00a4\u00ce\u00ba0\u00e2\u02c6\u2014subscript\u011f\ufffd\u0153\u20260superscriptsubscript\u011f\ufffd\u0153\u20260\u00e2\u02c6\u2014 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_\u00ce\u00ba start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT with some \u00ce\u00ba0\u00e2\u02c6\u2014>0superscriptsubscript\u011f\ufffd\u0153\u20260\u00e2\u02c6\u20140 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT > 0 under the condition in discrete time cases. The proof of linearly boundedness property can be shown by noting that \u011f\ufffd\ufffd\ufffd\u00e2\ufffd\u00a2(t)\u011f\ufffd\ufffd\ufffd\u011f\ufffd\u2018\u00a1 ( italic_t ) is uniformly bounded. Proof of b). We proceed to show the compressor \u011f\ufffd\ufffd\u201a2\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e)subscript\u011f\ufffd\ufffd\u201a2subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ) satisfying properties Definition 1. Note that the contractive compressor (3) is equivalent to First, we prove that \u011f\ufffd\ufffd\u201a2subscript\u011f\ufffd\ufffd\u201a2 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT is the ST compressor in continuous time by proving the system x\u00cb\u2122e=\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u201a2\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e,t)subscript\u00cb\u2122\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2019subscript\u011f\ufffd\ufffd\u201a2subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1 start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT = - bold_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) is exponentially stable at the zero equilibrium. By choosing the Lyapunov function Ve\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e)=\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b1e\u00e2\u20ac\u20132/psubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2019subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019superscriptnormsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u20192\u011f\ufffd\u2018\ufffdV_{e}( start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ) = \u00e2\u02c6\u00a5 bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT / italic_p and using (16), we have Thus \u011f\ufffd\ufffd\u00b1esubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT-system is globally exponentially stable at the zero equilibrium with \u00cf\u2020>0\u011f\ufffd\u0153\u20180 > 0. Next, we prove that \u011f\ufffd\ufffd\u201a2subscript\u011f\ufffd\ufffd\u201a2 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT is the ST compressor in discrete time by proving the system \u011f\ufffd\ufffd\u00b1e\u00e2\ufffd\u00a2(t+1)=\u011f\ufffd\ufffd\u00b1e\u00e2\ufffd\u00a2(t)\u00e2\u02c6\u2019\u00ce\u00ba0\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u201a2\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e\u00e2\ufffd\u00a2(t))subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a11subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u0153\u20260subscript\u011f\ufffd\ufffd\u201a2subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1 t))bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t + 1 ) = bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ) - italic_\u00ce\u00ba start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT bold_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ) ) is exponentially stable at the zero equilibrium with \u00ce\u00ba0=1psubscript\u011f\ufffd\u0153\u202601\u011f\ufffd\u2018\ufffd start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG italic_p end_ARG. By (16), Thus \u011f\ufffd\ufffd\u00b1esubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT-system is exponentially stable at the zero equilibrium with \u00cf\u2020\u00e2\u02c6\u02c6(0,1]) \u00e2\u02c6\u02c6 ( 0 , 1 ] ). Then, by (16) and using the Young\u00e2\u20ac\u2122s inequality, we have where the last inequality is obtained by \u00cf\u2020\u00e2\u02c6\u02c6(0,1]\u011f\ufffd\u0153\u201801 \u00e2\u02c6\u02c6 ( 0 , 1 ]. Thus the linearly boundedness property is proved with Lc=2\u00e2\ufffd\u00a2p>0subscript\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\ufffd0L_{c}=2p>0italic_L start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT = 2 italic_p > 0. This completes the proof. Flow (5) can be written in tight form as where \u011f\ufffd\ufffd\u00b1:=[\u011f\ufffd\ufffd\u00b11T,\u00e2\u20ac\u00a6,\u011f\ufffd\ufffd\u00b1nT]Tassign\u011f\ufffd\ufffd\u00b1superscriptsuperscriptsubscript\u011f\ufffd\ufffd\u00b11\u011f\ufffd\u2018\u2021\u00e2\u20ac\u00a6superscriptsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u2021 := [ bold_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT , \u00e2\u20ac\u00a6 , bold_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ] start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT, \u011f\ufffd\ufffd\u00b1c:=[\u011f\ufffd\ufffd\u00b11,cT,\u00e2\u20ac\u00a6,\u011f\ufffd\ufffd\u00b1n,cT]Tassignsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\ufffdsuperscriptsuperscriptsubscript\u011f\ufffd\ufffd\u00b11\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2021\u00e2\u20ac\u00a6superscriptsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u2021 start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT := [ bold_x start_POSTSUBSCRIPT 1 , italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT , \u00e2\u20ac\u00a6 , bold_x start_POSTSUBSCRIPT italic_n , italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ] start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT and \u00e2\u201e\u2019:=\u011f\ufffd\ufffd\u2039\u00e2\u0160\u2014\u011f\ufffd\ufffd\u02c6dassign\u00e2\u201e\u2019tensor-product\u011f\ufffd\ufffd\u2039subscript\u011f\ufffd\ufffd\u02c6\u011f\ufffd\u2018\u2018 := bold_L \u00e2\u0160\u2014 bold_I start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT. We decompose \u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b1 by defining \u011f\ufffd\ufffd\u00b1\u00e2\u0178\u201a:=\u011f\ufffd\u2022\u0160T\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b1=[\u011f\ufffd\ufffd\u00b1\u00e2\u0178\u201a,1T,\u00e2\u20ac\u00a6,\u011f\ufffd\ufffd\u00b1\u00e2\u0178\u201a,n\u00e2\u02c6\u20191T]Tassignsubscript\u011f\ufffd\ufffd\u00b1perpendicular-tosuperscript\u011f\ufffd\u2022\u0160\u011f\ufffd\u2018\u2021\u011f\ufffd\ufffd\u00b1superscriptsubscriptsuperscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2021perpendicular-to1\u00e2\u20ac\u00a6subscriptsuperscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2021perpendicular-to\u011f\ufffd\u2018\u203a1\u011f\ufffd\u2018\u2021 start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT := blackboard_S start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_x = [ bold_x start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT \u00e2\u0178\u201a , 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , bold_x start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT start_POSTSUBSCRIPT \u00e2\u0178\u201a , italic_n - 1 end_POSTSUBSCRIPT ] start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT and \u011f\ufffd\ufffd\u00b1\u00e2\u02c6\u00a5:=\u011f\ufffd\u2022\u20acT\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b1assignsubscript\u011f\ufffd\ufffd\u00b1parallel-tosuperscript\u011f\ufffd\u2022\u20ac\u011f\ufffd\u2018\u2021\u011f\ufffd\ufffd\u00b1 start_POSTSUBSCRIPT \u00e2\u02c6\u00a5 end_POSTSUBSCRIPT := blackboard_I start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_x, where \u011f\ufffd\u2022\u20ac:=1n\u00e2\ufffd\u00a2\u011f\ufffd\u0178\ufffdn\u00e2\u0160\u2014\u011f\ufffd\ufffd\u02c6dassign\u011f\ufffd\u2022\u20actensor-product1\u011f\ufffd\u2018\u203asubscript1\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\ufffd\u02c6\u011f\ufffd\u2018\u2018 := divide start_ARG 1 end_ARG start_ARG square-root start_ARG italic_n end_ARG end_ARG bold_1 start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT \u00e2\u0160\u2014 bold_I start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT. We can obtain that \u011f\ufffd\ufffd\u00b1\u00cb\u2122\u00e2\u02c6\u00a5=\u011f\ufffd\u0178\ufffddsubscript\u00cb\u2122\u011f\ufffd\ufffd\u00b1parallel-tosubscript0\u011f\ufffd\u2018\u2018 start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u02c6\u00a5 end_POSTSUBSCRIPT = bold_0 start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT in (18) by the fact Then with the fact it can be noticed that we can prove \u011f\ufffd\ufffd\u00b1isubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT converges to average consensus by proving \u011f\ufffd\ufffd\u00b1\u00e2\u0178\u201asubscript\u011f\ufffd\ufffd\u00b1perpendicular-to start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT converges to zero equilibrium. We can obtain the derivation of \u011f\ufffd\ufffd\u00b1\u00e2\u0178\u201asubscript\u011f\ufffd\ufffd\u00b1perpendicular-to start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT along with time . Define the Lypanuov function of (21) V\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1\u00e2\u0178\u201a,t):=Ve\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1\u00e2\u0178\u201a,t)assign\u011f\ufffd\u2018\u2030subscript\u011f\ufffd\ufffd\u00b1perpendicular-to\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2019subscript\u011f\ufffd\ufffd\u00b1perpendicular-to\u011f\ufffd\u2018\u00a1V( ( bold_x start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT , italic_t ) := italic_V start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( bold_x start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT , italic_t ). which is defined in (6), then we have where the inequality is obtained by the fact If \u00ce\u00b4\u00e2\u2030\u00a4c3c4\u00e2\ufffd\u00a2\u00ce\u00bbn\u011f\ufffd\u203a\u00bfsubscript\u011f\ufffd\u2018\ufffd3subscript\u011f\ufffd\u2018\ufffd4subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u203a \u00e2\u2030\u00a4 divide start_ARG italic_c start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG start_ARG italic_c start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_\u00ce\u00bb start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_ARG, V\u00cb\u2122\u00cb\u2122\u011f\ufffd\u2018\u2030 start_ARG italic_V end_ARG is negative definite. With (6), we have then \u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b1\u00e2\u0178\u201a\u00e2\ufffd\u00a2(t)\u00e2\u20ac\u20132=\u011f\ufffd\u2019\u00aa\u00e2\ufffd\u00a2(e\u00e2\u02c6\u2019\u00ce\u00b3\u00e2\ufffd\u00a2t)superscriptnormsubscript\u011f\ufffd\ufffd\u00b1perpendicular-to\u011f\ufffd\u2018\u00a12\u011f\ufffd\u2019\u00aasuperscript\u011f\ufffd\u2018\u2019\u011f\ufffd\u203a\u00be\u011f\ufffd\u2018\u00a1 t})\u00e2\u02c6\u00a5 bold_x start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT ( italic_t ) \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = caligraphic_O ( italic_e start_POSTSUPERSCRIPT - italic_\u00ce\u00b3 italic_t end_POSTSUPERSCRIPT ), where \u00ce\u00b3=c3\u00e2\u02c6\u2019c4\u00e2\ufffd\u00a2\u00ce\u00b4\u00e2\ufffd\u00a2\u00ce\u00bbnc1\u011f\ufffd\u203a\u00besubscript\u011f\ufffd\u2018\ufffd3subscript\u011f\ufffd\u2018\ufffd4\u011f\ufffd\u203a\u00bfsubscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\u2018\ufffd1 = divide start_ARG italic_c start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT - italic_c start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_\u00ce\u00b4 italic_\u00ce\u00bb start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_ARG start_ARG italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG. Thus the theorem is proved. From Flow (8) and its initial condition, we can obtain that for every i\u00e2\u02c6\u02c6V\u011f\ufffd\u2018\u2013Vi \u00e2\u02c6\u02c6 roman_V, \u011f\ufffd\ufffd\u00b1j,ci\u00e2\ufffd\u00a2(0)=\u011f\ufffd\ufffd\u00b1i,cj\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(0),\u00e2\u02c6\u20acj,j\u00e2\u20ac\u00b2\u00e2\u02c6\u02c6Vformulae-sequencesubscriptsuperscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\ufffd0subscriptsuperscript\u011f\ufffd\ufffd\u00b1superscript\u011f\ufffd\u2018\u2014\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd0for-all\u011f\ufffd\u2018\u2014superscript\u011f\ufffd\u2018\u2014\u00e2\u20ac\u00b2V j,j^{ start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j , italic_c end_POSTSUBSCRIPT ( 0 ) = bold_x start_POSTSUPERSCRIPT italic_j start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_c end_POSTSUBSCRIPT ( 0 ) , \u00e2\u02c6\u20ac italic_j , italic_j start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u02c6\u02c6 roman_V, i.e. the stored value of \u011f\ufffd\ufffd\u00b1isubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is same in every node. Thus the stored value of each node can be written as \u011f\ufffd\ufffd\u00b1c:=[\u011f\ufffd\ufffd\u00b11,cT,\u00e2\u20ac\u00a6,\u011f\ufffd\ufffd\u00b1n,cT]Tassignsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\ufffdsuperscriptsuperscriptsubscript\u011f\ufffd\ufffd\u00b11\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2021\u00e2\u20ac\u00a6superscriptsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u2021 start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT := [ bold_x start_POSTSUBSCRIPT 1 , italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT , \u00e2\u20ac\u00a6 , bold_x start_POSTSUBSCRIPT italic_n , italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ] start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT. Then Flow (8) can be written in a tight form as where \u011f\ufffd\u2019\ufffd\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00b1c,t):=[\u011f\ufffd\ufffd\u201aT\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b11\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00b11,c,t)\u00e2\ufffd\u00a2\u00e2\u20ac\u00a6\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u201aT\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1n\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00b1n,c,t)]T.assign\u011f\ufffd\u2019\ufffd\u011f\ufffd\ufffd\u00b1subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1superscriptdelimited-[]superscript\u011f\ufffd\ufffd\u201a\u011f\ufffd\u2018\u2021subscript\u011f\ufffd\ufffd\u00b11subscript\u011f\ufffd\ufffd\u00b11\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u00e2\u20ac\u00a6superscript\u011f\ufffd\ufffd\u201a\u011f\ufffd\u2018\u2021subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2021 ( bold_x - bold_x start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT , italic_t ) := [ bold_C start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ( bold_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - bold_x start_POSTSUBSCRIPT 1 , italic_c end_POSTSUBSCRIPT , italic_t ) \u00e2\u20ac\u00a6 bold_C start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ( bold_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT - bold_x start_POSTSUBSCRIPT italic_n , italic_c end_POSTSUBSCRIPT , italic_t ) ] start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT . Similarly, we decompose \u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b1 by defining \u011f\ufffd\ufffd\u00b1\u00e2\u0178\u201a:=\u011f\ufffd\u2022\u0160T\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b1assignsubscript\u011f\ufffd\ufffd\u00b1perpendicular-tosuperscript\u011f\ufffd\u2022\u0160\u011f\ufffd\u2018\u2021\u011f\ufffd\ufffd\u00b1 start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT := blackboard_S start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_x and \u011f\ufffd\ufffd\u00b1\u00e2\u02c6\u00a5:=\u011f\ufffd\u2022\u20acT\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b1assignsubscript\u011f\ufffd\ufffd\u00b1parallel-tosuperscript\u011f\ufffd\u2022\u20ac\u011f\ufffd\u2018\u2021\u011f\ufffd\ufffd\u00b1 start_POSTSUBSCRIPT \u00e2\u02c6\u00a5 end_POSTSUBSCRIPT := blackboard_I start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_x, still \u011f\ufffd\ufffd\u00b1\u00cb\u2122\u00e2\u02c6\u00a5=\u011f\ufffd\u0178\ufffddsubscript\u00cb\u2122\u011f\ufffd\ufffd\u00b1parallel-tosubscript0\u011f\ufffd\u2018\u2018 start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u02c6\u00a5 end_POSTSUBSCRIPT = bold_0 start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT and we will prove the convergence of \u011f\ufffd\ufffd\u00b1\u00e2\u0178\u201asubscript\u011f\ufffd\ufffd\u00b1perpendicular-to start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT. By (23), we have We choose V1\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1\u00e2\u0178\u201a):=12\u00e2\ufffd\u00a2\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b1\u00e2\u0178\u201a\u00e2\u20ac\u20132assignsubscript\u011f\ufffd\u2018\u20301subscript\u011f\ufffd\ufffd\u00b1perpendicular-to12superscriptnormsubscript\u011f\ufffd\ufffd\u00b1perpendicular-to2V_{1}( start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( bold_x start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT ) := divide start_ARG 1 end_ARG start_ARG 2 end_ARG \u00e2\u02c6\u00a5 bold_x start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, then we have As \u011f\ufffd\ufffd\u00b1\u00cb\u2122e=\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u201a\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e,t)subscript\u00cb\u2122\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\ufffd\u201asubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1 start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT = - bold_C ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) is exponentially convergent at the zero equilibrium, where \u011f\ufffd\ufffd\u00b1e\u00e2\u02c6\u02c6\u00e2\u201e\ufffddsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, then there exists a Lyapunov function Ve\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e,t):\u00e2\u201e\ufffdd\u00c3\u2014\u00e2\u201e\ufffd+\u00e2\u2020\u2019\u00e2\u201e\ufffd:subscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2019subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1\u00e2\u2020\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018subscript\u00e2\u201e\ufffd\u00e2\u201e\ufffdV_{e}( start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \u00c3\u2014 blackboard_R start_POSTSUBSCRIPT + end_POSTSUBSCRIPT \u00e2\u2020\u2019 blackboard_R which satisfies for some c1,c2,c3,c4>0subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd3subscript\u011f\ufffd\u2018\ufffd40c_{1},c_{2},c_{3},c_{4}>0italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT > 0. We choose V2\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00b1c,t):=\u00e2\u02c6\u2018i=1nVe\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1i\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00b1i,c,t)assignsubscript\u011f\ufffd\u2018\u20302\u011f\ufffd\ufffd\u00b1subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1superscriptsubscript\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2019subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1V_{2}( {x}_{i,c},t)italic_V start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( bold_x - bold_x start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT , italic_t ) := \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_V start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT - bold_x start_POSTSUBSCRIPT italic_i , italic_c end_POSTSUBSCRIPT , italic_t ), then we have where the first inequality is obtained by (26) and the second inequality is obtained by the fact Define the Lypanuov function of (24) V:=\u00cf\u20210\u00e2\ufffd\u00a2V1+V2assign\u011f\ufffd\u2018\u2030subscript\u011f\ufffd\u0153\u20190subscript\u011f\ufffd\u2018\u20301subscript\u011f\ufffd\u2018\u20302V:= := italic_\u00cf\u2021 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_V start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_V start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT with \u00cf\u20210=4\u00e2\ufffd\u00a2\u00ce\u00bbn\u00e2\ufffd\u00a2c4\u00e2\ufffd\u00a2n\u00ce\u00bb2subscript\u011f\ufffd\u0153\u201904subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\u2018\ufffd4\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\u0153\u20202 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = divide start_ARG 4 italic_\u00ce\u00bb start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT square-root start_ARG italic_n end_ARG end_ARG start_ARG italic_\u00ce\u00bb start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG. If we let \u00ce\u00b1\u00e2\u2030\u00a4min\u00e2\ufffd\u00a2{2\u00e2\ufffd\u00a2c39\u00e2\ufffd\u00a2\u00ce\u00bbn\u00e2\ufffd\u00a2c4\u00e2\ufffd\u00a2n,2\u00e2\ufffd\u00a2c33\u00e2\ufffd\u00a2\u00ce\u00bbn}\u011f\ufffd\u203a\u00bcmin2subscript\u011f\ufffd\u2018\ufffd39subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\u2018\ufffd4\u011f\ufffd\u2018\u203a2subscript\u011f\ufffd\u2018\ufffd33subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u203a {3 \u00e2\u2030\u00a4 roman_min { divide start_ARG 2 italic_c start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG start_ARG 9 italic_\u00ce\u00bb start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT square-root start_ARG italic_n end_ARG end_ARG , divide start_ARG 2 italic_c start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG start_ARG 3 italic_\u00ce\u00bb start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_ARG } then with (25) and (27), we have With (26), we have then \u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b1\u00e2\u0178\u201a\u00e2\ufffd\u00a2(t)\u00e2\u20ac\u20132=\u011f\ufffd\u2019\u00aa\u00e2\ufffd\u00a2(e\u00e2\u02c6\u2019\u00ce\u00b3\u00e2\ufffd\u00a2t)superscriptnormsubscript\u011f\ufffd\ufffd\u00b1perpendicular-to\u011f\ufffd\u2018\u00a12\u011f\ufffd\u2019\u00aasuperscript\u011f\ufffd\u2018\u2019\u011f\ufffd\u203a\u00be\u011f\ufffd\u2018\u00a1 t})\u00e2\u02c6\u00a5 bold_x start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT ( italic_t ) \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = caligraphic_O ( italic_e start_POSTSUPERSCRIPT - italic_\u00ce\u00b3 italic_t end_POSTSUPERSCRIPT ), where \u00ce\u00b3=min\u00e2\ufffd\u00a2{\u00ce\u00b1\u00e2\ufffd\u00a2\u00ce\u00bb22,c33\u00e2\ufffd\u00a2c1}\u011f\ufffd\u203a\u00bemin\u011f\ufffd\u203a\u00bcsubscript\u011f\ufffd\u0153\u202022subscript\u011f\ufffd\u2018\ufffd33subscript\u011f\ufffd\u2018\ufffd1 = roman_min { divide start_ARG italic_\u00ce\u00b1 italic_\u00ce\u00bb start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG start_ARG 2 end_ARG , divide start_ARG italic_c start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG start_ARG 3 italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG }. The theorem is proved. Flow (9) can be written in a tight form as where \u011f\ufffd\ufffd\u00af:=[\u011f\ufffd\ufffd\u00af1T,\u00e2\u20ac\u00a6\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00afnT]Tassign\u011f\ufffd\ufffd\u00afsuperscriptsuperscriptsubscript\u011f\ufffd\ufffd\u00af1\u011f\ufffd\u2018\u2021\u00e2\u20ac\u00a6superscriptsubscript\u011f\ufffd\ufffd\u00af\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u2021 := [ bold_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT , \u00e2\u20ac\u00a6 bold_v start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ] start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT and \u011f\ufffd\ufffd\u2026\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1):=[\u00e2\u02c6\u2021f1T\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b11)\u00e2\ufffd\u00a2\u00e2\u20ac\u00a6\u00e2\ufffd\u00a2\u00e2\u02c6\u2021fnT\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1n)]Tassign\u011f\ufffd\ufffd\u2026\u011f\ufffd\ufffd\u00b1superscriptdelimited-[]\u00e2\u02c6\u2021superscriptsubscript\u011f\ufffd\u2018\u201c1\u011f\ufffd\u2018\u2021subscript\u011f\ufffd\ufffd\u00b11\u00e2\u20ac\u00a6\u00e2\u02c6\u2021superscriptsubscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2021subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2021 f_{1}^{T}( f_{n}^{T}(% ( bold_x ) := [ \u00e2\u02c6\u2021 italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ( bold_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) \u00e2\u20ac\u00a6 \u00e2\u02c6\u2021 italic_f start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ( bold_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) ] start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT. As f\u00e2\ufffd\u00a2(x)\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u00a5f(x)italic_f ( italic_x ) is strongly convex, there exists a unique s\u00e2\u02c6\u2014\u00e2\u02c6\u02c6\u00e2\u201e\ufffddsuperscript\u011f\ufffd\u2018 \u00e2\u02c6\u2014superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018s^{ start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT that \u00e2\u02c6\u2021f\u00e2\ufffd\u00a2(s\u00e2\u02c6\u2014)=\u011f\ufffd\u0178\ufffdd\u00e2\u02c6\u2021\u011f\ufffd\u2018\u201csuperscript\u011f\ufffd\u2018 \u00e2\u02c6\u2014subscript0\u011f\ufffd\u2018\u2018 f(s^{ italic_f ( italic_s start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT ) = bold_0 start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT, i.e. \u011f\ufffd\u2022\u20acT\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u2026\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00ac)=\u011f\ufffd\u0178\ufffddsuperscript\u011f\ufffd\u2022\u20ac\u011f\ufffd\u2018\u2021\u011f\ufffd\ufffd\u2026\u011f\ufffd\ufffd\u00acsubscript0\u011f\ufffd\u2018\u2018 start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_F ( bold_s ) = bold_0 start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT, where \u011f\ufffd\ufffd\u00ac:=n\u00e2\ufffd\u00a2\u011f\ufffd\u2022\u20ac\u00e2\ufffd\u00a2s\u00e2\u02c6\u2014assign\u011f\ufffd\ufffd\u00ac\u011f\ufffd\u2018\u203a\u011f\ufffd\u2022\u20acsuperscript\u011f\ufffd\u2018 \u00e2\u02c6\u2014 := square-root start_ARG italic_n end_ARG blackboard_I italic_s start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT. It can be noticed that \u011f\ufffd\ufffd\u00b1\u00e2\u02c6\u2014=\u011f\ufffd\ufffd\u00acsuperscript\u011f\ufffd\ufffd\u00b1\u00e2\u02c6\u2014\u011f\ufffd\ufffd\u00ac start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT = bold_s, and \u011f\ufffd\ufffd\u00af\u00e2\u02c6\u2014=\u00e2\u02c6\u2019\u00ce\u00b7\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u2026\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1\u00e2\u02c6\u2014)\u00ce\u00b2superscript\u011f\ufffd\ufffd\u00af\u00e2\u02c6\u2014\u011f\ufffd\u0153\u201a\u011f\ufffd\ufffd\u2026superscript\u011f\ufffd\ufffd\u00b1\u00e2\u02c6\u2014\u011f\ufffd\u203a\u00bd start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT = - divide start_ARG italic_\u00ce\u00b7 bold_F ( bold_x start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT ) end_ARG start_ARG italic_\u00ce\u00b2 end_ARG is the equilibrium point of system (30). We introduce the state error by defining \u011f\ufffd\ufffd\u00b1\u00c2\u00af:=\u011f\ufffd\ufffd\u00b1\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00acassign\u00c2\u00af\u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00ac start_ARG bold_x end_ARG := bold_x - bold_s, \u011f\ufffd\ufffd\u00af\u00c2\u00af:=\u011f\ufffd\ufffd\u00af\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00af\u00e2\u02c6\u2014assign\u00c2\u00af\u011f\ufffd\ufffd\u00af\u011f\ufffd\ufffd\u00afsuperscript\u011f\ufffd\ufffd\u00af\u00e2\u02c6\u2014 start_ARG bold_v end_ARG := bold_v - bold_v start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT . Taking the time derivative of the state errors along (30) yields where \u011f\ufffd\ufffd\u2026~\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1\u00c2\u00af):=\u011f\ufffd\ufffd\u2026\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1\u00c2\u00af+\u011f\ufffd\ufffd\u00ac)\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u2026\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00ac)assign~\u011f\ufffd\ufffd\u2026\u00c2\u00af\u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u2026\u00c2\u00af\u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00ac\u011f\ufffd\ufffd\u2026\u011f\ufffd\ufffd\u00ac start_ARG bold_F end_ARG ( over\u00c2\u00af start_ARG bold_x end_ARG ) := bold_F ( over\u00c2\u00af start_ARG bold_x end_ARG + bold_s ) - bold_F ( bold_s ). We decompose \u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00c2\u00af\u011f\ufffd\ufffd\u00b1 start_ARG bold_x end_ARG and \u011f\ufffd\ufffd\u00af\u00c2\u00af\u00c2\u00af\u011f\ufffd\ufffd\u00af start_ARG bold_v end_ARG by defining \u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u0178\u201a:=\u011f\ufffd\u2022\u0160T\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b1\u00c2\u00afassignsubscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1perpendicular-tosuperscript\u011f\ufffd\u2022\u0160\u011f\ufffd\u2018\u2021\u00c2\u00af\u011f\ufffd\ufffd\u00b1 start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT := blackboard_S start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT over\u00c2\u00af start_ARG bold_x end_ARG, \u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u02c6\u00a5:=\u011f\ufffd\u2022\u20acT\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b1\u00c2\u00afassignsubscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1parallel-tosuperscript\u011f\ufffd\u2022\u20ac\u011f\ufffd\u2018\u2021\u00c2\u00af\u011f\ufffd\ufffd\u00b1 start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u02c6\u00a5 end_POSTSUBSCRIPT := blackboard_I start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT over\u00c2\u00af start_ARG bold_x end_ARG, \u011f\ufffd\ufffd\u00af\u00c2\u00af\u00e2\u0178\u201a:=\u011f\ufffd\u2022\u0160T\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00af\u00c2\u00afassignsubscript\u00c2\u00af\u011f\ufffd\ufffd\u00afperpendicular-tosuperscript\u011f\ufffd\u2022\u0160\u011f\ufffd\u2018\u2021\u00c2\u00af\u011f\ufffd\ufffd\u00af start_ARG bold_v end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT := blackboard_S start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT over\u00c2\u00af start_ARG bold_v end_ARG and \u011f\ufffd\ufffd\u00af\u00c2\u00af\u00e2\u02c6\u00a5:=\u011f\ufffd\u2022\u20acT\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00af\u00c2\u00afassignsubscript\u00c2\u00af\u011f\ufffd\ufffd\u00afparallel-tosuperscript\u011f\ufffd\u2022\u20ac\u011f\ufffd\u2018\u2021\u00c2\u00af\u011f\ufffd\ufffd\u00af start_ARG bold_v end_ARG start_POSTSUBSCRIPT \u00e2\u02c6\u00a5 end_POSTSUBSCRIPT := blackboard_I start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT over\u00c2\u00af start_ARG bold_v end_ARG. It can be noticed that the convergence of \u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00c2\u00af\u011f\ufffd\ufffd\u00b1 start_ARG bold_x end_ARG and \u011f\ufffd\ufffd\u00af\u00c2\u00af\u00c2\u00af\u011f\ufffd\ufffd\u00af start_ARG bold_v end_ARG can be shown as if \u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u02c6\u00a5subscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1parallel-to start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u02c6\u00a5 end_POSTSUBSCRIPT, \u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u0178\u201asubscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1perpendicular-to start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT, \u011f\ufffd\ufffd\u00af\u00c2\u00af\u00e2\u0178\u201asubscript\u00c2\u00af\u011f\ufffd\ufffd\u00afperpendicular-to start_ARG bold_v end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT and \u011f\ufffd\ufffd\u00af\u00c2\u00af\u00e2\u0178\u201asubscript\u00c2\u00af\u011f\ufffd\ufffd\u00afperpendicular-to start_ARG bold_v end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT converge to the zero equilibrium by (20). By the initial condition we know that \u011f\ufffd\u2022\u20acT\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00af\u00e2\ufffd\u00a2(0)=\u011f\ufffd\u0178\ufffddsuperscript\u011f\ufffd\u2022\u20ac\u011f\ufffd\u2018\u2021\u011f\ufffd\ufffd\u00af0subscript0\u011f\ufffd\u2018\u2018 start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_v ( 0 ) = bold_0 start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT. With system (30) and (19), we conclude that \u011f\ufffd\u2022\u20acT\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00af\u00e2\ufffd\u00a2(t)=\u011f\ufffd\u0178\ufffddsuperscript\u011f\ufffd\u2022\u20ac\u011f\ufffd\u2018\u2021\u011f\ufffd\ufffd\u00af\u011f\ufffd\u2018\u00a1subscript0\u011f\ufffd\u2018\u2018 start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_v ( italic_t ) = bold_0 start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT, then By (19) and (32), the system (31) becomes where the fact \u00e2\u201e\u2019\u00e2\ufffd\u00a2\u011f\ufffd\u2019\ufffd\u00e2\ufffd\u00a2(\u011f\ufffd\u2022\u20ac\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b1\u00c2\u00af+\u011f\ufffd\ufffd\u00ac,t)=\u011f\ufffd\u0178\ufffdn\u00e2\ufffd\u00a2d\u00e2\u201e\u2019\u011f\ufffd\u2019\ufffd\u011f\ufffd\u2022\u20ac\u00c2\u00af\u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00ac\u011f\ufffd\u2018\u00a1subscript0\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2018 }_{nd}caligraphic_L caligraphic_C ( blackboard_I over\u00c2\u00af start_ARG bold_x end_ARG + bold_s , italic_t ) = bold_0 start_POSTSUBSCRIPT italic_n italic_d end_POSTSUBSCRIPT is used. Let \u011f\ufffd\ufffd\u00b3:=1\u00ce\u00b2\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00af\u00c2\u00af\u00e2\u0178\u201a+\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u0178\u201aassign\u011f\ufffd\ufffd\u00b31\u011f\ufffd\u203a\u00bdsubscript\u00c2\u00af\u011f\ufffd\ufffd\u00afperpendicular-tosubscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1perpendicular-to _{ := divide start_ARG 1 end_ARG start_ARG italic_\u00ce\u00b2 end_ARG over\u00c2\u00af start_ARG bold_v end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT + over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT. The system (33) then becomes It can be noticed that the exponential stability of the system (\u00e2\ufffd\u00a233\u00e2\ufffd\u00a2)italic-(33italic-) italic_) and the system (\u00e2\ufffd\u00a234\u00e2\ufffd\u00a2)italic-(34italic-) italic_) are equal. Define V1\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u0178\u201a,\u011f\ufffd\ufffd\u00b3)=12\u00e2\ufffd\u00a2(\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u0178\u201a\u00e2\u20ac\u20132+\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b3\u00e2\u20ac\u20132)subscript\u011f\ufffd\u2018\u20301subscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1perpendicular-to\u011f\ufffd\ufffd\u00b312superscriptnormsubscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1perpendicular-to2superscriptnorm\u011f\ufffd\ufffd\u00b32V_{1}( start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT , bold_z ) = divide start_ARG 1 end_ARG start_ARG 2 end_ARG ( \u00e2\u02c6\u00a5 over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + \u00e2\u02c6\u00a5 bold_z \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ), then we have where the second inequality is obtained by the fact from property of \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a and . Define V2\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u0178\u201a,t):=Ve\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u0178\u201a,t)assignsubscript\u011f\ufffd\u2018\u20302subscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1perpendicular-to\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2019subscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1perpendicular-to\u011f\ufffd\u2018\u00a1V_{2}( start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT , italic_t ) := italic_V start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT , italic_t ), where Vesubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2019V_{e}italic_V start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT is defined in (6). then we have where we let \u00ce\u00b4\u00e2\u2030\u00a4c3c4\u00e2\ufffd\u00a2\u00ce\u00bbn\u011f\ufffd\u203a\u00bfsubscript\u011f\ufffd\u2018\ufffd3subscript\u011f\ufffd\u2018\ufffd4subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u203a \u00e2\u2030\u00a4 divide start_ARG italic_c start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG start_ARG italic_c start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_\u00ce\u00bb start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_ARG and then c3\u00e2\u20ac\u00b2:=c3\u00e2\u02c6\u2019c4\u00e2\ufffd\u00a2\u00ce\u00b4\u00e2\ufffd\u00a2\u00ce\u00bbn>0assignsubscriptsuperscript\u011f\ufffd\u2018\ufffd\u00e2\u20ac\u00b23subscript\u011f\ufffd\u2018\ufffd3subscript\u011f\ufffd\u2018\ufffd4\u011f\ufffd\u203a\u00bfsubscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u203a0c^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT := italic_c start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT - italic_c start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_\u00ce\u00b4 italic_\u00ce\u00bb start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT > 0, and the last inequality is obtained by (22) with the fact \u011f\ufffd\u2022\u0160T\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b1=\u011f\ufffd\u2022\u0160T\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b1\u00c2\u00af=\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u0178\u201asuperscript\u011f\ufffd\u2022\u0160\u011f\ufffd\u2018\u2021\u011f\ufffd\ufffd\u00b1superscript\u011f\ufffd\u2022\u0160\u011f\ufffd\u2018\u2021\u00c2\u00af\u011f\ufffd\ufffd\u00b1subscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1perpendicular-to {x}}_{ start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_x = blackboard_S start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT over\u00c2\u00af start_ARG bold_x end_ARG = over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT, (37) and Young\u00e2\u20ac\u2122s Inequality, where r>0\u011f\ufffd\u2018\u01780r>0italic_r > 0 is a parameter which will be determined later. Define V3\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u02c6\u00a5):=12\u00e2\ufffd\u00a2\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u02c6\u00a5\u00e2\u20ac\u20132assignsubscript\u011f\ufffd\u2018\u20303subscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1parallel-to12superscriptnormsubscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1parallel-to2V_{3}( start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u02c6\u00a5 end_POSTSUBSCRIPT ) := divide start_ARG 1 end_ARG start_ARG 2 end_ARG \u00e2\u02c6\u00a5 over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u02c6\u00a5 end_POSTSUBSCRIPT \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, as f\u00e2\ufffd\u00a2(x)\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u00a5f(x)italic_f ( italic_x ) is \u00ce\u00bc\u011f\ufffd\u0153\u2021 convex, we have where the last inequality is obtained by property i). and ii). of f\u00e2\ufffd\u00a2(x)\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u00a5f(x)italic_f ( italic_x ) with \u00ce\u00bcn:=\u00ce\u00bcnassignsubscript\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u203a\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u203a start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT := divide start_ARG italic_\u00ce\u00bc end_ARG start_ARG italic_n end_ARG. We introduce some positive parameters that have nothing to do with \u00ce\u00b2\u011f\ufffd\u203a\u00bd r\u011f\ufffd\u2018\u0178ritalic_r and \u00ce\u00b7\u011f\ufffd\u0153\u201a We define the Lyapunov functions of system (34) V:=V1+\u00cf\u20210\u00e2\ufffd\u00a2V2+\u00cf\u20211\u00e2\ufffd\u00a2V3assign\u011f\ufffd\u2018\u2030subscript\u011f\ufffd\u2018\u20301subscript\u011f\ufffd\u0153\u20190subscript\u011f\ufffd\u2018\u20302subscript\u011f\ufffd\u0153\u20191subscript\u011f\ufffd\u2018\u20303V:=V_{1}+ := italic_V start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_\u00cf\u2021 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_V start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + italic_\u00cf\u2021 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_V start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT. It is easy to prove that V\u011f\ufffd\u2018\u2030Vitalic_V is positive definite. In fact First, let\u00e2\u20ac\u2122s impose some prime limit, By (35), (38), (39), (41), we can derive V\u00cb\u2122\u00cb\u2122\u011f\ufffd\u2018\u2030 start_ARG italic_V end_ARG is negative when we choose r=min\u00e2\ufffd\u00a2{14\u00e2\ufffd\u00a2\u00ce\u00be3,1}\u011f\ufffd\u2018\u0178min14subscript\u011f\ufffd\u0153\u203031r= = roman_min { divide start_ARG 1 end_ARG start_ARG 4 italic_\u00ce\u00be start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG , 1 }, \u00ce\u00b22\u00e2\u2030\u00a4min\u00e2\ufffd\u00a2{\u00cf\u20210\u00e2\ufffd\u00a2c3\u00e2\u20ac\u00b28\u00e2\ufffd\u00a2\u00ce\u00be1,\u00cf\u20210\u00e2\ufffd\u00a2c3\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2r8\u00e2\ufffd\u00a2\u00ce\u00be2}superscript\u011f\ufffd\u203a\u00bd2minsubscript\u011f\ufffd\u0153\u20190subscriptsuperscript\u011f\ufffd\u2018\ufffd\u00e2\u20ac\u00b238subscript\u011f\ufffd\u0153\u20301subscript\u011f\ufffd\u0153\u20190subscriptsuperscript\u011f\ufffd\u2018\ufffd\u00e2\u20ac\u00b23\u011f\ufffd\u2018\u01788subscript\u011f\ufffd\u0153\u20302 {0}c^{ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT \u00e2\u2030\u00a4 roman_min { divide start_ARG italic_\u00cf\u2021 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_c start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG start_ARG 8 italic_\u00ce\u00be start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG , divide start_ARG italic_\u00cf\u2021 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_c start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT italic_r end_ARG start_ARG 8 italic_\u00ce\u00be start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG }, \u00ce\u00b7\u00e2\u2030\u00a4min\u00e2\ufffd\u00a2{\u00ce\u00b22,\u00ce\u00b224\u00e2\ufffd\u00a2\u00ce\u00be4}\u011f\ufffd\u0153\u201aminsuperscript\u011f\ufffd\u203a\u00bd2superscript\u011f\ufffd\u203a\u00bd24subscript\u011f\ufffd\u0153\u20304 \u00e2\u2030\u00a4 roman_min { italic_\u00ce\u00b2 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , divide start_ARG italic_\u00ce\u00b2 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG 4 italic_\u00ce\u00be start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT end_ARG }. With (40), we have With the definition of V\u011f\ufffd\u2018\u2030Vitalic_V, we derive \u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\ufffd\u00a2(t)\u00e2\u20ac\u20132=\u011f\ufffd\u2019\u00aa\u00e2\ufffd\u00a2(e\u00e2\u02c6\u2019\u00ce\u00b3\u00e2\ufffd\u00a2t)superscriptnorm\u00c2\u00af\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a12\u011f\ufffd\u2019\u00aasuperscript\u011f\ufffd\u2018\u2019\u011f\ufffd\u203a\u00be\u011f\ufffd\u2018\u00a1 t})\u00e2\u02c6\u00a5 over\u00c2\u00af start_ARG bold_x end_ARG ( italic_t ) \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = caligraphic_O ( italic_e start_POSTSUPERSCRIPT - italic_\u00ce\u00b3 italic_t end_POSTSUPERSCRIPT ). With the definition \u011f\ufffd\ufffd\u00b1\u00c2\u00af=\u011f\ufffd\ufffd\u00b1\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00ac\u00c2\u00af\u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00ac start_ARG bold_x end_ARG = bold_x - bold_s before, we know that \u011f\ufffd\ufffd\u00b1i\u00e2\ufffd\u00a2(t)subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) in Flow (9) converge exponentially to the optimal solution s\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018 \u00e2\u02c6\u2014s^{ start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT with the SST compressor. As analyzed in Appendix C, Flow (10) satisfies that for every i\u00e2\u02c6\u02c6V\u011f\ufffd\u2018\u2013Vi \u00e2\u02c6\u02c6 roman_V, \u011f\ufffd\ufffd\u00b1i,cj\u00e2\ufffd\u00a2(0)=\u011f\ufffd\ufffd\u00b1i,cj\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(0),\u00e2\u02c6\u20acj,j\u00e2\u20ac\u00b2\u00e2\u02c6\u02c6Vformulae-sequencesubscriptsuperscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd0subscriptsuperscript\u011f\ufffd\ufffd\u00b1superscript\u011f\ufffd\u2018\u2014\u00e2\u20ac\u00b2\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd0for-all\u011f\ufffd\u2018\u2014superscript\u011f\ufffd\u2018\u2014\u00e2\u20ac\u00b2V j,j^{ start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_c end_POSTSUBSCRIPT ( 0 ) = bold_x start_POSTSUPERSCRIPT italic_j start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_c end_POSTSUBSCRIPT ( 0 ) , \u00e2\u02c6\u20ac italic_j , italic_j start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT \u00e2\u02c6\u02c6 roman_V. Then Flow (10) can be written as We carry out a similar analysis process as in Appendix D with \u011f\ufffd\ufffd\u00b3:=\u00ce\u00b1\u00ce\u00b2\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00af\u00c2\u00af\u00e2\u0178\u201a+\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u0178\u201aassign\u011f\ufffd\ufffd\u00b3\u011f\ufffd\u203a\u00bc\u011f\ufffd\u203a\u00bdsubscript\u00c2\u00af\u011f\ufffd\ufffd\u00afperpendicular-tosubscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1perpendicular-to := divide start_ARG italic_\u00ce\u00b1 end_ARG start_ARG italic_\u00ce\u00b2 end_ARG over\u00c2\u00af start_ARG bold_v end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT + over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT, and the system (42) becomes where \u011f\ufffd\ufffd\u00b1\u00c2\u00afc:=\u011f\ufffd\ufffd\u00b1c\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00acassignsubscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00ac start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT := bold_x start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT - bold_s and \u00ce\u00b2\u00ce\u00b12:=\u00ce\u00b22/\u00ce\u00b1assignsubscriptsuperscript\u011f\ufffd\u203a\u00bd2\u011f\ufffd\u203a\u00bcsuperscript\u011f\ufffd\u203a\u00bd2\u011f\ufffd\u203a\u00bc start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_\u00ce\u00b1 end_POSTSUBSCRIPT := italic_\u00ce\u00b2 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT / italic_\u00ce\u00b1. Define V1\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u0178\u201a,\u011f\ufffd\ufffd\u00b3)=12\u00e2\ufffd\u00a2(\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u0178\u201a\u00e2\u20ac\u20132+\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b3\u00e2\u20ac\u20132)subscript\u011f\ufffd\u2018\u20301subscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1perpendicular-to\u011f\ufffd\ufffd\u00b312superscriptnormsubscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1perpendicular-to2superscriptnorm\u011f\ufffd\ufffd\u00b32V_{1}( start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT , bold_z ) = divide start_ARG 1 end_ARG start_ARG 2 end_ARG ( \u00e2\u02c6\u00a5 over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + \u00e2\u02c6\u00a5 bold_z \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ), we have where the second inequality is obtained by the fact For V2\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00b1\u00c2\u00afc,t)subscript\u011f\ufffd\u2018\u20302\u00c2\u00af\u011f\ufffd\ufffd\u00b1subscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1V_{2}( start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( over\u00c2\u00af start_ARG bold_x end_ARG - over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT , italic_t ), which is defined in Appendix C. then we have where the first inequality is obtained by \u011f\ufffd\ufffd\u00af\u00c2\u00af=\u011f\ufffd\u2022\u0160\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00af\u00c2\u00af\u00e2\u0178\u201a\u00c2\u00af\u011f\ufffd\ufffd\u00af\u011f\ufffd\u2022\u0160subscript\u00c2\u00af\u011f\ufffd\ufffd\u00afperpendicular-to start_ARG bold_v end_ARG = blackboard_S over\u00c2\u00af start_ARG bold_v end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT and (26), and the last inequality is obtained by (37), the fact and Young\u00e2\u20ac\u2122s Inequality, where r>0\u011f\ufffd\u2018\u01780r>0italic_r > 0 is a parameter which will be determined later. Define V3\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u02c6\u00a5):=12\u00e2\ufffd\u00a2\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u02c6\u00a5\u00e2\u20ac\u20132assignsubscript\u011f\ufffd\u2018\u20303subscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1parallel-to12superscriptnormsubscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1parallel-to2V_{3}( start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u02c6\u00a5 end_POSTSUBSCRIPT ) := divide start_ARG 1 end_ARG start_ARG 2 end_ARG \u00e2\u02c6\u00a5 over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u02c6\u00a5 end_POSTSUBSCRIPT \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, then (39) still holds. We introduce some positive parameters that have nothing to do with \u00ce\u00b1\u011f\ufffd\u203a\u00bc \u00ce\u00b2\u011f\ufffd\u203a\u00bd r\u011f\ufffd\u2018\u0178ritalic_r and \u00ce\u00b7\u011f\ufffd\u0153\u201a We define the Lyapunov functions of system (43) V:=V1+V2+\u00cf\u20211\u00e2\ufffd\u00a2V3assign\u011f\ufffd\u2018\u2030subscript\u011f\ufffd\u2018\u20301subscript\u011f\ufffd\u2018\u20302subscript\u011f\ufffd\u0153\u20191subscript\u011f\ufffd\u2018\u20303V:=V_{1}+V_{2}+ := italic_V start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_V start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + italic_\u00cf\u2021 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_V start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT. It is easy to prove that V\u011f\ufffd\u2018\u2030Vitalic_V is positive definite. In fact First, let\u00e2\u20ac\u2122s impose some prime limit, By (44), (46), (39) (49), we can derive V\u00cb\u2122\u00cb\u2122\u011f\ufffd\u2018\u2030 start_ARG italic_V end_ARG is negative when we choose r=min\u00e2\ufffd\u00a2[\u00ce\u00be14\u00e2\ufffd\u00a2\u00ce\u00be3,14\u00e2\ufffd\u00a2\u00ce\u00be5,1]\u011f\ufffd\u2018\u0178minsubscript\u011f\ufffd\u0153\u203014subscript\u011f\ufffd\u0153\u2030314subscript\u011f\ufffd\u0153\u203051r= = roman_min [ divide start_ARG italic_\u00ce\u00be start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG 4 italic_\u00ce\u00be start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG , divide start_ARG 1 end_ARG start_ARG 4 italic_\u00ce\u00be start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT end_ARG , 1 ], \u00ce\u00b1\u00e2\u2030\u00a4min\u00e2\ufffd\u00a2[c3\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2\u00ce\u00be6,c34\u00e2\ufffd\u00a2\u00ce\u00be7]\u011f\ufffd\u203a\u00bcminsubscript\u011f\ufffd\u2018\ufffd3\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u0153\u20306subscript\u011f\ufffd\u2018\ufffd34subscript\u011f\ufffd\u0153\u20307 \u00e2\u2030\u00a4 roman_min [ divide start_ARG italic_c start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT italic_r end_ARG start_ARG 4 italic_\u00ce\u00be start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT end_ARG , divide start_ARG italic_c start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG start_ARG 4 italic_\u00ce\u00be start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT end_ARG ], \u00ce\u00b22\u00e2\u2030\u00a4min\u00e2\ufffd\u00a2[\u00ce\u00b12,\u00ce\u00be1\u00e2\ufffd\u00a2\u00ce\u00b124\u00e2\ufffd\u00a2\u00ce\u00be2]superscript\u011f\ufffd\u203a\u00bd2minsuperscript\u011f\ufffd\u203a\u00bc2subscript\u011f\ufffd\u0153\u20301superscript\u011f\ufffd\u203a\u00bc24subscript\u011f\ufffd\u0153\u20302 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT \u00e2\u2030\u00a4 roman_min [ italic_\u00ce\u00b1 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , divide start_ARG italic_\u00ce\u00be start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_\u00ce\u00b1 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG 4 italic_\u00ce\u00be start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG ], \u00ce\u00b7\u00e2\u2030\u00a4min\u00e2\ufffd\u00a2[\u00ce\u00b2\u00ce\u00b12,14\u00e2\ufffd\u00a2\u00ce\u00be4]\u011f\ufffd\u0153\u201aminsuperscriptsubscript\u011f\ufffd\u203a\u00bd\u011f\ufffd\u203a\u00bc214subscript\u011f\ufffd\u0153\u20304 \u00e2\u2030\u00a4 roman_min [ italic_\u00ce\u00b2 start_POSTSUBSCRIPT italic_\u00ce\u00b1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , divide start_ARG 1 end_ARG start_ARG 4 italic_\u00ce\u00be start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT end_ARG ]. With (48), we have With the definition of V\u011f\ufffd\u2018\u2030Vitalic_V, we derive \u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\ufffd\u00a2(t)\u00e2\u20ac\u20132=\u011f\ufffd\u2019\u00aa\u00e2\ufffd\u00a2(e\u00e2\u02c6\u2019\u00ce\u00b3\u00e2\ufffd\u00a2t)superscriptnorm\u00c2\u00af\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a12\u011f\ufffd\u2019\u00aasuperscript\u011f\ufffd\u2018\u2019\u011f\ufffd\u203a\u00be\u011f\ufffd\u2018\u00a1 t})\u00e2\u02c6\u00a5 over\u00c2\u00af start_ARG bold_x end_ARG ( italic_t ) \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = caligraphic_O ( italic_e start_POSTSUPERSCRIPT - italic_\u00ce\u00b3 italic_t end_POSTSUPERSCRIPT ). With the definition \u011f\ufffd\ufffd\u00b1\u00c2\u00af=\u011f\ufffd\ufffd\u00b1\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00ac\u00c2\u00af\u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00ac start_ARG bold_x end_ARG = bold_x - bold_s before, we know that \u011f\ufffd\ufffd\u00b1i\u00e2\ufffd\u00a2(t)subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) in Flow (10) converge exponentially to the optimal solution s\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018 \u00e2\u02c6\u2014s^{ start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT with the ST compressor. Flow (11) can be written in a tight form as Similar to the proof of continuous time form in Appendix D. We introduce the state error by defining \u011f\ufffd\ufffd\u00b1\u00c2\u00af:=\u011f\ufffd\ufffd\u00b1\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00acassign\u00c2\u00af\u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00ac start_ARG bold_x end_ARG := bold_x - bold_s, \u011f\ufffd\ufffd\u00af\u00c2\u00af:=\u011f\ufffd\ufffd\u00af\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00af\u00e2\u02c6\u2014assign\u00c2\u00af\u011f\ufffd\ufffd\u00af\u011f\ufffd\ufffd\u00afsuperscript\u011f\ufffd\ufffd\u00af\u00e2\u02c6\u2014 start_ARG bold_v end_ARG := bold_v - bold_v start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT. Then decompose \u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00c2\u00af\u011f\ufffd\ufffd\u00b1 start_ARG bold_x end_ARG and \u011f\ufffd\ufffd\u00af\u00c2\u00af\u00c2\u00af\u011f\ufffd\ufffd\u00af start_ARG bold_v end_ARG by defining \u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u0178\u201a:=\u011f\ufffd\u2022\u0160T\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b1\u00c2\u00afassignsubscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1perpendicular-tosuperscript\u011f\ufffd\u2022\u0160\u011f\ufffd\u2018\u2021\u00c2\u00af\u011f\ufffd\ufffd\u00b1 start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT := blackboard_S start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT over\u00c2\u00af start_ARG bold_x end_ARG, \u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u02c6\u00a5:=\u011f\ufffd\u2022\u20acT\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b1\u00c2\u00afassignsubscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1parallel-tosuperscript\u011f\ufffd\u2022\u20ac\u011f\ufffd\u2018\u2021\u00c2\u00af\u011f\ufffd\ufffd\u00b1 start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u02c6\u00a5 end_POSTSUBSCRIPT := blackboard_I start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT over\u00c2\u00af start_ARG bold_x end_ARG, \u011f\ufffd\ufffd\u00af\u00c2\u00af\u00e2\u0178\u201a:=\u011f\ufffd\u2022\u0160T\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00af\u00c2\u00afassignsubscript\u00c2\u00af\u011f\ufffd\ufffd\u00afperpendicular-tosuperscript\u011f\ufffd\u2022\u0160\u011f\ufffd\u2018\u2021\u00c2\u00af\u011f\ufffd\ufffd\u00af start_ARG bold_v end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT := blackboard_S start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT over\u00c2\u00af start_ARG bold_v end_ARG and \u011f\ufffd\ufffd\u00af\u00c2\u00af\u00e2\u02c6\u00a5:=\u011f\ufffd\u2022\u20acT\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00af\u00c2\u00afassignsubscript\u00c2\u00af\u011f\ufffd\ufffd\u00afparallel-tosuperscript\u011f\ufffd\u2022\u20ac\u011f\ufffd\u2018\u2021\u00c2\u00af\u011f\ufffd\ufffd\u00af start_ARG bold_v end_ARG start_POSTSUBSCRIPT \u00e2\u02c6\u00a5 end_POSTSUBSCRIPT := blackboard_I start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT over\u00c2\u00af start_ARG bold_v end_ARG. The convergence of \u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00c2\u00af\u011f\ufffd\ufffd\u00b1 start_ARG bold_x end_ARG and \u011f\ufffd\ufffd\u00af\u00c2\u00af\u00c2\u00af\u011f\ufffd\ufffd\u00af start_ARG bold_v end_ARG can be shown as if \u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u02c6\u00a5subscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1parallel-to start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u02c6\u00a5 end_POSTSUBSCRIPT, \u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u0178\u201asubscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1perpendicular-to start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT, \u011f\ufffd\ufffd\u00af\u00c2\u00af\u00e2\u0178\u201asubscript\u00c2\u00af\u011f\ufffd\ufffd\u00afperpendicular-to start_ARG bold_v end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT and \u011f\ufffd\ufffd\u00af\u00c2\u00af\u00e2\u0178\u201asubscript\u00c2\u00af\u011f\ufffd\ufffd\u00afperpendicular-to start_ARG bold_v end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT converge to the zero equilibrium. Also we can conclude (32). Let \u011f\ufffd\ufffd\u00b3:=1\u00ce\u00b2\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00af\u00c2\u00af\u00e2\u0178\u201a+\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u0178\u201aassign\u011f\ufffd\ufffd\u00b31\u011f\ufffd\u203a\u00bdsubscript\u00c2\u00af\u011f\ufffd\ufffd\u00afperpendicular-tosubscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1perpendicular-to _{ := divide start_ARG 1 end_ARG start_ARG italic_\u00ce\u00b2 end_ARG over\u00c2\u00af start_ARG bold_v end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT + over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT, with (34), the system (50) becomes It can be noticed that the exponential stability of the system (\u00e2\ufffd\u00a250\u00e2\ufffd\u00a2)italic-(50italic-) italic_) and the system (\u00e2\ufffd\u00a251\u00e2\ufffd\u00a2)italic-(51italic-) italic_) are equal. Define V1,t\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u0178\u201a,\u011f\ufffd\ufffd\u00b3)=12\u00e2\ufffd\u00a2(\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u0178\u201a\u00e2\u20ac\u20132+\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b3\u00e2\u20ac\u20132)subscript\u011f\ufffd\u2018\u20301\u011f\ufffd\u2018\u00a1subscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1perpendicular-to\u011f\ufffd\ufffd\u00b312superscriptnormsubscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1perpendicular-to2superscriptnorm\u011f\ufffd\ufffd\u00b32V_{1,t}( start_POSTSUBSCRIPT 1 , italic_t end_POSTSUBSCRIPT ( over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT , bold_z ) = divide start_ARG 1 end_ARG start_ARG 2 end_ARG ( \u00e2\u02c6\u00a5 over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + \u00e2\u02c6\u00a5 bold_z \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ), then where the second inequality is obtained by (36) and (37). Before we introduce the second Lyapunov function, we will show that the following system where \u011f\ufffd\ufffd\u00b2e\u00e2\u02c6\u02c6\u00e2\u201e\ufffd(n\u00e2\u02c6\u20191)\u00e2\ufffd\u00a2dsubscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u203a1\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT ( italic_n - 1 ) italic_d end_POSTSUPERSCRIPT, \u011f\ufffd\ufffd\u00b1e\u00e2\u02c6\u02c6\u00e2\u201e\ufffdn\u00e2\ufffd\u00a2dsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_n italic_d end_POSTSUPERSCRIPT and \u011f\ufffd\ufffd\u00b2e=\u011f\ufffd\u2022\u0160T\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b1esubscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019superscript\u011f\ufffd\u2022\u0160\u011f\ufffd\u2018\u2021subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019{ start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT = blackboard_S start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT, achieves exponential convergence at the zero equilibrium for some positive \u00ce\u00ba0,\u00ce\u00b4subscript\u011f\ufffd\u0153\u20260\u011f\ufffd\u203a\u00bf start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_\u00ce\u00b4 in Theorem 5. By definition of \u011f\ufffd\ufffd\u201a\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e,t)\u011f\ufffd\ufffd\u201asubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1 ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ), it is easy to find the following system exponential convergence at the zero equilibrium if \u00ce\u00ba0\u00e2\u2030\u00a4\u00ce\u00ba0\u00e2\u02c6\u2014/\u00ce\u00bbnsubscript\u011f\ufffd\u0153\u20260superscriptsubscript\u011f\ufffd\u0153\u20260\u00e2\u02c6\u2014subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u203a start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_\u00ce\u00ba start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT / italic_\u00ce\u00bb start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT, Then there exists positive constants C\u011f\ufffd\ufffd\u00b6Citalic_C, \u00ce\u00b3D<1subscript\u011f\ufffd\u203a\u00be\u011f\ufffd\ufffd\u00b71 start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT < 1, for any t\u011f\ufffd\u2018\u00a1titalic_t and N\u00e2\u02c6\u02c6\u00e2\u201e\u2022+\u011f\ufffd\u2018\ufffdsubscript\u00e2\u201e\u2022N \u00e2\u02c6\u02c6 blackboard_N start_POSTSUBSCRIPT + end_POSTSUBSCRIPT, the solution satisfies Assume \u00cf\u2022tt+T\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b2e\u00e2\ufffd\u00a2(t))superscriptsubscriptitalic-\u00cf\u2022\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2021subscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t + italic_T end_POSTSUPERSCRIPT ( bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ) ) is the state of system \u011f\ufffd\ufffd\u00b2e\u00e2\ufffd\u00a2(t+1)=\u011f\ufffd\ufffd\u00b2e\u00e2\ufffd\u00a2(t)\u00e2\u02c6\u2019\u00ce\u00ba0\u00e2\ufffd\u00a2\u00ce\u203a\u00e2\ufffd\u00a2\u011f\ufffd\u2019\ufffd\u00e2\u02c6\u2019\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b2e\u00e2\ufffd\u00a2(t),t)subscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a11subscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u0153\u20260\u00ce\u203asuperscript\u011f\ufffd\u2019\ufffdsubscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a1 {y}_{e}(t),t)bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t + 1 ) = bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ) - italic_\u00ce\u00ba start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT roman_\u00ce\u203a caligraphic_C start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT ( bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ) , italic_t ) in t+N\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffdt+Nitalic_t + italic_N moment with the state in t\u011f\ufffd\u2018\u00a1titalic_t moment is \u011f\ufffd\ufffd\u00b2e\u00e2\ufffd\u00a2(t)subscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ). It is easy to verified that for any \u011f\ufffd\ufffd\u00b2\u00e2\u02c6\u02c6\u00e2\u201e\ufffd(n\u00e2\u02c6\u20191)\u00e2\ufffd\u00a2d\u011f\ufffd\ufffd\u00b2superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u203a1\u011f\ufffd\u2018\u2018 \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT ( italic_n - 1 ) italic_d end_POSTSUPERSCRIPT and some L\u00cf\u2022>0subscript\u011f\ufffd\ufffd\u00bfitalic-\u00cf\u20220L_{ start_POSTSUBSCRIPT italic_\u00cf\u2022 end_POSTSUBSCRIPT > 0 by property of compressor \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a We find Lyapunov function Ve\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b2e,t)=\u00e2\u02c6\u2018j=0N\u00e2\u02c6\u20191\u00e2\u20ac\u2013\u00cf\u2022tt+j\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b2e)\u00e2\u20ac\u20132subscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2019subscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1superscriptsubscript\u011f\ufffd\u2018\u20140\u011f\ufffd\u2018\ufffd1superscriptnormsuperscriptsubscriptitalic-\u00cf\u2022\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u20192V_{e}( start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) = \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_j = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N - 1 end_POSTSUPERSCRIPT \u00e2\u02c6\u00a5 italic_\u00cf\u2022 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t + italic_j end_POSTSUPERSCRIPT ( bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ) \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT satisfies for c1=1,c2=N\u00e2\ufffd\u00a2L\u00cf\u2022formulae-sequencesubscript\u011f\ufffd\u2018\ufffd11subscript\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\ufffd\u00bfitalic-\u00cf\u2022c_{1}=1,c_{2}=NL_{ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1 , italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = italic_N italic_L start_POSTSUBSCRIPT italic_\u00cf\u2022 end_POSTSUBSCRIPT. Moreover, we have We choose a N\u00e2\u02c6\u02c6\u00e2\u201e\u2022+\u011f\ufffd\u2018\ufffdsubscript\u00e2\u201e\u2022N \u00e2\u02c6\u02c6 blackboard_N start_POSTSUBSCRIPT + end_POSTSUBSCRIPT large enough and then c3=1\u00e2\u02c6\u2019C\u00e2\ufffd\u00a2\u00ce\u00b3DN>0subscript\u011f\ufffd\u2018\ufffd31\u011f\ufffd\ufffd\u00b6superscriptsubscript\u011f\ufffd\u203a\u00be\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\ufffd0c_{3}=1-C start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1 - italic_C italic_\u00ce\u00b3 start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT > 0, i. e. Besides, for \u00ce\u00b8=2+2\u00e2\ufffd\u00a2Lc2\u00e2\ufffd\u00a2\u00ce\u00ba02\u00e2\ufffd\u00a2\u00ce\u00bbn2>0\u011f\ufffd\u0153\u019222superscriptsubscript\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\ufffd2superscriptsubscript\u011f\ufffd\u0153\u202602superscriptsubscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u203a20 = 2 + 2 italic_L start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_\u00ce\u00ba start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_\u00ce\u00bb start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT > 0 by property of \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a For system (53), we apply Lyapunov function Ve\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b2e,t)subscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2019subscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1V_{e}( start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) and obtain the difference of Ve\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b2e,t)subscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2019subscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1V_{e}( start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) for c4:=N\u00e2\ufffd\u00a2L\u00cf\u2022\u00e2\ufffd\u00a2\u00ce\u00b8assignsubscript\u011f\ufffd\u2018\ufffd4\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\ufffd\u00bfitalic-\u00cf\u2022\u011f\ufffd\u0153\u0192c_{4}:=NL_{ start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT := italic_N italic_L start_POSTSUBSCRIPT italic_\u00cf\u2022 end_POSTSUBSCRIPT italic_\u00ce\u00b8, where the first inequality is obtained by (LABEL:eq:DPD.a.Vec3) and the second inequality is obtained by (7). It is obvious that for that the difference of Ve\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b2e,t)subscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2019subscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1V_{e}( start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) is negative definite with c3\u00e2\u20ac\u00b2:=c3\u00e2\u02c6\u20192\u00e2\ufffd\u00a2c4\u00e2\ufffd\u00a2\u00ce\u00ba0\u00e2\ufffd\u00a2\u00ce\u00bbn\u00e2\ufffd\u00a2\u00ce\u00b4\u00e2\u02c6\u2019c4\u00e2\ufffd\u00a2\u00ce\u00ba02\u00e2\ufffd\u00a2\u00ce\u00bbn2\u00e2\ufffd\u00a2\u00ce\u00b42>0assignsuperscriptsubscript\u011f\ufffd\u2018\ufffd3\u00e2\u20ac\u00b2subscript\u011f\ufffd\u2018\ufffd32subscript\u011f\ufffd\u2018\ufffd4subscript\u011f\ufffd\u0153\u20260subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u203a\u011f\ufffd\u203a\u00bfsubscript\u011f\ufffd\u2018\ufffd4superscriptsubscript\u011f\ufffd\u0153\u202602superscriptsubscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u203a2superscript\u011f\ufffd\u203a\u00bf20c_{3}^{ start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT := italic_c start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT - 2 italic_c start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_\u00ce\u00ba start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_\u00ce\u00bb start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT italic_\u00ce\u00b4 - italic_c start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_\u00ce\u00ba start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_\u00ce\u00bb start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_\u00ce\u00b4 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT > 0, thus system (53) achieves exponential convergence at the zero equilibrium. Next we continue to choose Lyapunov function by defining V2,t:=Ve\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u0178\u201a,t)assignsubscript\u011f\ufffd\u2018\u20302\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2019subscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1perpendicular-to\u011f\ufffd\u2018\u00a1V_{2,t}:=V_{e}( start_POSTSUBSCRIPT 2 , italic_t end_POSTSUBSCRIPT := italic_V start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT , italic_t ), then where the second inequality is obtained by (56) and (LABEL:eq:DPD.a.Ve'), and the last inequality is obtained by (37) and Young\u00e2\u20ac\u2122s Inequality, where r>0\u011f\ufffd\u2018\u01780r>0italic_r > 0 is a parameter which will be determined later. Define V3,t\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u02c6\u00a5):=12\u00e2\ufffd\u00a2\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u02c6\u00a5\u00e2\u20ac\u20132assignsubscript\u011f\ufffd\u2018\u20303\u011f\ufffd\u2018\u00a1subscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1parallel-to12superscriptnormsubscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1parallel-to2V_{3,t}( _{ start_POSTSUBSCRIPT 3 , italic_t end_POSTSUBSCRIPT ( over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u02c6\u00a5 end_POSTSUBSCRIPT ) := divide start_ARG 1 end_ARG start_ARG 2 end_ARG \u00e2\u02c6\u00a5 over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u02c6\u00a5 end_POSTSUBSCRIPT \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, with (39), we have where the second equality is obtained by (37) and the first inequality is obtained by (39). We introduce some parameters \u00cf\u20210subscript\u011f\ufffd\u0153\u20190 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, \u00cf\u20211subscript\u011f\ufffd\u0153\u20191 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, \u00ce\u00be1subscript\u011f\ufffd\u0153\u20301 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, \u00ce\u00be2subscript\u011f\ufffd\u0153\u20302 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT\u00e2\u20ac\u00a6>0absent0>0> 0 that have nothing to do with \u00ce\u00b2\u011f\ufffd\u203a\u00bd r\u011f\ufffd\u2018\u0178ritalic_r and \u00ce\u00b7\u011f\ufffd\u0153\u201a and some parameters \u00ce\u00b61subscript\u011f\ufffd\u0153\ufffd1 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, \u00ce\u00b62subscript\u011f\ufffd\u0153\ufffd2 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT\u00e2\u20ac\u00a6>0absent0>0> 0. We define the Lyapunov functions of system (51) Vt:=V1,t+\u00cf\u20210\u00e2\ufffd\u00a2V2,t+\u00cf\u20211\u00e2\ufffd\u00a2V3,tassignsubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\u20301\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u0153\u20190subscript\u011f\ufffd\u2018\u20302\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u0153\u20191subscript\u011f\ufffd\u2018\u20303\u011f\ufffd\u2018\u00a1V_{t}:=V_{1,t}+ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT := italic_V start_POSTSUBSCRIPT 1 , italic_t end_POSTSUBSCRIPT + italic_\u00cf\u2021 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_V start_POSTSUBSCRIPT 2 , italic_t end_POSTSUBSCRIPT + italic_\u00cf\u2021 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_V start_POSTSUBSCRIPT 3 , italic_t end_POSTSUBSCRIPT. It is easy to prove that V\u011f\ufffd\u2018\u2030Vitalic_V is positive definite. In fact First, let\u00e2\u20ac\u2122s impose prime limit (41). By (52), (58), (59), (41) we can derive \u00ce\u201d\u00e2\ufffd\u00a2Vt\u00ce\u201dsubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u00a1 V_{t}roman_\u00ce\u201d italic_V start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is negative definite when we choose r=min\u00e2\ufffd\u00a2{14\u00e2\ufffd\u00a2\u00ce\u00be3,1}\u011f\ufffd\u2018\u0178min14subscript\u011f\ufffd\u0153\u203031r= = roman_min { divide start_ARG 1 end_ARG start_ARG 4 italic_\u00ce\u00be start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG , 1 }, \u00ce\u00b22\u00e2\u2030\u00a4min\u00e2\ufffd\u00a2{\u00cf\u20210\u00e2\ufffd\u00a2c3\u00e2\u20ac\u00b28\u00e2\ufffd\u00a2\u00ce\u00be1,\u00cf\u20210\u00e2\ufffd\u00a2c3\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2r8\u00e2\ufffd\u00a2\u00ce\u00be2}superscript\u011f\ufffd\u203a\u00bd2minsubscript\u011f\ufffd\u0153\u20190subscriptsuperscript\u011f\ufffd\u2018\ufffd\u00e2\u20ac\u00b238subscript\u011f\ufffd\u0153\u20301subscript\u011f\ufffd\u0153\u20190subscriptsuperscript\u011f\ufffd\u2018\ufffd\u00e2\u20ac\u00b23\u011f\ufffd\u2018\u01788subscript\u011f\ufffd\u0153\u20302 {0}c^{ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT \u00e2\u2030\u00a4 roman_min { divide start_ARG italic_\u00cf\u2021 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_c start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG start_ARG 8 italic_\u00ce\u00be start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG , divide start_ARG italic_\u00cf\u2021 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_c start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT italic_r end_ARG start_ARG 8 italic_\u00ce\u00be start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG }, \u00ce\u00b7\u00e2\u2030\u00a4min\u00e2\ufffd\u00a2{\u00ce\u00b22,\u00ce\u00b224\u00e2\ufffd\u00a2\u00ce\u00be4}\u011f\ufffd\u0153\u201aminsuperscript\u011f\ufffd\u203a\u00bd2superscript\u011f\ufffd\u203a\u00bd24subscript\u011f\ufffd\u0153\u20304 \u00e2\u2030\u00a4 roman_min { italic_\u00ce\u00b2 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , divide start_ARG italic_\u00ce\u00b2 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG 4 italic_\u00ce\u00be start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT end_ARG } and \u00ce\u00ba\u00e2\u2030\u00a4\u00ce\u00ba1:=12\u00e2\ufffd\u00a2min\u00e2\ufffd\u00a2{\u00cf\u20210\u00e2\ufffd\u00a2c3\u00e2\u20ac\u00b24\u00e2\ufffd\u00a2\u00ce\u00b61,\u00ce\u00b222\u00e2\ufffd\u00a2\u00ce\u00b62,\u00ce\u00b7\u00e2\ufffd\u00a2\u00ce\u00bcn\u00e2\ufffd\u00a2\u00cf\u202114\u00e2\ufffd\u00a2\u00ce\u00b63,1}\u011f\ufffd\u0153\u2026subscript\u011f\ufffd\u0153\u20261assign12minsubscript\u011f\ufffd\u0153\u20190subscriptsuperscript\u011f\ufffd\u2018\ufffd\u00e2\u20ac\u00b234subscript\u011f\ufffd\u0153\ufffd1superscript\u011f\ufffd\u203a\u00bd22subscript\u011f\ufffd\u0153\ufffd2\u011f\ufffd\u0153\u201asubscript\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\u0153\u201914subscript\u011f\ufffd\u0153\ufffd31 ,1 \u00e2\u2030\u00a4 italic_\u00ce\u00ba start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT := divide start_ARG 1 end_ARG start_ARG 2 end_ARG roman_min { divide start_ARG italic_\u00cf\u2021 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_c start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG start_ARG 4 italic_\u00ce\u00b6 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG , divide start_ARG italic_\u00ce\u00b2 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG 2 italic_\u00ce\u00b6 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG , italic_\u00ce\u00b7 divide start_ARG italic_\u00ce\u00bc start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT italic_\u00cf\u2021 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG 4 italic_\u00ce\u00b6 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG , 1 }. With (60), then Let \u00ce\u00ba2:=2/min\u00e2\ufffd\u00a2{\u00cf\u20210\u00e2\ufffd\u00a2c3\u00e2\u20ac\u00b22\u00e2\ufffd\u00a2(1+2\u00e2\ufffd\u00a2\u00cf\u20210\u00e2\ufffd\u00a2c1),\u00ce\u00b22,\u00ce\u00b7\u00e2\ufffd\u00a2\u00ce\u00bcn2}assignsubscript\u011f\ufffd\u0153\u202622minsubscript\u011f\ufffd\u0153\u20190subscriptsuperscript\u011f\ufffd\u2018\ufffd\u00e2\u20ac\u00b23212subscript\u011f\ufffd\u0153\u20190subscript\u011f\ufffd\u2018\ufffd1superscript\u011f\ufffd\u203a\u00bd2\u011f\ufffd\u0153\u201asubscript\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u203a2 , start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT := 2 / roman_min { divide start_ARG italic_\u00cf\u2021 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_c start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG start_ARG 2 ( 1 + 2 italic_\u00cf\u2021 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) end_ARG , italic_\u00ce\u00b2 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , italic_\u00ce\u00b7 divide start_ARG italic_\u00ce\u00bc start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_ARG start_ARG 2 end_ARG }. When \u00ce\u00ba\u00e2\u2030\u00a4min\u00e2\ufffd\u00a2{\u00ce\u00ba1,\u00ce\u00ba2}\u011f\ufffd\u0153\u2026minsubscript\u011f\ufffd\u0153\u20261subscript\u011f\ufffd\u0153\u20262 \u00e2\u2030\u00a4 roman_min { italic_\u00ce\u00ba start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u00ce\u00ba start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT }, we can derive for \u00ce\u00b3\u00e2\u02c6\u02c6(0,1)\u011f\ufffd\u203a\u00be01 \u00e2\u02c6\u02c6 ( 0 , 1 ) , Vt=\u011f\ufffd\u2019\u00aa\u00e2\ufffd\u00a2((1\u00e2\u02c6\u2019\u00ce\u00b3)t)subscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2019\u00aasuperscript1\u011f\ufffd\u203a\u00be\u011f\ufffd\u2018\u00a1V_{t}= start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = caligraphic_O ( ( 1 - italic_\u00ce\u00b3 ) start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT ). With the definition of Vtsubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u00a1V_{t}italic_V start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, we derive \u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\ufffd\u00a2(t)\u00e2\u20ac\u20132=\u011f\ufffd\u2019\u00aa\u00e2\ufffd\u00a2((1\u00e2\u02c6\u2019\u00ce\u00b3)t)superscriptnorm\u00c2\u00af\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a12\u011f\ufffd\u2019\u00aasuperscript1\u011f\ufffd\u203a\u00be\u011f\ufffd\u2018\u00a1 over\u00c2\u00af start_ARG bold_x end_ARG ( italic_t ) \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = caligraphic_O ( ( 1 - italic_\u00ce\u00b3 ) start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT ). With the definition \u011f\ufffd\ufffd\u00b1\u00c2\u00af=\u011f\ufffd\ufffd\u00b1\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00ac\u00c2\u00af\u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00ac start_ARG bold_x end_ARG = bold_x - bold_s before, we know that \u011f\ufffd\ufffd\u00b1i\u00e2\ufffd\u00a2(t)subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) in Algorithm (12) converge exponentially to the optimal solution s\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018 \u00e2\u02c6\u2014s^{ start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT with the SST compressor. Based on the proof of Theorem 5 and Theorem 4, with (42) in mind, the system (12) becomes Define V1,t\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u0178\u201a,\u011f\ufffd\ufffd\u00b3)=12\u00e2\ufffd\u00a2(\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u0178\u201a\u00e2\u20ac\u20132+\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b3\u00e2\u20ac\u20132)subscript\u011f\ufffd\u2018\u20301\u011f\ufffd\u2018\u00a1subscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1perpendicular-to\u011f\ufffd\ufffd\u00b312superscriptnormsubscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1perpendicular-to2superscriptnorm\u011f\ufffd\ufffd\u00b32V_{1,t}( start_POSTSUBSCRIPT 1 , italic_t end_POSTSUBSCRIPT ( over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT , bold_z ) = divide start_ARG 1 end_ARG start_ARG 2 end_ARG ( \u00e2\u02c6\u00a5 over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + \u00e2\u02c6\u00a5 bold_z \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ), then where the second inequality is obtained by (37) and (45). Now that \u011f\ufffd\ufffd\u00b1e\u00e2\ufffd\u00a2(t+1)\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00b1e\u00e2\ufffd\u00a2(t)=\u00e2\u02c6\u2019\u00ce\u00ba0\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u201a\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e\u00e2\ufffd\u00a2(t),t)subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a11subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u0153\u20260\u011f\ufffd\ufffd\u201asubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t + 1 ) - bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ) = - italic_\u00ce\u00ba start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT bold_C ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ) , italic_t ), where \u011f\ufffd\ufffd\u00b1e\u00e2\u02c6\u02c6\u00e2\u201e\ufffddsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, achieves exponential convergence at the zero equilibrium, then clearly \u011f\ufffd\ufffd\u00b2e\u00e2\ufffd\u00a2(t+1)\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00b2e\u00e2\ufffd\u00a2(t)=\u00e2\u02c6\u2019\u00ce\u00ba0\u00e2\ufffd\u00a2\u011f\ufffd\u2019\ufffd\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b2e\u00e2\ufffd\u00a2(t),t)subscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a11subscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u0153\u20260\u011f\ufffd\u2019\ufffdsubscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a1 ,t)bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t + 1 ) - bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ) = - italic_\u00ce\u00ba start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT caligraphic_C ( bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ) , italic_t ), where \u011f\ufffd\ufffd\u00b2e\u00e2\u02c6\u02c6\u00e2\u201e\ufffdn\u00e2\ufffd\u00a2dsubscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_n italic_d end_POSTSUPERSCRIPT, achieves also. Then there exists positive constants C\u011f\ufffd\ufffd\u00b6Citalic_C, \u00ce\u00b3D<1subscript\u011f\ufffd\u203a\u00be\u011f\ufffd\ufffd\u00b71 start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT < 1, for any t\u011f\ufffd\u2018\u00a1titalic_t and N\u00e2\u02c6\u02c6\u00e2\u201e\u2022+\u011f\ufffd\u2018\ufffdsubscript\u00e2\u201e\u2022N \u00e2\u02c6\u02c6 blackboard_N start_POSTSUBSCRIPT + end_POSTSUBSCRIPT, the solution satisfies Assume \u00cf\u2022tt+N\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b2e\u00e2\ufffd\u00a2(t))superscriptsubscriptitalic-\u00cf\u2022\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t + italic_N end_POSTSUPERSCRIPT ( bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ) ) is the state of system \u011f\ufffd\ufffd\u00b2e\u00e2\ufffd\u00a2(t+1)\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00b2e\u00e2\ufffd\u00a2(t)=\u00e2\u02c6\u2019\u00ce\u00ba0\u00e2\ufffd\u00a2\u011f\ufffd\u2019\ufffd\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b2e\u00e2\ufffd\u00a2(t),t)subscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a11subscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u0153\u20260\u011f\ufffd\u2019\ufffdsubscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a1 ,t)bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t + 1 ) - bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ) = - italic_\u00ce\u00ba start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT caligraphic_C ( bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ) , italic_t ) in t+N\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffdt+Nitalic_t + italic_N moment with the state in t\u011f\ufffd\u2018\u00a1titalic_t moment is \u011f\ufffd\ufffd\u00b2e\u00e2\ufffd\u00a2(t)subscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ). It is easy to verified that for any \u011f\ufffd\ufffd\u00b2\u00e2\u02c6\u02c6\u00e2\u201e\ufffdn\u00e2\ufffd\u00a2d\u011f\ufffd\ufffd\u00b2superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2018 \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_n italic_d end_POSTSUPERSCRIPT and some L\u00cf\u2022>0subscript\u011f\ufffd\ufffd\u00bfitalic-\u00cf\u20220L_{ start_POSTSUBSCRIPT italic_\u00cf\u2022 end_POSTSUBSCRIPT > 0 by property of compressor \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a With (LABEL:eq:DPD.a.Vec3) in mind, we can proof Lyapunov function Ve\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b2e,t)=\u00e2\u02c6\u2018j=0N\u00e2\u02c6\u20191\u00e2\u20ac\u2013\u00cf\u2022tt+j\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b2e)\u00e2\u20ac\u20132subscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2019subscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1superscriptsubscript\u011f\ufffd\u2018\u20140\u011f\ufffd\u2018\ufffd1superscriptnormsuperscriptsubscriptitalic-\u00cf\u2022\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u20192V_{e}( start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) = \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_j = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N - 1 end_POSTSUPERSCRIPT \u00e2\u02c6\u00a5 italic_\u00cf\u2022 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t + italic_j end_POSTSUPERSCRIPT ( bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ) \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT with some N>0\u011f\ufffd\u2018\ufffd0N>0italic_N > 0 satisfies for c1=1,c2=N\u00e2\ufffd\u00a2L\u00cf\u2022,c3>0formulae-sequencesubscript\u011f\ufffd\u2018\ufffd11formulae-sequencesubscript\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\ufffd\u00bfitalic-\u00cf\u2022subscript\u011f\ufffd\u2018\ufffd30c_{1}=1,c_{2}=NL_{ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1 , italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = italic_N italic_L start_POSTSUBSCRIPT italic_\u00cf\u2022 end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT > 0. Besides, for \u00ce\u00b8=2+2\u00e2\ufffd\u00a2Lc2\u00e2\ufffd\u00a2\u00ce\u00ba02>0\u011f\ufffd\u0153\u019222superscriptsubscript\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\ufffd2superscriptsubscript\u011f\ufffd\u0153\u2026020 = 2 + 2 italic_L start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_\u00ce\u00ba start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT > 0 by property of \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a Moreover, (47) still holds. Define V2\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00b1\u00c2\u00afc,t):=Ve\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00b1\u00c2\u00afc,t)assignsubscript\u011f\ufffd\u2018\u20302\u00c2\u00af\u011f\ufffd\ufffd\u00b1subscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2019\u00c2\u00af\u011f\ufffd\ufffd\u00b1subscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1V_{2}( start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( over\u00c2\u00af start_ARG bold_x end_ARG - over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT , italic_t ) := italic_V start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( over\u00c2\u00af start_ARG bold_x end_ARG - over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT , italic_t ), we can derive for c4:=N\u00e2\ufffd\u00a2L\u00cf\u2022\u00e2\ufffd\u00a2\u00ce\u00b8assignsubscript\u011f\ufffd\u2018\ufffd4\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\ufffd\u00bfitalic-\u00cf\u2022\u011f\ufffd\u0153\u0192c_{4}:=NL_{ start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT := italic_N italic_L start_POSTSUBSCRIPT italic_\u00cf\u2022 end_POSTSUBSCRIPT italic_\u00ce\u00b8, where the first inequality is obtained by \u011f\ufffd\ufffd\u00af\u00c2\u00af=\u011f\ufffd\u2022\u0160\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00af\u00c2\u00af\u00e2\u0178\u201a\u00c2\u00af\u011f\ufffd\ufffd\u00af\u011f\ufffd\u2022\u0160subscript\u00c2\u00af\u011f\ufffd\ufffd\u00afperpendicular-to start_ARG bold_v end_ARG = blackboard_S over\u00c2\u00af start_ARG bold_v end_ARG start_POSTSUBSCRIPT \u00e2\u0178\u201a end_POSTSUBSCRIPT, (63) and (64), and the last inequality is obtained by (37), (47) and Young\u00e2\u20ac\u2122s Inequality, where r>0\u011f\ufffd\u2018\u01780r>0italic_r > 0 is a parameter which will be determined later. Define V3,t\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u02c6\u00a5):=12\u00e2\ufffd\u00a2\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u02c6\u00a5\u00e2\u20ac\u20132assignsubscript\u011f\ufffd\u2018\u20303\u011f\ufffd\u2018\u00a1subscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1parallel-to12superscriptnormsubscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1parallel-to2V_{3,t}( _{ start_POSTSUBSCRIPT 3 , italic_t end_POSTSUBSCRIPT ( over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u02c6\u00a5 end_POSTSUBSCRIPT ) := divide start_ARG 1 end_ARG start_ARG 2 end_ARG \u00e2\u02c6\u00a5 over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT \u00e2\u02c6\u00a5 end_POSTSUBSCRIPT \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, then (59) still holds. We introduce some parameters \u00cf\u20211subscript\u011f\ufffd\u0153\u20191 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, \u00ce\u00be1subscript\u011f\ufffd\u0153\u20301 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT\u00e2\u20ac\u00a6>0absent0>0> 0 that have nothing to do with \u00ce\u00b1\u011f\ufffd\u203a\u00bc \u00ce\u00b2\u011f\ufffd\u203a\u00bd r\u011f\ufffd\u2018\u0178ritalic_r and \u00ce\u00b7\u011f\ufffd\u0153\u201a and some parameters \u00ce\u00b61subscript\u011f\ufffd\u0153\ufffd1 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, \u00ce\u00b62subscript\u011f\ufffd\u0153\ufffd2 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT\u00e2\u20ac\u00a6>0absent0>0> 0. We define the Lyapunov functions of system (43) Vt:=V1,t+V2,t+\u00cf\u20211\u00e2\ufffd\u00a2V3,tassignsubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\u20301\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\u20302\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u0153\u20191subscript\u011f\ufffd\u2018\u20303\u011f\ufffd\u2018\u00a1V_{t}:=V_{1,t}+V_{2,t}+ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT := italic_V start_POSTSUBSCRIPT 1 , italic_t end_POSTSUBSCRIPT + italic_V start_POSTSUBSCRIPT 2 , italic_t end_POSTSUBSCRIPT + italic_\u00cf\u2021 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_V start_POSTSUBSCRIPT 3 , italic_t end_POSTSUBSCRIPT. It is easy to prove that Vtsubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u00a1V_{t}italic_V start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is positive definite. In fact First, let\u00e2\u20ac\u2122s impose some prime limit (49). By (62), (65), (59) (49), we can derive \u00ce\u201d\u00e2\ufffd\u00a2Vt\u00ce\u201dsubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u00a1 italic_V start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is negative when we choose r=min\u00e2\ufffd\u00a2{\u00ce\u00be14\u00e2\ufffd\u00a2\u00ce\u00be3,14\u00e2\ufffd\u00a2\u00ce\u00be5,1}\u011f\ufffd\u2018\u0178minsubscript\u011f\ufffd\u0153\u203014subscript\u011f\ufffd\u0153\u2030314subscript\u011f\ufffd\u0153\u203051r= = roman_min { divide start_ARG italic_\u00ce\u00be start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG 4 italic_\u00ce\u00be start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG , divide start_ARG 1 end_ARG start_ARG 4 italic_\u00ce\u00be start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT end_ARG , 1 }, \u00ce\u00ba\u00e2\u2030\u00a4\u00ce\u00ba1=c32\u00e2\ufffd\u00a2\u00ce\u00be6\u00e2\ufffd\u00a2r+2\u00e2\ufffd\u00a2\u00ce\u00be7\u011f\ufffd\u0153\u2026subscript\u011f\ufffd\u0153\u20261subscript\u011f\ufffd\u2018\ufffd32subscript\u011f\ufffd\u0153\u20306\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u0153\u20307 \u00e2\u2030\u00a4 italic_\u00ce\u00ba start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = divide start_ARG italic_c start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG start_ARG 2 italic_\u00ce\u00be start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT italic_r + 2 italic_\u00ce\u00be start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT end_ARG, \u00ce\u00b22\u00e2\u2030\u00a4min\u00e2\ufffd\u00a2{1,\u00ce\u00be14\u00e2\ufffd\u00a2\u00ce\u00be2}superscript\u011f\ufffd\u203a\u00bd2min1subscript\u011f\ufffd\u0153\u203014subscript\u011f\ufffd\u0153\u20302 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT \u00e2\u2030\u00a4 roman_min { 1 , divide start_ARG italic_\u00ce\u00be start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG 4 italic_\u00ce\u00be start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG }, \u00ce\u00b7\u00e2\u2030\u00a4min\u00e2\ufffd\u00a2{\u00ce\u00b22,14\u00e2\ufffd\u00a2\u00ce\u00be4}\u011f\ufffd\u0153\u201aminsuperscript\u011f\ufffd\u203a\u00bd214subscript\u011f\ufffd\u0153\u20304 \u00e2\u2030\u00a4 roman_min { italic_\u00ce\u00b2 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , divide start_ARG 1 end_ARG start_ARG 4 italic_\u00ce\u00be start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT end_ARG } and \u00ce\u00ba\u00e2\u2030\u00a4\u00ce\u00ba2:=12\u00e2\ufffd\u00a2min\u00e2\ufffd\u00a2{\u00ce\u00be12\u00e2\ufffd\u00a2\u00ce\u00b61,\u00ce\u00b222\u00e2\ufffd\u00a2\u00ce\u00b62,\u00ce\u00b7\u00e2\ufffd\u00a2\u00cf\u20211\u00e2\ufffd\u00a2\u00ce\u00bcn4\u00e2\ufffd\u00a2\u00ce\u00b63,c32\u00e2\ufffd\u00a2\u00ce\u00b64}\u011f\ufffd\u0153\u2026subscript\u011f\ufffd\u0153\u20262assign12minsubscript\u011f\ufffd\u0153\u203012subscript\u011f\ufffd\u0153\ufffd1superscript\u011f\ufffd\u203a\u00bd22subscript\u011f\ufffd\u0153\ufffd2\u011f\ufffd\u0153\u201asubscript\u011f\ufffd\u0153\u20191subscript\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u203a4subscript\u011f\ufffd\u0153\ufffd3subscript\u011f\ufffd\u2018\ufffd32subscript\u011f\ufffd\u0153\ufffd4 }}{2 \u00e2\u2030\u00a4 italic_\u00ce\u00ba start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT := divide start_ARG 1 end_ARG start_ARG 2 end_ARG roman_min { divide start_ARG italic_\u00ce\u00be start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG 2 italic_\u00ce\u00b6 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG , divide start_ARG italic_\u00ce\u00b2 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG 2 italic_\u00ce\u00b6 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG , italic_\u00ce\u00b7 divide start_ARG italic_\u00cf\u2021 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_\u00ce\u00bc start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_ARG start_ARG 4 italic_\u00ce\u00b6 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG , divide start_ARG italic_c start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG start_ARG 2 italic_\u00ce\u00b6 start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT end_ARG }. With (66), then Let \u00ce\u00ba3:=2/min\u00e2\ufffd\u00a2{\u00ce\u00be1,\u00ce\u00b22,\u00ce\u00b7\u00e2\ufffd\u00a2\u00ce\u00bcn2,c32\u00e2\ufffd\u00a2c1}assignsubscript\u011f\ufffd\u0153\u202632minsubscript\u011f\ufffd\u0153\u20301superscript\u011f\ufffd\u203a\u00bd2\u011f\ufffd\u0153\u201asubscript\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u203a2subscript\u011f\ufffd\u2018\ufffd32subscript\u011f\ufffd\u2018\ufffd1 c_{3}}{2c_{1}} start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT := 2 / roman_min { italic_\u00ce\u00be start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u00ce\u00b2 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , italic_\u00ce\u00b7 divide start_ARG italic_\u00ce\u00bc start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_ARG start_ARG 2 end_ARG , divide start_ARG italic_c start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG start_ARG 2 italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG }, When \u00ce\u00ba\u00e2\u2030\u00a4min\u00e2\ufffd\u00a2{\u00ce\u00ba1,\u00ce\u00ba2,\u00ce\u00ba3}\u011f\ufffd\u0153\u2026minsubscript\u011f\ufffd\u0153\u20261subscript\u011f\ufffd\u0153\u20262subscript\u011f\ufffd\u0153\u20263 \u00e2\u2030\u00a4 roman_min { italic_\u00ce\u00ba start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u00ce\u00ba start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_\u00ce\u00ba start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT }, we can derive for \u00ce\u00b3\u00e2\u02c6\u02c6(0,1)\u011f\ufffd\u203a\u00be01 \u00e2\u02c6\u02c6 ( 0 , 1 ) , Vt=\u011f\ufffd\u2019\u00aa\u00e2\ufffd\u00a2((1\u00e2\u02c6\u2019\u00ce\u00b3)t)subscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2019\u00aasuperscript1\u011f\ufffd\u203a\u00be\u011f\ufffd\u2018\u00a1V_{t}= start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = caligraphic_O ( ( 1 - italic_\u00ce\u00b3 ) start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT ). With the definition of Vtsubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u00a1V_{t}italic_V start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, we derive \u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\ufffd\u00a2(t)\u00e2\u20ac\u20132=\u011f\ufffd\u2019\u00aa\u00e2\ufffd\u00a2((1\u00e2\u02c6\u2019\u00ce\u00b3)t)superscriptnorm\u00c2\u00af\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a12\u011f\ufffd\u2019\u00aasuperscript1\u011f\ufffd\u203a\u00be\u011f\ufffd\u2018\u00a1 over\u00c2\u00af start_ARG bold_x end_ARG ( italic_t ) \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = caligraphic_O ( ( 1 - italic_\u00ce\u00b3 ) start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT ). With the definition \u011f\ufffd\ufffd\u00b1\u00c2\u00af=\u011f\ufffd\ufffd\u00b1\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00ac\u00c2\u00af\u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00ac start_ARG bold_x end_ARG = bold_x - bold_s before, we know that \u011f\ufffd\ufffd\u00b1i\u00e2\ufffd\u00a2(t)subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) in Algorithm (12) converge exponentially to the optimal solution s\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018 \u00e2\u02c6\u2014s^{ start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT with the ST compressor. The idea of proof is quite similar to that in Appendix G. We just recalculate \u00ce\u201d\u00e2\ufffd\u00a2V2,t\u00ce\u201dsubscript\u011f\ufffd\u2018\u20302\u011f\ufffd\u2018\u00a1 V_{2,t}roman_\u00ce\u201d italic_V start_POSTSUBSCRIPT 2 , italic_t end_POSTSUBSCRIPT with stochastic impact while the other proof process is the same. Now that \u011f\ufffd\ufffd\u00b1e\u00e2\ufffd\u00a2(t+1)\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00b1e\u00e2\ufffd\u00a2(t)=\u00e2\u02c6\u2019\u00ce\u00ba0\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u201a\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1e\u00e2\ufffd\u00a2(t),t)subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a11subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u0153\u20260\u011f\ufffd\ufffd\u201asubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t + 1 ) - bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ) = - italic_\u00ce\u00ba start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT bold_C ( bold_x start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ) , italic_t ), where \u011f\ufffd\ufffd\u00b1e\u00e2\ufffd\u00a2(t)\u00e2\u02c6\u02c6\u00e2\u201e\ufffddsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ) \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, achieves mean square exponential convergence at the zero equilibrium, then clearly \u011f\ufffd\ufffd\u00b2e\u00e2\ufffd\u00a2(t+1)\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00b2e=\u00e2\u02c6\u2019\u00ce\u00ba0\u00e2\ufffd\u00a2\u011f\ufffd\u2019\ufffd\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b2e,t)subscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a11subscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019subscript\u011f\ufffd\u0153\u20260\u011f\ufffd\u2019\ufffdsubscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t + 1 ) - bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT = - italic_\u00ce\u00ba start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT caligraphic_C ( bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ), where \u011f\ufffd\ufffd\u00b2e\u00e2\u02c6\u02c6\u00e2\u201e\ufffdn\u00e2\ufffd\u00a2dsubscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2018 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_n italic_d end_POSTSUPERSCRIPT, achieves also. Then there exists positive constants C\u011f\ufffd\ufffd\u00b6Citalic_C, \u00ce\u00b3<1\u011f\ufffd\u203a\u00be1 < 1, for any t\u011f\ufffd\u2018\u00a1titalic_t and T\u00e2\u02c6\u02c6\u00e2\u201e\u2022+\u011f\ufffd\u2018\u2021subscript\u00e2\u201e\u2022T \u00e2\u02c6\u02c6 blackboard_N start_POSTSUBSCRIPT + end_POSTSUBSCRIPT, the solution satisfies Assume \u00cf\u2022tt+N\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b2e)superscriptsubscriptitalic-\u00cf\u2022\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t + italic_N end_POSTSUPERSCRIPT ( bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ) is the state of system \u011f\ufffd\ufffd\u00b2e\u00e2\ufffd\u00a2(t+1)\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00b2e\u00e2\ufffd\u00a2(t)=\u00e2\u02c6\u2019\u00ce\u00ba0\u00e2\ufffd\u00a2\u011f\ufffd\u2019\ufffd\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b2e\u00e2\ufffd\u00a2(t),t)subscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a11subscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u0153\u20260\u011f\ufffd\u2019\ufffdsubscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a1 ,t)bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t + 1 ) - bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ) = - italic_\u00ce\u00ba start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT caligraphic_C ( bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ) , italic_t ) in t+N\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffdt+Nitalic_t + italic_N moment with the state in t\u011f\ufffd\u2018\u00a1titalic_t moment is \u011f\ufffd\ufffd\u00b2e\u00e2\ufffd\u00a2(t)subscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_t ). It is easy to verified that for any \u011f\ufffd\ufffd\u00b2\u00e2\u02c6\u02c6\u00e2\u201e\ufffd(n\u00e2\u02c6\u20191)\u00e2\ufffd\u00a2d\u011f\ufffd\ufffd\u00b2superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u203a1\u011f\ufffd\u2018\u2018 \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT ( italic_n - 1 ) italic_d end_POSTSUPERSCRIPT and some L\u00cf\u2022>0subscript\u011f\ufffd\ufffd\u00bfitalic-\u00cf\u20220L_{ start_POSTSUBSCRIPT italic_\u00cf\u2022 end_POSTSUBSCRIPT > 0 by property of compressor \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a With (LABEL:eq:DPD.a.Vec3) in mind, we can proof Lyapunov function Ve\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b2e,t)=\u00e2\u02c6\u2018j=0N\u00e2\u02c6\u20191\u00e2\u20ac\u2013\u00cf\u2022tt+j\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b2e)\u00e2\u20ac\u20132subscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2019subscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1superscriptsubscript\u011f\ufffd\u2018\u20140\u011f\ufffd\u2018\ufffd1superscriptnormsuperscriptsubscriptitalic-\u00cf\u2022\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\ufffd\u00b2\u011f\ufffd\u2018\u20192V_{e}( start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT , italic_t ) = \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_j = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N - 1 end_POSTSUPERSCRIPT \u00e2\u02c6\u00a5 italic_\u00cf\u2022 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t + italic_j end_POSTSUPERSCRIPT ( bold_y start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ) \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT with some N>0\u011f\ufffd\u2018\ufffd0N>0italic_N > 0 satisfies for c1=1,c2=N\u00e2\ufffd\u00a2L\u00cf\u2022,c3>0formulae-sequencesubscript\u011f\ufffd\u2018\ufffd11formulae-sequencesubscript\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\ufffd\u00bfitalic-\u00cf\u2022subscript\u011f\ufffd\u2018\ufffd30c_{1}=1,c_{2}=NL_{ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1 , italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = italic_N italic_L start_POSTSUBSCRIPT italic_\u00cf\u2022 end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT > 0. Besides, for \u00ce\u00b8=2+2\u00e2\ufffd\u00a2Lc2\u00e2\ufffd\u00a2\u00ce\u00ba02>0\u011f\ufffd\u0153\u019222subscriptsuperscript\u011f\ufffd\ufffd\u00bf2\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u0153\u2026020 = 2 + 2 italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT italic_\u00ce\u00ba start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT > 0 by property of \u011f\ufffd\ufffd\u201a\u011f\ufffd\ufffd\u201a Define V2\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00b1\u00c2\u00afc,t):=Ve\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00b1\u00c2\u00afc,t)assignsubscript\u011f\ufffd\u2018\u20302\u00c2\u00af\u011f\ufffd\ufffd\u00b1subscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u2019\u00c2\u00af\u011f\ufffd\ufffd\u00b1subscript\u00c2\u00af\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1V_{2}( start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( over\u00c2\u00af start_ARG bold_x end_ARG - over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT , italic_t ) := italic_V start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( over\u00c2\u00af start_ARG bold_x end_ARG - over\u00c2\u00af start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT , italic_t ), with (65) in mind, we can derive for c4:=N\u00e2\ufffd\u00a2L\u00cf\u2022\u00e2\ufffd\u00a2\u00ce\u00b8assignsubscript\u011f\ufffd\u2018\ufffd4\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\ufffd\u00bfitalic-\u00cf\u2022\u011f\ufffd\u0153\u0192c_{4}:=NL_{ start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT := italic_N italic_L start_POSTSUBSCRIPT italic_\u00cf\u2022 end_POSTSUBSCRIPT italic_\u00ce\u00b8, where the first inequality is obtained (67) and (68), and r>0\u011f\ufffd\u2018\u01780r>0italic_r > 0 is a parameter which will be determined later. We define the same Vtsubscript\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u00a1V_{t}italic_V start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT as that in Appendix G, then (66) holds and we have with the same parameters. Then we can derive \u011f\ufffd\u201d\u00bc\u00e2\ufffd\u00a2\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u00b1\u00c2\u00af\u00e2\ufffd\u00a2(t)\u00e2\u20ac\u20132=\u011f\ufffd\u2019\u00aa\u00e2\ufffd\u00a2((1\u00e2\u02c6\u2019\u00ce\u00b3)t)\u011f\ufffd\u201d\u00bcsuperscriptnorm\u00c2\u00af\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a12\u011f\ufffd\u2019\u00aasuperscript1\u011f\ufffd\u203a\u00be\u011f\ufffd\u2018\u00a1 \u00e2\u02c6\u00a5 over\u00c2\u00af start_ARG bold_x end_ARG ( italic_t ) \u00e2\u02c6\u00a5 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = caligraphic_O ( ( 1 - italic_\u00ce\u00b3 ) start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT ). With the definition \u011f\ufffd\ufffd\u00b1\u00c2\u00af=\u011f\ufffd\ufffd\u00b1\u00e2\u02c6\u2019\u011f\ufffd\ufffd\u00ac\u00c2\u00af\u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00ac start_ARG bold_x end_ARG = bold_x - bold_s before, we know that the mean square of \u011f\ufffd\ufffd\u00b1i\u00e2\ufffd\u00a2(t)subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) in Algorithm (12) converge exponentially to the optimal solution s\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018 \u00e2\u02c6\u2014s^{ start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT with the StST compressor.",
        "keywords": ""
    },
    {
        "id": 17,
        "title": "Enhancing Trustworthiness and Minimising Bias Issues in Leveraging Social Media Data for Disaster Management Response",
        "abstract": "AbstractDisaster events often unfold rapidly, necessitating a swift and effective response. Developing plans of action, resource allocation, and resolution of help requests in disaster scenarios is a time-consuming and complex process since the disaster-relevant information is often uncertain. Leveraging real-time data can significantly deal with data uncertainty and enhance disaster response efforts. To deal with uncertainty in data in real-time, social media appeared as an alternative effective source of real-time data as there has been extensive use of social media during and after the disasters. However, it also brings forth challenges regarding trustworthiness and bias in these data. To fully leverage social media data for disaster management, it becomes crucial to mitigate biases that may arise due to specific disaster types or regional contexts. Additionally, the presence of misinformation within social media data raises concerns about the reliability of data sources, potentially impeding actionable insights and leading to improper resource utilization. To overcome these challenges, our research aimed to investigate how to ensure trustworthiness and address biases in social media data. We aim to investigate to identify the factors that can be used to enhance trustworthiness and minimize bias to make an efficient and scalable disaster management system utilizing real-time social media posts, identify disaster-related keywords, and assess the severity of the disaster. By doing so, the integration of real-time social data can improve the speed and accuracy of disaster management systems.",
        "corpus": "Disaster events often unfold rapidly, necessitating a swift and effective response. Developing plans of action, resource allocation, and resolution of help requests in disaster scenarios is a time-consuming and complex process since the disaster-relevant information is often uncertain. Leveraging real-time data can significantly deal with data uncertainty and enhance disaster response efforts. To deal with uncertainty in data in real-time, social media appeared as an alternative effective source of real-time data as there has been extensive use of social media during and after the disasters. However, it also brings forth challenges regarding trustworthiness and bias in these data. To fully leverage social media data for disaster management, it becomes crucial to mitigate biases that may arise due to specific disaster types or regional contexts. Additionally, the presence of misinformation within social media data raises concerns about the reliability of data sources, potentially impeding actionable insights and leading to improper resource utilization. To overcome these challenges, our research aimed to investigate how to ensure trustworthiness and address biases in social media data. We aim to investigate to identify the factors that can be used to enhance trustworthiness and minimize bias to make an efficient and scalable disaster management system utilizing real-time social media posts, identify disaster-related keywords, and assess the severity of the disaster. By doing so, the integration of real-time social data can improve the speed and accuracy of disaster management systems. Disasters, whether natural or human-induced, have profound impacts on society. Its consequences include the human toll, environmental degradation, economic loss, psychological disruption, and infrastructure damage [1]. Unfortunate events like Hurricane Sandy (2012), the Nepal Earthquake (2015), Hurricane Harvey (2017), Cyclone Idai (2019), the ongoing COVID-19 pandemic [2], and the Palestine-Israel conflict, etc have resulted in the loss of millions of lives, disrupted the economies, and strained healthcare systems. In such uncertain scenarios, effective disaster management and decision-making systems are central to mitigating and minimizing the effects of future calamities. However, not all emergency stakeholders possess specialized expertise in emergencies [3]. The rise of social networks plays an important role in bridging the gap between stakeholders and those with more informed decision-making capabilities. Among various communication mediums, social media platforms have proven to be effective in disseminating real-time situational awareness, and safety instructions and facilitating rapid response. It has been reported that 5.04 billion people worldwide now use social media, a significant increase from the 3.6 billion users recorded in 2020 [4]. Due to the accessibility of platforms like Facebook, Twitter, and Instagram, social media have been recognized as a powerful data source for studying disastrous events over the last decade. Compared to traditional methods of data collection like cameras [5], RFID readers [6], and GPS information [7], social media data has promising merits: 1) scrapping posts from social media is economical, 2) the availability of user-generated content that can only be acquired through traditional data sources and government and regulatory organizations 3) real-time disaster updates, and 4) swift data acquisition. A massive amount and variety of user-generated content is shared on social media. These platforms enable a human-centric approach where the public can share rich footprints of disastrous events that can be used to enhance the effectiveness of disaster management systems. With potential benefits, several challenges are associated with the vast unstructured data coming from indeterminant sources [8]. First, determining the veracity and quality of data sources is a significant issue. A reliable disaster management system demands trust in data for responsible disaster management. Moreover, to fully leverage social media data for disaster management, it is essential to aim at the conscious elimination of biases that may arise due to specific disaster types or regional contexts. Otherwise, these biases will be encoded into the latent representation of the disaster management system which in turn will result in unfair responses. This research work is dedicated to mitigating biases and ensuring the trustworthiness and quality of social media data for a fair and responsible disaster management and response system. We investigate the approaches that can enhance the veracity and quality of social media data. The approaches explored in this work can ensure the integrity of a scalable disaster management system. The rest of the paper is organized as follows: Section II highlights the significant biases present in disaster-related social media data and provides effective mitigation strategies to address them. Section III focuses on trustworthiness concerns and the corresponding methods to tackle those issues. While Section IV concludes the presented work. Literature has witnessed the utilization of social media data in disaster management, contributing towards real-time crisis and public sentiments. Table I presents datasets used in the literature to advance research in disaster management and response. The CrisisLexT26 dataset has been utilized for early detection of crisis-related events [9]. CrisisNLP has been employed in research to develop a natural language processing tool to detect crisis-relevant information for humanitarian aid [10]. Moreover, CrisisMMD has facilitated multimodal analysis of crises, exploring the integration of text, image, and video data for enhanced situational awareness [11]. Similarly, the UnifiedCEHMET Dataset has demonstrated high precision in severity classification using deep learning methods [12]. These studies exhibit the versatility and significance of these datasets in advancing understanding and improving response strategies in disaster management. However, the human-driven nature of these social media datasets can exhibit socio-demographics, language preferences, content, and spatial biases. The datasets contain inherent biases that hinder precise evaluation and response to crisis events, while the representation of disasters affects response strategies and resource allocation. Recently, this dilemma has caught the attention of researchers, and various biases have been identified. The identified biases are presented in 1. To mitigate their impact several approaches are discussed in the subsequent subsections. The geographic bias in social media data can hinder disaster response efforts due to the skewed geographic distribution of data. Recent studies have highlighted that the uneven representation of certain locations or regions leads to disparities in data coverage during disaster situations [13]. To address this issue, spatial sampling helps to enhance geographic representativeness by collecting data from diverse geographic regions. To quantify and visualize geographic biases in the dataset, sampbias has been developed as a tool to promote the usefulness of data in several research areas [14]. Moreover, sampling techniques like the synthetic minority over-sampling technique (SMOTE) can improve the representativeness of the skewed instances from the majority regions [15]. By mitigating the geographic concentration of data, the machine-learning models will be more effective at capturing situations from social media in disasters. Language biases can limit the inclusivity and comprehensiveness of the data. It arises in social media-based datasets from the prevalent utilization of specific languages to post help and rescue requests in crises. According to [16], the language of posts shared on social media data is categorized into four types, including, i) global language, ii) local language, iii) mixed language, and iv) mixed script. Being the global language, most social media posts are shared in English. Potential countermeasures to demographic language bias are multilingual data collection [17] and utilization of translation services. The inception of large language models (LLMs) has advanced the field of natural language processing. Multilingual LLMs (MLLMs) address lingual biases because these language models are trained on multiple languages [18]. Notable examples of MLLMs include mBERT [19], XLM-R [20], PaLM [21], mT5 [22], Falcon [23], BLOOM [24], and LLaMA [25]. These MLLMs are trained on multiple languages and provide reasonably fair language processing capabilities. BLOOM is an outstanding MLLM due to its ability to support 46 languages, including French, English, African, Indonesian, Mandarin, etc. However, despite these advancements certain challenges like corpora, misalignment of MLLMs, and inherent biases in corpora still persist. To exemplify, ChatGPT is trained on 92.099% of English Corpora and only 0.16% of the corpora account for the Chinese language. True multilingualism can be achieved by creating a high-quality multilingual dataset. This area is undervalued and needs the attention of researchers. For a fair and unbiased representation of the training data, de-biasing the crisis-relevant data while preserving the important information is of paramount significance. To maintain the representation integrity, the learning fair representation (LFR) algorithm [26] is designed to transform the training data while minimizing the loss of non-sensitive instances. Additionally, the prejudice-free representations (PFR) algorithm [27] is proposed to identify and remove the features causing discrimination in the dataset, particularly those relevant to the sensitive attributes. By utilizing representation methods like LFR and PFR, the fairness of models in de-biasing disaster-relevant data can be ensured. The trustworthiness of social media-based user-generated content is of paramount importance. The human-driven and diverse nature of the content and the spread of misinformation pose significant threats. It requires attention to assess the trustworthiness of the information provided on social media before using it for crisis-relevant applications, since the content may have been generated to spread false information. To combat these concerns and entrust social-media information relevant to sensitive events, various approaches have been proposed in the existing research (presented in Fig 2. In this section, we delve into existing techniques and mitigation strategies to ensure the quality and authenticity of social media data during disasters. It is essential to understand the dynamics of disaster-relevant social media users that contribute to data quality and trustworthiness. The main actors that spread information in crises are non-governmental organizations, government agencies, research/academic bodies, and public profiles [16]. Information disseminated through government organizations\u2019 accounts is more trusted than that of a personal account. However, government authorities are noticed to be showing reduced participation in informing communities of the crises. Public users, on the other hand, have promising engagement on social media platforms. Enhancing Data Verification: The verification of social media data emphasizes the development of mechanisms to assure trust. Algorithms such as Na\u00efve Bayes and Feature Tree (FT) classifiers are used to detect spam and fake posts on social media during crises [28]. These algorithms are utilized to distinguish between legitimate and false tweets with significance. Moreover, factors such as verified accounts, premium subscription services, and engagement metrics play an important role in ensuring trust in social media content and combatting misinformation propagation. In Twitter, factors like verified users, blue tick subscriptions, and retweet metrics enhance the trust level of their shared content. Transfer Learning: Advanced transformer-based language models like BERT or RoBERTa leveraging transfer learning facilitate the detection of misinformation conveyed on social media platforms [29]. Fine-tuning these models on misinformation datasets can help the system identify misleading information. Thereby, the reliability of the information disseminated on social media platforms can be enhanced. Deepfake Detection Techniques: Researchers are exploring various approaches utilizing Deepfake detection techniques to discern real from manipulated media [30]. Computer vision methodologies and deep neural networks are among the approaches that can be employed to mitigate potential implications leading to distrust. Early Detection Using Linguistic Patterns: Early identification of fraudulent information on social media platforms is made possible by linguistic cue analysis linked to misinformation and user attribute inference based on linguistic traits. By understanding various patterns like how the information spreads and recognizing linguistic traits indicative of misinformation, it is possible to mitigate the spread of false information. For instance, authors in [31] address the spread of misinformation on Twitter during the COVID-19 pandemic. The authors analyzed textual and non-textual cues to understand their influence on retweeting behavior and the spread of false information on social media. By analyzing 4923 tweets featuring disaster-relevant hashtags in May 2020, the study aims to discern retweet probability and volume. For this purpose, they have focused on employing logistic regression and machine learning techniques. These approaches can be leveraged in disaster management and response applications to enhance trust in social media data. These methods facilitate effective management for resource allocation and rescue during disastrous events. Disaster, either natural or human-induced, necessitates swift response to the situations for effective allocation of resources to mitigate the loss and save lives. The prevalent utilization of social media data has made it possible due to rich user-generated content which can help disaster management systems locate the victims and volunteers. However, social media data has challenges in terms of certain biases and trustworthiness. To encounter these issues, we have identified three types of biases that need to be mitigated before the utilization of social media data for sensitive crisis-relevant decision-making systems. We also highlight the importance of verifying the authenticity and quality of information posted on these platforms to ensure trustworthiness. For this purpose, we have explored several techniques from the literature to ensure trust in social media data by identifying misleading content. Incorporating the factors that can be used to enhance trustworthiness and minimize bias can help to develop an efficient and scalable disaster management system utilizing real-time social media posts. In the future, we intend to conduct rigorous analysis by considering case studies to provide empirical evidence. Furthermore, we will delve into the challenges and limitations of the mitigation strategies discussed in this research by focusing on concerns regarding implementation, resource constraints, and adaptability. It will help in the successful adoption of the proposed strategies and highlight the need for future research in this area.",
        "keywords": "Index Terms: \nTrustworthiness, Bias Minimization, Social Media Data, Disaster Management"
    },
    {
        "id": 18,
        "title": "iSurgARy: A mobile augmented reality solution for ventriculostomy in resource-limited settings",
        "abstract": "AbstractGlobal disparities in neurosurgical care necessitate innovations addressing affordability and accuracy, particularly for critical procedures like ventriculostomy. This intervention, vital for managing life-threatening intracranial pressure increases, is associated with catheter misplacement rates exceeding 30% when using a freehand technique. Such misplacements hold severe consequences including haemorrhage, infection, prolonged hospital stays, and even morbidity and mortality. To address this issue, we present a novel, stand-alone mobile-based augmented reality system (iSurgARy) aimed at significantly improving ventriculostomy accuracy, particularly in resource-limited settings such as those in low- and middle-income countries. iSurgARy uses landmark based registration by taking advantage of Light Detection and Ranging (LiDaR) to allow for accurate surgical guidance. To evaluate iSurgARy, we conducted a two-phase user study. Initially, we assessed usability and learnability with novice participants using the System Usability Scale (SUS), incorporating their feedback to refine the application. In the second phase, we engaged human-computer interaction (HCI) and clinical domain experts to evaluate our application, measuring Root Mean Square Error (RMSE), System Usability Scale (SUS) and NASA Task Load Index (TLX) metrics to assess accuracy usability, and cognitive workload, respectively.",
        "corpus": "Global disparities in neurosurgical care necessitate innovations addressing affordability and accuracy, particularly for critical procedures like ventriculostomy. This intervention, vital for managing life-threatening intracranial pressure increases, is associated with catheter misplacement rates exceeding 30% when using a freehand technique. Such misplacements hold severe consequences including haemorrhage, infection, prolonged hospital stays, and even morbidity and mortality. To address this issue, we present a novel, stand-alone mobile-based augmented reality system (iSurgARy) aimed at significantly improving ventriculostomy accuracy, particularly in resource-limited settings such as those in low- and middle-income countries. iSurgARy uses landmark based registration by taking advantage of Light Detection and Ranging (LiDaR) to allow for accurate surgical guidance. To evaluate iSurgARy, we conducted a two-phase user study. Initially, we assessed usability and learnability with novice participants using the System Usability Scale (SUS), incorporating their feedback to refine the application. In the second phase, we engaged human-computer interaction (HCI) and clinical domain experts to evaluate our application, measuring Root Mean Square Error (RMSE), System Usability Scale (SUS) and NASA Task Load Index (TLX) metrics to assess accuracy usability, and cognitive workload, respectively. Ventriculostomy, a common neurosurgical procedure, establishes a drainage pathway for cerebrospinal fluid (CSF) from the brain ventricles to a collection and monitoring system at bedside. This intervention aims to relieve excessive intracranial pressure within the skull caused by obstructed CSF flow. The need for ventriculostomy arises when various pathological processes such as hemorrhages (e.g., aneurysms and vascular malformations), head trauma, tumours, spina bifida, hydrocephalus, or congenital issues block or impede normal CSF flow, CSF production, or its absorption. A recent global study found that traumatic brain injury (TBI) and the presence of hydrocephalus accounts for 45% and 7%, respectively, of all cases admitted for acute neurosurgical care.\u00c2 [21]. Placement of an external ventricular catheter (ventriculostomy) involves drilling a small hole in the skull and carefully inserting a thin, flexible catheter into the ventricle. Pre-operative CT scans along with well-known external cranial landmarks are typically used to guide placement for optimal accuracy. Relying solely on external landmarks in emergency situations can lead to misplacement in over 30% of cases, and can potentially cause unwanted bleeding, inaccurate pressure readings, and ineffective drainage. These complications can also lead to longer hospital stays and increase in mortality\u00c2 [23, 26]. Image-guided neurosurgery (IGNS) improves any ventriculostomy procedure accuracy through use of pre-operative CT and MRI scans to provide real-time reference and spatial guidance, but its widespread use faces several challenges. The cost of acquiring these systems, ranging from USD 650,000 to over 900,000, can be a major barrier for many institutions\u00c2 [34].Furthermore, effectively operating IGNS systems requires the expertise of specialized technicians skilled in planning and systems setup. Additionally, the bulky nature of the equipment, including the workstation and tracking camera, limits its use to large operating rooms, making it difficult to use these systems in other tighter settings like emergency rooms, wards, and ICUs (Intensive Care Units). These challenges limit IGNS use in low- and middle-income countries (LMICs) and remote communities. Additionally, a technician-intensive system is limited to elective and not emergency procedures. Indeed, geographic disparities for timely and inexpensive EVD (External Ventricular Drain) placement exist. For example, Sub-Saharan Africa reports a much higher rate of infant hydrocephalus compared to other regions, with 750 new cases per 100,000 births compared to approximately 110 cases in Europe and the USA\u00c2 [20]. This disparity in disease prevalence and access to advanced technology creates a concerning disparity in the quality of care between the resource-constrained settings with those high-resource settings. Our aim is to narrow this gap by developing a solution that is affordable, easily deployable, has a small footprint, and requires minimal expertise, making it suitable for use in LMICs, remote communities, and other resource-limited settings. To address the challenges faced in translating surgical innovations into clinical practice \u00c2 [37], we focus on designing a ventriculostomy guidance system through co-design with neurosurgeons and a focus on user experience. By applying user-centered design practices, we aim to create a system that aligns with both technological advances and the practical needs of surgeons, ensuring its usability and successful integration into daily surgical practice in resource-limited settings. Specifically, we present iSurgARy, a mobile system designed to operate exclusively on iPhones or iPads. iSurgARy leverages LiDAR for precise patient tracking, complemented by augmented reality (AR) for procedural guidance. Neurosurgical procedures are constantly evolving with the integration of innovative technologies such as robotics, mixed and virtual reality, 3D printing and intraoperative imaging methods. Hong et al.\u00c2 [27] introduced a mobile AR navigation system (MARNS) for precise transverse-sigmoid sinus junction location determination during retrosigmoid craniotomy. It demonstrates efficacy with a mean matching error of 2.88 mm (SD \u00c2\u00b1 0.69 mm), a positioning time of 279.71 seconds (SD \u00c2\u00b1 27.29 seconds), and was found to maintain bone flap integrity in 86.7% of cases. In another study, de Almeida et al.\u00c2 [19] addressed the cost and complexity of traditional neuronavigation systems. Their research presents a mobile-based AR solution for localizing points or landmarks on the scalp surface. In laboratory testing with a 3D phantom under optimal conditions, the system achieved an accuracy of 2.6 mm (SD \u00c2\u00b1 1.6 mm). Gorkem et al.\u00c2 [25] investigated a 3D-printed marker-based AR system for intracranial tumor segmentation. It demonstrated high precision (0.5 to 3.5 mm targeting error), clinical feasibility, and cost-effectiveness, highlighting its potential for real-world application. In a separate study, L\u00c3\u00a9ger et al. proposed MARIN, an iPad-based AR neuronavigation system\u00c2 [32], as well as NousNav\u00c2 [31], a low-cost and an open-source neuronagivation system, as a solution for use in low-resource settings. NousNav uses low-cost off-the-shelf components, can be easily built for \u00c2 6k USD, features an intuitive interface and easy intraoperative control, and is robust and modular, making it a promising candidate for wider accessibility. For ventriculostomy in particular, several mixed reality systems have been proposed to improve accuracy. Azimi et al.,\u00c2 [16] developed an automated registration and trajectory planning system for ventriculostomy where a pointer equipped with a Vuforia marker was used for landmark-based registration. They achieved a 37% improvement in accuracy for tip placement compared to manual registration methods, with a pointer tip-to-target distance of 10.96\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2m10.96\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u016110.96mm10.96 italic_m italic_m. In a similar study by Schneider et al.\u00c2 [38], the authors used AR for ventriculostomy. They attached a Vuforia marker to the patient\u00e2\u20ac\u2122s head to guide the projection of 3D ventricle models onto the skull. A game controller was employed to align the holograms with the patient. Their system achieved a success rate of 68.2% for ventriculostomy, with an average deviation of 5.2 mm from the planned trajectory. A subgroup showed significant improvement in results and precision after repeated attempts, suggesting a learning curve for using the AR system. The use of a rigid needle is assumed in AR-assisted medical procedures. Lin et al.\u00c2 [33] explored the limitations of this approach. They developed a system utilizing the HoloLens to display segmented ventricles and the desired catheter trajectory, achieving a target registration error of 4.34\u00c2\u00b11.63plus-or-minus4.341.634.34 1.634.34 \u00c2\u00b1 1.63 mm and reducing catheter passes from 2.33\u00c2\u00b10.98plus-or-minus2.330.982.33 0.982.33 \u00c2\u00b1 0.98 to 1.07\u00c2\u00b10.258plus-or-minus1.070.2581.07 0.2581.07 \u00c2\u00b1 0.258 times. However, this method does not account for needle deflection, which can lead to inaccuracies. As highlighted in their study, incorporating real-time deflection data into AR systems could further improve precision in needle procedures. To improve freehand ventriculostomy accuracy, Ansari et al.\u00c2 [35] developed VentroAR, a HoloLens-based AR system. This system guides surgeons in locating ventricles, aiming to reduce the risk of complications associated with misplaced catheters. In a user study with 15 novices, VentroAR achieved an average gesture-based registration accuracy of 10.75\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2m10.75\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u016110.75mm10.75 italic_m italic_m and a targeting accuracy of 10.64\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2m10.64\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u016110.64mm10.64 italic_m italic_m. While promising in terms of workflow and ease of use, the authors acknowledge the need for further accuracy improvements before clinical adoption. For a more comprehensive examination of mixed reality in ventriculostomy, readers are directed to the 2024 review by Alizadeh et al.\u00c2 [14]. Although tablet and smartphone systems have been developed for neurosurgery, to the best of our knowledge, they all either require external tracking systems, markers, or tags. Dogan et al.\u00c2 [22] (2024) used a smartphone for neurosurgery but had issues with repeated manual \u00e2\u20ac\u0153failed registrations\u00e2\u20ac\ufffd. Santos et al.\u00c2 [24] developed a smartphone app to be used with a compass for neurosurgery procedures, yet their system required skin makers. De Almeida et al\u00c2 [19] developed a smartphone system, however their focus was on looking at the impact of lighting on registration. Furthermore, they used non-pro iPhones and thus were unable to take advantage of LiDAR for registration. MARIN\u00c2 [32] uses an iPad yet requires the use of an external optical tracker. In comparison to these works, iSurgARy is novel as it requires the use of only a smartphone, uses LiDAR, and does not require additional trackers or markers on the patient. This simplifies the workflow in emergency and low-resource settings. iSurgARy was developed to be a small-footprint, low-cost image-guided neurosurgery (IGNS) system suitable for use in resource-limited and emergency settings. To achieve this, iSurgARy features a simple user interface (UI) designed to allow clinicians to easily select anatomical landmarks on the patient using the touch screen of mobile devices. These selected landmarks are then used in a rigid registration process to map the patient to their pre-operative scans. Once the registration process is complete, the clinician can visualize the ventricles (in the case of ventriculostomy) or other relevant 3D models (such as the cerebral vacsculature) in AR. This visualization aids in guiding the clinician to optimal EVD placement. Additionally, the catheter tracking tool enhances the clinician\u00e2\u20ac\u2122s spatial understanding of the distance between the catheter tip and the ventricles (see Figure 1). The current iSurgARy prototype utilizes an iPhone 15 Pro (MTUA3VC/A) running iOS 17.4 as the primary device. However, the application is also compatible with iPad Pro tablets that house the LiDAR sensor, offering greater flexibility in its use. Development is conducted within XCode Version 15.2 (15C500b) on a MacBook Air 15-inch, M2, 2023 with MacOS 14.3 (23D56), 16GB memory, and 1TB SSD. Additionally, a 3D-printed head phantom, designed for MRN system development and testing in neurosurgery, is used for alignment with corresponding digital ventricle and artery segments[36]. iSurgARy was built for iOS using the Swift [11] and C++[6] programming languages. It leverages Apple\u00e2\u20ac\u2122s ARKit[28] and RealityKit[10] frameworks to track and assign anatomical landmarks to 3D anchors and visualize the AR 3D model. The UI was implemented with SwiftUI[12], while the asynchronous events are managed by the Combine framework[7]. For unit conversion compatible with ARKit and transform matrix computation, Accelerate framework is utilized. On the C++ side, the iterative closest point algorithm (ItCP) and its helper functions rely on the Eigen library[8] and standard libraries like cmath, algorithm, and limits. In the following section, we describe the user experience and workflow of using iSurgARy. Technical details about the tracking and registration implementation follow in the next sections. The application features a user-friendly interface designed for effortless registration and navigation. Users will load patient CT scans and select specific points on the scan for both landmark registration and surgical targeting. For instance, users can choose Koscher\u00e2\u20ac\u2122s point for burr hole localization and catheter targeting and may move the target entry point as deemed appropriate if there is cortical and ventricular distortion from blood or other space occupying lesions. The app guides clinicians to place seven key anatomical landmarks on the patient, commonly used for patient-to-image registration in IGNS: the right tragus, the right outer canthus, the right inner canthus, the nose bridge, the left inner canthus, the left outer canthus, and the left tragus. During the registration process, the interface displays a text field at the top of the screen indicating the current landmark to target. A target cursor is centrally displayed on screen to aid in precise targeting. The right side of the interface contains an \u00e2\u20ac\u02dcacquire\u00e2\u20ac\u2122 button to confirm landmark placement relative to the center target cursor. When the user presses the \u00e2\u20ac\u02dcacquire\u00e2\u20ac\u2122 button, a red spherical AR object is rendered on the device\u00e2\u20ac\u2122s camera feed at the aimed landmark. Once landmark placement is made, the user can either use the \u00e2\u20ac\u02dcdelete\u00e2\u20ac\u2122 button to remove the AR landmark reference or choose a different anatomical target by using the \u00e2\u20ac\u02dcnext\u00e2\u20ac\u2122 navigation buttons. The process of landmark placement for each target, guided by the text field at the top of the screen, is repeated until all seven key anatomical landmarks have been placed. The user can also navigate backwards and choose a previous anatomical target by using the \u00e2\u20ac\u02dcback\u00e2\u20ac\u2122 button. Technical details on landmark placement are discussed in Section 3.4. Once all landmarks are placed, the \u00e2\u20ac\u02dcregister\u00e2\u20ac\u2122 button aligns the landmarks to the AR model using an iterative closest point algorithm (ItCP), described in Section LABEL:registration. When the program completes registration, an AR view of the patient\u00e2\u20ac\u2122s internal structures for guidance is generated and the RMSE of the alignment is displayed at the top of the screen. If the user is dissatisfied with the alignment, they can easily re-select some or all of the anatomical landmarks for a more precise registration. If satisfied, the \u00e2\u20ac\u02dcconfirm\u00e2\u20ac\u2122 button proceeds to the next phase. In the EVD entry point placement phase, an entry point button enables the placement of a target for burr hole localization. If an entry point target is misplaced, a \u00e2\u20ac\u02dcdelete\u00e2\u20ac\u2122 button allows the user to remove the saved entry point location and re-select an entry-point. After saving the entry point location and navigating to the next phase, using the \u00e2\u20ac\u02dcnext\u00e2\u20ac\u2122 button, the target registration error (TRE) is displayed in the text field at the top of the screen (if the entry point was chosen on the pre-operative CT). Catheter tracking is done using 2D image detection. Specifically, when the catheter tracking tool is within the camera frame, an AR view of a straight line is overlaid on the catheter from the QR code to the catheter tip, aiding in depth assessment during catheter insertion into the patient. Lastly, a \u00e2\u20ac\u02dcreset\u00e2\u20ac\u2122 button is available to remove all seven landmark targets placed by the user, providing a fast and convenient way to redo all landmarks, and reset the interface to the initial target stage where the user is asked to place the first landmark, the right tragus. The interface allows clinicians to move around the patient from different angles, improving their 3D spatial awareness of internal structures by providing a better understanding of distance and direction between the catheter tip and the ventricle. For registration, i.e. mapping of patient space to image space, iterative closest point (ItCP)\u00c2 [39] was used. ItCP aligns the landmarks placed in AR and the predefined landmarks from the patient\u00e2\u20ac\u2122s CT scan. Our ItCP implementation processes coordinates of both AR-placed landmarks and predefined landmarks, producing a scale factor, a rotation matrix, and the RMSE. To visualize the aligned internal structures in AR, the 3D model is anchored at the centroid of the AR landmarks, with its origin as the mean of the predefined landmarks. The scale factor derived from the ItCP process is applied to the loaded 3D model. The rotation matrix is then used to adjust the orientation of the 3D model ensuring optimal alignment of the landmarks. Traditional IGNS systems present navigation information on a computer outside the sterile operating region. This requires the surgeon to shift their gaze away from the patient and surgical field for guidance information and mentally map it to the patient\u00e2\u20ac\u2122s anatomy. This process can be time-consuming, cognitively demanding, and prone to error\u00c2 [29, 15]. Furthermore, it results in a disconnect between where the surgeon is working and where they are looking for guidance. This constant shifting of attention can negatively influence the successful completion of a surgical task\u00c2 [30]. To address these issues, we use AR to superimpose the patient\u00e2\u20ac\u2122s ventricular anatomy onto the head and track the tip of the catheter. In iSurgARy, ARKit provides world tracking capabilities, utilizing the devices\u00e2\u20ac\u2122 camera and motion sensors to monitor its position and orientation in the real world[4]. In an ARKit ARSession[5], feature points are detected within the camera\u00e2\u20ac\u2122s image space and used to represent key details of the real-world environment. These feature points are then compiled into an ARPointCloud, which is a collection of 3D coordinates in the world space that ARKit uses for various tracking tasks. This point cloud is crucial for continuously updating fixed anchor points in the environment that serve as reference frames for placing and tracking virtual objects in real-time as the camera moves. ARKit uses this data to ensure that virtual content remains accurately positioned and aligned with the physical world across each frame. Additionally, the housed LiDAR scanner enhances depth tracking and anchor placement precision, we access the depth data using ARDepthData[2]. When the user presses the \u00e2\u20ac\u02dcacquire\u00e2\u20ac\u2122 button for placing a landmark, we use ARCamera[1] to capture the position and orientation of the camera, and we use ARDepthData to determine the distance between the device and the subject being targeted. From this, we compute the spatial coordinates of the landmarks from each capture and pass it into the ItCP algorithm in order to align our 3D model to the real-world environment. RealityKit is employed to render the 3D content, such as the virtual 3D spheres for the placed landmarks and the 3D model of the ventricles. To track the tip of the catheter, we pass a QR code image as a reference image to the detectionImages property of the world-tracking configuration[9]. When the ARsession recognizes the QR code reference image, an ARImageAnchor[3] is added to the detected image. Once detected, a rectangular AR object is rendered from the detected image extending to the tip of the catheter as shown in rightmost image of Figure \u00c2 1. To evaluate the iSurgARy app in a laboratory setting, we conducted a two-phase user study. The first phase involved a preliminary study with novice participants, focusing on assessing the usability and learnability of the app. Feedback from this phase was used to refine the application. In the second phase, we engaged clinical and HCI experts to evaluate usability and performance. This phase included measuring RMSE to assess accuracy, SUS for system usability and the NASA TLX to evaluate cognitive workload. For the novice study, we had 10 university participants (5 female and 5 male) who were graduate students in engineering and science fields. They performed landmark registration and patient tracking and completed the SUS[17] to provide feedback on the app\u00e2\u20ac\u2122s usability. We started with a brief introduction of the app to each participant. We explained that the accuracy of task completion was not the primary concern. Instead, the focus was on how easily the participants could follow the app instructions and navigate the user interface to complete the tasks. This approach ensured that we received meaningful feedback on the usability and learnability of the app, allowing us to identify and address any issues. In the second phase of our evaluation, we focused on assessing both the usability and learnability of iSurgARy, as well as its accuracy and cognitive load when used by domain knowledge users. This study involved 11 participants, including nurses, clinicians, and HCI experts. The demographics and backgrounds of these domain experts are presented in Table\u00c2 1. We had a gender split of almost 50%, with the following backgrounds: A neurosurgeon with over 25 years of experience A clinician with a Master\u00e2\u20ac\u2122s degree focused on IGNS Three nurses working at a neurological institute, including two with OR/ER experience and one nurse manager Three HCI researchers One HCI and mobile app developer One IGNS researcher/developer All participants had relevant or related experience, ensuring the feedback we received was well-informed and applicable to real-world scenarios. The study concluded by collecting qualitative feedback on the app\u00e2\u20ac\u2122s usability. This feedback guided further improvements in the application\u00e2\u20ac\u2122s design. For system usability, we used the SUS, a questionnaire employed to evaluate the usability of products and services. The results of the SUS are presented in Table\u00c2 2. The average SUS was 81.52% indicating an easy-to-use system (Note: The average SUS score is 68% and scores up to 70% are considered good). Furthermore, comments from the participants indicated that they felt the system was easy to learn, understand and use. For evaluating system usability in our second study, we used SUS, the results of which are summarized in Table\u00c2 3. The average SUS was 80.95%, indicating that the system was perceived as easy to use by our expert domain knowledge participants. The NASA Task Load Index (NASA TLX) was used to assess the subjective workload experienced by participants. The mean scores (with standard deviations) for the dimensions were as follows: Mental Demand, 7.17 (\u00c2\u00b14.04); Physical Demand, 7.5 (\u00c2\u00b14.19); Temporal Demand, 5.67 (\u00c2\u00b13.60); Performance, 16.33 (\u00c2\u00b13.17); Effort, 7.33 (\u00c2\u00b14.38); and Frustration, 5.33 (\u00c2\u00b14.03) (see Figure\u00c2 4). Among these dimensions, performance had the highest mean score, suggesting that participants felt they had to work hard to get a good level of performance, in this case a low RMSE. The overall workload, based on the NASA TLX scores is 41.1 on a 100-point scale suggesting a moderate workload. The variability in standard deviations across the dimensions reflects differing levels of consensus among participants regarding their experience. In terms of accuracy, on average, we found an RMSE of 2.54\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2m\u00c2\u00b10.46plus-or-minus2.54\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u01610.462.54mm 0.462.54 italic_m italic_m \u00c2\u00b1 0.46. These findings align with previous works\u00c2 [19, 27]. Furthermore, according to our experts as the ventricles are a large target, an RMSE of < 5 mm is generally acceptable. To ensure the application\u00e2\u20ac\u2122s scope aligned with the needs of neurosurgeons, we collaborated closely with them during the development process. One of the neurosurgeons who participated in our expert user study provided particularly encouraging feedback. Comments included: \"Wow. I think you have the gist of it. Simple and quick registration and very responsive tracking. Sign me up. When would you like to test this in a clinical setting?\", \"I would like to use the iPad, but I think the residents will prefer the iPhone form factor as they can just pull it out of their pocket.\" and \"Superb user-friendly and easy-to-use tool for the task at hand. It will be a valuable adjunct towards the safe and timely placement of EVDs.\" Other comments included: \"Another anchor point that isn\u00e2\u20ac\u2122t co-planar with rigid points to better account for out of plane rotations\" and \"Try using multiple selections of the same point to both assess intra-user variability in point selection and to use centroid of chosen points as anchor point for registration\", suggesting that improvements could be made on the registration procedure. Based on the various feedback, we have determined an ergonomic solution that would work in resource-limited emergency and ICU settings. First, an iPhone/iPad holder that would be clamped to the bed during the procedure would allow the user to have both hands available for catheter placement (see Figure\u00c2 5). Next, simple solutions for stabalizing the patient\u00e2\u20ac\u2122s head were discussed. Lastly, in future work, to ensure that the catheter can be tracked without the need for the QR code, we will focus on developing computer vision techniques. iSurgARy prioritizes affordability, aiming to make advanced navigation technology accessible to a wider range of medical institutions while maintaining accuracy. Unlike traditional IGNS systems, which can cost thousands of dollars due to sophisticated tracking cameras and dedicated computers, iSurgARy utilizes commercially available and affordable mobile devices. While there is an initial investment associated with these devices, it represents a significantly more economical option. The cost-effectiveness, combined with the portability and ease of use of our system makes it a much better navigation option for resource-constrained settings. iSurgARy combines both human expertise and machine capabilities, and in doing so, this introduces potential sources of error for which the user should be aware. The initial placement of virtual landmarks is a key step for accurate guidance, but it relies on the user\u00e2\u20ac\u2122s judgment and precision. This can lead to inaccuracies that may significantly affect subsequent stages, particularly alignment. Errors can also arise from the ItCP algorithm and the ARKit framework. The ItCP algorithm, while robust in aligning 3D structures, can struggle with sparse data, uneven distributions of landmarks, or large initial misalignment that exceed its convergence criteria. The ARKit framework, used for real-world environment tracking, has its own limitations due to sensor accuracy and environmental factors. The iPhone/iPad uses an accelerometer and a gyroscope, and their precision limitations can manifest as inaccuracies in landmark tracking, potentially causing misalignment between the real world and the augmented overlay. In future work, we will consider capturing a point cloud of the patient with LiDAR and performing a more dense point-based registration. Despite a modest user study sample size, we believe our findings provide reliable results about the usability and applicability of the system. Our second study aimed at using domain experts (mobile app developers, HCI experts and clinicians) to determine the usability of the system as human-computer interaction (HCI) research suggests that a sample of even just 3-5 system evaluators can identify \u00c2 75% of usability issues. Furthermore, the inclusion of double experts (in this case a clinician who was also an IGNS researcher) may identify more issues\u00c2 [13, 18]. Feedback from the neurosurgeon, clinician with IGNS research background and an IGNS researcher and developer, as well as our HCI experts not only validated our approach but also helped us identify areas for improvement in the next iteration of our application. This collaboration underscores the importance of iterative development and expert input in refining and enhancing the usability and functionality of medical applications. The next step of this work will be to further test iSurgARy with neurosurgeons and residents. This testing will be important in evaluating the robustness and accuracy of our system in real-world surgical settings, determining its practical viability and clinical effectiveness in achieving precise EVD placement. Furthermore, we plan to compare our smartphone/tablet system accuracy, usability, and ergonomics with head-mounted displays (HMDs) like the Apple Vision Pro or Microsoft HoloLens. These devices potentially offer a hands-free experience and potentially better immersion, which could be advantageous for complex procedures. However, weight, battery life, and maintaining sterility remain challenges. Our future research will explore these trade-offs to identify the most effective AR solution for surgical applications. In this work, we aimed to develop a practical system with an intuitive interface that could be used in an ICU, emergency room and/or resource-limited settings. By working closely with neurosurgeons in defining the app\u00e2\u20ac\u2122s scope that aligns with their needs, iSurgARy addresses a critical need for a low-cost, portable, and user-friendly IGNS system in resource-limited settings and emergency situations. Ventriculostomy, a common neurosurgical procedure, is particularly suited to such a system. Our initial prototype demonstrates promising accuracy and sets the stage for continued refinement and clinical evaluation. Successful implementation of iSurgARy has the potential to significantly improve the accuracy of EVD placement, leading to reduced healthcare costs, mortality and morbidity rates. The work described in this paper was funded by XXX Conflict of interest: None declared.",
        "keywords": "keywords: \nVentriculostomyLow-CostAugmented Reality Neurosurgery Mobile ComputingResource-limited Settings"
    },
    {
        "id": 19,
        "title": "Language-centered Human Activity Recognition",
        "abstract": "Abstract.Human Activity Recognition (HAR) using Inertial Measurement Unit (IMU) sensors is critical for applications in healthcare, safety, and industrial production. However, variations in activity patterns, device types, and sensor placements create distribution gaps across datasets, reducing the performance of HAR models. To address this, we propose LanHAR, a novel system that leverages Large Language Models (LLMs) to generate semantic interpretations of sensor readings and activity labels for cross-dataset HAR. This approach not only mitigates cross-dataset heterogeneity but also enhances the recognition of new activities.\nLanHAR\u00c2\u00a0employs an iterative re-generation method to produce high-quality semantic interpretations with LLMs and a two-stage training framework that bridges the semantic interpretations of sensor readings and activity labels. This ultimately leads to a lightweight sensor encoder suitable for mobile deployment, enabling any sensor reading to be mapped into the semantic interpretation space.\nExperiments on four public datasets demonstrate that our approach significantly outperforms state-of-the-art methods in both cross-dataset HAR and new activity recognition. The source code will be made publicly available.",
        "corpus": "Human Activity Recognition (HAR) using Inertial Measurement Unit (IMU) sensors is critical for applications in healthcare, safety, and industrial production. However, variations in activity patterns, device types, and sensor placements create distribution gaps across datasets, reducing the performance of HAR models. To address this, we propose LanHAR, a novel system that leverages Large Language Models (LLMs) to generate semantic interpretations of sensor readings and activity labels for cross-dataset HAR. This approach not only mitigates cross-dataset heterogeneity but also enhances the recognition of new activities. LanHAR\u00c2 employs an iterative re-generation method to produce high-quality semantic interpretations with LLMs and a two-stage training framework that bridges the semantic interpretations of sensor readings and activity labels. This ultimately leads to a lightweight sensor encoder suitable for mobile deployment, enabling any sensor reading to be mapped into the semantic interpretation space. Experiments on four public datasets demonstrate that our approach significantly outperforms state-of-the-art methods in both cross-dataset HAR and new activity recognition. The source code will be made publicly available. Human Activity Recognition (HAR) based on data collected from Inertial Measurement Unit (IMU) sensors on mobile platforms such as smartphones and wearable devices is one of the key problems in mobile computing due to its important applications in fields such as healthcare\u00c2 (Subasi et\u00c2 al., 2018, 2020), safety\u00c2 (Sun and Chen, 2022; Liagkou et\u00c2 al., 2022), and industrial production\u00c2 (Niemann et\u00c2 al., 2021; Zheng et\u00c2 al., 2018). However, variations in activity patterns, device types, and sensor placements across different individuals result in significant distributional differences between datasets, even when capturing the same activity\u00c2 (Xu et\u00c2 al., 2023; Liu et\u00c2 al., 2022). Consequently, the performance of HAR models deteriorates considerably in cross-dataset human activity recognition scenarios\u00c2 (Xu et\u00c2 al., 2023). Therefore, developing HAR models capable of generalizing across different datasets remains a critical research problem that needs solutions. Existing work on cross-dataset HAR can be broadly categorized into two approaches: domain adaptation and data augmentation. Domain adaptation methods\u00c2 (Chang et\u00c2 al., 2020; Qin et\u00c2 al., 2019; Khan et\u00c2 al., 2018; Zhou et\u00c2 al., 2020) aim to bridge the distribution gap between source and target datasets to enhance model performance in training. Data augmentation methods\u00c2 (Um et\u00c2 al., 2017; Xu et\u00c2 al., 2023; Qian et\u00c2 al., 2022; Saeed et\u00c2 al., 2019) seek to increase the diversity of training data to improve the model\u00e2\u20ac\u2122s generalization ability. While both approaches are valuable, they still suffer from two limitations: (i) Most existing work overlooks the physical meanings of activities. This can exacerbate the impact of classification errors on downstream applications. For instance, misclassifying a walking activity as running may have a relatively minor effect compared to misclassifying it as a significantly different activity such as biking (see quantitative results in Evaluation). (ii) Moreover, cross-dataset scenarios often introduce new activities that these methods struggle to handle, as these new activities are typically missing from the training phase. We argue that semantic interpretations of sensor readings and activity labels can play a crucial role in addressing the aforementioned limitations as shown in Figure\u00c2 1. (i) For cross-dataset heterogeneity, interpreting sensor readings based on its physical meanings can help identify patterns associated with specific activities (e.g., jogging often exhibits regular periodicity). The underlying intuition is that, despite the variability across datasets, activities may still reveal common underlying patterns. By identifying these patterns, we can map the heterogeneous data into a common space, thereby mitigating the impact of dataset variability. (ii) When dealing with new activities, semantic interpretations of activity labels can enhance their meaning by generating detailed descriptions. Combining semantic interpretations of both sensor readings and activity labels creates the potential to map new data to new activity labels. However, manual semantic interpretation is resource-intensive. The recent success of large language models (LLMs) offers a promising solution, enabling the generation of semantic interpretations from both sensor readings and activity labels through natural language\u00c2 (Jiang et\u00c2 al., 2024; Zhang et\u00c2 al., 2023). Research has shown that LLMs have the ability to perceive aspects of the physical world\u00c2 (Xu et\u00c2 al., 2024), providing an opportunity to leverage these capabilities to bridge the gap in cross-dataset HAR through automated semantic interpretation. Despite the promise of semantic interpretations using LLMs, several challenges remain to be addressed: (i) Generation Challenge: The semantic interpretations generated by LLMs can suffer from issues like hallucinations and randomness. Ensuring consistent and high-quality semantic interpretations remains a significant challenge. (ii) Alignment Challenge: Once LLMs generate semantic interpretations of sensor readings and labels, the next step is to align them for Human Activity Recognition (HAR), i.e., aligning sensor reading and label based on their interpretation. While language models can be used to align these interpretations, general LLMs lack specific knowledge of IMU data and human activity recognition, limiting their ability to accurately understand and reason about activities. (iii) Deployment Challenge: Frequent access to cloud-based LLMs or deploying them locally on mobile devices is impractical due to high latency and resource constraints. A lightweight framework is needed to effectively leverage LLMs for on-device HAR. To address these challenges, we design LanHAR\u00e2\u20ac\u2030 a novel system that leverages LLMs to generate semantic interpretations of sensor readings and activity labels, aimed at improving cross-dataset human activity recognition. LanHAR\u00c2 consists of three key components. (i) Generation: we carefully design prompts to guide LLMs in generating semantic interpretations and develop an iterative re-generation method to ensure high-quality semantic outputs. (ii) Alignment: we design a semantic interpretation alignment module to enhance understanding of semantic interpretations based on a pre-trained text encoder to encode interpretations and two contrastive learning tasks to improve the alignment between activities and sensor readings. (iii) Deployment: We introduce a lightweight, two-stage training and inference framework. First, we train the semantic interpretation alignment module, then design and train a sensor reading encoder to map sensor data to the semantic interpretation space. For inference on mobile devices, we use the trained encoder to obtain sensor reading encodings and measure their similarity to activity label semantics to determine the HAR results. In particular, our main contributions are as follows. To our knowledge, we are the first to leverage LLMs to generate semantic interpretations for cross-dataset human activity recognition. Our approach introduces a novel perspective by utilizing semantic interpretations from both sensor readings and activity labels, which helps mitigate the impact of cross-dataset heterogeneity and opens the door to recognizing new activities. We design LanHAR, a novel system that leverages LLMs to generate semantic interpretations of sensor readings and activity labels, addressing the challenge of cross-dataset human activity recognition. The system features a semantic interpretation generation process with an iterative re-generation method to ensure high-quality outputs, alongside a two-stage training framework that transfers the capabilities of large language models (LLMs) to mobile devices. We evaluate our system based on four public datasets. The experimental results demonstrate that it outperforms other state-of-the-art methods in cross-dataset activity recognition, achieving an improvement of 7.21% in accuracy and 13.31% in F1 score. Additionally, for new activity recognition, it shows further enhancement, with improvements of 74.65% in accuracy. Existing research\u00c2 (Xu et\u00c2 al., 2024; Ji et\u00c2 al., 2024) has demonstrated that LLMs possess the ability to perceive and interpret the physical world. For instance, LLMs can analyze various types of sensor data to infer a person\u00e2\u20ac\u2122s location or activity. Building on this capability, we explore the use of LLMs to analyze sensor readings and describe activity labels, thereby generating semantic interpretations for both. Specifically, we design prompts that include data introduction, data analysis, relevant knowledge, and task instructions (detailed in Section\u00c2 3.3) to guide LLMs in generating semantic interpretations of sensor readings. Similarly, we guide LLMs to produce descriptions related to activity labels. Figure\u00c2 2 provides an example where GPT-4 generates its understanding of jogging alongside an analysis of sensor data sequences. We explain why LLM-generated semantic interpretation offers a valuable approach to addressing data heterogeneity in cross-dataset HAR. The key intuition is that, despite variations in how heterogeneous data manifests, it often has underlying common activity patterns. By identifying these shared patterns, we can map the original heterogeneous sensor data into a common shared space (i.e., a language space with encoded semantic interpretation), effectively reducing the impact of data heterogeneity. To understand how data heterogeneity is mitigated using generated semantic interpretations, we compare data distributions under three settings: raw data, data encoded by encoders, and generated semantic interpretations. Data encoding is a common approach used in existing research\u00c2 (Auge et\u00c2 al., 2021), aimed at learning better representations or embeddings of sensor readings. For data encoding, we employ a self-supervised learning model, BERT\u00c2 (Devlin et\u00c2 al., 2018), as a representative method, following prior work\u00c2 (Xu et\u00c2 al., 2021) that masks and predicts parts of the sensor readings. For semantic interpretation, we use GPT-4 to generate interpretations from raw IMU data based on a designed prompt (detailed in Section\u00c2 3.3). These interpretations are then input into a pre-trained language model (BERT) to produce representations in the language space. We use two public datasets\u00e2\u20ac\u201dUCI\u00c2 (Reyes-Ortiz et\u00c2 al., 2016) (D1) and Motion\u00c2 (Malekzadeh et\u00c2 al., 2019) (D2) as a cross-dataset example including four common activities: walking, sitting, going upstairs, and going downstairs. Qualitative results: We visualize the results from the three settings using t-SNE to project them onto a 2D surface. As an example, we plot two activities, \u00e2\u20ac\u0153sit\u00e2\u20ac\ufffd (blue) and \u00e2\u20ac\u0153walk\u00e2\u20ac\ufffd (orange), in Figure\u00c2 3. Initially, in the raw data, the same activities from different datasets are far apart. After applying self-supervised learning, the distribution gap between the datasets decreases, but the activities also become less distinguishable. However, when using semantic interpretations, the distribution gap reduces further, and the same activities (same color) cluster more closely, demonstrating improved grouping of the same activities. Quantitative results: We quantitatively assess the impact of introducing semantic interpretations for sensor readings across all activities. To measure the distribution differences between the two datasets under the three settings, we use Kullback-Leibler (KL) divergence, a widely used metric for comparing distributions. Table\u00c2 1 presents the KL divergence for all activities across the two datasets under each setting. The results show that introducing semantic interpretations significantly reduces the distribution gap for all activities. On average, the KL divergence is reduced by 56.89%. Recognizing new activities has been a longstanding challenge in HAR, particularly for machine learning-based methods, which are unable to identify activities that were not present during the training phase. The most relevant approach to address this challenge involves using predefined attributes of activities to establish connections between new and existing activities\u00c2 (Cheng et\u00c2 al., 2013). However, the performance of this method relies heavily on the quality of manually defined activity attributes, making it costly and difficult to generalize to new labels. We argue that combining the semantic interpretations of sensor readings and labels offers a new perspective for addressing this challenge. By converting all activity labels into a language space using their semantic interpretations, we can represent labels even without corresponding sensor readings (which is common for new labels). Similarly, with sensor readings mapped into the same language space, we can match each reading to a label, regardless of whether the label was previously encountered. Figure\u00c2 4 illustrates this concept, where we assume \u00e2\u20ac\u0153biking\u00e2\u20ac\ufffd and \u00e2\u20ac\u0153going upstairs\u00e2\u20ac\ufffd are known activities from the training phase, while \u00e2\u20ac\u0153going downstairs\u00e2\u20ac\ufffd is a new activity. In our approach, we first convert all activity labels into the same language space using their LLM-generated semantic interpretations. We then obtain semantic interpretations for the sensor readings. Even though \u00e2\u20ac\u0153going downstairs\u00e2\u20ac\ufffd is unseen during training, we can still measure its distance to all activity labels in the language space, enabling the recognition of new activities. In our setting, we assume that we have the knowledge of possible activity labels in the inference stage. We consider LanHAR\u00c2 to be implemented in a cloud-client setting, where each client possesses locally collected, unlabeled IMU datasets. The cloud holds an initial source dataset, XssuperscriptX\u011f\ufffd\u2018 start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT, collected from a subset of clients, with labels YssuperscriptY\u011f\ufffd\u2018 start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT provided by clients or experts. Given an unlabeled target dataset XtsuperscriptX\u011f\ufffd\u2018\u00a1 start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT from the clients, our goal is to achieve high activity recognition accuracy on XtsuperscriptX\u011f\ufffd\u2018\u00a1 start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT, even when the label set YssuperscriptY\u011f\ufffd\u2018 start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT differs from YtsuperscriptY\u011f\ufffd\u2018\u00a1 start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT. We design LanHAR, a novel system that leverages LLM-generated semantic interpretations of sensor readings and activity labels for cross-dataset human activity recognition. As shown in Figure\u00c2 5, LanHAR\u00c2 consists of four processes: (1) LLMs for semantic interpretations. We utilize LLMs to generate semantic interpretations of sensor readings XssuperscriptX\u011f\ufffd\u2018 start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT and activity labels YssuperscriptY\u011f\ufffd\u2018 start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT. We introduce an iterative re-generation process to filter out low-quality interpretations due to issues such as hallucinations. (2) Text encoder for semantic interpretations alignment. We train a text encoder (i.e., initialized by a pre-trained language model) to encode and align the semantic interpretations generated in step (1). This alignment enables us to leverage language for human activity recognition by matching the semantic interpretation of sensor readings to the most similar semantic interpretation of activity labels within the language space. (3) Sensor encoder for mapping sensor reading to language space. We train a sensor reading encoder, based on the text encoder from step (2), which is capable of mapping any sensor reading into the language space resulted from semantic interpretations. (4) Inference on the mobile device. For inference, we deploy the sensor encoder from (3) on mobile devices to generate sensor embeddings, which are then compared with pre-stored (new) activity label embeddings to determine the activity through similarity computation. We introduce how we guide LLMs to generate semantic interpretations of sensor readings and activity labels. We also discuss our approach to handling low-quality interpretations to ensure the accuracy and reliability of LLM responses. We carefully design a prompt to help LLMs better understand the problem setting and deliver more accurate and meaningful answers. An example is shown in Figure\u00c2 6. The prompt consists of four key parts: data introduction, data analysis, knowledge, and task introduction. (i) Data introduction: We provide details about the data, including its source, the meaning of each dimension, the sampling frequency, and the context in which the data was collected during different activities. (ii) Data analysis: Intermediate steps (i.e., Chain-of-Thought (Wei et\u00c2 al., 2022)) can enhance LLMs\u00e2\u20ac\u2122 reasoning abilities. Our offline testing revealed that while LLMs are capable of performing various data analyses, skipping intermediate steps often leads to less confident responses. To address this, we design multiple auxiliary analysis steps, including amplitude, frequency, time series analysis, and statistical measures like mean, standard deviation, maximum, and minimum values. These steps help LLMs generate more accurate and precise answers. (iii) Knowledge: We include relevant background knowledge to support the LLMs in making accurate judgments. In many cases, specialized knowledge is essential for accurate interpretation. For example, we describe typical patterns observed in accelerometer and gyroscope readings during activities like running, which aids the LLMs in focusing on the appropriate knowledge area. This knowledge can be sourced from public databases like Wikipedia or generated by LLMs. (iv) Task introduction: We outline the task clearly, specifying what the LLMs need to achieve and the format of the final output. This ensures that the LLMs have a clear understanding of the task requirements and can deliver standardized responses that meet our expectations. Similarly, we design a prompt to guide LLMs in generating semantic interpretations of activity labels. In this prompt, we outline the task for the LLMs, instructing them to generate a description for a given activity. The description should cover three key aspects: a general overview of the activity, the potential states or patterns detected by the accelerometer and gyroscope during the activity, and the body parts likely involved in performing the activity. An example of this prompt is shown in Figure\u00c2 7. The quality of LLMs\u00e2\u20ac\u2122 interpretations is critical for our approach. However, due to hallucinations or other incidental factors, LLMs may sometimes generate inaccurate or illogical responses. Through manual review, we identified many such cases when generating semantic interpretations. To improve the accuracy of LLM responses, we developed an iterative re-generation method to ensure high-quality outputs. The key intuition is that filtering out low-quality responses will result in a lower KL divergence within the same activity. As illustrated in Figure\u00c2 8, the framework first identifies the k\u011f\ufffd\u2018\u02dckitalic_k most problematic responses based on KL divergence. These data points are re-input into the LLM to regenerate the semantic interpretations. We then assess whether to incorporate the new interpretations based on their ability to reduce the overall KL divergence. The details are as follows. We show in the evaluation this process improves the data quality. (1) Filter out inaccurate semantic interpretations: We randomly divide the generated semantic interpretations of the same activity into two parts, A\u011f\ufffd\ufffd\u00b4Aitalic_A and B\u011f\ufffd\ufffd\u00b5Bitalic_B, and calculate the initial KL divergence between them. Next, we perform an iterative selection process: in each iteration, we identify and select the data sample from one part that most negatively impacts of KL divergence, adding it to a selection set. After selecting a data sample, it is removed from its original part. This process is repeated until the selection set contains k\u011f\ufffd\u2018\u02dckitalic_k data samples. (2) Regenerate new semantic interpretations by LLMs: After identifying the k\u011f\ufffd\u2018\u02dckitalic_k data samples, we update the task introduction in the prompt (Section\u00c2 3.3.1) to inform the LLMs of the inaccurate responses. The revised prompt includes the following: \u00e2\u20ac\u0153This is your previous response to the task. Please analyze it step by step to identify any logical errors, inconsistencies with real-world knowledge, or discrepancies with the input data. Provide a corrected response according to the required format.\u00e2\u20ac\ufffd (3) Incorporate the new semantic interpretation based on whether it can reduce the overall KL divergence: If the newly generated interpretations reduce the KL divergence, we accept the new semantic interpretation; otherwise, we retain the original one. We repeat this process until either the KL divergence no longer shows significant improvement for multiple continuous iterations or the specified number of iterations is reached. After generating the semantic interpretations of sensor readings and activity labels, we train a text encoder (initialized with a pre-trained language model) to encode and align these interpretations in a shared language space. To ensure the text encoder effectively captures the relationship between the semantic interpretations of sensor readings and activity labels, as well as their alignment, we design two subtasks: a contrastive learning task and a reconstruction task. We adopt a pre-trained language model as the text encoder due to its robust ability to understand semantic interpretations through language. Specifically, we use the text encoder to encode the semantic interpretations of sensor readings \u011f\ufffd\ufffd\u2019zsuperscript\u011f\ufffd\ufffd\u2019\u011f\ufffd\u2018\u00a7 start_POSTSUPERSCRIPT italic_z end_POSTSUPERSCRIPT and activity labels \u011f\ufffd\ufffd\u2019lsuperscript\u011f\ufffd\ufffd\u2019\u011f\ufffd\u2018\u2122 start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT, which are represented as \u011f\ufffd\ufffd\u2122=gen\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u2019z)\u011f\ufffd\ufffd\u2122subscript\u011f\ufffd\u2018\u201densuperscript\u011f\ufffd\ufffd\u2019\u011f\ufffd\u2018\u00a7 = italic_g start_POSTSUBSCRIPT en end_POSTSUBSCRIPT ( bold_S start_POSTSUPERSCRIPT italic_z end_POSTSUPERSCRIPT ) and \u011f\ufffd\ufffd\u2021=gen\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u2019l)\u011f\ufffd\ufffd\u2021subscript\u011f\ufffd\u2018\u201densuperscript\u011f\ufffd\ufffd\u2019\u011f\ufffd\u2018\u2122 = italic_g start_POSTSUBSCRIPT en end_POSTSUBSCRIPT ( bold_S start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT ), where gen\u00e2\ufffd\u00a2(\u00e2\u2039\u2026)subscript\u011f\ufffd\u2018\u201den\u00e2\u2039\u2026g_{ start_POSTSUBSCRIPT en end_POSTSUBSCRIPT ( \u00e2\u2039\u2026 ) denotes the text encoder. In our work, we utilize the BERT architecture as the text encoder, initializing it with pre-trained BERT parameters\u00c2 (Devlin et\u00c2 al., 2018). BERT consists of multiple Transformer encoder layers, each incorporating multi-head self-attention mechanisms and feedforward neural networks, allowing it to generate word representations in a bidirectional context. We chose BERT because of its superior ability to understand text semantics and compare text similarity, as it captures word meanings in a bidirectional context, enabling nuanced comprehension and effective comparisons. However, this text encoder structure is flexible and can be substituted with other language models if needed. Inspired by multimodal alignment (e.g., vision and language)\u00c2 (Radford et\u00c2 al., 2021), we adopt contrastive learning to align the semantic representations of activity labels with those of sensor readings. This alignment enables the use of language to guide human activity recognition by matching the semantic interpretations of sensor readings to the most similar activity label interpretations in the language space. First, we normalize both the embeddings of the semantic interpretations of sensor readings and activity labels to have unit length. Then, we compute the similarity between the normalized embeddings using the dot product, defined as: The goal of training is to maximize the similarity between matching pairs of semantic interpretations and minimize the similarity between non-matching pairs. Given a batch of N\u011f\ufffd\u2018\ufffdNitalic_N matching pairs, the loss function is defined as: where \u00cf\u201e\u011f\ufffd\u0153\ufffd is a temperature parameter that scales the similarities, and Hisubscript\u011f\ufffd\ufffd\u00bb\u011f\ufffd\u2018\u2013H_{i}italic_H start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and Zisubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013Z_{i}italic_Z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT represent the embeddings of the semantic interpretations of sensor readings and activity labels for the i\u011f\ufffd\u2018\u2013iitalic_i-th matching pair. We design two contrastive learning subtasks to enable the text encoder to fully understand the knowledge related to human activity recognition. Firstly, we use pre-defined category-level relations (details in Section\u00c2 4.4) to guide the comparison between the semantic interpretations of sensor readings and activity labels. For semantic interpretations of activity labels, two activity labels in the same category have a higher similarity than two activity labels in the different categories. The loss function for this task is defined as where \u011f\ufffd\u2019\u00aba1subscript\u011f\ufffd\u2019\u00absubscript\u011f\ufffd\u2018\ufffd1 start_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT represents comparison pairs among the semantic interpretations of activity labels. Hicmsuperscriptsubscript\u011f\ufffd\ufffd\u00bb\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0161H_{i}^{c_{m}}italic_H start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_c start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT end_POSTSUPERSCRIPT and Hjcmsuperscriptsubscript\u011f\ufffd\ufffd\u00bb\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0161H_{j}^{c_{m}}italic_H start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_c start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT end_POSTSUPERSCRIPT denote the embeddings of two activity label samples i\u011f\ufffd\u2018\u2013iitalic_i and j\u011f\ufffd\u2018\u2014jitalic_j, that belong to category cmsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0161c_{m}italic_c start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT. Similarly, we apply the same comparison method to the semantic interpretations of sensor reading. The loss function for this task is defined as where \u011f\ufffd\u2019\u00aba2subscript\u011f\ufffd\u2019\u00absubscript\u011f\ufffd\u2018\ufffd2 start_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT represents comparison pairs among the semantic interpretations of sensor readings. Zicmsuperscriptsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0161Z_{i}^{c_{m}}italic_Z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_c start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT end_POSTSUPERSCRIPT and Zjcmsuperscriptsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0161Z_{j}^{c_{m}}italic_Z start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_c start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT end_POSTSUPERSCRIPT denote the embeddings of two semantic interpretations of sensor readings samples i\u011f\ufffd\u2018\u2013iitalic_i and j\u011f\ufffd\u2018\u2014jitalic_j, that belong to category cmsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0161c_{m}italic_c start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT. Secondly, to enrich the semantic interpretations of activity labels and enable the model to adapt to diverse descriptions, we generate multiple descriptions for each activity label. These descriptions guide the comparison, ensuring that the similarity of descriptions for the same activity is higher than that for different activities. The loss function for this task is defined as \u00e2\u201e\u2019Ca3=\u00e2\u02c6\u2019\u00e2\u02c6\u2018\u011f\ufffd\u2019\u00aba3(l\u00e2\ufffd\u00a2n\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2(s\u00e2\ufffd\u00a2(Hilm\u00e2\u2039\u2026Hjlm)\u00e2\u02c6\u2019s\u00e2\ufffd\u00a2(Hilm\u00e2\u2039\u2026Hjln)))subscript\u00e2\u201e\u2019subscript\u011f\ufffd\ufffd\u00b6subscript\u011f\ufffd\u2018\ufffd3subscriptsubscript\u011f\ufffd\u2019\u00absubscript\u011f\ufffd\u2018\ufffd3\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u203a\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018 \u00e2\u2039\u2026subscriptsuperscript\u011f\ufffd\ufffd\u00bbsubscript\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2013subscriptsuperscript\u011f\ufffd\ufffd\u00bbsubscript\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018 \u00e2\u2039\u2026subscriptsuperscript\u011f\ufffd\ufffd\u00bbsubscript\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2013subscriptsuperscript\u011f\ufffd\ufffd\u00bbsubscript\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2014 H^{l_{m}}_{j}})-s({H^{l_{m}}_{i} H^{l_{n}}_{j}})))caligraphic_L start_POSTSUBSCRIPT italic_C start_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT end_POSTSUBSCRIPT = - \u00e2\u02c6\u2018 start_POSTSUBSCRIPT caligraphic_P start_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_l italic_n italic_\u00cf\u0192 ( italic_s ( italic_H start_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u2039\u2026 italic_H start_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) - italic_s ( italic_H start_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u2039\u2026 italic_H start_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) ) ), where \u011f\ufffd\u2019\u00aba3subscript\u011f\ufffd\u2019\u00absubscript\u011f\ufffd\u2018\ufffd3 start_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT represents comparison pairs among the semantic interpretations of activity labels. Hilmsubscriptsuperscript\u011f\ufffd\ufffd\u00bbsubscript\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2013H^{l_{m}}_{i}italic_H start_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and Hjlmsubscriptsuperscript\u011f\ufffd\ufffd\u00bbsubscript\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2014H^{l_{m}}_{j}italic_H start_POSTSUPERSCRIPT italic_l start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT denote the embeddings of two different semantic interpretations of the activity label lmsubscript\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u0161l_{m}italic_l start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT. Lastly, we design a reconstruction task to retain the characteristics of the language model, ensuring it can function as a language model to understand the new activity descriptions and new sensor pattern descriptions. We design a text decoder to reconstruct semantic interpretations of sensor reading and activity labels. The objective of the text decoder can be formulated as \u011f\ufffd\ufffd\u2019^\u011f\ufffd\ufffd\u00b3=gde\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u2122)superscript^\u011f\ufffd\ufffd\u2019\u011f\ufffd\ufffd\u00b3subscript\u011f\ufffd\u2018\u201dde\u011f\ufffd\ufffd\u2122 start_ARG bold_S end_ARG start_POSTSUPERSCRIPT bold_z end_POSTSUPERSCRIPT = italic_g start_POSTSUBSCRIPT de end_POSTSUBSCRIPT ( bold_Z ) and \u011f\ufffd\ufffd\u2019^\u011f\ufffd\ufffd\u00a5=gde\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u2021)superscript^\u011f\ufffd\ufffd\u2019\u011f\ufffd\ufffd\u00a5subscript\u011f\ufffd\u2018\u201dde\u011f\ufffd\ufffd\u2021 start_ARG bold_S end_ARG start_POSTSUPERSCRIPT bold_l end_POSTSUPERSCRIPT = italic_g start_POSTSUBSCRIPT de end_POSTSUBSCRIPT ( bold_H ), where \u011f\ufffd\ufffd\u2122\u011f\ufffd\ufffd\u2122 and \u011f\ufffd\ufffd\u2021\u011f\ufffd\ufffd\u2021 denote embeddings of semantic interpretations of sensor readings and activity labels, respectively, and \u011f\ufffd\ufffd\u2019^\u011f\ufffd\ufffd\u00b3superscript^\u011f\ufffd\ufffd\u2019\u011f\ufffd\ufffd\u00b3 start_ARG bold_S end_ARG start_POSTSUPERSCRIPT bold_z end_POSTSUPERSCRIPT and \u011f\ufffd\ufffd\u2019^\u011f\ufffd\ufffd\u00a5superscript^\u011f\ufffd\ufffd\u2019\u011f\ufffd\ufffd\u00a5 start_ARG bold_S end_ARG start_POSTSUPERSCRIPT bold_l end_POSTSUPERSCRIPT denote reconstructed semantic interpretations of sensor reading and activity labels, respectively. The text decoder consists of multiple layers of the Transformer decoder, each containing multi-head attention mechanisms and feedforward neural networks. The loss function of the reconstruction task is defined as \u00e2\u201e\u2019re=1N\u00e2\ufffd\u00a2\u00e2\u02c6\u2018iNC\u00e2\ufffd\u00a2E\u00e2\ufffd\u00a2(S^iz,Siz)+1N\u00e2\ufffd\u00a2\u00e2\u02c6\u2018iNC\u00e2\ufffd\u00a2E\u00e2\ufffd\u00a2(S^il,Sil)subscript\u00e2\u201e\u2019re1\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00b8subscriptsuperscript^\u011f\ufffd\u2018\u2020\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u2013subscriptsuperscript\u011f\ufffd\u2018\u2020\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00b8subscriptsuperscript^\u011f\ufffd\u2018\u2020\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u2013subscriptsuperscript\u011f\ufffd\u2018\u2020\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT re end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG italic_N end_ARG \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT italic_C italic_E ( over^ start_ARG italic_S end_ARG start_POSTSUPERSCRIPT italic_z end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_S start_POSTSUPERSCRIPT italic_z end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) + divide start_ARG 1 end_ARG start_ARG italic_N end_ARG \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT italic_C italic_E ( over^ start_ARG italic_S end_ARG start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_S start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ), where CE denotes Cross-Entropy (CE) loss and N\u011f\ufffd\u2018\ufffdNitalic_N denotes the number of training samples. In total, the loss function of training the text encoder is defined as where \u00ce\u00b1\u011f\ufffd\u203a\u00bc and \u00ce\u00b2\u011f\ufffd\u203a\u00bd are weighting factors that control the contributions of the different tasks. To bridge IMU sensor readings with their semantic interpretations and enable mobile deployment, we introduce a sensor encoder that maps IMU sensor readings to the language space, aligning them with the semantic interpretation encodings of the same sensor readings. We first describe the structure of the sensor encoder, followed by an explanation of the training process. The objective of the sensor encoder is to capture key features and generate embeddings from IMU data, which can be formulated as: \u011f\ufffd\ufffd\u201e=fs\u00e2\ufffd\u00a2e\u00e2\ufffd\u00a2n\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u2014)\u011f\ufffd\ufffd\u201esubscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018 \u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u203a\u011f\ufffd\ufffd\u2014 = italic_f start_POSTSUBSCRIPT italic_s italic_e italic_n end_POSTSUBSCRIPT ( bold_X ) where \u011f\ufffd\ufffd\u2014\u00e2\u02c6\u02c6\u00e2\u201e\ufffdSdim\u00c3\u2014L\u011f\ufffd\ufffd\u2014superscript\u00e2\u201e\ufffdsubscript\u011f\ufffd\u2018\u2020dim\u011f\ufffd\ufffd\u00bf L}bold_X \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_S start_POSTSUBSCRIPT dim end_POSTSUBSCRIPT \u00c3\u2014 italic_L end_POSTSUPERSCRIPT represents the IMU sensor readings, and \u011f\ufffd\ufffd\u201e\u011f\ufffd\ufffd\u201e denotes the corresponding embeddings. The structure of the sensor encoder is flexible, allowing for either a CNN or Transformer-based architecture. In our work, we adopt a Transformer-based sensor encoder. First, following\u00c2 (Xu et\u00c2 al., 2021), we normalize the IMU sensor readings \u011f\ufffd\ufffd\u2014\u011f\ufffd\ufffd\u2014 to obtain the normalized readings, \u011f\ufffd\ufffd\u2014\u011f\ufffd\ufffd\u00a7\u011f\ufffd\ufffd\u00a8\u011f\ufffd\ufffd\u00absuperscript\u011f\ufffd\ufffd\u2014\u011f\ufffd\ufffd\u00a7\u011f\ufffd\ufffd\u00a8\u011f\ufffd\ufffd\u00ab start_POSTSUPERSCRIPT bold_nor end_POSTSUPERSCRIPT. Next, we project the normalized sensor readings through a linear layer and apply layer normalization to the projected data: \u011f\ufffd\ufffd\u2014\u00e2\u20ac\u00b2=LayerNorm\u00e2\ufffd\u00a2(Wp\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u2014\u011f\ufffd\ufffd\u00a7\u011f\ufffd\ufffd\u00a8\u011f\ufffd\ufffd\u00ab)superscript\u011f\ufffd\ufffd\u2014\u00e2\u20ac\u00b2LayerNormsubscript\u011f\ufffd\u2018\u0160\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\ufffd\u2014\u011f\ufffd\ufffd\u00a7\u011f\ufffd\ufffd\u00a8\u011f\ufffd\ufffd\u00ab start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT = LayerNorm ( italic_W start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT bold_X start_POSTSUPERSCRIPT bold_nor end_POSTSUPERSCRIPT ) where Wpsubscript\u011f\ufffd\u2018\u0160\u011f\ufffd\u2018\ufffdW_{p}italic_W start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT is the weight matrix of the linear layer. Then, we add positional encoding to the normalized data:\u011f\ufffd\ufffd\u2014\u011f\ufffd\u0178\ufffd=\u011f\ufffd\ufffd\u2014\u00e2\u20ac\u00b2+PositionEncoding\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u2014\u00e2\u20ac\u00b2)superscript\u011f\ufffd\ufffd\u20140superscript\u011f\ufffd\ufffd\u2014\u00e2\u20ac\u00b2PositionEncodingsuperscript\u011f\ufffd\ufffd\u2014\u00e2\u20ac\u00b2 { start_POSTSUPERSCRIPT bold_0 end_POSTSUPERSCRIPT = bold_X start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT + PositionEncoding ( bold_X start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ) The position-encoded data \u011f\ufffd\ufffd\u2014\u011f\ufffd\u0178\ufffdsuperscript\u011f\ufffd\ufffd\u20140 start_POSTSUPERSCRIPT bold_0 end_POSTSUPERSCRIPT is then fed through the Transformer encoder, which processes the data across multiple layers to capture complex relationships and dependencies. Each Transformer layer consists of two main sub-layers: Multi-Head Self-Attention and a Feed-Forward Network, both followed by layer normalization and residual connections. For the i\u011f\ufffd\u2018\u2013iitalic_i-th encoder layer, the operations are as follows: First, the Multi-Head Self-Attention mechanism calculates self-attention scores, producing the output: Next, the output from the Multi-Head Self-Attention sub-layer is passed through the Feed-Forward Network: This process is repeated across multiple encoder layers, with the output of each layer serving as the input for the next. Similar to the alignment task in Section\u00c2 3.4.2, we adopt contrastive learning to align embeddings of sensor reading with the embeddings of semantic interpretation of sensor reading. First, the embeddings of both the sensor reading and its semantic interpretation are normalized to unit length. Their similarity is calculated using the dot product between the normalized embeddings, denoted as s\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u201e,\u011f\ufffd\ufffd\u2122)=\u011f\ufffd\ufffd\u201e\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u201e\u00e2\u20ac\u2013\u00e2\u2039\u2026\u011f\ufffd\ufffd\u2122\u00e2\u20ac\u2013\u011f\ufffd\ufffd\u2122\u00e2\u20ac\u2013.\u011f\ufffd\u2018 \u011f\ufffd\ufffd\u201e\u011f\ufffd\ufffd\u2122\u00e2\u2039\u2026\u011f\ufffd\ufffd\u201enorm\u011f\ufffd\ufffd\u201e\u011f\ufffd\ufffd\u2122norm\u011f\ufffd\ufffd\u2122s( }}{|| ( bold_E , bold_Z ) = divide start_ARG bold_E end_ARG start_ARG | | bold_E | | end_ARG \u00e2\u2039\u2026 divide start_ARG bold_Z end_ARG start_ARG | | bold_Z | | end_ARG . The goal of the training is to maximize the similarity between matching pairs while minimizing the similarity between non-matching pairs. Given a batch of N sensor reading and semantic interpretation of sensor reading pairs, the loss function is computed as: where \u00cf\u201e\u011f\ufffd\u0153\ufffd is a temperature parameter. Training process: (i) Training the text encoder: We use the semantic interpretations of sensor readings and activity labels from the source dataset to train the text encoder, embedding human activity recognition-related knowledge and semantics. (ii) Training the sensor encoder for all datasets using raw IMU data and its semantic interpretations (i.e., unlabeled data): The sensor encoder is designed to map any sensor reading into the semantic interpretation space of sensor readings. Inference process: For inference, the sensor encoder and activity label embeddings are deployed on mobile devices. IMU sensor readings are input into the encoder to generate embeddings, which are then compared with the activity label embeddings to calculate similarity. The activity label with the highest similarity is identified as the recognized activity. This process is also used for recognizing new activities. We evaluate the performance of LanHAR\u00c2 using four public datasets that have been extensively employed in existing research\u00c2 (Xu et\u00c2 al., 2023). (1) HHAR\u00c2 (Stisen et\u00c2 al., 2015) includes individuals performing six activities (sitting, standing, walking, going downstairs, going upstairs, and biking) using six different mobile phone types. (2) UCI\u00c2 (Reyes-Ortiz et\u00c2 al., 2016) captures six activities (i.e., standing, sitting, lying, walking, going downstairs, and going upstairs). (3) Motion\u00c2 (Malekzadeh et\u00c2 al., 2019) involves 24 participants performing six activities (sitting, standing, walking, going upstairs, going downstairs, and jogging). (4) Shoaib\u00c2 (Shoaib et\u00c2 al., 2014) includes 10 participants engaged in seven activities (sitting, standing, walking, going upstairs, going downstairs, jogging, and biking). We preprocess all datasets to ensure consistent sampling rates and window sizes. The sampling rate is set to 20 Hz to simulate a resource-constrained scenario, following prior studies\u00c2 (Xu et\u00c2 al., 2023). For cross-dataset activity recognition, we focus on four common activities (walking, going upstairs, going downstairs, and sitting) across the four datasets. We select one dataset as the source and one of the remaining three as the target, resulting in a total of 12 combinations. Datasets are categorized based on their role as either source or target. For source datasets, each is split into a training set (80%) and a validation set (20%). For target datasets, the entire dataset is used as the test set to directly assess cross-dataset performance. For new activity recognition, we train the model on the four common activities from the source dataset. We then select activities from the target dataset that differ from the four common activities as new activities. Finally, we evaluate the model\u00e2\u20ac\u2122s ability to recognize these new activities by determining which activity labels the new data corresponds to. We compare our method LanHAR\u00c2 with three categories of baselines including conventional HAR, cross-dataset HAR, and new activity baselines. (i) Conventional HAR baselines: DCNN\u00c2 (Yang et\u00c2 al., 2015) are widely used in the field of human activity recognition for their ability to automatically extract local features from time-series sensor data. Transformers\u00c2 (Vaswani, 2017) utilize self-attention mechanisms to capture long-range dependencies in sensor data. (ii) Cross-dataset HAR baselines: SDMix\u00c2 (Lu et\u00c2 al., 2022) It is a method for cross-domain activity recognition that uses the mixup method that addresses semantic inconsistencies caused by domain gaps. UDAHAR\u00c2 (Chang et\u00c2 al., 2020) is a method for cross-dataset activity recognition using domain adaptation. UniHAR\u00c2 (Xu et\u00c2 al., 2023) is a method for cross-dataset activity recognition. It designs physical-informed augmentation methods to improve the cross-dataset HAR performance. (iii) New activity baselines: DCNN\u00c2 (Yang et\u00c2 al., 2015) To adapt it for recognizing new activities, we fine-tune it using a small portion of data from the target dataset. Nuactiv\u00c2 (Cheng et\u00c2 al., 2013) is a method designed for new activities. It predefined activity label-related attributes: actions of a specific part of the body. (iv) Variants of our model: (1) LanHAR without Subtasks of Text Encoder (w/o STE). We remove the subtasks from the text encoder, focusing its training on alignment. (2) LanHAR\u00c2 without Training of Text Encoder (w/o TTE). We remove the training part of the text encoder and directly use a pre-trained BERT model to replace the text encoder. (3) LanHAR\u00c2 with LLAMA2 (w LLAMA2). We replace GPT-4 with LLAMA2 for obtaining semantic interpretations. (4) LanHAR\u00c2 with GPT-3 (w GPT-3). We replace GPT-4 with GPT-3 for obtaining semantic interpretations. (5) LanHAR\u00c2 with Different Language Model (w DLM). We use the transformer architecture to replace the BERT in LanHAR. (6) LanHAR\u00c2 without Iterative re-Generation (w/o IG). We remove iterative re-generation method. (7) LanHAR\u00c2 without Iterative re-Generation and designed Prompt (w/o IGP). We remove the iterative re-generation method and designed prompt. We directly use a simple prompt only containing data and task requirement. We evaluate our model using two metrics: accuracy and F1 score. For cross-dataset HAR performance, we use accuracy to measure the correctness of the classification results for the selected four activities. For new activities, we use accuracy to evaluate the correctness of the classification results only for the new activity. We implement our method and baselines using PyTorch 1.9.0 in a Python 3.7 environment and train them using two NVIDIA RTX A5000 GPUs, each with 24 GB of memory. For LLMs, we choose GPT4 as our LLMs to obtain semantic interpretations of sensor readings and activity labels. For the text encoder, we use the BERT-base architecture as its structure and initialize it with the pre-trained BERT-base parameters\u00c2 (Devlin et\u00c2 al., 2018). For the sensor encoder, we set the embedding dimension to 768768768768 for consistency with pre-trained BERT. The multi-head attention parameter is set to 2222 and the encoder layer consists of 3333 layers. We apply the AdamW optimizer with a learning rate of 1e-5 and set the batch size to 32. We compare our method with various baselines, with the results presented in Table\u00c2 2. Overall, our method demonstrates superior average performance across 12 different source and target dataset combinations, leading in the majority of settings. Compared to conventional HAR baselines, our method consistently outperforms them. These traditional baselines are not specifically designed for cross-dataset HAR, and their strong performance typically depends on large, carefully collected datasets. Compared to cross-dataset HAR baselines, our method outperforms the cross-dataset HAR baselines (except in the setting from Shoaib to Motion). Although SDMix and UDAHAR are also designed for cross-dataset HAR, they have certain requirements. For instance, UDAHAR may be more suitable for datasets with smaller distribution gaps. This consistent performance indicates the robustness and reliability of our method in diverse conditions and datasets. We compare our method with two new activity recognition baselines, with the results presented in Table\u00c2 3. Specifically, we train the model using four common activities from the source dataset and evaluate it on different activities from the target dataset that are not among the four common activities, treating them as new activities. The trained model is then used for recognizing these new activities, i.e., determining which activity new data belong to. For new activity HAR, our model outperforms the baseline. Our model\u00e2\u20ac\u2122s performance is superior to that of a fine-tuned DCNN model, which indicates its advantage over simple fine-tuniing on small datasets. Additionally, our model performs better than Nuactiv, which relies on predefined attributes for activities. Defining these attributes is challenging and varies significantly across different activity contexts, directly impacting Nuactiv\u00e2\u20ac\u2122s performance. This limitation hinders Nuactiv\u00e2\u20ac\u2122s performance in cross-dataset settings. We further evaluate the category-level accuracy of HAR performance. An activity is considered correctly classified if it is categorized into a similar activity category, and incorrect if placed into a dissimilar category. Specifically, we group seven activities (walking, jogging, biking, sitting, standing, going upstairs, going downstairs, and lying) into three categories based on their similarity: Category 1 (walking, jogging, biking), Category 2 (sitting, standing, lying), and Category 3 (going upstairs, going downstairs). We compared our method with all the baselines. The average results are shown in Figure\u00c2 10. As shown, our method improves category-level HAR accuracy compared to the baselines. This improvement has the potential to reduce the impact of classification errors on downstream applications. To assess the impact of the subtasks in the text encoder, we compare our method with a variant (i.e., w/o STE), as shown in Figure\u00c2 10. In the w/o STE variant, we remove the subtasks (i.e., the two contrastive learning and reconstruction tasks) and focus only on aligning the semantic interpretations of sensor readings and activity labels. As shown in the figure, removing the subtasks leads to a decline in performance compared to our full model. This demonstrates that the subtasks we designed help the model better understand IMU sensor readings and HAR-related semantics. To further explore the effect of the text encoder for semantic interpretation alignment, we replace the carefully designed text encoder with a pre-trained BERT model and directly use it for training in stage 2. The results are shown in Figure\u00c2 10. From the figure, it is clear that the performance of w/o TTE is lower than both w/o STE and our full model. This suggests that pre-trained language models without fine-tuning cannot fully capture HAR-related semantics or effectively align different HAR-related semantic interpretations. In our text encoder, we used a pre-trained BERT architecture and fine-tuned it with our designed tasks. To explore the impact of using different language model architectures on HAR performance, we replaced the BERT-based structure with GPT-2. As shown in Figure\u00c2 12, this replacement resulted in decreased HAR performance. BERT is generally more suitable for tasks that require understanding sentence meaning and comparing text similarities, as its architecture and pre-training are optimized for capturing semantics and contextual relationships in a bidirectional manner. In contrast, GPT-2, with its unidirectional processing, is less effective at understanding sentence-level meaning and comparing text similarity, though it excels in generating coherent and contextually relevant text. This explains the performance drop when GPT-2 is used for HAR tasks. Given the varying capabilities of different LLMs, we explore the impact of three LLMs (GPT-4, GPT-3, and LLAMA2) on interpreting sensor readings and activity labels for HAR performance. As shown in Figure\u00c2 12, the performance of GPT-3 and LLAMA2 is noticeably lower than that of GPT-4, highlighting the importance of the LLM\u00e2\u20ac\u2122s capability in language-centered human activity recognition. To ensure the quality of the LLM\u00e2\u20ac\u2122s interpretation of sensor readings, we (i) design specific prompts to guide the LLM\u00e2\u20ac\u2122s responses and (ii) develop an iterative re-generation method to filter out low-quality semantic interpretations and generate improved ones. To demonstrate the effectiveness of the automatic iterative re-generation method, we compared the KL divergence of the same activities across different datasets before and after applying the method. Specifically, for each activity, we measure the KL divergence between any two datasets both with and without applying the iterative re-generation method (i.e., \u00e2\u20ac\u0153w iterative re-generation\u00e2\u20ac\ufffd and \u00e2\u20ac\u0153w/o iterative re-generation\u00e2\u20ac\ufffd), as shown in Figure\u00c2 14. After applying the method, the average KL divergence for the same activity across different datasets decreased by 58.75%, indicating that the automatic iterative re-generation method significantly improves the quality of LLM responses and reduces the distribution gap in heterogeneous data. To verify the impact of these methods on HAR performance, we compare our method with two variants: one using only simple prompts (w/o IGP) and another using only specifically designed prompts (w/o IG). As shown in Figure\u00c2 14, the performance when using only simple prompts is the lowest, indicating that LLMs require guidance to generate high-quality responses. The combination of specially designed prompts and the automatic iterative re-generation method performs the best, demonstrating that our approach effectively enhances the quality of LLM responses, leading to improved human activity recognition outcomes. In our model, selecting the appropriate parameters for the sensor encoder is critical, as it directly affects its suitability for deployment on mobile devices (e.g., ensuring the parameter size is sufficiently small). In this section, we primarily analyze the impact of the embedding dimensions and the number of encoding layers on performance. Figure\u00c2 16 shows the performance comparison w.r.t.formulae-sequence\u011f\ufffd\u2018\u00a4\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u00a1w.r.t.italic_w . italic_r . italic_t . the number of attention heads in the sensor encoder. Overall, the performance is relatively stable under different numbers of attention heads. We chose the number of attention heads of 2 because it provides good performance while reducing the model\u00e2\u20ac\u2122s parameter size. Figure\u00c2 16 shows the performance comparison with respect to different numbers of encoding layers in the sensor encoder. As observed, a smaller number of encoding layers (e.g., 2 layers) results in insufficient representation, while a larger number (e.g., 6 layers) increases model complexity. We selected 3 encoding layers as it strikes a balance, delivering good performance without significantly increasing model complexity. To ensure the sensor encoder is suitable for deployment on mobile devices, we analyze its parameter size and inference time. When deployed on a mobile device, the sensor encoder, along with the activity label embeddings (approximately 0.01 MB of memory), requires around 61 MB of total memory. For inference, the execution time for processing one IMU sample (i.e., recognizing an activity) on a Pixel 7 device is 23.71ms. These results confirm that the sensor encoder can operate efficiently on mobile devices. Lessons learned: We summarized the following lessons to benefit future studies: (1) Introducing semantic interpretation can mitigate heterogeneity in cross-dataset HAR and offers the potential for recognizing new activities, as indicated in Table\u00c2 2 and Table\u00c2 3. (2) The success of LLMs in cross-dataset HAR is partly due to their ability to summarize patterns and represent them using language. This leads to lower KL divergence between cross-dataset data distributions compared to raw data. (3) Improving the quality of LLM responses through iterative re-generation, guided by KL divergence, enhances HAR performance. The evaluation shows that generating high-quality responses has a direct positive impact on HAR accuracy. Comparison to other ways of utilizing LLMs: In addition to our approach, there are two other potential methods for utilizing LLMs in HAR: training a foundation model specifically for HAR or fine-tuning an existing open-source LLM, such as Llama. A key advantage of our approach lies in its low cost and flexibility. On one hand, our method does not require large amounts of data or computing resources for model training or fine-tuning. On the other hand, different LLMs can be flexibly integrated into our framework. As demonstrated in our evaluation, incorporating a high-quality LLM could further enhance the performance of our method. Other ways of improving LLMs responses: There are ongoing efforts in the AI community aimed at improving the trustworthiness of LLMs through methods such as retrieval-augmented generation and memory-augmented models. Our approach offers a general framework for post-hoc factuality verification, where advancements in these AI methods can be seamlessly integrated into our framework. Limitations: The process of obtaining semantic interpretations using LLMs is time-consuming, primarily due to the slow inference speed of current LLMs. We anticipate that future advancements in accelerating LLMs will enhance the efficiency of our approach. Although we used four public datasets in the evaluation, they remain relatively small in scale with a limited number of activities. A larger dataset could provide a more comprehensive evaluation and further validate our method\u00e2\u20ac\u2122s effectiveness. Human activity recognition: Human Activity Recognition (HAR) leverages data from various sensors such as accelerometers and gyroscopes to detect and classify human activities\u00c2 (Yao et\u00c2 al., 2017). To mitigate the issue of data heterogeneity, existing work can be classified into three categories, including self-supervised learning methods, domain adaptation methods, and data augmentation methods. Self-supervised methods\u00c2 (Xu et\u00c2 al., 2021; Saeed et\u00c2 al., 2019) aim to maximize the use of unlabeled data to extract valuable features. This approach allows models to require only a minimal amount of labeled data to efficiently adapt to downstream tasks. Despite their capabilities, these models still depend on a certain amount of labeled data to train classifiers, which may underperform when applied to target datasets that lack any labeled data. The core idea of domain adaptation methods\u00c2 (Chang et\u00c2 al., 2020; Qin et\u00c2 al., 2019; Khan et\u00c2 al., 2018; Zhou et\u00c2 al., 2020) involves taking a classifier that has been pre-trained on a source domain and using it with an unlabeled dataset from a target domain, then adjusting the source model\u00e2\u20ac\u2122s weights to enhance its performance in the target domain. Data augmentation\u00c2 (Um et\u00c2 al., 2017; Xu et\u00c2 al., 2023; Qian et\u00c2 al., 2022; Saeed et\u00c2 al., 2019; Wang et\u00c2 al., 2022; Tang et\u00c2 al., 2021) in HAR aims to increase the diversity and quality of training data, thereby enhancing the model\u00e2\u20ac\u2122s generalization ability and accuracy. However, they still face data heterogeneity and heterogeneity can amplify the impact of classification errors on downstream applications. Additionally, cross-dataset scenarios often introduce new activities that existing methods struggle to handle. Some work\u00c2 (Cheng et\u00c2 al., 2013) attempts to address the challenge of recognizing new activities by using predefined semantics, such as actions of specific body parts. These approaches train two mappings: one from sensor readings to predefined semantics, and another from predefined semantics to activity labels. However, the quality of these predefined semantics heavily impacts the model\u00e2\u20ac\u2122s performance. Additionally, this work are not well-suited for cross-dataset new activities, as the new activities may differ significantly from the original dataset. LLM for human activity recognition: Recently, there has been a surge of interest in leveraging the capabilities of large language models (LLMs) to enhance mobile computing applications\u00c2 (Leng et\u00c2 al., 2024). UniHAR\u00c2 (Xu et\u00c2 al., 2023) explore the potential of leveraging large language models (LLMs) to comprehend and interact with the physical world. Kim et al.\u00c2 (Kim et\u00c2 al., 2024) harness the power of large language models (LLMs) to improve health prediction using data collected from wearable sensors. IMUGPT2.0\u00c2 (Leng et\u00c2 al., 2024) utilize LLMs to help data generation since IMU-labeled data is challenging to collect. MotionGPT\u00c2 (Jiang et\u00c2 al., 2023) fuse language data with large-scale motion models, and motion-language pre-training that can enhance the performance of motion-related tasks becomes feasible. We design LanHAR, a novel system that leverages LLMs to generate semantic interpretations of sensor readings and activity labels for cross-dataset human activity recognition and new activity recognition. It adopts a two-stage training framework to transfer the capabilities of LLMs to mobile devices. The experimental results demonstrate that the proposed approach outperforms other state-of-the-art methods.",
        "keywords": "Human activity recognition, Natural language, Large language models"
    },
    {
        "id": 20,
        "title": "Retro-li: Small-Scale Retrieval Augmented Generation Supporting Noisy Similarity Searches and Domain Shift Generalization",
        "abstract": "AbstractThe retrieval augmented generation (RAG) system such asRetrohas been shown to improve language modeling capabilities and reduce toxicity and hallucinations by retrieving from a database of non-parametric memory containing trillions of entries. We introduceRetro-lithat shows retrieval can also help using a small scale database, but it demands more accurate and better neighbors when searching in a smaller hencesparsernon-parametric memory. This can be met by using a proper semantic similarity search. We further propose adding a regularization to the non-parametric memory for the first time: it significantly reduces perplexity when the neighbor search operations are noisy during inference, and it improves generalization when a domain shift occurs. We also show that theRetro-li\u00e2\u20ac\u2122s non-parametric memory can potentially be implemented on analog in-memory computing hardware, exhibitingO\u00e2\ufffd\u00a2(1)\u011f\ufffd\u2018\u201a1O(1)italic_O ( 1 )search time while causing noise in retrieving neighbors, with minimal (<1%) performance loss. Our code is available at:https://github.com/IBM/Retrieval-Enhanced-Transformer-Little",
        "corpus": "The retrieval augmented generation (RAG) system such as Retro has been shown to improve language modeling capabilities and reduce toxicity and hallucinations by retrieving from a database of non-parametric memory containing trillions of entries. We introduce Retro-li that shows retrieval can also help using a small scale database, but it demands more accurate and better neighbors when searching in a smaller hence sparser non-parametric memory. This can be met by using a proper semantic similarity search. We further propose adding a regularization to the non-parametric memory for the first time: it significantly reduces perplexity when the neighbor search operations are noisy during inference, and it improves generalization when a domain shift occurs. We also show that the Retro-li\u00e2\u20ac\u2122s non-parametric memory can potentially be implemented on analog in-memory computing hardware, exhibiting O\u00e2\ufffd\u00a2(1)\u011f\ufffd\u2018\u201a1O(1)italic_O ( 1 ) search time while causing noise in retrieving neighbors, with minimal (<1%) performance loss. Our code is available at: https://github.com/IBM/Retrieval-Enhanced-Transformer-Little 2402 Natural language processing is a rapidly growing field in machine learning. Advancements in large language models are mostly a product of the neural scaling law\u00c2 [20]. Not only are language models themselves becoming larger, but their training data also follows suit. While GPT-3\u00c2 [3] was trained on 300 billion tokens, GPT-4\u00c2 [36] was trained on around 13 trillion tokens. As a result, the information retained by a language model is difficult to update or fact-check. Many of these data sources contain discriminatory language or misinformation, which are difficult to remove given the sizes of these datasets\u00c2 [7]. In retrieval augmented generation (RAG)\u00c2 [26], a language model is enhanced with a non-parametric memory as depicted in Figure\u00c2 1. During training and inference, for each input sequence, RAG searches this memory for the k\u011f\ufffd\u2018\u02dckitalic_k most similar sequences (the so-called nearest neighbors) and uses them as additional input. RAG has been shown to help with under-fitted language models as the non-parametric memory increases with the number of training tokens\u00c2 [15]. Moreover, it has been shown to reduce toxic language and hallucinations\u00c2 [52] through its use of retrieval. Furthermore, unlike in purely parametric models, it is straightforward and does not require extensive computing power to update the retrieval database of a RAG model to reflect updated information. Finally, in a question-answering context, the ability to provide sources for the answer helps combat misinformation. This provides users with the opportunity to double-check the responses themselves, aiding the models\u00e2\u20ac\u2122 interpretability. Despite all the aforementioned functional advantages of RAG, in many cases, the retrieval database of non-parametric memory contains trillions of tokens to be searched. In fact, in Retro\u00c2 [2], the scale begins at a retrieval database size of billions of tokens, which raises the question of search speed and optimization. Although similarity search acceleration libraries such as Faiss\u00c2 [19] and ScaNN\u00c2 [10] can compare millions of vectors in milliseconds, they quickly become a bottleneck, especially for retrieval databases containing trillions of tokens (e.g., see Section\u00c2 3.3.1) . To address this critical bottleneck, we suggest three directions whose effectiveness is shown in our proposed Retro-li. The contributions of this paper are as follows: 1) We enable RAG to work with a small-scale database. In Retro-li, we change the embedding of the retrieval system, and for the first time add regularization in the form of Gaussian noise to the neighbor embeddings of the non-parametric memory. We employ a novel embedding model that excels in semantic similarity search allowing retrieval of higher quality neighbors despite searching in a sparse non-parametric memory, and the regularization consistently improves domain shift generalization. We show that the new retrieval helps with language modeling on small-sized retrieval databases over having no retrieval database. 2) We advocate for the use of in-memory computing (IMC) hardware to reduce the complexity of search. Analog IMC performs certain operations in place in-memory by exploiting the physics of e.g., non-volatile memory devices, offering O\u00e2\ufffd\u00a2(1)\u011f\ufffd\u2018\u201a1O(1)italic_O ( 1 ) computational complexity for similarity search with a set of precomputed vectors (see\u00c2 [43] for an overview). This feature is highly valuable for the efficient realization of memory-augmented neural networks as shown in\u00c2 [21]. Due to nonidealities, however, the analog search operation of IMC is noisy. We simulate this behavior of the IMC hardware by adding a wide range of noise to the neighbor embeddings at inference time. We show that the resulting noisy retrieval does not decrease the Retro-li\u00e2\u20ac\u2122s performance (i.e., a maximum of <1% drop) thanks to our training with regularization. This suggests deployment of the non-parametric memory on the IMC hardware which would significantly improve inference time, in addition to energy consumption and computational density. 3) For domain shift generalization, we plug-and-play the related domain database without any fine-tuning in Retro-li. This is encouraged by having a closer look at the Retro that reveals that size is not the most important aspect of the retrieval database: a smaller but relevant retrieval database improved the model performance w.r.t. an order of magnitude larger database. Although Retro advocates for a large retrieval database with as much variety as possible to make the model more general, we show that their system can be even more modular than that. In Retro-li, it is straightforward to replace the retrieval database with data from domain A if inference sequences are also from domain A. With this high degree of plug-and-play, there is no need to build a database with trillions of tokens from as many sources as possible. The user can easily build a new database for each domain of interest. Furthermore, we show Retro-li can also benefit from fine-tuning similar to the other models without a retrieval. Our proposed Retro-li is a medium-sized parametric model based on Retro with a small-scale non-parametric database. In Retro-li, the embedding model used for the neighbor search is a Bert based sentence similarity model called SBert. The architecture diagram of Retro-li is shown in Figure\u00c2 2, where we enhanced GPT-2 attention blocks similarly to what has been down with Retro-fitting to improve our language modeling performance without extensive re-training. Retro-fitting as introduced in the Retro paper\u00c2 [2], refers to taking a language model not trained with retrieval and adding retrieval in the form of a frozen retrieval database and chunked cross-attention (CCA) blocks in order to incorporate the information from neighbor embeddings in the training sequences. To query the key-value retrieval database (DB), each input sequence is split into chunks. An input sequence contains 1024 tokens, for a chunk length of 64 tokens this is 16 chunks per sequence. The neighbors consist of [N, C], each N containing 64 tokens and C containing another 64 tokens. The retrieval is based on N only, the key of this key-value pair, the value being C, which is the continuation of N. We retrieve them for each chunk. Equation\u00c2 1 shows retrieval of 10 neighbors for each chunk in a sequence consisting of 16 chunks from the retrieval database (DB). It is worth noting that Retro does not exhibit any meaningful results concerning improved performance below a retrieval database size of 100 billion tokens. For their two smallest models, adding a retrieval database of two billion tokens improves performance slightly (0.1 bits-per-byte on C4). However, then even increasing the database ten-fold does not change performance further. The only meaningful jump in performance for the smallest models happens once the retrieval database increases from 360\u00e2\u20ac\u2030B tokens to 900\u00e2\u20ac\u2030B tokens. This is expensive in terms of space and compute power, thus unrealistic for most setups. Instead, in Retro-li, we show how performance can be improved using retrieval databases at orders of magnitude smaller scale (570\u00e2\u20ac\u2030K up to 2.89\u00e2\u20ac\u2030B database tokens) through architectural enhancements and training strategies. Retro\u00e2\u20ac\u2122s retrieval database is built using ScaNN\u00c2 [10], a locality sensitivity hashing index, while for Retro-li we use Faiss\u00c2 [19], an inverted vector files (IVF) index. Retro embed their chunks using Bert embeddings\u00c2 [5], while for Retro-li we choose SBert\u00c2 [41], specifically trained for semantic similarity search. For the tokenization, Retro uses SentencePiece\u00c2 [24], a byte-level encoding model, and a vocabulary size of 128\u00e2\u20ac\u2122000. Retro-li instead uses the GPT-2 tokenizer, thus a vocabulary size 50\u00e2\u20ac\u2122257. In Retro-li, we set out to work with small retrieval databases and almost no token overlap (see Appendix A.2). Thus, we have to be judicious about which neighbors are returned. In this setup with smaller retrieval databases, the search space of sequences is not as densely populated, thus not finding the true closest sequence carries a bigger penalty. Considering both ease of use and theoretical results, we choose to use SBert\u00c2 [41], a Bert-based sentence-similarity model, in Retro-li. We use the pre-trained model multi-qa-mpnet-base-dot-v1 of SBert due to its superior performance in semantic textual similarity tasks in the massive text embedding benchmark (MTEB\u00c2 [32]). The embedding model outputs 768-dimensional vectors and has a model size of 420\u00c2 MB. This vector dimensionality and model size are compatible with the embedding size and the model size of the GPT-2 backbone used in Retro-li. SBert adds a pooling operation to the output of Bert, resulting in a fixed-size sentence embedding. For our chosen embedding model, this pooling operation is CLS pooling, which involves using the CLS token embedding to represent the sentence. These embeddings were specifically trained for semantic similarity search. More details on SBert can be found in Appendix\u00c2 B. The role of noise in the retrieval has to the best of our knowledge never been analyzed. Here, a first foray into this topic is made. Adding noise to word embedding as a way of improving the generalization capabilities of language models has been done before\u00c2 [55], but not in combination with retrieval. Taking inspiration from NEFTune\u00c2 [18], we aim to improve generalization through a word-embedding regularizer. We introduce a new regularization method by adding noise to the word embeddings of the non-parametric memory, in contrast to NEFTune which regularizes the input sequence, in Retro-li their retrieved neighbors are regularized (see Figure\u00c2 2). For a matrix M of dimension n_emb \u00c3\u2014 seq_len describing the embedding matrix of a sequence, we compute: The relative standard deviation \u00ce\u00bbtsubscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT describes the magnitude of the noise added. During training, we add a vector sampled from this \u011f\ufffd\u2019\u00a9\u00e2\ufffd\u00a2(0,\u00cf\u0192)\u011f\ufffd\u2019\u00a90\u011f\ufffd\u0153\ufffd ( 0 , italic_\u00cf\u0192 ) distribution to our neighbor embeddings. We explore a variety of regularizers, some similar to NEFTune, some more similar to the intrinsic noise in the stochastic IMC hardware (see Section\u00c2 3.2.3), ensuring that the signal-to-noise ratio from different approaches remains comparable. We base our work on an earlier Retro implementation\u00c2 [50] in which the retrieval database and the similarity search are implemented with Faiss index. The training is accelerated with a single Tesla V100 GPU with a maximum 80\u00c2 GB memory. The task is language modeling on WikiText-103 and the numbers we report are the perplexities for WikiText-103-Validation. Just as in Retro, we employ a sliding window approach, where we compute the perplexities for an overlapping proportion greater than or equal to 75% of the context, more on this in Appendix\u00c2 D. Our work is also inspired by the Chinchilla law\u00c2 [15] to determine the architecture and training strategy so that it fits a setup of any scale. For this particular task, we train on one GPU for 1\u00e2\u20ac\u2122078\u00e2\u20ac\u2122012 sample sequences resulting in a total of 1.104\u00c3\u20141091.104superscript1091.104 10^{9}1.104 \u00c3\u2014 10 start_POSTSUPERSCRIPT 9 end_POSTSUPERSCRIPT tokens. The time to train one epoch grows with the number of neighbors, but sub-linearly. Training on 10 neighbors takes about twice as long as training on 2 neighbors but training on 2 neighbors takes about the same time as training on no neighbors. We conduct an initial exploration of the experiment space with only a frozen GPT-2 component. So we train not only the CCA but also the feed-forward (FFW) blocks (see Appendix\u00c2 E for the corresponding architecture diagram). A pattern emerges, where SBert does better than Bert and 3 neighbors do best while not taking much more time to train on, compared to no neighbors. For our retrieval experiments we only freeze the GPT-2 layers as shown in Figure 2. We explored un-freezing these layers as well, see Appendix\u00c2 F. Both Retro-li-off and Retro-li-on are trained on the same data and, aside from the GPT-2 attention blocks and embeddings, from scratch. For the first batch of experiments, we gradually increase the number of neighbors from 2 up to 10 and run the experiments for three random seeds. In Table\u00c2 1 we report their average. Bert embeddings with 5 neighbors already outperforms Retro-li-off. Moreover, changing the embedding model to SBert improves our performance significantly. This shows that not only does SBert find more semantically similar neighbors, but our model also correctly attends to them. Furthermore, we see that for Bert embeddings all cases except the number of neighbors equal to 5 under-perform Retro-li-off. At this stage of the model training, where we only freeze GPT-2 blocks, it is too difficult for our model to find its way through the loss landscape to get to the best possible performance. Adding sub-optimal neighbors at this point exacerbates the issue. This makes the SBert results even more remarkable. The neighbors found through the SBert embeddings genuinely inform the model, helping it to converge. Still, not all numbers of neighbors improve the performance compared to no retrieval, confirming what\u00c2 [1] and\u00c2 [42] have already observed. Finally, we note that with this setup, for the Bert embeddings, and Retro-li-off the variance between the random seeds is very large. This is partially because we were unable to train all checkpoints to convergence, as some got stuck in local minima. Thus another aspect we show here is how SBert embeddings help to avoid/escape these local minima. Overall, adding neighbors at a stage where the language model itself has not converged yet can help, but does not always. We conclude that we must first address the language modeling before we can add neighbors and benefit from them. Similarly to NEFTune, we add uniform noise to the word embeddings during training. The goal of it is to improve the generalization capabilities of our model. We add it to the training sequence itself, to the neighbors, and also both. We again average the result over three random seeds and ablate the noise type as well as the noise strength. Preliminary ablations performed to determine the best type of noise, both in terms of magnitude and in terms of where the noise is added (so whether to add on the input embeddings or to the neighbor embeddings), showed that regularization works best when moderately added only to the neighbor embeddings. The full results are in Appendix\u00c2 C. We also performed additional experiments to determine the best type of noise among the uniform and the Gaussian while ensuring a similar signal-to-noise ratio. Results are shown in Table\u00c2 2. A Gaussian with zero mean and \u00ce\u00bbt=0.2subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u00a10.2 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0.2 (the variance as described by Equation\u00c2 2) improves our generalization performance better than the rest of the regularizers we have tried. Table\u00c2 3 shows the impact of this best-performing regularizer (the Gaussian regularizer with \u00ce\u00bbt=0.2subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u00a10.2 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0.2) in both language modeling and domain shift. In the WikiText-103 language modeling, the regularizer improves or at least does not impair the validation perplexity in various inference settings: having no neighbors, ideal retrieval, or different amounts of noise during inference (i.e., \u00ce\u00bbi\u00e2\u02c6\u02c6{0.2,0.4,1}subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u20130.20.41 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 { 0.2 , 0.4 , 1 }). For the domain shift experiments, it exhibits more promising behavior and consistently shows benefits when different noisy scenarios are considered. More details are provided in the next subsection. WikiText BBC-News Reuters We use three architectural settings for domain shift generalization: Off (i.e., no retrieval). This model was never trained with retrieval. Retro-li-on with no neighbors: This model was trained with retrieval, but we do not give it any neighbors at inference time. Retro-li-on with ideal (i.e., not noisy) retrieval: This model was trained with retrieval and we give it the ten nearest neighbors per chunk at inference time. The setting Retro-li-on with no neighbors is meant to ascertain how much of the domain shift performance gain is simply due to improved language modeling capabilities, and not due to the retrieval itself. In settings with Retro-li-on, we further have a model trained with a regularizer or without one. In Table\u00c2 3, we only include the best-performing regularizer, a Gaussian regularizer with \u00ce\u00bbt=0.2subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u00a10.2 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0.2 (see Equation\u00c2 2), which also reflects the signal-to-noise ratio observed in the modern IMC hardware (more on this in Section\u00c2 3.3.1). For domain shift experiments with Retro-li-on settings, we take the model and plug in a new retrieval database. In this case, creating a new retrieval database consists of the following steps. First, we train the models on a base dataset A. For a new domain dataset B, C, D, or E (i.e., a different domain) we create a retrieval database with the training tokens of B, C, D, or E, respectively, then chunk the validation sequences of B, C, D, or E, respectively, and find the closest neighbors in the retrieval database for each validation chunk. Then, we plug this database, which includes chunk-to-neighbor mapping, into our model, feed it with the validation sequences as input, and measure the new perplexity. We do not fine-tune the models on any of the target domains whatsoever. Table\u00c2 4 lists the datasets used for domain shift experiments, which are ordered by the size of the retrieval databases. The datasets are chosen such that they are sourced from a variety of domains and have sufficiently distinctive characteristics to identify them as unique domains. The datasets are further explained with their differences highlighted in Appendix\u00c2 A. In the context of this work, a domain refers to the formality of the language. At one end, we have Wikipedia, which is highly formal text, and on the other end, we have SlimPajama, which consists mostly of text gathered through web crawling and thus contains predominantly informal, poorly or unstructured text, in a variety of languages and even quite a bit of code (see Appendix\u00c2 A.3 for more details). Unlike for the previous experiments, here we take our best baseline transformer (Retro-li-off), re-set the optimizer and only train the CCA blocks on top of it using dataset A (see above). For the neighbors, we choose three neighbors and SBert embeddings. This way, we can more closely emulate the experiments done by Retro and observe what the true performance gain of retrieval is. This has the benefit of not only decreasing the variance across seeds but additionally enabling us to keep the Retro-li-off performance exactly intact. We take the best Retro-li-off checkpoint and keep training it for six random seeds, with and without retrieval, and with and without regularization. WikiText-103 is taken as the base dataset (dataset A, see above) for the taining. We train both Retro-li-on and Retro-li-off, in order to confirm that the improved performance is not due to the increased number of training tokens. As is evident in the rows for Retro-li-on with ideal retrieval in Table\u00c2 3, when compared to Table\u00c2 1 with training from scratch, this setup decreases WikiText-103-Validation set perplexity for both, Retro-li-on and Retro-li-off. The seemingly significant perplexity improvement of Retro-li-off is due to there no longer being one particularly bad random seed, as this setup reduces the variance across seeds. Retro-li-off has 109\u00e2\u20ac\u2030M trainable parameters, and 234\u00e2\u20ac\u2030M parameters in total, while Retro-li-on has 24\u00e2\u20ac\u2030M additional parameters due to the CCA blocks. Moreover, since Retro-li-on freezes all parameters except for the CCA blocks, only those 24\u00e2\u20ac\u2030M are updated, as opposed to 109\u00e2\u20ac\u2030M parameters for Retro-li-off. As shown in Table\u00c2 3, even without a regularizer, we see across seeds and datasets that Retro-li-on deals with the domain shift better than Retro-li-off. Adding a regularizer to the retrieval improves this performance even further. In this table, the datasets are ordered by the size of the retrieval databases. Although retrieval and regularization help, the perplexity also keeps going up, despite our retrieval database size increasing as well. However, considering the improved percentage, where Retro-li-off is our baseline, we can see that our Retro-li-off model struggles with a large domain shift, where retrieval and regularization help the most. This performance improvement is not solely due to the fact that Retro-li-on is already better at language modeling. Consider the \"No neighbors\" rows, where we replace the nearest neighbors of a sequence with the sequence itself and mask out the continuation. Hence, the model cannot benefit from retrieval in this setup (i.e., no extra information is retrieved) but includes the additional 24\u00e2\u20ac\u2030M parameters due to the CCA blocks. We observe that Retro-li-on\u00e2\u20ac\u2122s performance without neighbors drops significantly and the performance is similar to Retro-li-off. This indicates that neither the additional parameters nor the better language modeling capability, but the actual retrieval improves our model\u00e2\u20ac\u2122s generalization ability. For Retro-li-on with the Gaussian regularization we observe that the model outperforms Retro-li-on without a regularizer on all domain shift datasets. This suggests that the retrieval model can be trained with the regularizer to emulate a denser search space. Moreover, in the setup where no neighbors are given, the regularizer also improves the performance of the language model without any access to retrieval. Before delving into the potential benefits and challenges of retrieval with the IMC hardware, let us explain how it has been done in the state-of-the-art. Currently, we search for the nearest neighbors using Faiss which is an inverted vector file (IVF) index. An IVF index clusters the vectors to be searched into c\u011f\ufffd\u2018\ufffdcitalic_c centroids, where each vector is assigned to one centroid. Upon receiving a query, Faiss searches n\u00e2\ufffd\u00a2p\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2o\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2e\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u0153\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2019nprobeitalic_n italic_p italic_r italic_o italic_b italic_e of those c\u011f\ufffd\u2018\ufffdcitalic_c cells to find the nearest neighbors. This reduces the search time by reducing the search space to the number of centroids to be probed while preserving good performance. However, an IVF index requires training to identify optimal centroids. In Table\u00c2 5, we measure the time it takes for the search function call to IndexIVF_search to complete. This function is called on 16 chunks concurrently on a Tesla V100 GPU. More on these measurements including the search time distributions can be found in Appendix\u00c2 G. Next, as a natural extension of memory-augmented neural networks\u00c2 [21], we assess whether the non-parametric memory of Retro-li can be moved to a specialized hardware that operates based on the IMC principles. This would make vector searches and thus retrieval much faster, as it foregoes the memory wall issues prevailing in GPUs caused by the high bandwidth data transfers. If the retrieval database is very large (such as in Retro\u00e2\u20ac\u2122s case where we have trillions of tokens and 28 billion database keys) the data transfer becomes the bottleneck, especially during inference. We estimate that on a larger scale IMC hardware platform inspired by the early-stage prototype\u00c2 [22], the similarity search time could be brought down to several hundred nano-seconds. One drawback of the IMC hardware however is low-precision and noisy similarity searches due to analog computations with non-idealities. We simulate the noise on such a hardware platform by a Gaussian distribution with zero mean and a certain standard deviation \u00cf\u0192\u011f\ufffd\u0153\ufffd described by Equation\u00c2 2. This additive noise at inference time is denoted by \u00ce\u00bbisubscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT as opposed to \u00ce\u00bbtsubscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT which is used to describe the noise during training. For a more in-depth explanation of noise modeling on IMC-based hardware, please refer to\u00c2 [39]. For instance, for a recent large-scale chip based on phase-change memory devices\u00c2 [22], this relative standard deviation is 0.2. Adding Gaussian noise with a variety of relative standard deviations to our neighbor word embeddings at inference time gives us stable results, despite it not being seen during training (i.e., trained with \u00ce\u00bbt=0.2subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u00a10.2 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0.2 while tested with \u00ce\u00bbi\u00e2\u02c6\u02c6{0,0.2,0.4,1.0}subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u201300.20.41.0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 { 0 , 0.2 , 0.4 , 1.0 } ). This is evident in Table\u00c2 3, in the rows describing the setting noisy retrieval with no regularize (i.e., None). Even for a relative standard deviation as large as 1.0, the performance never drops more than 1% compared to the ideal retrieval without any noisy neighbors. This suggests that the searches on the non-parametric memory can be moved to the IMC hardware without issue. Training with the regularizer does not decrease the performance drop upon adding noisy retrieval at inference time in all cases. For \u00ce\u00bbi=0.2subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u20130.2 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 0.2 and \u00ce\u00bbi=0.4subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u20130.4 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 0.4, even when we did not train using a regularizer, our performance dropped about the same relative to ideal retrieval as if we had trained with a regularizer. On the other hand, for \u00ce\u00bbi=1.0subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u20131.0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 1.0, a large relative standard deviation, this regularized training does make a difference. Where other models fail, the one trained with a Gaussian regularizer is barely affected. This can be seen more clearly in Table\u00c2 2 where we also add the standard deviation error bar for the six random seeds. Finally, we perform an ablation study with a more detailed and accurate noise inference model given in Analog AI hardware kit\u00c2 [39]. This model splits the database to store its content on realistic IMC crossbar sizes. During the similarity search, it captures the non-idealities associated with the crossbars both short term such as read noise, and long term such as drift. For the memory device level noise modeling Phase-change Memory (PCM) preset\u00c2 [35] is chosen with a maximum conductance of 25\u00c2 uS and the rest of the parameters as default. The results of this study are presented in Table\u00c2 6. We use the best-trained models on the WikiText and BBC-News datasets and compare the inference results where in one case there is no noise on retrieved neighbors and in the other case the retrieval neighbors\u00e2\u20ac\u2122 noise is modeled comprehensively using the Analog AI hardware kit. We notice that the noisy retrieval across both datasets drops only by a negligible margin (<0.003%) indicating the robustness of the Retro-li models trained with regularization towards noisy retrieval. In order to better understand the quantitative results, we present here some generated samples from our worst-performing domain, SlimPajama. We evaluate the semantic similarity of the model-generated chunk to the real continuation chunk. For Retro-li-on and Retro-li-off we pick their best-performing validation samples on SlimPajama-Validation, feed 75% of the context window into the model and generate the next chunk. In order to evaluate the similarity of the generated chunk to the real continuation, we embed it using SBert and report the similarity measure. We employed several generation modes of which we only present the best-performing ones from retrieval on and off in Tables\u00c2 7 and\u00c2 8 respectively, full results for this experiment can be found in Appendix\u00c2 H. The dot product results are in brackets for each chunk. We see that the Retro-li-on generated sample is not only more coherent but more similar semantically to the real continuation chunk than the Retro-li-off generated sample is to its own real continuation chunk. In addition to the plug-and-play style domain shift generalization experiments, we conduct experiments in which both Retro-li-on (with regularization of Gaussian with \u00ce\u00bbt=0.2subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u00a10.2 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0.2) and Retro-li-off models undergo a minimal amount of fine-tuning steps with partial parameter updates while the bulk of their parameters remain frozen. The main motivation for this exercise is to assess how far the perplexity performance can go down with a minimalistic fine-tuning effort (in terms of both the number of updated parameters and steps of updates) compared to the plug-and-play domain shift experiments which involved no fine-tuning whatsoever. From a selected dataset (e.g. B, C, D), we first randomly sample 15% of the training set data and reserve it as the input sequences to be used during the fine-tuning phase. The remaining 85% of the training set data are directed toward building the retrieval database to be used during the fine-tuning phase. Note that the training input sequences and the retrieval database are made mutually exclusive in order to avoid undesired leakage effects during retrieval. As a starting point, we take the best checkpoints created by training both Retro-li-off and Retro-li-on models on the base WikiText-103 dataset as mentioned in Section\u00c2 3.3. For Retro-li-on models we observe updating CCA layer parameters leads to slightly worse performance. Hence we update only the parameters in the feed-forward layers and the read-out layers for both model types during fine-tuning for a few epochs. After fine-tuning for a few epochs, the updated model checkpoints are used to run inference on the validation sets from the corresponding datasets. The validation training sequences and the validation retrieval database are prepared exactly the same way as in plug-and-play experiments explained in Section\u00c2 3.3 such that the performance can be compared under equal settings. The results of fine-tuning experiments are presented in Table\u00c2 9. We evaluate on a subset of datasets used for the plug-and-play domain shift generalization experiments, namely, BBC-News, Reuters, CNN-DailyMail. At epoch=0, i.e., before any fine-tuning, the perplexities reported on the validation show that Retro-li-on consistently dominates Retro-li-off. This is in line with the plug-and-play results in Table\u00c2 3; the slight deviations are due to the number of tokens considered in each sequence for the evaluation. We observe that for all datasets, the best perplexities are achieved within the first five epochs. This indicates that only a minimal amount of updates are sufficient to fine-tune both Retro-li-on and Retro-li-off models. Retro-li-on variant tends to take one or two additional epochs to reach the best perplexity and remains slightly higher compared to the best perplexity of Retro-li-off. However Retro-li-off shows signs of strong overfitting with training on more and more epochs. In summary, fine-tuning leads to competitive perplexities in both Retro-li-on and Retro-li-off models. In RAG, there are various approaches to make use of retrieved neighbors. For instance, one approach\u00c2 [26] adds the neighbors to enhance the context of an input sequence, whereas Retro\u00c2 [2] attends to the neighbors using the CCA mechanism. It is also possible to use both approaches by adding the nearest neighbor to the context window as well as attending to the other neighbors through CCA. Retro outperforms the approaches without CCA slightly on Natural Questions tasks, but\u00c2 [52] outperforms Retro by a wide margin by combining the two approaches. Scalability is central for Retro in particular, as it significantly improved results in language modeling once the retrieval database reached one trillion tokens. For the models closer to our model size adding retrieval barely made a difference. The figure on the second page of the Retro paper reveals that although bits-per-byte drops upon adding retrieval, even making the retrieval database almost 10\u00c3\u2014 larger (up to 10 billion tokens) did not affect the performance. All of this culminates in a state-of-the-art test perplexity of 2.4 on WikiText-103-Validation. It has to be said that, as the Retro\u00e2\u20ac\u2122s authors noted themselves, it is evident that this perplexity is mainly due to validation set leakage. This is practically unavoidable with a retrieval database of this size no matter the validation set, as there is only so much data that can be web-scraped and is public domain. Furthermore, a retrieval database consisting of trillions of tokens is unrealistic for most setups. Although it is a one-time cost and adding new entries is straightforward, it is difficult to find open-source datasets of this size, let alone have the resources to clean up and process them appropriately. Recent works\u00c2 [17, 27, 31] apply principles of RAG for few-shot learning tasks where retrieval helps with the meta-learning process. However, these models are typically larger compared to Retro-li, operate on different tasks/datasets, and crucially fail to establish a retrieval-off baseline for their respective models. This makes the quantitative comparison of Retro-li against these models somewhat unrealistic. Harnessing the inherent capabilities of language models for specific tasks can be done in many ways. One is through classical fine-tuning, where we add a task-specific head to a pre-trained model to obtain a task-specific model. We can also use pre-trained models via few-shot prompting for tasks such as generative question answering. Finally, in\u00c2 [18] they settled on instruction tuning, where existing samples were augmented with instructions in natural language. The authors observed that adding uniform noise, reminiscent of noise added in adversarial literature, to the word embeddings of the instructions improved the performance of such models significantly through a regularization effect. Given that one objective of these RAGs is to improve generalization through the non-parametric memory, we investigated adding such a regularizer to our non-parametric memory. With Retro-li, we have shown that by proper architectural enhancements and training strategies, there is a role for retrieval in the medium-size parametric models using small-sized retrieval databases that are orders of magnitude smaller (570\u00e2\u20ac\u2030K up to 2.89\u00e2\u20ac\u2030B database tokens) compared to Retro. Retro-li consistently improves language modeling and cross-domain generalization compared to the same architecture without retrieval. By applying regularization to the non-parametric memory, we improved the generalization ability of Retro-li even further. Additionally, we have shown that the non-parametric memory can be made robust against noisy similarity searches, which makes it amenable for deployment on the efficient IMC hardware without performance loss. When needed, Retro-li can similarly benefit from fine-tuning. Future work would evaluate task-specific performance, especially in the domain of question answering. Retro has been shown to lower hallucinations and be less toxic when compared to its non-retrieval counterpart by retrieving from trillions of tokens, but not yet at a small scale. Moreover, there are embedding models that are better suited for semantic similarity search than SBert, as measured by the MTEB benchmark. Changing the embedding model is straightforward, although the retrieval database must be re-computed. In Retro-li, we attend to all retrieved neighbors indiscriminately, whereas future work could add a similar mechanism as Self-RAG\u00c2 [1] to decide when and if to retrieve neighbors, or select an optimal subset of them\u00c2 [53]. It might also explore Retro-fitting better foundational models, or different attention-based architectures altogether. Future work would also include more accurate hardware-aware training, obtained by applying training techniques similar to the ones presented in\u00c2 [40]. These techniques so far are applied to parametric weights. It will be interesting to see how these training dynamics play out in the non-parametric memories similar to the ones used in Retro-li. This work is supported by the Swiss National Science foundation (SNF), grant 200800. We describe the dataset used in the language modeling experiments and the datasets used for the domain shift experiments. The goal was to use datasets with strong baselines to compare our model to, and which would need minimal pre-processing for our purposes. The WikiText dataset [30] was created to address the issue of there not being a text dataset with long-form content and original punctuation, capitalization, and numbers. As opposed to web-scraped content, the text is more structured and has fewer typos or colloquialisms. This is because the authors employed a measure of quality control by only considering Wikipedia articles, as well as restricting themselves to verified good or featured articles. A good article has been nominated by a reviewer as well as confirmed by an impartial editor to be \"well-written, contain factually accurate and verifiable information, are broad in coverage, neutral in point of view, stable, and illustrated, where possible, by relevant images with suitable copyright licenses.\"111https://en.wikipedia.org/wiki/Wikipedia:Good_articles. Only about 0.5% of Wikipedia articles make the cut. On the other hand, a featured article refers to one of the best articles on Wikipedia as decided upon by the editors. The criteria for a featured article are stricter than for a good article, and more comprehensive222https://en.wikipedia.org/wiki/ Wikipedia:Featured_article_criteria.. Such articles make up around 0.09% of Wikipedia. More details on the processing steps can be found in Section 4.3 of their paper. We use WikiText-103 which consists of around 103 million training and 254 thousand validation tokens. We use the same database for training and validation and generate it using WikiText-103-Train. Validation and training sequences of the WikiText dataset are disjoint by design. To avoid leakage during training we ensure that the neighbors of the training sequences are never direct continuations. Finally, we report the 1-gram Jaccard-Similarity [33] of the training sequences and their two nearest neighbors in Figure 4 and the ten nearest neighbors in Figure 5 as a way to determine leakage. As is evident in the histograms, for most neighbors we do not get a Jaccard-Similarity of more than 0.2, so limited leakage is assured. In the Retro paper they checked if the training sequences have eight or more contiguous tokens in common with one of their neighbors to determine the degree of leakage. In our case, for the training and validation set, 4.76% and 5.1% of the ten nearest neighbors respectively have at least eight contiguous tokens in common with the sequence used to query the index. Evaluating such samples qualitatively, in Figure 3 we can show that this is hardly leakage in a sense that our model could exploit, as the neighbors come from different articles. For our domain shift experiments, we choose datasets of varying textual structures and sources. If a train/test/validation split is given, we take the training data to create the retrieval database and validation data to evaluate on. If only a train/test split is given, we use the test data to evaluate on. Since for the inference experiments we created the retrieval database fully out of the training data and only predicted on the validation data, no leakage is possible. Retro was trained on MassiveText [37] which is unfortunately proprietary. Furthermore, The Pile [6] which is an open-source alternative to MassiveText and on which Retro was also trained for comparison purposes, was taken down in July of 2023 due to a DMCA (Digital Millenium Copyright Act) notice333https://academictorrents.com/details/ 0d366035664fdf51cfbe9f733953ba325776e667.. The Nvidia Retro implementation training data was mostly based on The Pile [45] as well. This means that we could not use the same dataset as Retro, which would make it harder for us to compare our performance to theirs. As an alternative, looking for datasets similar in data sources and size to The Pile, we decided on SlimPajama [46] which is a cleaned and de-duplicated version of RedPajama [4]. De-duplication is especially important for textual training data, see [25]. In Table 10 we compare The Pile to SlimPajama, where Pile-CC is comparable to CommonCrawl and C4 [38]. We see that although the data sources themselves are similar, the proportions are only somewhat comparable. As most text in the SlimPajama dataset comes from CommonCrawl, it is largely unstructured and conversational. Although for humans it is easy to read and understand, this type of content is significantly dissimilar to Wikipedia articles, in flow, grammar, as well as vocabulary. We use a sub-sampled version of Slimpajama-627B, namely Slimpajama-6B444https://huggingface.co/datasets/DKYoon/SlimPajama-6B.. Furthermore, Slimpajama-6B still needed some clean-up, as there were many instances of repeating characters used as filler or for code comments in the CommonCrawl portion of the dataset. This leads to a total of 5.5B tokens usable for training. Finally, to reduce memory usage and simplify the code structure, we truncate all samples longer than 1024 tokens. Considering all of this as well as using their train/validation split, we end up with 2\u00e2\u20ac\u2122886\u00e2\u20ac\u2122850\u00e2\u20ac\u2122140 training tokens and 4\u00e2\u20ac\u2122948\u00e2\u20ac\u2122252 validation tokens. The BBC-News dataset [9] consists of 2\u00e2\u20ac\u2122225 documents from the British Broadcast Corporation news website, across topics such as business, entertainment, politics, sports, and tech. News articles are highly structured in terms of flow, grammar, and vocabulary, so this dataset is similar to WikiText in that regard. Using their train/test split and our tokenization scheme, we end up with 589\u00e2\u20ac\u2122677 training tokens and 468\u00e2\u20ac\u2122831 validation tokens. The validation set size is unusually large with respect to the training set size. Since we used the training set as our retrieval database, this might have hindered performance somewhat. The Reuters-21578 dataset as created and used by Hayes in [11], consists of 19\u00e2\u20ac\u2122043 documents and has 674 categories in total. This dataset is comprised of news stories from the Reuters financial news-wire service in 1987 and just like the BBC-News dataset, is very similar to WikiText in terms of structure and language. However, the differences in vocabulary might be larger here, as the articles are from decades ago. Using Hayes\u00e2\u20ac\u2122 train/test split and our tokenization scheme, we end up with 3\u00e2\u20ac\u2122454\u00e2\u20ac\u2122605 training tokens and 174\u00e2\u20ac\u2122335 validation tokens. The Pile-of-Law dataset [12] was created in order to mitigate the effects of potentially harmful and biased training data such as can be found through web-crawling alone. The 34 data sources range from \"legal case opinions and filings\", mostly from the U.S.A., to study materials for law exams and were extensively analyzed for toxicity and biases. We use two of their data sources. The Atticus contracts subset contains contracts from the Atticus project, specifically the commercial contracts dataset [13]. It consists of 510 contracts and was created to train a model to highlight portions of the contract a human should review. Contract language is highly structured and repetitive, but not necessarily similar to Wikipedia or news articles. We now move away from article style text into something new entirely. Using their train/test split and our tokenization scheme, we end up with 456\u00e2\u20ac\u2122681\u00e2\u20ac\u2122888 training tokens and 152\u00e2\u20ac\u2122337\u00e2\u20ac\u2122169 validation tokens, which for performance reasons we had to sub-sample into 7\u00e2\u20ac\u2122605\u00e2\u20ac\u2122872 validation tokens. This subset consists of letters by U.S.A., founders, which were scraped from Founders Online [49] and consists of 137\u00e2\u20ac\u2122883 training and 45\u00e2\u20ac\u2122781 validation samples. Although this is in the Pile-of-Law dataset as well, it is not at all similar in structure to the Atticus contracts. Since these are letters, they are structurally more similar to articles than contracts, but as they are letters from the 1800s, the vocabulary and sentence structure are quite dissimilar to contemporary Wikipedia articles. Using their train/test split and our tokenization scheme, we end up with 55\u00e2\u20ac\u2122818\u00e2\u20ac\u2122926 training tokens and 18\u00e2\u20ac\u2122605\u00e2\u20ac\u2122985 validation tokens. The original WebText dataset used to train GPT-2 has not been released. However, as the authors have published how to re-create it, it has been repeatedly reconstructed. OpenWebText is created by taking the text of articles linked on Reddit555www.reddit.com. which have at least 3 upvotes. We use [8], this version has over 8 million documents and no inherent train/test split. To keep the sizes manageable, we sub-sample 55% of the dataset to get 2\u00e2\u20ac\u2122491\u00e2\u20ac\u2122806\u00e2\u20ac\u2122520 tokens which we split by taking 1% of it for validation. This is large enough to give us a good picture but not so large as to overwhelm the retrieval database size as in BBC-News. Overall we end up with 2\u00e2\u20ac\u2122477\u00e2\u20ac\u2122892\u00e2\u20ac\u2122482 training tokens and 13\u00e2\u20ac\u2122914\u00e2\u20ac\u2122038 validation tokens. This is our second-largest retrieval database, right after SlimPajama-6B. The CNN-DailyMail dataset originally created in [14] for question answering, has been processed for summarization in [34], which is the version we use. Since these are again news articles, the text formality and structure are comparable to Reuters and BBC-News. Using their train/test split and our tokenization scheme, we end up with 223\u00e2\u20ac\u2122216\u00e2\u20ac\u2122223 training tokens and 10\u00e2\u20ac\u2122116\u00e2\u20ac\u2122369 validation tokens. WikiText BBC-News Reuters This is an extension of Section 4. In the main body of the work, only the three most important papers are chosen in order to adhere to the page limit. The papers presented here and their concepts were also crucial for this work and for possible future avenues to explore. In natural language processing the branch of retrieval augmented generation has been gaining traction for a few years now. Given the tasks language models are expected to fulfill, from simple question answering, to fact-checking, to multi-turn conversations, combining a model\u00e2\u20ac\u2122s parametric memory with a non-parametric database is the natural next step. It builds upon an earlier idea of knowledge graphs [48] and enables not only a better understanding of our models\u00e2\u20ac\u2122 reasoning but also makes it easier to update knowledge. This is difficult at best and virtually impossible at worst with only parametric knowledge. In the RAG paper [26] they did exactly that, where retrieval from the non-parametric memory is jointly learned with sequence generation. The neighbors are split into 100-word Wikipedia passages, as opposed to chunks. Just like Retro, RAG computes cross-attention over the neighbors of tokens/sequences. Moreover, RAG\u00e2\u20ac\u2122s non-parametric memory only consists of a single Wikipedia dump (December 2018), as opposed to Retro which has many data sources. RAG set a new state-of-the-art on many open-domain QA tasks and even where they did not, they got close to the performance of more complex systems. Although since then there have been many systems that have outperformed RAG on open-domain QA, such as EDMR2superscriptEDMR2 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT [44] and FiD [16] which were specifically trained for QA. It must be said that Retro does not outperform these models either. Though interestingly, Nvidia\u00e2\u20ac\u2122s Retro++, where they add the top-1 neighbor to the context, does outperform them. SentenceTransformers [41] is a Python framework for embeddings of images and text, specifically sentences. While Bert is a general encoder model, only trained for language modeling, SentenceTransformers (also called SBert) is designed to generate embeddings for entire sentences. The purpose is to encode sentences and improve semantic similarity search. It works by adding a simple pooling layer after the Bert embeddings. In this pooling layer word embeddings can be averaged, we can take the max embedding or we can take the embedding of the CLS token, which is used for classification. In this paper, the authors use Siamese and triplet networks to train Bert. These neural network architectures are designed to learn embeddings for pairs or triplets of data points in a way that emphasizes their similarities and/or differences. Siamese networks have two subnetworks with shared weights. Each subnetwork takes as input a data point (in our case a sentence) and produces embeddings for those inputs. The objective is then to minimize the distance between similar pairs of inputs and maximize the distance between dissimilar pairs. Triplet networks work analogously, but with an anchor (A), a positive example (P), and a negative example (N). The objective is then to minimize the distance between the anchor and the positive example and maximize the distance between the anchor and the negative example. In the end, we obtain sentence embeddings that carry semantic meaning and can be compared using cosine-similarity. The pre-trained model we use is called multi-qa-mpnet-base-dot-v1 and is the best SentenceTranformers model for semantic similarity search. It was trained on question-answer pairs, which is the main use case for retrieval-augmented language models. Retrieval may not always be helpful and can in some cases be detrimental to the model\u00e2\u20ac\u2122s performance. In [1] they explored this question, where they retrieved passages on-demand, as opposed to indiscriminately retrieving a fixed number of neighbors like most retrieval systems do, such as our own. This decision is made using reflection tokens, which allow the language model to critique its own output and decide if it needs retrieval to improve the factuality and overall quality of the generated text. They evaluated their system on fact verification, multiple-choice reasoning, and a variety of question-answering datasets and setups. For these answers, they not only evaluated the exact match but considered fluency and precision/recall as well. They were able to show that their system outperformed other retrieval models on a majority of their tasks and datasets, achieving significant improvements in some cases. This is an entirely new approach compared to how most RAG systems currently work. Through their evaluation on a diverse set of tasks, they have shown the need for and role of such reflection. We have observed similar issues in our experiments, so the next step would be to add such a self-reflection mechanism as well. In [15] they argue that most large language models are under-trained. The authors analyze the relationship between the number of parameters and training tokens given a fixed compute budget. Given two out of the compute budget, the number of model parameters, and the number of training tokens, they explain and validate through their experiments how to compute the third. Due to our resource restrictions, we implemented the smallest Retro model with 175M parameters. Considering Figure 2 in the Chinchilla paper, we can fix the number of parameters and estimate the number of FLOPs as C=N\u00e2\u2039\u2026D\u011f\ufffd\ufffd\u00b6\u00e2\u2039\u2026\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b7C=N Ditalic_C = italic_N \u00e2\u2039\u2026 italic_D where D\u011f\ufffd\ufffd\u00b7Ditalic_D is the number of training tokens and N\u011f\ufffd\u2018\ufffdNitalic_N is the number of trainable parameters according to [20]. For Retro-li with WikiText-103 as both retrieval database and training data, N=120\u00e2\ufffd\u00a2M\u011f\ufffd\u2018\ufffd120\u011f\ufffd\u2018\u20acN=120Mitalic_N = 120 italic_M. We trained on 1\u00e2\u20ac\u2122078\u00e2\u20ac\u2122012 samples in total, for each sample we have 16 chunks, and for each chunk, we get 2 up to 10 neighbors, where each neighbor is 128 tokens long. This is 5.52\u00c3\u20141095.52superscript1095.52 10^{9}5.52 \u00c3\u2014 10 start_POSTSUPERSCRIPT 9 end_POSTSUPERSCRIPT to 2.32\u00c3\u201410102.32superscript10102.32 10^{10}2.32 \u00c3\u2014 10 start_POSTSUPERSCRIPT 10 end_POSTSUPERSCRIPT tokens in total, so C is 3.97\u00c3\u201410183.97superscript10183.97 10^{18}3.97 \u00c3\u2014 10 start_POSTSUPERSCRIPT 18 end_POSTSUPERSCRIPT to 1.7\u00c3\u201410181.7superscript10181.7 10^{18}1.7 \u00c3\u2014 10 start_POSTSUPERSCRIPT 18 end_POSTSUPERSCRIPT. Even for only two neighbors, this puts us in the optimal model size range. The non-parametric retrieval database helps with the Chinchilla law, as the retrieved neighbors increase the number of training tokens, alleviating the problem of under-trained large language models. We present some details on the NEFTune noise regularization and as it pertains to the approximation to the hardware platform. The regularizer is added to the neighbor embeddings for the CCA blocks during training. For validation and inference, no noise is added to the neighbors, unless specified. For this set of experiments, we chose three neighbors and the SBert word embedding model, which gave us the best results so far. Looking at the results for WikiText-103-Validation, we cannot see an improvement of perplexity in any combination of noise and noise placement when averaged over the random seeds, see Tables 16 to 16. It is not entirely surprising that the generalization capability of the train to test set did not improve, as adding noise at train time can lead to the model effectively memorizing the noise [54]. The best combination for these experiments is setting \u00ce\u00b1=10\u011f\ufffd\u203a\u00bc10 = 10 and adding noise to the neighbors only, see Table 13. Adding noise to both, sequences and neighbors, see Table 16 gives worse results than adding noise only to the sequences. This suggests that the neighbors stabilize the negative effects of the noisy sequence. Furthermore, considering our best result comes from adding noise to the neighbors only, we can see that this NEFTune noise has a regularizing effect on the neighbors. This is likely due to the fact that our retrieval database is too small for our training set. In the original Retro the retrieval database consisted of trillions of tokens and only saw improvement once the size of the retrieval database was in the order of billions, see the Figure on page 1 of the Retro paper as well as the table on page 34. As we show in Table 17, the checkpoints we trained with uniform noise and \u00ce\u00b1=10\u011f\ufffd\u203a\u00bc10 = 10 do not handle approximation to the hardware platform at inference time any better than the checkpoints trained without noise. Thus, uniform regularization does not play a role in this case. WikiText BBC-News Reuters It is clear in Table 17 and Figures 6 that not only is Gaussian, \u00ce\u00bbt=0.2subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u00a10.2 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0.2 the best checkpoint overall it can handle large amounts of noise better than other regularizers or no regularizer. We see how for \u00ce\u00bbi=0.2subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u20130.2 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 0.2 and \u00ce\u00bbi=0.4subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u20130.4 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 0.4 the perplexity barely increases for any of the regularizers (None, Uniform, Gaussian). For \u00ce\u00bbi=1.0subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u20131.0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 1.0 which is the largest relative standard deviation in our setup this changes. Here clear patterns emerge. For instance, Gaussian, \u00ce\u00bbt=0.4subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u00a10.4 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0.4 does consistently worst because it has the lowest signal-to-noise ratio of the regularizers shown here. It is most affected by \u00ce\u00bbi=1.0subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u20131.0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 1.0. Moreover, Gaussian, \u00ce\u00bbt=0.2subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u00a10.2 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0.2 does best for every dataset and noise level at inference time. It is least affected by \u00ce\u00bbi=1.0subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u20131.0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 1.0. This is unsurprising, as we also observe that out of all the regularizers Gaussian, \u00ce\u00bbt=0.2subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u00a10.2 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0.2 is least affected by the inference mode no retrieval. Most of this model\u00e2\u20ac\u2122s generalization performance comes from improved language modeling and not from the retrieved neighbors themselves. The uniform regularizer and no regularizer get similar results for almost all combinations of datasets and types of inference noise, but that changes for \u00ce\u00bbi=1.0subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u20131.0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 1.0. For all datasets except BBC-News and WikiText-103, no regularizer is less affected by \u00ce\u00bbi=1.0subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u20131.0 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 1.0 than the uniform regularizer. However, it has to be said that, even for these two datasets, the performance decrease is very similar. Perplexity is a performance measure in natural language processing (NLP) used to evaluate how well a model predicts a sample. It quantifies how a probability distribution or language model represents the data it is trained on. A lower perplexity score indicates that the model is more accurate and has a better understanding of the data. The model is essentially less surprised by the next word it sees, hence the name. In language modeling, perplexity is the exponential of the cross-entropy loss. In NLP we usually use the exponent base as opposed to base 2 but both are acceptable. The state-of-the-art language modeling perplexity of 2.4 on WikiText-103-Test is achieved by the Retro model666https://paperswithcode.com/sota/language-modelling-on-wikitext-103., with a large gap to the second best perplexity of 10.6. As already discussed, advancements of perplexity on WikiText-103 are usually due to dataset leakage. Most if not all large language models train on some snapshot of English Wikipedia. With the emergence of foundational models, it is nearly impossible to avoid validation/test set leakage. Perplexity has other issues as well. As it is a manner of evaluating the probability distribution, it cannot handle words with zero probability, so out of vocabulary words. Language models with a closed vocabulary will have lower perplexity than those with an open vocabulary, which assign probabilities to all words, if need be down to the characters. Finally, it is difficult to compare perplexities between closed vocabulary tokenizers, due to the size of the vocabularies. A larger vocabulary can lead to higher perplexities, as there are more words to consider for the next word. Despite these issues, perplexity is used as a performance measure due to its simplicity and comparability. In NLP we are aware of these issues and attempt to alleviate them by using closed vocabularies of similar sizes, when our goal is to present and compare perplexities. Furthermore, it is difficult to find a quantitative measure for language models. The BLEU or ROUGE score, Word error rate, or Character error rate all depend on generating text. Generation is already the next step which is subject to hyperparameter-tuning and post-processing. Not to mention, that the goal might not be to generate the exact continuation, as depending on the use-case, semantically similar output should be accepted as well. To compare the output of the language model directly, we must use a measure that does not sample but evaluates the probability distributions directly. Recently, bits-per-byte is used in order to measure the performance of a language model. Bits-per-byte refers to data storage efficiency, it describes a compression ratio. The idea behind it is the same as behind perplexity, where b\u00e2\ufffd\u00a2p\u00e2\ufffd\u00a2b=0\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd0bpb=0italic_b italic_p italic_b = 0 means that the model knows exactly what symbol will be next whereas b\u00e2\ufffd\u00a2p\u00e2\ufffd\u00a2b=l\u00e2\ufffd\u00a2o\u00e2\ufffd\u00a2g2\u00e2\ufffd\u00a2(v\u00e2\ufffd\u00a2o\u00e2\ufffd\u00a2c\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2_\u00e2\ufffd\u00a2s\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2z\u00e2\ufffd\u00a2e)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u0153subscript\u011f\ufffd\u2018\u201d2\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u0153\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd_\u011f\ufffd\u2018 \u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a7\u011f\ufffd\u2018\u2019bpb=log_{2}(vocab italic_p italic_b = italic_l italic_o italic_g start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_v italic_o italic_c italic_a italic_b _ italic_s italic_i italic_z italic_e ) means the model needs to be given the next symbol exactly. It is related to perplexity in the sense that cross-entropy loss for a character-level language model averaged over a dataset is bits-per-character. It is computed as L\u00c3\u2014l\u00e2\ufffd\u00a2o\u00e2\ufffd\u00a2g2\u00e2\ufffd\u00a2(e)\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u0153subscript\u011f\ufffd\u2018\u201d2\u011f\ufffd\u2018\u2019L log_{2}(e)italic_L \u00c3\u2014 italic_l italic_o italic_g start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_e ) where L\u011f\ufffd\ufffd\u00bfLitalic_L is the loss and is a loss-based performance measure. As it also highly depends on the vocabulary size, it is not a more general measure than perplexity. Here we present the full result tables, for each random seed and all number of neighbors. Variations across random seeds are likely due to the fact that we have to fix the number of training steps. We do not stop once we overfit, as we do not reach that stage with most of our experiments. For full transparency, we present both, the perplexity of the sliding window approach (as Retro computes it) and the full results (simply exp(loss)). We see strong variations across random seeds, suggesting that our system is sensitive to the initial samples and gets stuck in local minima quickly. Moreover, as we do not observe this behavior for SBert embeddings, we can conclude that this is due to less-than-ideal neighbors, which strongly impact the system, especially in the beginning. It has to be said that even Retro-Off has one particularly bad seed, which suggests that at least part of the reason we get stuck in local minima is due to the loss landscape itself. Finally, note how not all checkpoints improve upon utilizing the sliding window approach. This suggests that this approach is better suited for demonstrating the performance of a language model. If the performance decreases given 75% of the context, the model is truly unsuited for the task. In this section, we provide additional details on the architecture introduced in Section 2. Specifically, we elaborate on other changes we made to the Retro architecture and how we implemented them. One contribution of the Retro paper is that this type of architecture is straightforward to apply to other language models. This is called Retro-fitting. This is beneficial and efficient, as it allows us to leverage pre-trained models and augment them with retrieval capabilities. To do so, we must be able to access each attention block separately, as the chunked cross-attention blocks are added to every third layer starting from the sixth (or ninth for larger models). These attention blocks can then be frozen. This reduces the number of trainable parameters, making it faster to train. In the paper, instead of taking a pre-trained GPT-2 checkpoint, the authors built a GPT-2-like model with the appropriately changed parameters (see Table 20) . Then they trained it without retrieval before Retro-fitting it. Due to our limited resources, we use the publicly available GPT-2 checkpoints. Consequently, we had to change the aforementioned hyperparameters. Moreover, we had to train additional feed-forward network parameters at the end of the attention layers. Using a pre-trained model leads to a significant improvement of perplexity on the language modeling task compared to training Retro from scratch and it decreases our model size by 30%. For later experiments, we use our trained Retro-li-off with GPT-2 attention blocks as a checkpoint. This enables us to freeze all decoder layers except the CCA, just as in the original paper. Additionally, it decreases the number of trainable parameters even further from the complete Retro-li by 90.29%. The architecture is visualized in Diagram 7. Note that Retro differentiates between the baseline transformer, which is their GPT-2-like model, and Retro-off, which is their Retro-on without CCA. However, they repeatedly demonstrated that their performances are almost identical. In our work, we had no baseline transformer. We compare the Retro architecture with and without CCA. Most changes are made in order to adapt the Retro architecture to the GPT-2 attention blocks. Faiss is an open-source library for similarity search created by Facebook Research. Through clustering and quantization, it efficiently searches billions of vectors in milliseconds. Although Retro used ScaNN for their purposes, we chose Faiss due to its ease of use and its parallelization abilities. Faiss has several hyperparameters that must be set following the size of the database. According to their own recommendation, the number of centroids888Also called inverted lists. should be set as about n\u011f\ufffd\u2018\u203a start_ARG italic_n end_ARG where n is the number of index entries, in our case this refers to the number of chunks. For WikiText-103 this ends up being around 1024, for SlimPajama-6B and OpenWebText, this is around 4096. The number of inverted lists to be searched at query time can be set freely. Nvidia\u00e2\u20ac\u2122s Megatron Retro implementation set it as 0.1% of the inverted lists, whereas we stick to nc\u00e2\ufffd\u00a2e\u00e2\ufffd\u00a2n\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2o\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2d\u00e2\ufffd\u00a2ssubscript\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u0153\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018 start_ARG italic_n start_POSTSUBSCRIPT italic_c italic_e italic_n italic_t italic_r italic_o italic_i italic_d italic_s end_POSTSUBSCRIPT end_ARG. Creating the Index The workflow begins with the raw text files chosen for the retrieval database. We tokenize the text using the GPT-2 tokenizer. This first tokenization is only used to divide the text into chunks of length 64. To add them to the index, we de-tokenize the chunks, and re-tokenize them using Bert / SBert, so we can embed them using these models. We prefer them over GPT-2 embeddings as they more effectively capture the semantic meaning. These chunk embeddings are then added to the Faiss index as keys, with their continuations (the next 64 tokens) as values. Before we tokenize with GPT-2, we normalize the text using the Bert normalizer. This is essential, as Bert and GPT treat neither special characters nor repeated characters the same way. Without normalization, the re-tokenized chunk might be longer than 512 tokens. The pseudo-code for this algorithm is in Algorithm 1 in detail. IVFPQ 999https://faiss.ai/cpp_api/struct/structfaiss_1_1IndexIVFPQ.html. refers to an inverted file with product quantizer. The vectors are clustered and an inverted list for these clusters is created. Getting the nearest neighbors To make training more efficient, for each training sequence, we get the ten nearest neighbors for each chunk offline. We save them and their associated distance matrices to be loaded during training. In the first step, we again normalize using the Bert normalizer and tokenize using the GPT-2 tokenizer. Then we go through the entire tokenized text in steps of 1024 (our sequence length). Each sequence is split into chunks of length 64, which are used to query the index for their top k neighbors of each chunk. Once found, we save not only the source sequence, the nearest neighbors for all 16 chunks, and their distance matrices but also the target sequence, which is the source sequence shifted by one token. The distance matrices are not strictly necessary for our training setup and can be excluded. In our case, we kept them in order to analyze if adding noise to the distance matrix, thus shuffling the top 10 neighbors, then taking the new top k neighbors would significantly impact the performance. The goal of this experiment was to argue that saving these neighbors on specialized hardware with inherent noise is still feasible. It turned out that our system is even more robust, where we can not only shuffle the neighbors but also add noise to the neighbor embeddings themselves without significant performance degradation. Positional Embeddings The positional encodings were ablated in the paper, and Figure 8 shows minimal relevance to the choice of it. Thus, we instead use the state-of-the-art rotary positional embeddings [47]. They work by using rotational operations to capture positional information. Specifically, they rotate the embeddings based on the position in the sequence. These rotations are learnable and can be reversed. Sequence Length We use GPT-2 attention blocks, meaning the input sequence must be of length 1024. In the original paper, the chunk length was 64 tokens and the sequence length was 2048 tokens, neither of which is justified or ablated. As such, to have the input of the correct shape, we reduce the number of chunks per sequence to 16 as opposed to 32, whereas the chunk length remains unchanged. Optimizer and Batch Size Retro itself used AdamW [29], so Adam [23] with true weight decay (as opposed to Adam with L2 regularization), and a linearly increasing learning rate schedule with a batch size of 256 for their smallest model. Due to our memory restrictions, we can work with a batch size of 2 at most. Thus, using the same hyperparameters as Table 11 in [2] does not yield the same results in terms of convergence. As a consequence, we tried a variety of optimizers and decided on RAdam [28], which has the additional benefit of eliminating the need for us to tune the hyperparameters. RAdam works by regularizing the variance of the gradients, leading to more stable training, especially in the beginning where the variance might be particularly large. Note that what is displayed as \"noam\" in the figure, refers to the optimizer used in the original transformer paper [51], where we have Adam with linear warmup and a learning rate schedule that decays the learning rate proportional to the inverse square root of the step number. Nvidia\u00e2\u20ac\u2122s Megatron project already has a working version of Retro [52], but everything from the creation of the search database to the training is based on having much more resources than we do. Moreover, as it is part of a larger project, even following the code flow is difficult, let alone adding changes for this work. Due to these reasons, we chose not to move forward with this implementation of Retro. Although we kept the implementation as a reference to check our architectural decisions against. As a basis for our experiments, we used the smaller and easier-to-work-with \"labml\" [50] implementation of Retro to build our code on. Although only meant as a tutorial to better understand the chunked cross-attention and retrieval mechanism, it has such a clean and simple structure that adding to it for our needs was straightforward. Many changes to this code base were necessary, most importantly to the database, dataset creation, and the training loop, as well as adding Retro-fitted GPT-2. Still, having this framework to start with was hugely beneficial. Most of our ablations concern the retrieval aspect of the system. Here we explore the language model itself. We wanted to see if it would be possible to fine-tune the GPT-2 attention blocks as well, in order to improve performance even further. It did not, which makes the case for using foundational models stronger. We kept the GPT-2 backbone frozen for most experiments but did one ablation where we (1) Unfroze GPT-2 and continued to train on one of the pre-trained checkpoints (denoted from ckp), (2) Trained from scratch by keeping the GPT-2 parameters trainable (denoted from scratch). This increases the number of trainable parameters, which consequently increases the training time. Considering the results in Table 22, we observe that unfreezing GPT-2 and continuing to train from a previous checkpoint does improve our performance slightly for the Retro-li-off case. It is clear, however, that this was due to there no longer being one significant outlier (random seed 42). So it is a stabilizing effect, rather than an overall improved training. Moving on to Retro-li-on (2 neighbors, SBert embeddings) in Table 23, the case is even clearer, namely unfreezing GPT-2 did not improve our language modeling capabilities. This is likely because GPT-2 was trained to a minima of language modeling, so when adding retrieval we only have to train the retrieval parameters. Adding chunked cross-attention changed the loss landscape, which is why unfreezing does not help. On the non-parametric side, we need to store document vectors in a manner that facilitates search and optimizes space usage. Maximum inner product search (MIPS) goes through all the vectors in a database, computes the inner product with the query vector, and returns k vectors with the largest inner product. This is linear in the number of entries of the database, thus entirely impractical for databases consisting of millions or even billions of entries. Performing such a search is recommended only when the quality of the retrieved neighbors is crucial and the search time is less critical. In order to reduce the search time, we must reduce the search scope. This can be done through locality sensitivity hashing (LSH), which is the method employed by ScaNN. LSH works by hashing the vectors into b buckets, aiming to group similar vectors based on the hash function. Therefore, it might perform sub-optimally if the vectors are poorly distributed. Moreover, it is highly sensitive to the number of buckets b and the hash function. We can also reduce the scope by adopting an inverted vector files (IVF) approach, like Faiss does. An IVF index clusters the vectors into c centroids, where each vector is assigned to one centroid. Upon receiving a query, we search n\u00e2\ufffd\u00a2p\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2o\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2e\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u0153\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2019nprobeitalic_n italic_p italic_r italic_o italic_b italic_e of those c cells to find the nearest neighbors. This reduces the search time while preserving good performance. However, an IVF index requires that we train it in order to identify optimal centroids. Both index types reduce data transfer by decreasing the search scope. In any case, there is a trade-off between search time and result quality. We have established the importance of good neighbors for training a RAG model. Such approximations would not be necessary if the search could be done in memory. This move to an IMC-based platform would lead to the introduction of noise and non-determinism. However, we have demonstrated that any hardware approximate noise is negligible, especially compared to the approximations made by the index itself. For illustration purposes, we measure the time it takes for the search function call to IndexIVF_search to complete and show the results in Table\u00c2 5. This function is called on 16 chunks concurrently on a Tesla V100 GPU. As a way of profiling the speed of the index calls on Faiss we measure the time it takes for the search function call to IndexIVF_search to complete. This function is called on 16 chunks concurrently. We compare three retrieval databases, WikiText-103 with 1\u00e2\u20ac\u2122877\u00e2\u20ac\u2122559 entries, CNN-DailyMail with 3\u00e2\u20ac\u2122488\u00e2\u20ac\u2122000 entries, and SlimPajama with 45\u00e2\u20ac\u2122107\u00e2\u20ac\u2122000 entries. As the number of database entries almost doubles from WikiText-103 to CNN-DailyMail, so does the average search time. Due to the number of database entries, both have an index with 1024 centroids. However, as the number of database entries becomes 12 times larger from CNN-DailyMail to SlimPajama, the number of centroids becomes 4 times larger and the average search time only becomes 6 times longer. The nprobe parameter of how many out of the closest centroids to search is set to ncentroidsncentroids start_ARG ncentroids end_ARG. This emphasizes the role these parameters play in creating the index. Choosing such hyperparameters carefully can be either beneficial or detrimental to the results and speed of the retrieval. It is important to note that naively setting nprobe to ncentroids would lead to a longer search time than simply searching by brute force. 101010https://github.com/facebookresearch/faiss/wiki/Faster-search. Up to this point, all the results have been quantitative. To motivate retrieval, especially in domain shift, we now present some qualitative results. We generate the next chunk based on the context. Generation quality metrics such as fluency, diversity, and repetition depend almost exclusively on how well the generator function is written. Nvidia [52] and DeepMind [2] addressed this by only taking the greedy output. However, for real use cases, it is common to write the generator function with more care, as simple post-processing steps can make a substantial difference in the fluency and the diversity of the generated output. The model outputs a n\u00e2\ufffd\u00a2_\u00e2\ufffd\u00a2e\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2b\u00c3\u2014n\u00e2\ufffd\u00a2_\u00e2\ufffd\u00a2v\u00e2\ufffd\u00a2o\u00e2\ufffd\u00a2c\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2b\u011f\ufffd\u2018\u203a_\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a_\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u0153\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdn n _ italic_e italic_m italic_b \u00c3\u2014 italic_n _ italic_v italic_o italic_c italic_a italic_b matrix which is interpreted as a probability distribution over the vocabulary words. In greedy generation, we take the vocabulary word with the highest probability, but that can lead to significant degeneration, see Figure 13. To generate more natural language, it can be beneficial to occasionally opt for something other than the most likely word. In multinomial generation, we address this issue with the help of the probability matrix. We cast the matrix as a multinomial distribution and sample from it. This ensures on one hand that it remains likely that we generate words with a higher probability, but also enables us to eventually pick less probable words as well, improving diversity and reducing repetition. Top-p generation is also called nucleus sampling and aims to address similar issues as multinomial generation. It also helps with diversity of language and repetition, but in this case, the focus is not just on reducing the use of common words, but eliminating them altogether. In nucleus sampling, we set a parameter p\u011f\ufffd\u2018\ufffdpitalic_p describing the cumulative probability. We then remove all tokens in the vocabulary with a cumulative probability above this threshold. This results in a new probability distribution, from which we now sample the next token. We generate the next chunks for the best checkpoints and the best-performing validation samples of Retro-li-on and -off. We chose the datasets WikiText-103 and SlimPajama, which are the two most extreme cases in terms of perplexity. In order to paint a fuller picture, we present the greedy output, the multinomial and top-p generated results, and the real continuation. Although there has been tremendous success in evaluating generated samples with GPT-4 (for instance [18] used it and motivated its use by comparing it to human judgment) we had no access to it. GPT-3.5-Turbo rankings of the generated samples are unfortunately not deterministic, and even its evaluation of this handful of qualitative examples rarely aligned with human judgment. For WikiText-103 both Retro-li-on and -off have the same validation sample with the lowest perplexity, so their continuations can be compared directly. Here we anticipate little difference in the outputs between off and on, as the perplexities are close. Their generated outputs are similar in fluency and comprehensiveness. The SlimPajama dataset is by far the worst in terms of perplexity. Though this can easily be addressed with minimal fine-tuning (see Section H.4), we are more interested in true plug-and-play performance, as it pertains to retrieval. The question becomes: Can retrieval alone help a language model generalize to unseen domains? In Section 3 we show that this is the case quantitatively, here we analyze the output qualitatively as well. Looking at Figure 13 and Figure 14 side-by-side, we can see the benefit of retrieval. The topic of this excerpt is a description of an HDMI cable. For Retro-li-off the generated outputs are vaguely about technology whereas Retro-li-on\u00e2\u20ac\u2122s output is much more on-topic with respect to actual HDMI cables. To be completely fair, it must be said that this is the best validation sample for Retro-li-on, not for Retro-li-off. Although our focus so far has been on plug-and-play performance, fine-tuning is straightforward and improves the perplexities drastically with very few samples. We show some results here for minimal fine-tuning, on just one random seed, for our model trained with a Gaussian regularizer, \u00ce\u00bbt=0.2subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u00a10.2 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = 0.2. We set the number of samples to fine-tune on to 10% of the validation data size, to provide a balanced assessment. Interestingly, neither the initial perplexity nor the number of samples we fine-tune on is an indicator of how well the dataset takes to fine-tuning. Overall, we never have to fine-tune for longer than a few minutes to reach a perplexity of around 40. BBC-News has been fine-tuned the longest and yet has the second-highest final perplexity. This indicates that either the samples are chosen poorly or our model has trouble with this dataset in particular. Atticus contracts, on the other hand, dropped to a perplexity of around 16, which can be attributed to the repetitive nature of contracts.",
        "keywords": ""
    },
    {
        "id": 21,
        "title": "Some Diophantine Equations involving associated Pell numbers and repdigits",
        "abstract": "Abstract.In this paper, we explore the relationship between repdigits and associated Pell numbers, specifically focusing on two main aspects: expressing repdigits as the difference of two associated Pell numbers, and identifying which associated Pell numbers can be represented as the difference of two repdigits. Additionally, we investigate all associated Pell numbers which are concatenation of three repdigits. Our proof utilizes Baker\u00e2\u20ac\u2122s theory on linear forms in logarithms of algebraic numbers, along with the Baker-Davenport reduction technique. The computations were carried out with the help of a simple computer program inMathematica.",
        "corpus": "In this paper, we explore the relationship between repdigits and associated Pell numbers, specifically focusing on two main aspects: expressing repdigits as the difference of two associated Pell numbers, and identifying which associated Pell numbers can be represented as the difference of two repdigits. Additionally, we investigate all associated Pell numbers which are concatenation of three repdigits. Our proof utilizes Baker\u00e2\u20ac\u2122s theory on linear forms in logarithms of algebraic numbers, along with the Baker-Davenport reduction technique. The computations were carried out with the help of a simple computer program in Mathematica. A Diophantine equation is an algebraic or exponential equation with two or more variables intended to be solved in terms of integers only. These types of equations are named after the ancient Greek mathematician Diophantus. The associated Pell sequence (qn)n\u00e2\u2030\u00a50subscriptsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u203a0(q_{n})_{n 0}( italic_q start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_n \u00e2\u2030\u00a5 0 end_POSTSUBSCRIPT is defined by the binary recurrence relation with initial conditions q0=1,q1=1formulae-sequencesubscript\u011f\ufffd\u2018\ufffd01subscript\u011f\ufffd\u2018\ufffd11 q_{0}=1, q_{1}=1italic_q start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = 1 , italic_q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1. The closed form of associated Pell numbers is known as the Binet\u00e2\u20ac\u2122s formula has the form qn=\u00ce\u00b1n+\u00ce\u00b2n2subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203asuperscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u203asuperscript\u011f\ufffd\u203a\u00bd\u011f\ufffd\u2018\u203a2q_{n}= start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = divide start_ARG italic_\u00ce\u00b1 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT + italic_\u00ce\u00b2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_ARG start_ARG 2 end_ARG, where (\u00ce\u00b1,\u00ce\u00b2)=(1+2,1\u00e2\u02c6\u20192)\u011f\ufffd\u203a\u00bc\u011f\ufffd\u203a\u00bd1212( italic_\u00ce\u00b1 , italic_\u00ce\u00b2 ) = ( 1 + square-root start_ARG 2 end_ARG , 1 - square-root start_ARG 2 end_ARG ) is the pair of roots of the characteristic polynomial x2\u00e2\u02c6\u20192\u00e2\ufffd\u00a2x\u00e2\u02c6\u20191superscript\u011f\ufffd\u2018\u00a522\u011f\ufffd\u2018\u00a51x^{2}-2x-1italic_x start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - 2 italic_x - 1. This implies easily that the inequality holds for all n\u00e2\u2030\u00a51\u011f\ufffd\u2018\u203a1n 1italic_n \u00e2\u2030\u00a5 1. A palindromic number is one that remains unchanged when its digits are reversed. A special type of palindromic number, known as a repdigit, consists of a single distinct digit repeated multiple times in base 10. Mathematically, a repdigit can be expressed in the form d(10k\u00e2\u02c6\u201919)d ( divide start_ARG 10 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT - 1 end_ARG start_ARG 9 end_ARG ) , where d\u00e2\u02c6\u02c6{1,2,\u00e2\u20ac\u00a6,9}\u011f\ufffd\u2018\u201812\u00e2\u20ac\u00a69d \u00e2\u02c6\u02c6 { 1 , 2 , \u00e2\u20ac\u00a6 , 9 } and k\u00e2\u2030\u00a51\u011f\ufffd\u2018\u02dc1k 1italic_k \u00e2\u2030\u00a5 1. Notably, when k=1\u011f\ufffd\u2018\u02dc1k=1italic_k = 1, the result is simply the digit itself, representing a trivial case of a repdigit. Several authors have explored problems related to repdigits within the context of second-order linear recurrence sequences. All Balancing and Lucas-balancing numbers which are repdigits have been found in [14]. S. G. Rayaguru and G. K. Panda [13] investigated all balancing and Lucas-balancing numbers which can be expressed as the sums of two repdigits. Additionally, Rayaguru and Bravo [12] identified all Balancing and Lucas-balancing numbers formed by the concatenation of three repdigits. Erduwan et al. [7] found all Fibonacci and Lucas numbers which are difference of two repdigits. Edjeou and Faye [6] found all Pell and Pell-Lucas numbers, which are difference of two repdigits. MG Duman [5] identified all Padovan numbers representable as the difference of two repdigits. More recently, Mohapatra et al. [10] investigated the existence of repdigits as the difference of two Balancing or Lucas-balancing numbers, and they also enumerated all Balancing and Lucas-balancing numbers that can be expressed as the difference of two repdigits in [11]. This paper seeks to extend previous research by investigating the fascinating realm of repdigits. Specifically, we explore repdigits that can be expressed as the difference between two associated Pell numbers, those formed by concatenating three repdigits, and associated Pell numbers that can be represented as the difference of two repdigits. To facilitate this exploration, we consider the following equations: assume k\u00e2\u2030\u00a51\u011f\ufffd\u2018\u02dc1k 1italic_k \u00e2\u2030\u00a5 1 to avoid trivial solutions. where m1,m2,m3\u00e2\u2030\u00a51subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u016131m_{1},m_{2},m_{3} 1italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_m start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT \u00e2\u2030\u00a5 1, 1\u00e2\u2030\u00a4d1\u00e2\u2030\u00a491subscript\u011f\ufffd\u2018\u2018191 d_{1} 91 \u00e2\u2030\u00a4 italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 9 and 0\u00e2\u2030\u00a4d2,d\u00e2\ufffd\u00a23\u00e2\u2030\u00a49formulae-sequence0subscript\u011f\ufffd\u2018\u20182\u011f\ufffd\u2018\u2018390 d_{2},d3 90 \u00e2\u2030\u00a4 italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_d 3 \u00e2\u2030\u00a4 9. where (k,m,n)\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u203a(k,m,n)( italic_k , italic_m , italic_n ) are positive integers with n>m\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u0161n>mitalic_n > italic_m and n\u00e2\u2030\u00a52\u011f\ufffd\u2018\u203a2n 2italic_n \u00e2\u2030\u00a5 2. To solve the Diophantine equations, we will repeatedly invoke a Baker-type lower bound for a nonzero linear form in the logarithms of algebraic numbers. These lower bounds are instrumental in effectively resolving such equations. We shall commence by revisiting essential definitions and key results from the realm of algebraic number theory. Let \u00ce\u00bb\u011f\ufffd\u0153\u2020 be an algebraic number with minimal primitive polynomial where a0>0subscript\u011f\ufffd\u2018\ufffd00a_{0}>0italic_a start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT > 0 is the leading coefficient and \u00ce\u00bb(i)superscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u2013 start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT\u00e2\u20ac\u2122s are conjugates of \u00ce\u00bb\u011f\ufffd\u0153\u2020 Then the a\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2s\u00e2\ufffd\u00a2o\u00e2\ufffd\u00a2l\u00e2\ufffd\u00a2u\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2e\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018 \u011f\ufffd\u2018\u0153\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2019absoluteitalic_a italic_b italic_s italic_o italic_l italic_u italic_t italic_e l\u00e2\ufffd\u00a2o\u00e2\ufffd\u00a2g\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2h\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2c\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u0153\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a1\u00e2\u201e\ufffd\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffdlogarithmicitalic_l italic_o italic_g italic_a italic_r italic_i italic_t italic_h italic_m italic_i italic_c h\u00e2\ufffd\u00a2e\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2g\u00e2\ufffd\u00a2h\u00e2\ufffd\u00a2t\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u201d\u00e2\u201e\ufffd\u011f\ufffd\u2018\u00a1heightitalic_h italic_e italic_i italic_g italic_h italic_t of \u00ce\u00bb\u011f\ufffd\u0153\u2020 is given by h(\u00ce\u00bb)=1k(loga0+\u00e2\u02c6\u2018j=1kh( a_{0}+ ( italic_\u00ce\u00bb ) = divide start_ARG 1 end_ARG start_ARG italic_k end_ARG ( roman_log italic_a start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPTmax{0,log|\u00ce\u00bb(j)|}) 0 , roman_log | italic_\u00ce\u00bb start_POSTSUPERSCRIPT ( italic_j ) end_POSTSUPERSCRIPT | } ). If \u00ce\u00bb=ab\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd = divide start_ARG italic_a end_ARG start_ARG italic_b end_ARG is a rational number with g\u00e2\ufffd\u00a2c\u00e2\ufffd\u00a2d\u00e2\ufffd\u00a2(a,b)=1\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd1gcd(a,b)=1italic_g italic_c italic_d ( italic_a , italic_b ) = 1 and b>1\u011f\ufffd\u2018\ufffd1b>1italic_b > 1, then h\u00e2\ufffd\u00a2(\u00ce\u00bb)=log\u00e2\u201e\ufffd\u011f\ufffd\u0153\u2020h( ( italic_\u00ce\u00bb ) = roman_log(max{|a|,b}) | italic_a | , italic_b } ). Here are some properties of the a\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2s\u00e2\ufffd\u00a2o\u00e2\ufffd\u00a2l\u00e2\ufffd\u00a2u\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2e\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018 \u011f\ufffd\u2018\u0153\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2019absoluteitalic_a italic_b italic_s italic_o italic_l italic_u italic_t italic_e l\u00e2\ufffd\u00a2o\u00e2\ufffd\u00a2g\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2h\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2c\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u0153\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00a1\u00e2\u201e\ufffd\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffdlogarithmicitalic_l italic_o italic_g italic_a italic_r italic_i italic_t italic_h italic_m italic_i italic_c h\u00e2\ufffd\u00a2e\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2g\u00e2\ufffd\u00a2h\u00e2\ufffd\u00a2t\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u201d\u00e2\u201e\ufffd\u011f\ufffd\u2018\u00a1heightitalic_h italic_e italic_i italic_g italic_h italic_t whose proofs can be found in [2]. Let \u00ce\u00b3\u011f\ufffd\u203a\u00be and \u00ce\u00b7\u011f\ufffd\u0153\u201a be two algebraic numbers, then Building on the previous notations, we present a theorem that refines a result by Matveev [9], as extended by Bugeaud et al. [2]. This theorem offers a precise upper bound for our variables in equations (1.3), (1.4), and (1.5). [9]. Let \u00ce\u00b31,\u00e2\u20ac\u00a6,\u00ce\u00b3lsubscript\u011f\ufffd\u203a\u00be1\u00e2\u20ac\u00a6subscript\u011f\ufffd\u203a\u00be\u011f\ufffd\u2018\u2122 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_\u00ce\u00b3 start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT be positive real numbers in an algebraic number field \u011f\ufffd\u2022\u0192\u011f\ufffd\u2022\u0192 of degree d\u011f\ufffd\u2022\u0192subscript\u011f\ufffd\u2018\u2018\u011f\ufffd\u2022\u0192d_{ start_POSTSUBSCRIPT blackboard_L end_POSTSUBSCRIPT and b1,\u00e2\u20ac\u00a6,blsubscript\u011f\ufffd\u2018\ufffd1\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2122b_{1}, start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_b start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT be nonzero integers. If \u00ce\u201c=\u00e2\u02c6\ufffdi=1l\u00ce\u00b3ibi\u00e2\u02c6\u20191\u00ce\u201csuperscriptsubscriptproduct\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\u2122superscriptsubscript\u011f\ufffd\u203a\u00be\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20131 = \u00e2\u02c6\ufffd start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT italic_\u00ce\u00b3 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT - 1 is not zero, then where D\u00e2\u2030\u00a5\u011f\ufffd\ufffd\u00b7absentD \u00e2\u2030\u00a5 max{|b1|,\u00e2\u20ac\u00a6,|bl|}subscript\u011f\ufffd\u2018\ufffd1\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2122 | italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT | , \u00e2\u20ac\u00a6 , | italic_b start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT | } and A1,\u00e2\u2039\u00af,Alsubscript\u011f\ufffd\ufffd\u00b41\u00e2\u2039\u00afsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u2122A_{1}, start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u2039\u00af , italic_A start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT are positive integers such that Aj\u00e2\u2030\u00a5h\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(\u00ce\u00b3j)subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u2014superscript\u00e2\u201e\ufffd\u00e2\u20ac\u00b2subscript\u011f\ufffd\u203a\u00be\u011f\ufffd\u2018\u2014A_{j} h^{ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT \u00e2\u2030\u00a5 italic_h start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ( italic_\u00ce\u00b3 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) = m\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2x\u00e2\ufffd\u00a2{d\u011f\ufffd\u2022\u0192\u00e2\ufffd\u00a2h\u00e2\ufffd\u00a2(\u00ce\u00b3j),|log\u00e2\ufffd\u00a1\u00ce\u00b3j|,0.16},\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\u2018\u011f\ufffd\u2022\u0192\u00e2\u201e\ufffdsubscript\u011f\ufffd\u203a\u00be\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u203a\u00be\u011f\ufffd\u2018\u20140.16max italic_a italic_x { italic_d start_POSTSUBSCRIPT blackboard_L end_POSTSUBSCRIPT italic_h ( italic_\u00ce\u00b3 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) , | roman_log italic_\u00ce\u00b3 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | , 0.16 } , for j=1,\u00e2\u20ac\u00a6,l\u011f\ufffd\u2018\u20141\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u2122j=1, = 1 , \u00e2\u20ac\u00a6 , italic_l. The subsequent result, recognized as the Baker-Davenport theorem and credited to Dujella and Peth\u00c5\u2018 [4] is another tool in our proofs. It will be used to reduce the upper bounds on our variables. [4]. Let M\u011f\ufffd\u2018\u20acMitalic_M be a positive integer and pq\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd start_ARG italic_p end_ARG start_ARG italic_q end_ARG denote a convergent of the continued fraction of the irrational number \u00cf\u201e\u011f\ufffd\u0153\ufffd such that q>6\u00e2\ufffd\u00a2M\u011f\ufffd\u2018\ufffd6\u011f\ufffd\u2018\u20acq>6Mitalic_q > 6 italic_M. Consider the real numbers A,B,\u00ce\u00bc\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b5\u011f\ufffd\u0153\u2021A,B, , italic_B , italic_\u00ce\u00bc with A>0\u011f\ufffd\ufffd\u00b40A>0italic_A > 0 and B>1\u011f\ufffd\ufffd\u00b51B>1italic_B > 1. Let \u00cf\u00b5:=\u00e2\u02c6\u00a5\u00ce\u00bc\u00e2\ufffd\u00a2q\u00e2\u02c6\u00a5\u00e2\u02c6\u2019M\u00e2\ufffd\u00a2\u00e2\u02c6\u00a5\u00cf\u201e\u00e2\ufffd\u00a2q\u00e2\u02c6\u00a5assignitalic-\u00cf\u00b5delimited-\u00e2\u02c6\u00a5\u00e2\u02c6\u00a5\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20acdelimited-\u00e2\u02c6\u00a5\u00e2\u02c6\u00a5\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\ufffd q q := \u00e2\u02c6\u00a5 italic_\u00ce\u00bc italic_q \u00e2\u02c6\u00a5 - italic_M \u00e2\u02c6\u00a5 italic_\u00cf\u201e italic_q \u00e2\u02c6\u00a5, where \u00e2\u02c6\u00a5.\u00e2\u02c6\u00a5 . \u00e2\u02c6\u00a5 denotes the distance from the nearest integer. If \u00cf\u00b5>0italic-\u00cf\u00b50 > 0, then there exists no solution to the inequality in positive integers u,v,w\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u00a4u,v,witalic_u , italic_v , italic_w with u\u00e2\u2030\u00a4M\u011f\ufffd\u2018\u00a2\u011f\ufffd\u2018\u20acu Mitalic_u \u00e2\u2030\u00a4 italic_M and w\u00e2\u2030\u00a5log\u00e2\ufffd\u00a1(A\u00e2\ufffd\u00a2q/\u00cf\u00b5)log\u00e2\ufffd\u00a1B\u011f\ufffd\u2018\u00a4\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\ufffditalic-\u00cf\u00b5\u011f\ufffd\ufffd\u00b5w B}italic_w \u00e2\u2030\u00a5 divide start_ARG roman_log ( italic_A italic_q / italic_\u00cf\u00b5 ) end_ARG start_ARG roman_log italic_B end_ARG. We conclude this section by recalling the following lemma that we need in the sequel: [8]. Let r\u00e2\u2030\u00a51\u011f\ufffd\u2018\u01781r 1italic_r \u00e2\u2030\u00a5 1 and H>0\u011f\ufffd\ufffd\u00bb0H>0italic_H > 0 be such that H>(4\u00e2\ufffd\u00a2r2)r\u011f\ufffd\ufffd\u00bbsuperscript4superscript\u011f\ufffd\u2018\u01782\u011f\ufffd\u2018\u0178H>(4r^{2})^{r}italic_H > ( 4 italic_r start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT and H>L/(log\u00e2\ufffd\u00a1L)r\u011f\ufffd\ufffd\u00bb\u011f\ufffd\ufffd\u00bfsuperscript\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\u0178H>L/( L)^{r}italic_H > italic_L / ( roman_log italic_L ) start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT. Then L<2r\u00e2\ufffd\u00a2H\u00e2\ufffd\u00a2(log\u00e2\ufffd\u00a1H)r\u011f\ufffd\ufffd\u00bfsuperscript2\u011f\ufffd\u2018\u0178\u011f\ufffd\ufffd\u00bbsuperscript\u011f\ufffd\ufffd\u00bb\u011f\ufffd\u2018\u0178L<2^{r}H( H)^{r}italic_L < 2 start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT italic_H ( roman_log italic_H ) start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT. [3]. Let a,x\u00e2\u02c6\u02c6\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5\u00e2\u201e\ufffda,x , italic_x \u00e2\u02c6\u02c6 blackboard_R. If 0<a<10\u011f\ufffd\u2018\ufffd10<a<10 < italic_a < 1 and |x|<a\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\ufffd|x|<a| italic_x | < italic_a, then and [15] The only associated Pell numbers which are repdigits are 1, 3, 7, and 99. [15] The only associated Pell numbers which are concatenation of two repdigits are 17, 41, and 577. All solutions of the Diophantine Eq.(1.3) in positive integers with n>m\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u0161n>mitalic_n > italic_m, k\u00e2\u2030\u00a51\u011f\ufffd\u2018\u02dc1k 1italic_k \u00e2\u2030\u00a5 1, 1\u00e2\u2030\u00a4d\u00e2\u2030\u00a491\u011f\ufffd\u2018\u201891 d 91 \u00e2\u2030\u00a4 italic_d \u00e2\u2030\u00a4 9, are (n,m,d,k)\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u02dc(n,m,d,k)( italic_n , italic_m , italic_d , italic_k ) \u00e2\u02c6\u02c6 {(2,0,2,1), (2,1,2,1), (3,2,4,1), (3,0,6,1), (3,1,6,1), (7,4,4,3)}. Using M\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2h\u00e2\ufffd\u00a2e\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2c\u00e2\ufffd\u00a2a\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdMathematicaitalic_M italic_a italic_t italic_h italic_e italic_m italic_a italic_t italic_i italic_c italic_a, we get the repdigits as the difference of two associated Pell numbers for n\u00e2\u2030\u00a495\u011f\ufffd\u2018\u203a95n 95italic_n \u00e2\u2030\u00a4 95 as listed in Theorem 3.1. So, assume that n>95\u011f\ufffd\u2018\u203a95n>95italic_n > 95. By using Binet\u00e2\u20ac\u2122s formula, (1.3) can be written as We will now rearrange equation (3.1) into two distinct cases, as outlined below. First rearrangement of (3.1) is By applying the absolute value to both sides, we arrive at After applying \u00ce\u00b1n2superscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u203a2 start_ARG italic_\u00ce\u00b1 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_ARG start_ARG 2 end_ARG as a divisor to both sides of the inequality, we find Put \u00ce\u201c1subscript\u00ce\u201c1 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1\u00e2\u02c6\u2019\u00ce\u00b1\u00e2\u02c6\u2019n\u00e2\ufffd\u00a210k\u00e2\ufffd\u00a2(2\u00e2\ufffd\u00a2d9)1superscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u203asuperscript10\u011f\ufffd\u2018\u02dc2\u011f\ufffd\u2018\u201891- - italic_\u00ce\u00b1 start_POSTSUPERSCRIPT - italic_n end_POSTSUPERSCRIPT 10 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( divide start_ARG 2 italic_d end_ARG start_ARG 9 end_ARG ). It is enough to check that \u00ce\u201c1\u00e2\u2030 0subscript\u00ce\u201c10 0roman_\u00ce\u201c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030 0. On the contrary, suppose \u00ce\u201c1=0subscript\u00ce\u201c10 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0, then \u00ce\u00b1n=10k(2\u00e2\ufffd\u00a2d9)\u00e2\u02c6\u02c6\u00e2\u201e\u0161 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT = 10 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( divide start_ARG 2 italic_d end_ARG start_ARG 9 end_ARG ) \u00e2\u02c6\u02c6 blackboard_Q, which contradicts the fact that \u00ce\u00b1nsuperscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u203a start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT is irrational for any n>0\u011f\ufffd\u2018\u203a0n>0italic_n > 0. Therefore, \u00ce\u201c1\u00e2\u2030 0subscript\u00ce\u201c10 0roman_\u00ce\u201c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030 0. To implement Theorem 1, define \u00ce\u00bb1subscript\u011f\ufffd\u0153\u20201 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = \u00ce\u00b1\u011f\ufffd\u203a\u00bc \u00ce\u00bb2=10subscript\u011f\ufffd\u0153\u2020210 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 10, \u00ce\u00bb3subscript\u011f\ufffd\u0153\u20203 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 2\u00e2\ufffd\u00a2d92\u011f\ufffd\u2018\u20189 start_ARG 2 italic_d end_ARG start_ARG 9 end_ARG, b1=\u00e2\u02c6\u2019nsubscript\u011f\ufffd\u2018\ufffd1\u011f\ufffd\u2018\u203ab_{1}=-nitalic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = - italic_n, b2=ksubscript\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\u02dcb_{2}=kitalic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = italic_k, b3=1,l=3formulae-sequencesubscript\u011f\ufffd\u2018\ufffd31\u011f\ufffd\u2018\u21223b_{3}=1,l=3italic_b start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1 , italic_l = 3, where \u00ce\u00bb1subscript\u011f\ufffd\u0153\u20201 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, \u00ce\u00bb2subscript\u011f\ufffd\u0153\u20202 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, \u00ce\u00bb3subscript\u011f\ufffd\u0153\u20203 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT \u00e2\u02c6\u02c6\u00e2\u201e\u0161absent\u00e2\u201e\u0161 blackboard_Q and b1,b2,b3\u00e2\u02c6\u02c6\u00e2\u201e\u00a4subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd3\u00e2\u201e\u00a4b_{1},b_{2},b_{3} start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_b start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_Z. It can be observed that \u00e2\u201e\u0161\u00e2\ufffd\u00a2(\u00ce\u00bb1,\u00ce\u00bb2,\u00ce\u00bb3)=\u00e2\u201e\u0161\u00e2\ufffd\u00a2(\u00ce\u00b1)\u00e2\u201e\u0161subscript\u011f\ufffd\u0153\u20201subscript\u011f\ufffd\u0153\u20202subscript\u011f\ufffd\u0153\u20203\u00e2\u201e\u0161\u011f\ufffd\u203a\u00bc ( italic_\u00ce\u00bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u00ce\u00bb start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_\u00ce\u00bb start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) = blackboard_Q ( italic_\u00ce\u00b1 ), so d\u011f\ufffd\u2022\u0192=2subscript\u011f\ufffd\u2018\u2018\u011f\ufffd\u2022\u01922d_{ start_POSTSUBSCRIPT blackboard_L end_POSTSUBSCRIPT = 2. Since k<n\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u203ak<nitalic_k < italic_n, we have D=\u011f\ufffd\ufffd\u00b7absentD=italic_D =max{n,k,1}=n\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dc1\u011f\ufffd\u2018\u203a italic_n , italic_k , 1 } = italic_n. The absolute logarithmic heights of \u00ce\u00bb1subscript\u011f\ufffd\u0153\u20201 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, \u00ce\u00bb2subscript\u011f\ufffd\u0153\u20202 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT and \u00ce\u00bb3subscript\u011f\ufffd\u0153\u20203 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT are computed as h\u00e2\ufffd\u00a2(\u00ce\u00bb1)=log\u00e2\ufffd\u00a1\u00ce\u00b12\u00e2\u201e\ufffdsubscript\u011f\ufffd\u0153\u20201\u011f\ufffd\u203a\u00bc2h( ( italic_\u00ce\u00bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) = divide start_ARG roman_log italic_\u00ce\u00b1 end_ARG start_ARG 2 end_ARG, h\u00e2\ufffd\u00a2(\u00ce\u00bb2)=log\u00e2\ufffd\u00a110\u00e2\u201e\ufffdsubscript\u011f\ufffd\u0153\u2020210h( 10italic_h ( italic_\u00ce\u00bb start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) = roman_log 10 and h\u00e2\ufffd\u00a2(\u00ce\u00bb3)=h\u00e2\ufffd\u00a2(2\u00e2\ufffd\u00a2d)+h\u00e2\ufffd\u00a2(9)<5.1\u00e2\u201e\ufffdsubscript\u011f\ufffd\u0153\u20203\u00e2\u201e\ufffd2\u011f\ufffd\u2018\u2018\u00e2\u201e\ufffd95.1h( ( italic_\u00ce\u00bb start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) = italic_h ( 2 italic_d ) + italic_h ( 9 ) < 5.1 . Thus, we can express the following: Now, utilizing Theorem 2.1, we can determine a lower bound for log\u00e2\ufffd\u00a1|\u00ce\u201c1|subscript\u00ce\u201c1 | roman_\u00ce\u201c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT | as By comparing the inequality presented above with (3.2), we find that We perform the second rearrangement of (3.1) as \u00ce\u00b1n2\u00e2\u02c6\u2019\u00ce\u00b1m2\u00e2\u02c6\u2019d\u00e2\ufffd\u00a210k9=\u00ce\u00b2m2\u00e2\u02c6\u2019\u00ce\u00b2n2\u00e2\u02c6\u2019d9superscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u203a2superscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u01612\u011f\ufffd\u2018\u2018superscript10\u011f\ufffd\u2018\u02dc9superscript\u011f\ufffd\u203a\u00bd\u011f\ufffd\u2018\u01612superscript\u011f\ufffd\u203a\u00bd\u011f\ufffd\u2018\u203a2\u011f\ufffd\u2018\u20189 }}{2}- start_ARG italic_\u00ce\u00b1 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_ARG start_ARG 2 end_ARG - divide start_ARG italic_\u00ce\u00b1 start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT end_ARG start_ARG 2 end_ARG - divide start_ARG italic_d 10 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT end_ARG start_ARG 9 end_ARG = divide start_ARG italic_\u00ce\u00b2 start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT end_ARG start_ARG 2 end_ARG - divide start_ARG italic_\u00ce\u00b2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_ARG start_ARG 2 end_ARG - divide start_ARG italic_d end_ARG start_ARG 9 end_ARG. By taking the absolute values on both sides of the inequality, we arrive at When we divide both sides of the inequality by \u00ce\u00b1n2superscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u203a2 start_ARG italic_\u00ce\u00b1 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_ARG start_ARG 2 end_ARG(1\u00e2\u02c6\u2019\u00ce\u00b1m\u00e2\u02c6\u2019n)1superscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u203a(1- 1 - italic_\u00ce\u00b1 start_POSTSUPERSCRIPT italic_m - italic_n end_POSTSUPERSCRIPT ), it yields Define \u00ce\u201c2subscript\u00ce\u201c2 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1\u00e2\u02c6\u2019\u00ce\u00b1\u00e2\u02c6\u2019n10k(2\u00e2\ufffd\u00a2d9\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019\u00ce\u00b1m\u00e2\u02c6\u2019n))1- - italic_\u00ce\u00b1 start_POSTSUPERSCRIPT - italic_n end_POSTSUPERSCRIPT 10 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( divide start_ARG 2 italic_d end_ARG start_ARG 9 ( 1 - italic_\u00ce\u00b1 start_POSTSUPERSCRIPT italic_m - italic_n end_POSTSUPERSCRIPT ) end_ARG ). In the same way, it can be shown that \u00ce\u201c2\u00e2\u2030 0subscript\u00ce\u201c20 0roman_\u00ce\u201c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u00e2\u2030 0. Here we have h\u00e2\ufffd\u00a2(\u00ce\u00bb1)=h\u00e2\ufffd\u00a2(\u00ce\u00b1)=log\u00e2\ufffd\u00a1\u00ce\u00b12\u00e2\u201e\ufffdsubscript\u011f\ufffd\u0153\u20201\u00e2\u201e\ufffd\u011f\ufffd\u203a\u00bc\u011f\ufffd\u203a\u00bc2h( ( italic_\u00ce\u00bb start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) = italic_h ( italic_\u00ce\u00b1 ) = divide start_ARG roman_log italic_\u00ce\u00b1 end_ARG start_ARG 2 end_ARG and h\u00e2\ufffd\u00a2(\u00ce\u00bb2)=h\u00e2\ufffd\u00a2(10)=log\u00e2\ufffd\u00a110\u00e2\u201e\ufffdsubscript\u011f\ufffd\u0153\u20202\u00e2\u201e\ufffd1010h( 10italic_h ( italic_\u00ce\u00bb start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) = italic_h ( 10 ) = roman_log 10. Let \u00ce\u00bb3subscript\u011f\ufffd\u0153\u20203 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = (2\u00e2\ufffd\u00a2d9\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019\u00ce\u00b1m\u00e2\u02c6\u2019n)) divide start_ARG 2 italic_d end_ARG start_ARG 9 ( 1 - italic_\u00ce\u00b1 start_POSTSUPERSCRIPT italic_m - italic_n end_POSTSUPERSCRIPT ) end_ARG ). Then, Thus, from (3.3) we derive h\u00e2\ufffd\u00a2(\u00ce\u00bb3)<2.2\u00e2\u2039\u20261013\u00e2\ufffd\u00a2(1+log\u00e2\ufffd\u00a1n)\u00e2\u201e\ufffdsubscript\u011f\ufffd\u0153\u20203\u00e2\u2039\u20262.2superscript10131\u011f\ufffd\u2018\u203ah( 10^{13}(1+ n)italic_h ( italic_\u00ce\u00bb start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) < 2.2 \u00e2\u2039\u2026 10 start_POSTSUPERSCRIPT 13 end_POSTSUPERSCRIPT ( 1 + roman_log italic_n ). Accordingly, we define A3subscript\u011f\ufffd\ufffd\u00b43A_{3}italic_A start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 4.4 \u00e2\u2039\u20261013\u00e2\ufffd\u00a2(1+log\u00e2\ufffd\u00a1n)\u00e2\u2039\u2026absentsuperscript10131\u011f\ufffd\u2018\u203a 10^{13}(1+ n)\u00e2\u2039\u2026 10 start_POSTSUPERSCRIPT 13 end_POSTSUPERSCRIPT ( 1 + roman_log italic_n ). By virtue of Theorem 2.1, A comparison of the above inequality with (3.4) yields With the notations of Lemma 2.2, we take r=2,L=2,H=1.9\u00e2\u2039\u20261026log\u00e2\ufffd\u00a1\u00ce\u00b1formulae-sequence\u011f\ufffd\u2018\u01782formulae-sequence\u011f\ufffd\ufffd\u00bf2\u011f\ufffd\ufffd\u00bb\u00e2\u2039\u20261.9superscript1026\u011f\ufffd\u203a\u00bcr=2,L=2,H= 10^{26}}{ = 2 , italic_L = 2 , italic_H = divide start_ARG 1.9 \u00e2\u2039\u2026 10 start_POSTSUPERSCRIPT 26 end_POSTSUPERSCRIPT end_ARG start_ARG roman_log italic_\u00ce\u00b1 end_ARG to get n <<< 22superscript222^{2}2 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT (1.9\u00e2\u2039\u20261026log\u00e2\ufffd\u00a1\u00ce\u00b1) 10^{26}}{ divide start_ARG 1.9 \u00e2\u2039\u2026 10 start_POSTSUPERSCRIPT 26 end_POSTSUPERSCRIPT end_ARG start_ARG roman_log italic_\u00ce\u00b1 end_ARG ) (log(1.9\u00e2\u2039\u20261026log\u00e2\ufffd\u00a1\u00ce\u00b1))2 10^{26}}{ roman_log ( divide start_ARG 1.9 \u00e2\u2039\u2026 10 start_POSTSUPERSCRIPT 26 end_POSTSUPERSCRIPT end_ARG start_ARG roman_log italic_\u00ce\u00b1 end_ARG ) ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT <<< 3.2\u00e2\u2039\u20261030\u00e2\u2039\u20263.2superscript10303.2 10^{30}3.2 \u00e2\u2039\u2026 10 start_POSTSUPERSCRIPT 30 end_POSTSUPERSCRIPT. We now need to apply the Baker-Davenport reduction method, as developed by Dujella and Peth\u00c5\u2018 [4], to refine the bound. Let We can rewrite the inequality (3.2) as Observe that \u00ce\u203a1\u00e2\u2030 0subscript\u00ce\u203a10 0roman_\u00ce\u203a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030 0 as e\u00ce\u203a1\u00e2\u02c6\u20191=\u00ce\u201c1\u00e2\u2030 0superscript\u011f\ufffd\u2018\u2019subscript\u00ce\u203a11subscript\u00ce\u201c10e^{ 0italic_e start_POSTSUPERSCRIPT roman_\u00ce\u203a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT - 1 = roman_\u00ce\u201c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030 0. Under the assumption that n\u00e2\u02c6\u2019m\u00e2\u2030\u00a54\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u01614n-m 4italic_n - italic_m \u00e2\u2030\u00a5 4, the right-hand side of the above inequality is at most 9(1+2)4<129superscript12412 start_ARG 9 end_ARG start_ARG ( 1 + square-root start_ARG 2 end_ARG ) start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT end_ARG < divide start_ARG 1 end_ARG start_ARG 2 end_ARG. From the inequality |ez\u00e2\u02c6\u20191|<ysuperscript\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a71\u011f\ufffd\u2018\u00a6|e^{z}-1|<y| italic_e start_POSTSUPERSCRIPT italic_z end_POSTSUPERSCRIPT - 1 | < italic_y with real values of z\u011f\ufffd\u2018\u00a7zitalic_z and y\u011f\ufffd\u2018\u00a6yitalic_y, we deduce that z<2\u00e2\ufffd\u00a2y\u011f\ufffd\u2018\u00a72\u011f\ufffd\u2018\u00a6z<2yitalic_z < 2 italic_y. This leads us to the result |\u00ce\u203a1|<18\u00ce\u00b1n\u00e2\u02c6\u2019msubscript\u00ce\u203a118superscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u0161| roman_\u00ce\u203a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT | < divide start_ARG 18 end_ARG start_ARG italic_\u00ce\u00b1 start_POSTSUPERSCRIPT italic_n - italic_m end_POSTSUPERSCRIPT end_ARG, which indicates that |\u00e2\u02c6\u2019nlog\u00ce\u00b1+klog10+log(2\u00e2\ufffd\u00a2d9)|<18\u00ce\u00b1n\u00e2\u02c6\u2019m 10+ - italic_n roman_log italic_\u00ce\u00b1 + italic_k roman_log 10 + roman_log ( divide start_ARG 2 italic_d end_ARG start_ARG 9 end_ARG ) | < divide start_ARG 18 end_ARG start_ARG italic_\u00ce\u00b1 start_POSTSUPERSCRIPT italic_n - italic_m end_POSTSUPERSCRIPT end_ARG. Upon dividing both sides of the inequality by log\u00e2\ufffd\u00a1\u00ce\u00b1,\u011f\ufffd\u203a\u00bc italic_\u00ce\u00b1 , we find In order to implement Lemma 2.1, let us define u=k,\u00cf\u201e=log\u00e2\ufffd\u00a110log\u00e2\ufffd\u00a1\u00ce\u00b1,v=n,\u00ce\u00bc=(log\u00e2\ufffd\u00a1(2\u00e2\ufffd\u00a2d9)log\u00e2\ufffd\u00a1\u00ce\u00b1),A=21,B=\u00ce\u00b1,w=n\u00e2\u02c6\u2019mu=k, 10}{ )}{ = italic_k , italic_\u00cf\u201e = divide start_ARG roman_log 10 end_ARG start_ARG roman_log italic_\u00ce\u00b1 end_ARG , italic_v = italic_n , italic_\u00ce\u00bc = ( divide start_ARG roman_log ( divide start_ARG 2 italic_d end_ARG start_ARG 9 end_ARG ) end_ARG start_ARG roman_log italic_\u00ce\u00b1 end_ARG ) , italic_A = 21 , italic_B = italic_\u00ce\u00b1 , italic_w = italic_n - italic_m. We can set M=3.2\u00e2\u2039\u20261030\u011f\ufffd\u2018\u20ac\u00e2\u2039\u20263.2superscript1030M=3.2 10^{30}italic_M = 3.2 \u00e2\u2039\u2026 10 start_POSTSUPERSCRIPT 30 end_POSTSUPERSCRIPT as an upper bound on u\u011f\ufffd\u2018\u00a2uitalic_u. The denominator of 68-th convergent of \u00cf\u201e\u011f\ufffd\u0153\ufffd denoted as q68subscript\u011f\ufffd\u2018\ufffd68q_{68}italic_q start_POSTSUBSCRIPT 68 end_POSTSUBSCRIPT= 27232938992914655197439992935676, exceeds 6\u00e2\ufffd\u00a2M6\u011f\ufffd\u2018\u20ac6M6 italic_M. Considering the fact that 1\u00e2\u2030\u00a4d\u00e2\u2030\u00a491\u011f\ufffd\u2018\u201891 d 91 \u00e2\u2030\u00a4 italic_d \u00e2\u2030\u00a4 9, a quick computation with M\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2h\u00e2\ufffd\u00a2e\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2c\u00e2\ufffd\u00a2a\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdMathematicaitalic_M italic_a italic_t italic_h italic_e italic_m italic_a italic_t italic_i italic_c italic_a gives us the inequality 0<\u00cf\u00b5:=\u00e2\u02c6\u00a5\u00ce\u00bc\u00e2\ufffd\u00a2q68\u00e2\u02c6\u00a5\u00e2\u02c6\u2019M\u00e2\ufffd\u00a2\u00e2\u02c6\u00a5\u00cf\u201e\u00e2\ufffd\u00a2q68\u00e2\u02c6\u00a5=0.0003890italic-\u00cf\u00b5assigndelimited-\u00e2\u02c6\u00a5\u00e2\u02c6\u00a5\u011f\ufffd\u0153\u2021subscript\u011f\ufffd\u2018\ufffd68\u011f\ufffd\u2018\u20acdelimited-\u00e2\u02c6\u00a5\u00e2\u02c6\u00a5\u011f\ufffd\u0153\ufffdsubscript\u011f\ufffd\u2018\ufffd680.0003890< q_{68} q_{68} < italic_\u00cf\u00b5 := \u00e2\u02c6\u00a5 italic_\u00ce\u00bc italic_q start_POSTSUBSCRIPT 68 end_POSTSUBSCRIPT \u00e2\u02c6\u00a5 - italic_M \u00e2\u02c6\u00a5 italic_\u00cf\u201e italic_q start_POSTSUBSCRIPT 68 end_POSTSUBSCRIPT \u00e2\u02c6\u00a5 = 0.000389. Applying Lemma 2.1 to the inequality (3.5) for 1\u00e2\u2030\u00a4d\u00e2\u2030\u00a491\u011f\ufffd\u2018\u201891 d 91 \u00e2\u2030\u00a4 italic_d \u00e2\u2030\u00a4 9, we obtain n\u00e2\u02c6\u2019m\u00e2\u2030\u00a494\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u016194n-m 94italic_n - italic_m \u00e2\u2030\u00a4 94. Now, for n\u00e2\u02c6\u2019m\u00e2\u2030\u00a494\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u016194n-m 94italic_n - italic_m \u00e2\u2030\u00a4 94, put \u00ce\u203a2=\u00e2\u02c6\u2019nlog\u00ce\u00b1+klog10+log(2\u00e2\ufffd\u00a2d9\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019\u00ce\u00b1m\u00e2\u02c6\u2019n)) 10+ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = - italic_n roman_log italic_\u00ce\u00b1 + italic_k roman_log 10 + roman_log ( divide start_ARG 2 italic_d end_ARG start_ARG 9 ( 1 - italic_\u00ce\u00b1 start_POSTSUPERSCRIPT italic_m - italic_n end_POSTSUPERSCRIPT ) end_ARG ). The inequality (3.4) can be expressed as Observe that \u00ce\u203a2\u00e2\u2030 0subscript\u00ce\u203a20 0roman_\u00ce\u203a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u00e2\u2030 0 as e\u00ce\u203a2\u00e2\u02c6\u20191=\u00ce\u201c2\u00e2\u2030 0superscript\u011f\ufffd\u2018\u2019subscript\u00ce\u203a21subscript\u00ce\u201c20e^{ 0italic_e start_POSTSUPERSCRIPT roman_\u00ce\u203a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT - 1 = roman_\u00ce\u201c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u00e2\u2030 0. Assuming n\u00e2\u2030\u00a52\u011f\ufffd\u2018\u203a2n 2italic_n \u00e2\u2030\u00a5 2, the right-hand side in the above inequality is is limited to a maximum of 1212 start_ARG 1 end_ARG start_ARG 2 end_ARG. The inequality |ez\u00e2\u02c6\u20191|<ysuperscript\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a71\u011f\ufffd\u2018\u00a6|e^{z}-1|<y| italic_e start_POSTSUPERSCRIPT italic_z end_POSTSUPERSCRIPT - 1 | < italic_y for real values of z\u011f\ufffd\u2018\u00a7zitalic_z and y\u011f\ufffd\u2018\u00a6yitalic_y leads to the conclusion that z<2\u00e2\ufffd\u00a2y\u011f\ufffd\u2018\u00a72\u011f\ufffd\u2018\u00a6z<2yitalic_z < 2 italic_y. Therefore, we can assert |\u00ce\u203a2|<10\u00ce\u00b1nsubscript\u00ce\u203a210superscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u203a| roman_\u00ce\u203a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | < divide start_ARG 10 end_ARG start_ARG italic_\u00ce\u00b1 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_ARG, which implies that Dividing both sides of the above inequality by log\u00e2\ufffd\u00a1\u00ce\u00b1\u011f\ufffd\u203a\u00bc italic_\u00ce\u00b1 yields Let Choose M=3.2\u00e2\u2039\u20261030\u011f\ufffd\u2018\u20ac\u00e2\u2039\u20263.2superscript1030M=3.2 10^{30}italic_M = 3.2 \u00e2\u2039\u2026 10 start_POSTSUPERSCRIPT 30 end_POSTSUPERSCRIPT. We find q73=497885304750610764058413408775840subscript\u011f\ufffd\u2018\ufffd73497885304750610764058413408775840q_{73}=497885304750610764058413408775840italic_q start_POSTSUBSCRIPT 73 end_POSTSUBSCRIPT = 497885304750610764058413408775840, the denominator of 73-th convergent of \u00cf\u201e\u011f\ufffd\u0153\ufffd exceeds 6\u00e2\ufffd\u00a2M6\u011f\ufffd\u2018\u20ac6M6 italic_M with 0 <\u00cf\u00b5:=\u00e2\u02c6\u00a5\u00ce\u00bc\u00e2\ufffd\u00a2q73\u00e2\u02c6\u00a5\u00e2\u02c6\u2019M\u00e2\ufffd\u00a2\u00e2\u02c6\u00a5\u00cf\u201e\u00e2\ufffd\u00a2q73\u00e2\u02c6\u00a5=0.107792absentitalic-\u00cf\u00b5assigndelimited-\u00e2\u02c6\u00a5\u00e2\u02c6\u00a5\u011f\ufffd\u0153\u2021subscript\u011f\ufffd\u2018\ufffd73\u011f\ufffd\u2018\u20acdelimited-\u00e2\u02c6\u00a5\u00e2\u02c6\u00a5\u011f\ufffd\u0153\ufffdsubscript\u011f\ufffd\u2018\ufffd730.107792< q_{73} q_{73} italic_\u00cf\u00b5 := \u00e2\u02c6\u00a5 italic_\u00ce\u00bc italic_q start_POSTSUBSCRIPT 73 end_POSTSUBSCRIPT \u00e2\u02c6\u00a5 - italic_M \u00e2\u02c6\u00a5 italic_\u00cf\u201e italic_q start_POSTSUBSCRIPT 73 end_POSTSUBSCRIPT \u00e2\u02c6\u00a5 = 0.107792. Applying Lemma 2.1 to the inequality (3.6) for 1\u00e2\u2030\u00a4d\u00e2\u2030\u00a491\u011f\ufffd\u2018\u201891 d 91 \u00e2\u2030\u00a4 italic_d \u00e2\u2030\u00a4 9, we obtain n\u00e2\u2030\u00a491\u011f\ufffd\u2018\u203a91n 91italic_n \u00e2\u2030\u00a4 91. This conclusion directly contradicts our initial assumption that n>95\u011f\ufffd\u2018\u203a95n>95italic_n > 95. \u00e2\u02c6\ufffd The only associated Pell numbers which are concatenation of three repdigits are 239, 3363, and 8119. Assuming that (1.4) holds, we examined the first 50 associated Pell numbers and found that the solutions to the Diophantine equation (1.4) are qn\u00e2\u02c6\u02c6{239,3363,8119}subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a23933638119q_{n} start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 { 239 , 3363 , 8119 } for d1,d2\u00e2\u02c6\u02c6{0,1,\u00e2\u20ac\u00a6,9}subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u2018201\u00e2\u20ac\u00a69d_{1},d_{2} start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 { 0 , 1 , \u00e2\u20ac\u00a6 , 9 } with d1>0subscript\u011f\ufffd\u2018\u201810d_{1}>0italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT > 0. From this point forward, we assume that n>50\u011f\ufffd\u2018\u203a50n>50italic_n > 50. The scenarios d1=d2\u00e2\u2030 d3subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u20182subscript\u011f\ufffd\u2018\u20183d_{1}=d_{2} d_{3}italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u00e2\u2030 italic_d start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT and d1\u00e2\u2030 d2=d3subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u20182subscript\u011f\ufffd\u2018\u20183d_{1} d_{2}=d_{3}italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030 italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = italic_d start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT in (1.4) are ruled out, as the only associated Pell numbers, which are concatenation of two repdigits are 17, 41, 577 by Lemma 2.5. Furthermore, the case d1=d2=d3subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u20182subscript\u011f\ufffd\u2018\u20183d_{1}=d_{2}=d_{3}italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = italic_d start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT in (1.4) is also impossible since the largest repdigit in the associated Pell sequence is 99 as stated in Lemma 2.4. Let us define Then we can express qnsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203aq_{n}italic_q start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT as: which leads us to Alternatively, we can express it as: Combining the right side of inequality (1.2) with (4.1), we arrive at the following relationship: From this, we can conclude that: m1+m2+m3<n+2subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01613\u011f\ufffd\u2018\u203a2m_{1}+m_{2}+m_{3}<n+2italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + italic_m start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT < italic_n + 2. We will now rearrange equation (4.2) in three distinct cases by using the Binet\u00e2\u20ac\u2122s formula of associated Pell numbers. The first rearrangement of (4.2) is given by Taking the absolute values of both sides of (4.3) yields where n>50\u011f\ufffd\u2018\u203a50n>50italic_n > 50. Therefore, Dividing both sides of (4.4) by d1\u00e2\ufffd\u00a210m1+m2+m3subscript\u011f\ufffd\u2018\u20181superscript10subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01613d_{1}10^{m_{1}+m_{2}+m_{3}}italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT 10 start_POSTSUPERSCRIPT italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + italic_m start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT gives us Now, let us apply Theorem 2.1 with the parameters \u00ce\u00b31:=9/(2\u00e2\ufffd\u00a2d1),\u00ce\u00b32:=\u00ce\u00b1,\u00ce\u00b33:=10formulae-sequenceassignsubscript\u011f\ufffd\u203a\u00be192subscript\u011f\ufffd\u2018\u20181formulae-sequenceassignsubscript\u011f\ufffd\u203a\u00be2\u011f\ufffd\u203a\u00bcassignsubscript\u011f\ufffd\u203a\u00be310 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT := 9 / ( 2 italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) , italic_\u00ce\u00b3 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT := italic_\u00ce\u00b1 , italic_\u00ce\u00b3 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT := 10 and b1:=1,b2:=nformulae-sequenceassignsubscript\u011f\ufffd\u2018\ufffd11assignsubscript\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\u203ab_{1}:=1,b_{2}:=nitalic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT := 1 , italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT := italic_n, b3:=\u00e2\u02c6\u2019m1\u00e2\u02c6\u2019m2\u00e2\u02c6\u2019m3assignsubscript\u011f\ufffd\u2018\ufffd3subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01613b_{3}:=-m_{1}-m_{2}-m_{3}italic_b start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT := - italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_m start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT. It is worth noting that \u00ce\u00b31,\u00ce\u00b32subscript\u011f\ufffd\u203a\u00be1subscript\u011f\ufffd\u203a\u00be2 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u00ce\u00b3 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, and \u00ce\u00b33subscript\u011f\ufffd\u203a\u00be3 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT are positive real numbers and belong to the field \u011f\ufffd\u2022\u201a=\u00e2\u201e\u0161\u00e2\ufffd\u00a2(2)\u011f\ufffd\u2022\u201a\u00e2\u201e\u01612 = blackboard_Q ( square-root start_ARG 2 end_ARG ), which has degree dL=2subscript\u011f\ufffd\u2018\u2018\u011f\ufffd\ufffd\u00bf2d_{L}=2italic_d start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT = 2. We define: Setting \u00ce\u201c3=0subscript\u00ce\u201c30 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0, we arrive at However, this leads to a contradiction as \u00ce\u00b1nsuperscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u203a start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT is irrational for n\u00e2\u2030\u00a51\u011f\ufffd\u2018\u203a1n 1italic_n \u00e2\u2030\u00a5 1, which implies \u00ce\u201c3subscript\u00ce\u201c3 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT must indeed be nonzero. Furthermore, utilizing the properties of absolute logarithmic height, we can obtain and Now, we can assign values A1:=5.8,A2:=0.9formulae-sequenceassignsubscript\u011f\ufffd\ufffd\u00b415.8assignsubscript\u011f\ufffd\ufffd\u00b420.9A_{1}:=5.8,A_{2}:=0.9italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT := 5.8 , italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT := 0.9, and A3:=4.62assignsubscript\u011f\ufffd\ufffd\u00b434.62A_{3}:=4.62italic_A start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT := 4.62. Since, m1+m2+m3<n+2subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01613\u011f\ufffd\u2018\u203a2m_{1}+m_{2}+m_{3}<n+2italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + italic_m start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT < italic_n + 2 and D\u00e2\u2030\u00a5max\u00e2\ufffd\u00a1{|1|,|n|,|\u00e2\u02c6\u2019m1\u00e2\u02c6\u2019m2\u00e2\u02c6\u2019m3|}\u011f\ufffd\ufffd\u00b71\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01613D \u00e2\u2030\u00a5 roman_max { | 1 | , | italic_n | , | - italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_m start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT | }, we can conveniently set D:=n+2assign\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u203a2D:=n+2italic_D := italic_n + 2. Let us define: Analyzing inequality (4.5) in conjunction with Theorem 2.1, we obtain A straightforward computation yields the inequality Proceeding with the second rearrangement of equation (4.2) as and taking absolute values of both sides of (4.7), we get This equality leads to a series of inequalities based on the properties of absolute values as i.e. Dividing both sides of (4.8) by (d1\u00e2\ufffd\u00a210m1\u00e2\u02c6\u2019(d1\u00e2\u02c6\u2019d2))\u00e2\ufffd\u00a210m2+m3subscript\u011f\ufffd\u2018\u20181superscript10subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u20182superscript10subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01613 italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT 10 start_POSTSUPERSCRIPT italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT - ( italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ) 10 start_POSTSUPERSCRIPT italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + italic_m start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, we arrive at Let us introduce the following parameters: and With these definitions established, we can proceed to apply Theorem 2.1 . Here, dL=2subscript\u011f\ufffd\u2018\u2018\u011f\ufffd\ufffd\u00bf2d_{L}=2italic_d start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT = 2 as the values \u00ce\u00b31,\u00ce\u00b32subscript\u011f\ufffd\u203a\u00be1subscript\u011f\ufffd\u203a\u00be2 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u00ce\u00b3 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, and \u00ce\u00b33subscript\u011f\ufffd\u203a\u00be3 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT are positive real numbers and elements of the field K=Q\u00e2\ufffd\u00a2(2)\u011f\ufffd\ufffd\u00be\u011f\ufffd\u2018\u201e2K=Q( = italic_Q ( square-root start_ARG 2 end_ARG ). We define Using the same arguments applied earlier for \u00ce\u201c3subscript\u00ce\u201c3 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT, we conclude that \u00ce\u201c4\u00e2\u2030 0subscript\u00ce\u201c40 0roman_\u00ce\u201c start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT \u00e2\u2030 0. By employing the properties of the absolute logarithmic height, we obtain So, we can assign A1:=15.96+2\u00e2\ufffd\u00a2m1\u00e2\ufffd\u00a2log\u00e2\ufffd\u00a110,A2:=0.9formulae-sequenceassignsubscript\u011f\ufffd\ufffd\u00b4115.962subscript\u011f\ufffd\u2018\u0161110assignsubscript\u011f\ufffd\ufffd\u00b420.9A_{1}:=15.96+2m_{1} 10,A_{2}:=0.9italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT := 15.96 + 2 italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT roman_log 10 , italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT := 0.9, and A3:=4.62assignsubscript\u011f\ufffd\ufffd\u00b434.62A_{3}:=4.62italic_A start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT := 4.62. As m2+m3<nsubscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01613\u011f\ufffd\u2018\u203am_{2}+m_{3}<nitalic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + italic_m start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT < italic_n and D\u00e2\u2030\u00a5max\u00e2\ufffd\u00a1{|1|,|\u00e2\u02c6\u2019n|,|\u00e2\u02c6\u2019m2\u00e2\u02c6\u2019m3|}\u011f\ufffd\ufffd\u00b71\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01613D \u00e2\u2030\u00a5 roman_max { | 1 | , | - italic_n | , | - italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_m start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT | }, we can take D:=nassign\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u203aD:=nitalic_D := italic_n. Considering the inequality (4.9) and applying Theorem 2.1, we obtain From this, we derive Carrying out the third rearrangement of equation (4.2), we have By taking the absolute values of both sides of equation (4.11), we arrive at: This leads us to the pivotal inequality: Upon dividing both sides of (4.12) by 9\u00e2\ufffd\u00a2\u00ce\u00b1n/29superscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u203a29 italic_\u00ce\u00b1 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT / 2, we obtain Let us introduce the following parameters: Additionally, we set b1:=1,b2:=\u00e2\u02c6\u2019n,b3:=m3formulae-sequenceassignsubscript\u011f\ufffd\u2018\ufffd11formulae-sequenceassignsubscript\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u2018\u203aassignsubscript\u011f\ufffd\u2018\ufffd3subscript\u011f\ufffd\u2018\u01613b_{1}:=1,b_{2}:=-n,b_{3}:=m_{3}italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT := 1 , italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT := - italic_n , italic_b start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT := italic_m start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT. This configuration allows us to apply Theorem 2.1. The parameters \u00ce\u00b31,\u00ce\u00b32subscript\u011f\ufffd\u203a\u00be1subscript\u011f\ufffd\u203a\u00be2 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u00ce\u00b3 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, and \u00ce\u00b33subscript\u011f\ufffd\u203a\u00be3 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT are all positive real numbers that lie in the field K=\u00e2\u201e\u0161\u00e2\ufffd\u00a2(2)\u011f\ufffd\ufffd\u00be\u00e2\u201e\u01612K= = blackboard_Q ( square-root start_ARG 2 end_ARG ) implying that dL=2subscript\u011f\ufffd\u2018\u2018\u011f\ufffd\ufffd\u00bf2d_{L}=2italic_d start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT = 2. Let We can confirm that \u00ce\u201c5\u00e2\u2030 0subscript\u00ce\u201c50 0roman_\u00ce\u201c start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT \u00e2\u2030 0, just as for \u00ce\u201c3subscript\u00ce\u201c3 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT. By leveraging the properties of the absolute logarithmic height, we obtain So, we assign A1:=21.8+2\u00e2\ufffd\u00a2(m1+m2)\u00e2\ufffd\u00a2log\u00e2\ufffd\u00a110+2\u00e2\ufffd\u00a2m2\u00e2\ufffd\u00a2log\u00e2\ufffd\u00a110,A2:=0.9formulae-sequenceassignsubscript\u011f\ufffd\ufffd\u00b4121.82subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01612102subscript\u011f\ufffd\u2018\u0161210assignsubscript\u011f\ufffd\ufffd\u00b420.9A_{1}:=21.8+2(m_{1}+m_{2}) 10+2m_{2} 10,A_{2}:=0.9italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT := 21.8 + 2 ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) roman_log 10 + 2 italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT roman_log 10 , italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT := 0.9, and A3:=4.62assignsubscript\u011f\ufffd\ufffd\u00b434.62A_{3}:=4.62italic_A start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT := 4.62. As m3<n\u00e2\u02c6\u20191subscript\u011f\ufffd\u2018\u01613\u011f\ufffd\u2018\u203a1m_{3}<n-1italic_m start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT < italic_n - 1 and D\u00e2\u2030\u00a5max\u00e2\ufffd\u00a1{|1|,|\u00e2\u02c6\u2019n|,|m3|}\u011f\ufffd\ufffd\u00b71\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\u2018\u01613D \u00e2\u2030\u00a5 roman_max { | 1 | , | - italic_n | , | italic_m start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT | }, we can take D:=nassign\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u203aD:=nitalic_D := italic_n. Consequently, by taking the inequality (4.13) into account and invoking Theorem 2.1, we derive or Leveraging the inequalities (4.6), (13), and (4.14), a computational search conducted with M\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2h\u00e2\ufffd\u00a2e\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2c\u00e2\ufffd\u00a2a\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdMathematicaitalic_M italic_a italic_t italic_h italic_e italic_m italic_a italic_t italic_i italic_c italic_a yields the result that n<5\u00e2\u2039\u20261027\u011f\ufffd\u2018\u203a\u00e2\u2039\u20265superscript1027n<5 10^{27}italic_n < 5 \u00e2\u2039\u2026 10 start_POSTSUPERSCRIPT 27 end_POSTSUPERSCRIPT. Now, let us try to tighten the upper bound on n\u011f\ufffd\u2018\u203anitalic_n by applying Lemma 2.2. We define From (4.5), we can deduce that By selecting a:=0.9995assign\u011f\ufffd\u2018\ufffd0.9995a:=0.9995italic_a := 0.9995, we derive the inequality according to Lemma 2.3. Thus, it follows that Dividing this inequality by log\u00e2\ufffd\u00a1\u00ce\u00b1\u011f\ufffd\u203a\u00bc italic_\u00ce\u00b1, we get We can now invoke Lemma 2.2. Let us define Let M:=5\u00e2\u2039\u20261027assign\u011f\ufffd\u2018\u20ac\u00e2\u2039\u20265superscript1027M:=5 10^{27}italic_M := 5 \u00e2\u2039\u2026 10 start_POSTSUPERSCRIPT 27 end_POSTSUPERSCRIPT. Then M>m1+m2+m3\u011f\ufffd\u2018\u20acsubscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01613M>m_{1}+m_{2}+m_{3}italic_M > italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + italic_m start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT, ensuring that the denominator of the 66666666-th convergent of \u00ce\u00b3\u011f\ufffd\u203a\u00be exceeds 6\u00e2\ufffd\u00a2M6\u011f\ufffd\u2018\u20ac6M6 italic_M. We further define Consequently, the inequality (4.15) admits no solutions for Thus, we conclude that m1\u00e2\u2030\u00a483subscript\u011f\ufffd\u2018\u0161183m_{1} 83italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 83. Utilizing inequalities (4.10) and (4.14) together, and substituting this upper bound for m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT into (4.14), we obtain n<1.2\u00e2\u2039\u20261027\u011f\ufffd\u2018\u203a\u00e2\u2039\u20261.2superscript1027n<1.2 10^{27}italic_n < 1.2 \u00e2\u2039\u2026 10 start_POSTSUPERSCRIPT 27 end_POSTSUPERSCRIPT. Now, let us introduce From (4.9), we can assert that for m2\u00e2\u2030\u00a51subscript\u011f\ufffd\u2018\u016121m_{2} 1italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u00e2\u2030\u00a5 1. Choosing a:=0.2assign\u011f\ufffd\u2018\ufffd0.2a:=0.2italic_a := 0.2, we derive the inequality as confirmed by Lemma 2.3. This leads us to the conclusion that Dividing both sides of the preceding inequality by log\u00e2\ufffd\u00a1\u00ce\u00b1\u011f\ufffd\u203a\u00bc italic_\u00ce\u00b1, we get Putting \u00ce\u00b3:=log\u00e2\ufffd\u00a110log\u00e2\ufffd\u00a1\u00ce\u00b1assign\u011f\ufffd\u203a\u00be10\u011f\ufffd\u203a\u00bc 10}{ := divide start_ARG roman_log 10 end_ARG start_ARG roman_log italic_\u00ce\u00b1 end_ARG and taking m2+m3<M:=1.2\u00e2\u2039\u20261027subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01613\u011f\ufffd\u2018\u20acassign\u00e2\u2039\u20261.2superscript1027m_{2}+m_{3}<M:=1.2 10^{27}italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + italic_m start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT < italic_M := 1.2 \u00e2\u2039\u2026 10 start_POSTSUPERSCRIPT 27 end_POSTSUPERSCRIPT, we found that q63=7250590983807477127734940855subscript\u011f\ufffd\u2018\ufffd637250590983807477127734940855q_{63}=7250590983807477127734940855italic_q start_POSTSUBSCRIPT 63 end_POSTSUBSCRIPT = 7250590983807477127734940855, the denominator of the 63-th convergent of \u00ce\u00b3\u011f\ufffd\u203a\u00be exceeds 6\u00e2\ufffd\u00a2M6\u011f\ufffd\u2018\u20ac6M6 italic_M. Next, we define Considering the constraints m1\u00e2\u2030\u00a483,d1\u00e2\u2030 d2,1\u00e2\u2030\u00a4d1\u00e2\u2030\u00a49formulae-sequencesubscript\u011f\ufffd\u2018\u0161183formulae-sequencesubscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u201819m_{1} 83,d_{1} d_{2},1 d_{1} 9italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 83 , italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030 italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , 1 \u00e2\u2030\u00a4 italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 9 and 0\u00e2\u2030\u00a4d2\u00e2\u2030\u00a490subscript\u011f\ufffd\u2018\u2018290 d_{2} 90 \u00e2\u2030\u00a4 italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 9, a quick computation with M\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2h\u00e2\ufffd\u00a2e\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2c\u00e2\ufffd\u00a2a\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdMathematicaitalic_M italic_a italic_t italic_h italic_e italic_m italic_a italic_t italic_i italic_c italic_a yields the inequality Let A:=1.5,B:=10formulae-sequenceassign\u011f\ufffd\ufffd\u00b41.5assign\u011f\ufffd\ufffd\u00b510A:=1.5,B:=10italic_A := 1.5 , italic_B := 10, and w:=m2assign\u011f\ufffd\u2018\u00a4subscript\u011f\ufffd\u2018\u01612w:=m_{2}italic_w := italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT in Lemma 2.2. Using M\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2h\u00e2\ufffd\u00a2e\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2c\u00e2\ufffd\u00a2a\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdMathematicaitalic_M italic_a italic_t italic_h italic_e italic_m italic_a italic_t italic_i italic_c italic_a, we conclude that the inequality (4.16) has no solutions for Consequently, we have m2\u00e2\u2030\u00a475subscript\u011f\ufffd\u2018\u0161275m_{2} 75italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 75. As m1\u00e2\u2030\u00a483subscript\u011f\ufffd\u2018\u0161183m_{1} 83italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 83 and m2\u00e2\u2030\u00a475subscript\u011f\ufffd\u2018\u0161275m_{2} 75italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 75, substituting this upper bounds for m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and m2subscript\u011f\ufffd\u2018\u01612m_{2}italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT into (4.14), we obtain n<5\u00e2\u2039\u20261015\u011f\ufffd\u2018\u203a\u00e2\u2039\u20265superscript1015n<5 10^{15}italic_n < 5 \u00e2\u2039\u2026 10 start_POSTSUPERSCRIPT 15 end_POSTSUPERSCRIPT. Now, let From (4.13), we can express \u00ce\u201c5subscript\u00ce\u201c5 start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT as valid for n\u00e2\u2030\u00a550\u011f\ufffd\u2018\u203a50n 50italic_n \u00e2\u2030\u00a5 50. Choosing a:=0.01assign\u011f\ufffd\u2018\ufffd0.01a:=0.01italic_a := 0.01, it follows that as per Lemma 2.3. This leads us to the conclusion: Dividing both sides of the above inequality by log\u00e2\ufffd\u00a1\u00ce\u00b1\u011f\ufffd\u203a\u00bc italic_\u00ce\u00b1, we derive Let \u00ce\u00b3:=log\u00e2\ufffd\u00a110log\u00e2\ufffd\u00a1\u00ce\u00b1assign\u011f\ufffd\u203a\u00be10\u011f\ufffd\u203a\u00bc 10}{ := divide start_ARG roman_log 10 end_ARG start_ARG roman_log italic_\u00ce\u00b1 end_ARG and consider m3<M:=5\u00e2\u2039\u20261015subscript\u011f\ufffd\u2018\u01613\u011f\ufffd\u2018\u20acassign\u00e2\u2039\u20265superscript1015m_{3}<M:=5 10^{15}italic_m start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT < italic_M := 5 \u00e2\u2039\u2026 10 start_POSTSUPERSCRIPT 15 end_POSTSUPERSCRIPT. We have found that q40=30910886367884945subscript\u011f\ufffd\u2018\ufffd4030910886367884945q_{40}=30910886367884945italic_q start_POSTSUBSCRIPT 40 end_POSTSUBSCRIPT = 30910886367884945, and notably, the denominator of the 40-th convergent of \u00ce\u00b3\u011f\ufffd\u203a\u00be exceeds 6\u00e2\ufffd\u00a2M6\u011f\ufffd\u2018\u20ac6M6 italic_M. Defining and taking into account the constraints m1\u00e2\u2030\u00a483,m2\u00e2\u2030\u00a475,1\u00e2\u2030\u00a4d1\u00e2\u2030\u00a49formulae-sequencesubscript\u011f\ufffd\u2018\u0161183formulae-sequencesubscript\u011f\ufffd\u2018\u01612751subscript\u011f\ufffd\u2018\u201819m_{1} 83,m_{2} 75,1 d_{1} 9italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 83 , italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 75 , 1 \u00e2\u2030\u00a4 italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 9 and 0\u00e2\u2030\u00a4d2,d3\u00e2\u2030\u00a49formulae-sequence0subscript\u011f\ufffd\u2018\u20182subscript\u011f\ufffd\u2018\u2018390 d_{2},d_{3} 90 \u00e2\u2030\u00a4 italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 9, a swift computation with M\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2h\u00e2\ufffd\u00a2e\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2c\u00e2\ufffd\u00a2a\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdMathematicaitalic_M italic_a italic_t italic_h italic_e italic_m italic_a italic_t italic_i italic_c italic_a reveals the inequality except in the scenarios where d1=d2\u00e2\u2030 d3,d1\u00e2\u2030 d2=d3formulae-sequencesubscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u20182subscript\u011f\ufffd\u2018\u20183subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u20182subscript\u011f\ufffd\u2018\u20183d_{1}=d_{2} d_{3},d_{1} d_{2}=d_{3}italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u00e2\u2030 italic_d start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030 italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = italic_d start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT and d1=d2=d3subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u20182subscript\u011f\ufffd\u2018\u20183d_{1}=d_{2}=d_{3}italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = italic_d start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT. Let us set A:=1.17,B:=\u00ce\u00b1formulae-sequenceassign\u011f\ufffd\ufffd\u00b41.17assign\u011f\ufffd\ufffd\u00b5\u011f\ufffd\u203a\u00bcA:=1.17,B:= := 1.17 , italic_B := italic_\u00ce\u00b1, and w:=nassign\u011f\ufffd\u2018\u00a4\u011f\ufffd\u2018\u203aw:=nitalic_w := italic_n in Lemma 2.2. With the aid of M\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2h\u00e2\ufffd\u00a2e\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2c\u00e2\ufffd\u00a2a\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdMathematicaitalic_M italic_a italic_t italic_h italic_e italic_m italic_a italic_t italic_i italic_c italic_a, we can confidently assert that the inequality (4.17) has no solution for Thus, we arrive at the conclusion n<46\u011f\ufffd\u2018\u203a46n<46italic_n < 46, which stands in direct contradiction to our assumption that n>50\u011f\ufffd\u2018\u203a50n>50italic_n > 50. This completes the proof. \u00e2\u02c6\ufffd The only associated Pell numbers that can be expressed as the difference of two repdigits are 1, 3, 7, 17, and 41, i.e. q0=q1=1=9\u00e2\u02c6\u20198=8\u00e2\u02c6\u20197=7\u00e2\u02c6\u20196=6\u00e2\u02c6\u20195=5\u00e2\u02c6\u20194=4\u00e2\u02c6\u20193=3\u00e2\u02c6\u20192=2\u00e2\u02c6\u20191subscript\u011f\ufffd\u2018\ufffd0subscript\u011f\ufffd\u2018\ufffd119887766554433221q_{0}=q_{1}=1=9-8=8-7=7-6=6-5=5-4=4-3=3-2=2-1italic_q start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = italic_q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1 = 9 - 8 = 8 - 7 = 7 - 6 = 6 - 5 = 5 - 4 = 4 - 3 = 3 - 2 = 2 - 1, q2=3=11\u00e2\u02c6\u20198subscript\u011f\ufffd\u2018\ufffd23118q_{2}=3=11-8italic_q start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 3 = 11 - 8, q3=7=11\u00e2\u02c6\u20194subscript\u011f\ufffd\u2018\ufffd37114q_{3}=7=11-4italic_q start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 7 = 11 - 4, q4=17=22\u00e2\u02c6\u20195subscript\u011f\ufffd\u2018\ufffd417225q_{4}=17=22-5italic_q start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 17 = 22 - 5, and q5=41=44\u00e2\u02c6\u20193subscript\u011f\ufffd\u2018\ufffd541443q_{5}=41=44-3italic_q start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 41 = 44 - 3. Assume that (1.5) holds. Let 1\u00e2\u2030\u00a4k\u00e2\u2030\u00a4501\u011f\ufffd\u2018\u02dc501 k 501 \u00e2\u2030\u00a4 italic_k \u00e2\u2030\u00a4 50 and n\u00e2\u2030\u00a52\u011f\ufffd\u2018\u203a2n 2italic_n \u00e2\u2030\u00a5 2. Utilizing M\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2h\u00e2\ufffd\u00a2e\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2c\u00e2\ufffd\u00a2a\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdMathematicaitalic_M italic_a italic_t italic_h italic_e italic_m italic_a italic_t italic_i italic_c italic_a, we find only the solutions detailed in Theorem 5.1. So from this point forward, we assume that k>50\u011f\ufffd\u2018\u02dc50k>50italic_k > 50. If n=m\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u0161n=mitalic_n = italic_m, then it follows that d1>d2subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u20182d_{1}>d_{2}italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT > italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, implying that qksubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02dcq_{k}italic_q start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT is a repdigit. However, the largest possible repdigit in qksubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02dcq_{k}italic_q start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT is 99 [14]. Thus, we get a contradiction since k>50\u011f\ufffd\u2018\u02dc50k>50italic_k > 50. Next, the scenario where n\u00e2\u02c6\u2019m=1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u01611n-m=1italic_n - italic_m = 1. If d1\u00e2\u2030\u00a5d2subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u20182d_{1} d_{2}italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030\u00a5 italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, we encounter associated Pell numbers that are concatenations of two repdigits, which is impossible according to Lemma 2.5. If d1<d2subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u20182d_{1}<d_{2}italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, then we derive associated pell numbers that are concatenation of three repdigits, contradicting Theorem 4.1. Thus, we are left with the conclusion that n\u00e2\u02c6\u2019m\u00e2\u2030\u00a52\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u01612n-m 2italic_n - italic_m \u00e2\u2030\u00a5 2. The inequality implies that n<k+5\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dc5n<k+5italic_n < italic_k + 5. We will now reorganize (1.5) into two distinct cases by using Binet\u00e2\u20ac\u2122s formula of associated Pell numbers, as presented below. Continuing with the first rearrangement of equation (1.5), we obtain Taking the absolute value of both sides of (5.1), we obtain Dividing both sides of (5.2) by d1\u00e2\ufffd\u00a210nsubscript\u011f\ufffd\u2018\u20181superscript10\u011f\ufffd\u2018\u203ad_{1}10^{n}italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT 10 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, we obtain From this, we conclude that Next, we apply Theorem 2.1 with (\u00ce\u00b31,\u00ce\u00b32,\u00ce\u00b33)subscript\u011f\ufffd\u203a\u00be1subscript\u011f\ufffd\u203a\u00be2subscript\u011f\ufffd\u203a\u00be3( italic_\u00ce\u00b3 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u00ce\u00b3 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_\u00ce\u00b3 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) = (\u00ce\u00b1,10,9/2\u00e2\ufffd\u00a2d1)\u011f\ufffd\u203a\u00bc1092subscript\u011f\ufffd\u2018\u20181( italic_\u00ce\u00b1 , 10 , 9 / 2 italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) and (b1,b2,b3)subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd3(b_{1},b_{2},b_{3})( italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_b start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) = (k,\u00e2\u02c6\u2019n,1)\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u203a1(k,-n,1)( italic_k , - italic_n , 1 ). Notably, \u00ce\u00b31subscript\u011f\ufffd\u203a\u00be1 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, \u00ce\u00b32subscript\u011f\ufffd\u203a\u00be2 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, and \u00ce\u00b33subscript\u011f\ufffd\u203a\u00be3 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT are positive real numbers and elements of the field \u011f\ufffd\u2022\u201a=\u00e2\u201e\u0161\u00e2\ufffd\u00a2(2)\u011f\ufffd\u2022\u201a\u00e2\u201e\u01612 = blackboard_Q ( square-root start_ARG 2 end_ARG ). Consequently, the degree of the field \u011f\ufffd\u2022\u201a\u011f\ufffd\u2022\u201a is equal to dL=2subscript\u011f\ufffd\u2018\u2018\u011f\ufffd\ufffd\u00bf2d_{L}=2italic_d start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT = 2. Put We can ensure that \u00ce\u201c6\u00e2\u2030 0subscript\u00ce\u201c60 0roman_\u00ce\u201c start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT \u00e2\u2030 0 as per earlier arguments. Leveraging the properties of absolute logarithmic height, we can analyze the heights as h\u00e2\ufffd\u00a2(\u00ce\u00b31)=log\u00e2\ufffd\u00a1\u00ce\u00b12,\u00e2\u201e\ufffdsubscript\u011f\ufffd\u203a\u00be1\u011f\ufffd\u203a\u00bc2h( ( italic_\u00ce\u00b3 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) = divide start_ARG roman_log italic_\u00ce\u00b1 end_ARG start_ARG 2 end_ARG , h\u00e2\ufffd\u00a2(\u00ce\u00b32)=log\u00e2\ufffd\u00a110,\u00e2\u201e\ufffdsubscript\u011f\ufffd\u203a\u00be210h( 10,italic_h ( italic_\u00ce\u00b3 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) = roman_log 10 , and h\u00e2\ufffd\u00a2(\u00ce\u00b33)\u00e2\u2030\u00a4h\u00e2\ufffd\u00a2(2\u00e2\ufffd\u00a2d1)+h\u00e2\ufffd\u00a2(9)<5.09.\u00e2\u201e\ufffdsubscript\u011f\ufffd\u203a\u00be3\u00e2\u201e\ufffd2subscript\u011f\ufffd\u2018\u20181\u00e2\u201e\ufffd95.09h( h(2d_{1})+h(9)<5.09.italic_h ( italic_\u00ce\u00b3 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) \u00e2\u2030\u00a4 italic_h ( 2 italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) + italic_h ( 9 ) < 5.09 . We can set A1=log\u00e2\ufffd\u00a1\u00ce\u00b1subscript\u011f\ufffd\ufffd\u00b41\u011f\ufffd\u203a\u00bcA_{1}= start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = roman_log italic_\u00ce\u00b1, A2=2\u00e2\ufffd\u00a2log\u00e2\ufffd\u00a110subscript\u011f\ufffd\ufffd\u00b42210A_{2}=2 10italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 2 roman_log 10, A3=10.18subscript\u011f\ufffd\ufffd\u00b4310.18A_{3}=10.18italic_A start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 10.18. Since n<k+5\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dc5n<k+5italic_n < italic_k + 5 and D\u011f\ufffd\ufffd\u00b7Ditalic_D \u00e2\u2030\u00a5 max{n,k,1}\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dc1 italic_n , italic_k , 1 }, we can conveniently choose D=k+5\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u02dc5D=k+5italic_D = italic_k + 5. Considering equation (5.3) and implementing Theorem 2.1, we obtain A straightforward calculation reveals that this inequality leads to Advancing to the second rearrangement of (1.5) as and taking the absolute value of both sides of (5.5), we arrive at Dividing both sides of the above inequality by \u00ce\u00b1k2superscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u02dc2 start_ARG italic_\u00ce\u00b1 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT end_ARG start_ARG 2 end_ARG, we find We can now apply Theorem 2.1 to the above inequality with (\u00ce\u00b31,\u00ce\u00b32,\u00ce\u00b33)subscript\u011f\ufffd\u203a\u00be1subscript\u011f\ufffd\u203a\u00be2subscript\u011f\ufffd\u203a\u00be3( italic_\u00ce\u00b3 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u00ce\u00b3 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_\u00ce\u00b3 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) = (\u00ce\u00b1,10,(d1\u00e2\u02c6\u2019d2\u00e2\ufffd\u00a210m\u00e2\u02c6\u2019n)18) italic_\u00ce\u00b1 , 10 , divide start_ARG ( italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT 10 start_POSTSUPERSCRIPT italic_m - italic_n end_POSTSUPERSCRIPT ) end_ARG start_ARG 18 end_ARG ) and (b1,b2,b3)subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd3(b_{1},b_{2},b_{3})( italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_b start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) = (k,\u00e2\u02c6\u2019n,1)\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u203a1(k,-n,1)( italic_k , - italic_n , 1 ). Crucially, \u00ce\u00b31subscript\u011f\ufffd\u203a\u00be1 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, \u00ce\u00b32subscript\u011f\ufffd\u203a\u00be2 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, and \u00ce\u00b33subscript\u011f\ufffd\u203a\u00be3 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT are positive real numbers that lie within the field \u011f\ufffd\u2022\u201a=\u00e2\u201e\u0161\u00e2\ufffd\u00a2(2)\u011f\ufffd\u2022\u201a\u00e2\u201e\u01612 = blackboard_Q ( square-root start_ARG 2 end_ARG ). Thus, the degree of the field \u011f\ufffd\u2022\u201a\u011f\ufffd\u2022\u201a is dL=2subscript\u011f\ufffd\u2018\u2018\u011f\ufffd\ufffd\u00bf2d_{L}=2italic_d start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT = 2. Let If \u00ce\u201c7=0subscript\u00ce\u201c70 start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT = 0, then This leads to (d1\u00e2\u02c6\u2019d2\u00e2\ufffd\u00a210m\u00e2\u02c6\u2019n)\u00e2\u2039\u202610n\u00e2\u2039\u2026\u00ce\u00b1\u00e2\u02c6\u2019k=18\u00e2\u2039\u2026subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u20182superscript10\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u203asuperscript10\u011f\ufffd\u2018\u203asuperscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u02dc18(d_{1}-d_{2}10^{m-n}) 10^{n} italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT 10 start_POSTSUPERSCRIPT italic_m - italic_n end_POSTSUPERSCRIPT ) \u00e2\u2039\u2026 10 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT \u00e2\u2039\u2026 italic_\u00ce\u00b1 start_POSTSUPERSCRIPT - italic_k end_POSTSUPERSCRIPT = 18, implying \u00ce\u00b1k\u00e2\u02c6\u02c6\u00e2\u201e\u0161superscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u02dc\u00e2\u201e\u0161 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT \u00e2\u02c6\u02c6 blackboard_Q, which is a contradiction for k>0\u011f\ufffd\u2018\u02dc0k>0italic_k > 0. Using properties of absolute logarithmic height, we obtain Next, we will estimate h(\u00ce\u00b33)=h((d1\u00e2\u02c6\u2019d2\u00e2\ufffd\u00a210m\u00e2\u02c6\u2019n)18)h( ( italic_\u00ce\u00b3 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) = italic_h ( divide start_ARG ( italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT 10 start_POSTSUPERSCRIPT italic_m - italic_n end_POSTSUPERSCRIPT ) end_ARG start_ARG 18 end_ARG ). Applying the properties of absolute logarithmic heights, we obtain With these heights established, we can define Since n<k+5\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dc5n<k+5italic_n < italic_k + 5 and D\u011f\ufffd\ufffd\u00b7Ditalic_D \u00e2\u2030\u00a5 max{n,k,1}\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dc1 italic_n , italic_k , 1 }, we can take D=k+5\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u02dc5D=k+5italic_D = italic_k + 5. Thus, considering (5.7) and applying Theorem 2.1, we derive where C=\u00e2\u02c6\u20191.4\u00e2\u2039\u2026306\u00e2\u2039\u202634.5\u00e2\u2039\u202622\u011f\ufffd\ufffd\u00b6\u00e2\u2039\u20261.4superscript306superscript34.5superscript22C=-1.4 30^{6} 3^{4.5} 2^{2}italic_C = - 1.4 \u00e2\u2039\u2026 30 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT \u00e2\u2039\u2026 3 start_POSTSUPERSCRIPT 4.5 end_POSTSUPERSCRIPT \u00e2\u2039\u2026 2 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT. By a simple computation, it follows that Utilizing (5.4) and (5.8), a computational search with M\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2h\u00e2\ufffd\u00a2e\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2c\u00e2\ufffd\u00a2a\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdMathematicaitalic_M italic_a italic_t italic_h italic_e italic_m italic_a italic_t italic_i italic_c italic_a gives us that k<2\u00e2\u2039\u20261028\u011f\ufffd\u2018\u02dc\u00e2\u2039\u20262superscript1028k<2 10^{28}italic_k < 2 \u00e2\u2039\u2026 10 start_POSTSUPERSCRIPT 28 end_POSTSUPERSCRIPT. Let us reduce the upper bound on k\u011f\ufffd\u2018\u02dckitalic_k by using the Baker\u00e2\u20ac\u201cDavenport algorithm as described in Lemma 2.1. We define From (5.3), we have for n\u00e2\u02c6\u2019m\u00e2\u2030\u00a52\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u01612n-m 2italic_n - italic_m \u00e2\u2030\u00a5 2. Choosing a=0.1\u011f\ufffd\u2018\ufffd0.1a=0.1italic_a = 0.1, we arrive at the inequality by Lemma2.2. Consequently, we deduce that Dividing this inequality by log\u00e2\ufffd\u00a11010 10roman_log 10, we obtain We can select \u00cf\u201e=log\u00e2\ufffd\u00a1\u00ce\u00b1log\u00e2\ufffd\u00a110\u00e2\u02c6\u2030\u00e2\u201e\u0161\u011f\ufffd\u0153\ufffd\u011f\ufffd\u203a\u00bc10\u00e2\u201e\u0161 10} = divide start_ARG roman_log italic_\u00ce\u00b1 end_ARG start_ARG roman_log 10 end_ARG \u00e2\u02c6\u2030 blackboard_Q and M=2\u00e2\u2039\u20261028\u011f\ufffd\u2018\u20ac\u00e2\u2039\u20262superscript1028M=2 10^{28}italic_M = 2 \u00e2\u2039\u2026 10 start_POSTSUPERSCRIPT 28 end_POSTSUPERSCRIPT. Notably, we find that q68=2512046602227734280329853086909subscript\u011f\ufffd\u2018\ufffd682512046602227734280329853086909q_{68}=2512046602227734280329853086909italic_q start_POSTSUBSCRIPT 68 end_POSTSUBSCRIPT = 2512046602227734280329853086909, the denominator of the 68-th convergent of \u00cf\u201e\u011f\ufffd\u0153\ufffd exceeding 6\u00e2\ufffd\u00a2M6\u011f\ufffd\u2018\u20ac6M6 italic_M. Next, we define \u00ce\u00bc=log\u00e2\ufffd\u00a1(9/2\u00e2\ufffd\u00a2d1)log\u00e2\ufffd\u00a110\u011f\ufffd\u0153\u202192subscript\u011f\ufffd\u2018\u2018110 10}italic_\u00ce\u00bc = divide start_ARG roman_log ( 9 / 2 italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) end_ARG start_ARG roman_log 10 end_ARG. In this case, considering the fact that 1\u00e2\u2030\u00a4d1\u00e2\u2030\u00a491subscript\u011f\ufffd\u2018\u2018191 d_{1} 91 \u00e2\u2030\u00a4 italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 9, a quick computation with M\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2h\u00e2\ufffd\u00a2e\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2c\u00e2\ufffd\u00a2a\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdMathematicaitalic_M italic_a italic_t italic_h italic_e italic_m italic_a italic_t italic_i italic_c italic_a reveals Let A=4.5\u011f\ufffd\ufffd\u00b44.5A=4.5italic_A = 4.5, B=10\u011f\ufffd\ufffd\u00b510B=10italic_B = 10, and \u00cf\u2030=n\u00e2\u02c6\u2019m\u011f\ufffd\u0153\u201d\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u0161 = italic_n - italic_m in Lemma 2.1. Thus, employing M\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2h\u00e2\ufffd\u00a2e\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2c\u00e2\ufffd\u00a2a\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdMathematicaitalic_M italic_a italic_t italic_h italic_e italic_m italic_a italic_t italic_i italic_c italic_a, we can say that (5.9) has no solution if So n\u00e2\u02c6\u2019m\u00e2\u2030\u00a480\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u016180n-m 80italic_n - italic_m \u00e2\u2030\u00a4 80. Substituting this upper bound for n\u00e2\u02c6\u2019m\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u0161n-mitalic_n - italic_m in (5.8), we derive the result k<8.8\u00e2\u2039\u20261015\u011f\ufffd\u2018\u02dc\u00e2\u2039\u20268.8superscript1015k<8.8 10^{15}italic_k < 8.8 \u00e2\u2039\u2026 10 start_POSTSUPERSCRIPT 15 end_POSTSUPERSCRIPT. Now, let From (5.7), we have for k\u00e2\u2030\u00a525\u011f\ufffd\u2018\u02dc25k 25italic_k \u00e2\u2030\u00a5 25. Choosing a=0.1\u011f\ufffd\u2018\ufffd0.1a=0.1italic_a = 0.1, we get the inequality by Lemma 2.2. Thus, we conclude Dividing both sides by log\u00e2\ufffd\u00a1\u00ce\u00b1\u011f\ufffd\u203a\u00bc italic_\u00ce\u00b1, we obtain Putting \u00cf\u201e=log\u00e2\ufffd\u00a110log\u00e2\ufffd\u00a1\u00ce\u00b1\u00e2\u02c6\u2030\u00e2\u201e\u0161\u011f\ufffd\u0153\ufffd10\u011f\ufffd\u203a\u00bc\u00e2\u201e\u0161 10}{ = divide start_ARG roman_log 10 end_ARG start_ARG roman_log italic_\u00ce\u00b1 end_ARG \u00e2\u02c6\u2030 blackboard_Q and taking M=8.8\u00e2\u2039\u20261015\u011f\ufffd\u2018\u20ac\u00e2\u2039\u20268.8superscript1015M=8.8 10^{15}italic_M = 8.8 \u00e2\u2039\u2026 10 start_POSTSUPERSCRIPT 15 end_POSTSUPERSCRIPT, we found that q42=920197043232024959subscript\u011f\ufffd\u2018\ufffd42920197043232024959q_{42}=920197043232024959italic_q start_POSTSUBSCRIPT 42 end_POSTSUBSCRIPT = 920197043232024959, the denominator of the 42-th convergent of \u00cf\u201e\u011f\ufffd\u0153\ufffd exceeds 6\u00e2\ufffd\u00a2M6\u011f\ufffd\u2018\u20ac6M6 italic_M. Now set \u00ce\u00bc=log(d1\u00e2\u02c6\u2019d2\u00e2\ufffd\u00a210m\u00e2\u02c6\u2019n18)log\u00e2\ufffd\u00a1\u00ce\u00b1 = divide start_ARG roman_log ( divide start_ARG italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT 10 start_POSTSUPERSCRIPT italic_m - italic_n end_POSTSUPERSCRIPT end_ARG start_ARG 18 end_ARG ) end_ARG start_ARG roman_log italic_\u00ce\u00b1 end_ARG. In this scenario, noting that 1\u00e2\u2030\u00a4d1,d2\u00e2\u2030\u00a49formulae-sequence1subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u2018291 d_{1},d_{2} 91 \u00e2\u2030\u00a4 italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 9 and 2\u00e2\u2030\u00a4n\u00e2\u02c6\u2019m\u00e2\u2030\u00a4802\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u0161802 n-m 802 \u00e2\u2030\u00a4 italic_n - italic_m \u00e2\u2030\u00a4 80, a quick computation yields the inequality Let A=3.6\u011f\ufffd\ufffd\u00b43.6A=3.6italic_A = 3.6, B=\u00ce\u00b1\u011f\ufffd\ufffd\u00b5\u011f\ufffd\u203a\u00bcB= = italic_\u00ce\u00b1, and \u00cf\u2030=k\u011f\ufffd\u0153\u201d\u011f\ufffd\u2018\u02dc = italic_k in Lemma 2.1. Therefore, utilizing M\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2h\u00e2\ufffd\u00a2e\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2c\u00e2\ufffd\u00a2a\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdMathematicaitalic_M italic_a italic_t italic_h italic_e italic_m italic_a italic_t italic_i italic_c italic_a, we find that equation (5.10) has no solution if This leads to the result k\u00e2\u2030\u00a449\u011f\ufffd\u2018\u02dc49k 49italic_k \u00e2\u2030\u00a4 49, which contradicts our assumption that k>50\u011f\ufffd\u2018\u02dc50k>50italic_k > 50. Hence, the proof is complete. \u00e2\u02c6\ufffd Data Availability Statements: Data sharing is not applicable to this article as no datasets were generated or analyzed during the current study. Funding: The authors declare that no funds or grants were received during the preparation of this manuscript. Declarations: Conflict of interest: On behalf of all authors, the corresponding author states that there is no Conflict of interest.",
        "keywords": ""
    },
    {
        "id": 22,
        "title": "Noise Guided Structural Learning from Observing Stochastic Dynamics",
        "abstract": "AbstractWe develop an innovative learning framework that incorporate the noise structure to infer the governing equations from observation of trajectory data generated by stochastic dynamics. Our approach can proficiently captures both the noise and the drift terms. Furthermore, it can also accommodate a wide range of noise types, including correlated and state-dependent variations. Moreover, our method demonstrates scalability to high-dimensional systems. Through extensive numerical experiments, we showcase the exceptional performance of our learning algorithm in accurately reconstructing the underlying stochastic dynamics.",
        "corpus": "We develop an innovative learning framework that incorporate the noise structure to infer the governing equations from observation of trajectory data generated by stochastic dynamics. Our approach can proficiently captures both the noise and the drift terms. Furthermore, it can also accommodate a wide range of noise types, including correlated and state-dependent variations. Moreover, our method demonstrates scalability to high-dimensional systems. Through extensive numerical experiments, we showcase the exceptional performance of our learning algorithm in accurately reconstructing the underlying stochastic dynamics. Keywords\u00e2\u20ac\u201d Stochastic Dynamics, Random Noise, System Identification Stochastic Differential Equations (SDEs) provides an accessible and flexible framework for fundamental modeling of stochastic phenomena arising in science and engineering applications\u00c2 [10, 28]. Compared to traditional deterministic differential equations (ODEs) models, SDEs can capture the underlying randomness of the systems, thus leading to more accurate descriptions of the complex behaviors. By incorporating a random component, typically through a Brownian motion, SDE provides a more realistic and flexible framework for simulating and predicting the behavior of these complex and dynamic systems. The SDE model considered here takes on the following form where the the drift term \u011f\ufffd\u2019\u2021:\u00e2\u201e\ufffdd\u00e2\u2020\u2019\u00e2\u201e\ufffdd:\u011f\ufffd\u2019\u2021\u00e2\u2020\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018{ : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \u00e2\u2020\u2019 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT and diffusion coefficient \u00cf\u0192:\u00e2\u201e\ufffdd\u00e2\u2020\u2019\u00e2\u201e\ufffdd\u00c3\u2014d:\u011f\ufffd\u0153\ufffd\u00e2\u2020\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u2018 d}italic_\u00cf\u0192 : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \u00e2\u2020\u2019 blackboard_R start_POSTSUPERSCRIPT italic_d \u00c3\u2014 italic_d end_POSTSUPERSCRIPT (\u00cf\u0192\u011f\ufffd\u0153\ufffd is symmetric positive definite) can be both unknown, and the stochastic noise \u011f\ufffd\ufffd\u00b0tsubscript\u011f\ufffd\ufffd\u00b0\u011f\ufffd\u2018\u00a1{ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is a vector of independent standard Brownian motions. The noise structure of the SDE system is described by a state dependent covariance matrix \u00ce\u00a3:\u00e2\u201e\ufffdd\u00e2\u2020\u2019\u00e2\u201e\ufffdd\u00c3\u2014d:\u00ce\u00a3\u00e2\u2020\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u2018 d}roman_\u00ce\u00a3 : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \u00e2\u2020\u2019 blackboard_R start_POSTSUPERSCRIPT italic_d \u00c3\u2014 italic_d end_POSTSUPERSCRIPT where \u00ce\u00a3=\u00cf\u0192\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\u0160\u00ba\u00ce\u00a3\u011f\ufffd\u0153\ufffdsuperscript\u011f\ufffd\u0153\ufffd\u00e2\u0160\u00ba = italic_\u00cf\u0192 italic_\u00cf\u0192 start_POSTSUPERSCRIPT \u00e2\u0160\u00ba end_POSTSUPERSCRIPT. These SDE models are ubiquitous in physics, biology, finance, chemistry, and many other applications where they provide a robust framework for integrating noise directly into the evolution of system states. In physics, the Langevin equation [27, 6, 9, 32] models the behavior of particles under the influence of both systematic forces and random thermal fluctuations. The model offers insights into particle dynamics at microscopic scales where random forces dominate. Biology benefits from SDEs through models like the stochastic Lotka-Volterra equations, which describe the interactions between predator and prey populations under environmental uncertainty [31]. These models are vital for studying population dynamics where random events can significantly impact species survival and interaction.Additionally, SDEs are also applied in modeling biological systems [30] and cell dynamics [8]. In chemistry, SDEs model the kinetics of chemical reactions involving small numbers of molecules, where traditional deterministic models fail to capture the randomness of molecular collisions [36]. The Chemical Langevin Equation, for instance, is used to simulate reaction pathways in fluctuating environments. SDE models are at the core of mathematical finance, underpinning key areas such as option pricing, risk management, and modeling of interest rates, among which we mention classical Black-Scholes Model [2, 17], Vasicek Model [33] for analyzing interest rate dynamic, and Heston Model [14] for modeling stochastic volatility. Finally, we mention Diffusion Model\u00c2 [16] that currently got traction thanks to its formulation using SDE\u00c2 [29] that makes the analysis and improvement more flexible. The accurate application of SDEs critically depends on the proper calibration, or estimation of the drift and noise structure. Proper parameter estimation ensures that the SDEs not only reflect the theoretical properties of the systems but also closely align with observed phenomena. This alignment is crucial for the models to be truly predictive and reliable in practical applications. This requires the use of diverse statistical and mathematical techniques to ensure the models\u00e2\u20ac\u2122 outputs align with empirical data, thereby enhancing their predictive and explanatory power. Since usually SDE models in each field of study have explicit function form of both drift and diffusion terms, one common method to calibrate or estimate the parameters is done by minimizing the least square error between the observation and model prediction [25, 1]. Statistical inference for SDEs has a long history, and we refer to [18] for more details. A canonical approach for estimating the drift is to derive a maximum-likelihood estimator by maximizing the likelihood function or the Radon\u00e2\u20ac\u201cNikodym derivative [20, Chapter 7], assuming that the entire trajectory {\u011f\ufffd\ufffd\u00b1t}t\u00e2\u02c6\u02c6[0,T]subscriptsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a10\u011f\ufffd\u2018\u2021 bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_t \u00e2\u02c6\u02c6 [ 0 , italic_T ] end_POSTSUBSCRIPT is observed. This approach is employed in recent work of [13]. Following similar arguments, in this work we allowing state-dependent correlated noise, and using the likelihood function we are able to capture the essential structure of \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ from data with complex noise structure. System identification of the drift term from deterministic dynamics has been studied in many different scenarios, e.g. identification by enforcing sparsity such as SINDy\u00c2 [3], neural network based methods such as NeuralODE\u00c2 [4], PINN\u00c2 [26] and autoencoder\u00c2 [37], regression based\u00c2 [7], and high-dimensional reduction variational framework\u00c2 [23]. There are statistical methods which can be used to estimate the drift and noise terms using point-wise statistics. SINDy for SDEs was also developed in\u00c2 [34]. The observation data generated by SDEs can be treated as a time-series data with a mild assumption on the relationship between \u011f\ufffd\ufffd\u00b1tsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1{ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT and \u011f\ufffd\ufffd\u00b1t+\u00ce\u201d\u00e2\ufffd\u00a2tsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1\u00ce\u201d\u011f\ufffd\u2018\u00a1{ t}bold_x start_POSTSUBSCRIPT italic_t + roman_\u00ce\u201d italic_t end_POSTSUBSCRIPT. Various deep neural network architectures can be used to learn the drift term as well as predicting the trajectory data, using RNN, LSTM, and Transformers, see [19, 38, 35] for detailed discussion. Furthermore, when the noise level becomes a constant, i.e. \u00cf\u0192\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1)=\u00cf\u0192>0\u011f\ufffd\u0153\ufffd\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u0153\ufffd0 ( bold_x ) = italic_\u00cf\u0192 > 0, we arrive at a much simpler loss which has been investigated in [22] in combination of high-dimensional \u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b1{ with a special structure in \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ the drift term. The uniqueness of our method is that we incorporate the covariance matrix into the learning and hence improving the estimation especially when the noise is correlated. In this paper, we develop a novel noise guided trajectory based learning approach to infer the governing structures of SDEs from observation data. Our method has contributed to the following aspects We develop a novel noise guided trajectory based learning method that can discover the governing structures of SDEs from data, including both the drift and the noise terms. Our method takes the noise into the consideration of the learning procedure and focuses on the overall evolution of the trajectory instead of focusing on one particular time point. We investigate the stability, accuracy and efficiency of our learning method over various kinds of SDEs with different noise structures. We showcase the superior performance of our algorithm using these examples. We allow the noise to have different structures. The remainder of the paper is structured as follows. Section 2 outlines the framework we use to learn the drift term and the noise structure. We demonstrates the effectiveness of our learning by testing it on various cases summarized in section 3. We conclude our paper in section 4 with a few pointers for ongoing and future developments. Let (\u00ce\u00a9,\u011f\ufffd\u201d\u00bd,(\u011f\ufffd\u201d\u00bdt)0\u00e2\u2030\u00a4t\u00e2\u2030\u00a4T,\u00e2\u201e\u2122)\u00ce\u00a9\u011f\ufffd\u201d\u00bdsubscriptsubscript\u011f\ufffd\u201d\u00bd\u011f\ufffd\u2018\u00a10\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2021\u00e2\u201e\u2122( t T}, roman_\u00ce\u00a9 , blackboard_F , ( blackboard_F start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT 0 \u00e2\u2030\u00a4 italic_t \u00e2\u2030\u00a4 italic_T end_POSTSUBSCRIPT , blackboard_P ) be a filtered probability space, for a fixed and finite time horizon T>0\u011f\ufffd\u2018\u20210T>0italic_T > 0. As usual, the expectation operator with respect to \u00e2\u201e\u2122\u00e2\u201e\u2122 will be denoted by \u011f\ufffd\u201d\u00bc\u00e2\u201e\u2122subscript\u011f\ufffd\u201d\u00bc\u00e2\u201e\u2122 start_POSTSUBSCRIPT blackboard_P end_POSTSUBSCRIPT or simply \u011f\ufffd\u201d\u00bc\u011f\ufffd\u201d\u00bc For random variables X,Y\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u0152X,Yitalic_X , italic_Y we write X\u00e2\u02c6\u00bcYsimilar-to\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u0152X Yitalic_X \u00e2\u02c6\u00bc italic_Y, whenever X,Y\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u0152X,Yitalic_X , italic_Y have the same distribution. We consider governing equations for stochastic dynamics of the following form with some given initial condition \u011f\ufffd\ufffd\u00b10\u00e2\u02c6\u00bc\u00ce\u00bc0similar-tosubscript\u011f\ufffd\ufffd\u00b10subscript\u011f\ufffd\u0153\u20210{ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u00e2\u02c6\u00bc italic_\u00ce\u00bc start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, and where \u011f\ufffd\u2019\u2021:\u00e2\u201e\ufffdd\u00e2\u2020\u2019\u00e2\u201e\ufffdd:\u011f\ufffd\u2019\u2021\u00e2\u2020\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018{ : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \u00e2\u2020\u2019 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT is the drift term, \u00cf\u0192:\u00e2\u201e\ufffdd\u00e2\u2020\u2019\u00e2\u201e\ufffdd\u00c3\u2014d:\u011f\ufffd\u0153\ufffd\u00e2\u2020\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u2018 d}italic_\u00cf\u0192 : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \u00e2\u2020\u2019 blackboard_R start_POSTSUPERSCRIPT italic_d \u00c3\u2014 italic_d end_POSTSUPERSCRIPT is the diffusion coefficient (\u00cf\u0192\u011f\ufffd\u0153\ufffd is symmetric and positive definite, i.e. \u00cf\u0192\u00e2\u0160\u00a4=\u00cf\u0192superscript\u011f\ufffd\u0153\ufffdtop\u011f\ufffd\u0153\ufffd start_POSTSUPERSCRIPT \u00e2\u0160\u00a4 end_POSTSUPERSCRIPT = italic_\u00cf\u0192 and for any \u011f\ufffd\ufffd\u00b1\u00e2\u02c6\u02c6\u00e2\u201e\ufffdd\u011f\ufffd\ufffd\u00b1superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018{ \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, \u011f\ufffd\ufffd\u00b1\u00e2\u0160\u00a4\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b1\u00e2\u2030\u00a50superscript\u011f\ufffd\ufffd\u00b1top\u011f\ufffd\u0153\ufffd\u011f\ufffd\ufffd\u00b10{ 0bold_x start_POSTSUPERSCRIPT \u00e2\u0160\u00a4 end_POSTSUPERSCRIPT italic_\u00cf\u0192 bold_x \u00e2\u2030\u00a5 0 and \u011f\ufffd\ufffd\u00b1\u00e2\u0160\u00a4\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b1=0superscript\u011f\ufffd\ufffd\u00b1top\u011f\ufffd\u0153\ufffd\u011f\ufffd\ufffd\u00b10{ start_POSTSUPERSCRIPT \u00e2\u0160\u00a4 end_POSTSUPERSCRIPT italic_\u00cf\u0192 bold_x = 0 if and only if \u011f\ufffd\ufffd\u00b1=\u011f\ufffd\u0178\ufffd\u011f\ufffd\ufffd\u00b10{ = bold_0), and \u011f\ufffd\ufffd\u00b0\u011f\ufffd\ufffd\u00b0{ represents a vector of independent standard Brownian Motions. The covariance matrix of the SDE system is a symmetric positive definite matrix denoted by \u00ce\u00a3=\u00ce\u00a3\u00e2\ufffd\u00a2(\u011f\ufffd\u2019\u2122):\u00e2\u201e\ufffdd\u00e2\u2020\u2019\u00e2\u201e\ufffdd\u00c3\u2014d:\u00ce\u00a3\u00ce\u00a3\u011f\ufffd\u2019\u2122\u00e2\u2020\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u2018 d}roman_\u00ce\u00a3 = roman_\u00ce\u00a3 ( bold_italic_x ) : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \u00e2\u2020\u2019 blackboard_R start_POSTSUPERSCRIPT italic_d \u00c3\u2014 italic_d end_POSTSUPERSCRIPT where \u00ce\u00a3=\u00cf\u0192\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\u0160\u00ba\u00ce\u00a3\u011f\ufffd\u0153\ufffdsuperscript\u011f\ufffd\u0153\ufffd\u00e2\u0160\u00ba = italic_\u00cf\u0192 italic_\u00cf\u0192 start_POSTSUPERSCRIPT \u00e2\u0160\u00ba end_POSTSUPERSCRIPT. We consider the experiment when we are given continuous observation data in the form of {\u011f\ufffd\ufffd\u00b1t,d\u00e2\ufffd\u00a1\u011f\ufffd\ufffd\u00b1t}t\u00e2\u02c6\u02c6[0,T]subscriptsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1dsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a10\u011f\ufffd\u2018\u2021 bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , start_OPFUNCTION roman_d end_OPFUNCTION bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_t \u00e2\u02c6\u02c6 [ 0 , italic_T ] end_POSTSUBSCRIPT for \u011f\ufffd\ufffd\u00b10\u00e2\u02c6\u00bc\u00ce\u00bc0similar-tosubscript\u011f\ufffd\ufffd\u00b10subscript\u011f\ufffd\u0153\u20210{ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u00e2\u02c6\u00bc italic_\u00ce\u00bc start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, assuming \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ is the only unknown. We will estimate \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ by finding the minimizer to the following loss function for \u011f\ufffd\u2019\u2021~\u00e2\u02c6\u02c6\u00e2\u201e\u2039~\u011f\ufffd\u2019\u2021\u00e2\u201e\u2039 start_ARG bold_italic_f end_ARG \u00e2\u02c6\u02c6 caligraphic_H and \u00ce\u00a3\u00e2\u20ac superscript\u00ce\u00a3\u00e2\u20ac start_POSTSUPERSCRIPT \u00e2\u20ac end_POSTSUPERSCRIPT is the pseudo-inverse of \u00ce\u00a3\u00ce\u00a3 (when \u00cf\u0192\u011f\ufffd\u0153\ufffd is assumed to be SPD, \u00ce\u00a3\u00e2\u20ac =\u00ce\u00a3\u00e2\u02c6\u20191superscript\u00ce\u00a3\u00e2\u20ac superscript\u00ce\u00a31 start_POSTSUPERSCRIPT \u00e2\u20ac end_POSTSUPERSCRIPT = roman_\u00ce\u00a3 start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT); the function space \u00e2\u201e\u2039\u00e2\u201e\u2039{ is designed to be convex and compact w.r.t to the L\u00e2\u02c6\ufffdsuperscript\u011f\ufffd\ufffd\u00bfL^{ start_POSTSUPERSCRIPT \u00e2\u02c6\ufffd end_POSTSUPERSCRIPT norm, and its construction is partially decided by the observation data, while \u00e2\u0178\u00a8\u00e2\u2039\u2026,\u00e2\u2039\u2026\u00e2\u0178\u00a9\u00e2\u2039\u2026\u00e2\u2039\u2026 \u00e2\u2039\u2026 , \u00e2\u2039\u2026 \u00e2\u0178\u00a9 denotes the usuall inner product in \u00e2\u201e\ufffddsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018 start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT. This loss function is derived from Girsanov theorem and the corresponding Randon-Nykodim derivative or likelihood ratio for stochastic processes; see [20, Chpater\u00c2 7] and Section\u00c2 2.2 for details. In the case of uncorrelated noise, i.e. \u00ce\u00a3\u00e2\ufffd\u00a2(\u011f\ufffd\u2019\u2122)=\u00cf\u01922\u00e2\ufffd\u00a2(\u011f\ufffd\u2019\u2122)\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u02c6\u00ce\u00a3\u011f\ufffd\u2019\u2122superscript\u011f\ufffd\u0153\ufffd2\u011f\ufffd\u2019\u2122\u011f\ufffd\ufffd\u02c6 ( bold_italic_x ) = italic_\u00cf\u0192 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( bold_italic_x ) bold_I, where \u011f\ufffd\ufffd\u02c6\u011f\ufffd\ufffd\u02c6{ is the d\u00c3\u2014d\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u2018d ditalic_d \u00c3\u2014 italic_d identity matrix and \u00cf\u0192:\u00e2\u201e\ufffdd\u00e2\u2020\u2019\u00e2\u201e\ufffd+:\u011f\ufffd\u0153\ufffd\u00e2\u2020\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018superscript\u00e2\u201e\ufffd : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \u00e2\u2020\u2019 blackboard_R start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT is a scalar function depending on the state and representing the noise level, the loss function equation\u00c2 2 can be simplified to We estimate the covariance matrix \u00ce\u00a3\u00ce\u00a3 by usual quadratic (co)variation arguments. Namely, the estimation of \u00ce\u00a3\u00ce\u00a3 is the minimizer of the following loss function where [\u011f\ufffd\ufffd\u00b1,\u011f\ufffd\ufffd\u00b1]Tsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2021[{ bold_x , bold_x ] start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT is the quadratic variation of the stochastic process \u011f\ufffd\ufffd\u00b1tsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1{ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT over time interval [0,T]0\u011f\ufffd\u2018\u2021[0,T][ 0 , italic_T ]. We recall that for two stochastic processes \u011f\ufffd\ufffd\u00b1isubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and \u011f\ufffd\ufffd\u00b1jsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2014{ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT the quadratic variation over time interval [0,t]0\u011f\ufffd\u2018\u00a1[0,t][ 0 , italic_t ] is defined by where {tk}subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u02dc italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT } is a partition of interval [0,t]0\u011f\ufffd\u2018\u00a1[0,t][ 0 , italic_t ]. Respectively, for a vector of stochastic processes \u011f\ufffd\ufffd\u00b1t=(\u011f\ufffd\ufffd\u00b11\u00e2\ufffd\u00a2(t),\u011f\ufffd\ufffd\u00b12\u00e2\ufffd\u00a2(t),\u00e2\u20ac\u00a6,\u011f\ufffd\ufffd\u00b1d\u00e2\ufffd\u00a2(t))\u00e2\u0160\u00basubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1superscriptsubscript\u011f\ufffd\ufffd\u00b11\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\ufffd\u00b12\u011f\ufffd\u2018\u00a1\u00e2\u20ac\u00a6subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u00a1\u00e2\u0160\u00ba{ {d}(t))^{ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = ( bold_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_t ) , bold_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_t ) , \u00e2\u20ac\u00a6 , bold_x start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ( italic_t ) ) start_POSTSUPERSCRIPT \u00e2\u0160\u00ba end_POSTSUPERSCRIPT, the quadratic variation [\u011f\ufffd\ufffd\u00b1,\u011f\ufffd\ufffd\u00b1]tsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1[{ bold_x , bold_x ] start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is the matrix with entries [\u011f\ufffd\ufffd\u00b1i,\u011f\ufffd\ufffd\u00b1j]t,i,j=1,\u00e2\u20ac\u00a6,dformulae-sequencesubscriptsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20141\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u2018[{ i,j=1, bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , bold_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ] start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_i , italic_j = 1 , \u00e2\u20ac\u00a6 , italic_d. Estimation of the diffusion coefficient \u00cf\u0192~~\u011f\ufffd\u0153\ufffd start_ARG italic_\u00cf\u0192 end_ARG is hence calculated by spectrum decomposition of \u00ce\u00a3~~\u00ce\u00a3 start_ARG roman_\u00ce\u00a3 end_ARG. In particular, if \u00ce\u00a3\u00ce\u00a3 is constant, then the estimation can be simplified to \u00ce\u00a3~=\u011f\ufffd\u201d\u00bc\u00e2\ufffd\u00a2[\u011f\ufffd\ufffd\u00b1,\u011f\ufffd\ufffd\u00b1]TT~\u00ce\u00a3\u011f\ufffd\u201d\u00bcsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u2021 start_ARG roman_\u00ce\u00a3 end_ARG = blackboard_E divide start_ARG [ bold_x , bold_x ] start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT end_ARG start_ARG italic_T end_ARG. Note that estimation of \u00ce\u00a3\u00ce\u00a3 does not dependent on the drift function \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ Consequently, when both \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ and \u00ce\u00a3\u00ce\u00a3 are unknown, \u00ce\u00a3\u00ce\u00a3 can be estimated first, allowing the estimated covariance matrix to be used to implement equation\u00c2 2. Discrete Data: however in real life applications, the data is not given in its time-continuous form, and usually, the observer has access to data collected over several independently sampled trajectories observed at some discrete time points \u00c2 {\u011f\ufffd\ufffd\u00b1lm}l,m=1L,Msuperscriptsubscriptsuperscriptsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u01611\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\u20ac bold_x start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT } start_POSTSUBSCRIPT italic_l , italic_m = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_L , italic_M end_POSTSUPERSCRIPT, where \u011f\ufffd\ufffd\u00b1lm=\u011f\ufffd\ufffd\u00b1(m)\u00e2\ufffd\u00a2(tl)superscriptsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u0161superscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u0161subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2122{ start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT = bold_x start_POSTSUPERSCRIPT ( italic_m ) end_POSTSUPERSCRIPT ( italic_t start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT ) with 0=t1<\u00e2\u20ac\u00a6<tL=T0subscript\u011f\ufffd\u2018\u00a11\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\u20210=t_{1}< = italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < \u00e2\u20ac\u00a6 < italic_t start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT = italic_T and \u011f\ufffd\ufffd\u00b10msuperscriptsubscript\u011f\ufffd\ufffd\u00b10\u011f\ufffd\u2018\u0161{ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT is an i.i.d sample from \u00ce\u00bc0subscript\u011f\ufffd\u0153\u20210 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. In order to properly gauge the accuracy of our learning estimators, we provide three different performance measures of our estimated drift. First, if we have access to original drift function \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ then we will use the following error to compute the difference between \u011f\ufffd\u2019\u2021^^\u011f\ufffd\u2019\u2021 start_ARG bold_italic_f end_ARG (our estimator) to \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ with the following norm where the weighted measure \u00cf\ufffd\u011f\ufffd\u0153\u0152 defined on \u00e2\u201e\ufffddsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018 start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, is given as follows The norm given by equation\u00c2 5 is useful only from the theoretical perspective, e.g. showing convergence. Under normal circumstances, \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ is most likely non-accessible. Thus we look at a performance measure that compares the difference between \u011f\ufffd\ufffd\u2014\u00e2\ufffd\u00a2(\u011f\ufffd\u2019\u2021,\u011f\ufffd\ufffd\u00b10,T)={\u011f\ufffd\ufffd\u00b1t}t\u00e2\u02c6\u02c6[0,T]\u011f\ufffd\ufffd\u2014\u011f\ufffd\u2019\u2021subscript\u011f\ufffd\ufffd\u00b10\u011f\ufffd\u2018\u2021subscriptsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a10\u011f\ufffd\u2018\u2021{ ( bold_italic_f , bold_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_T ) = { bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_t \u00e2\u02c6\u02c6 [ 0 , italic_T ] end_POSTSUBSCRIPT (the observed trajectory that evolves from \u011f\ufffd\ufffd\u00b10\u00e2\u02c6\u00bc\u00ce\u00bc0similar-tosubscript\u011f\ufffd\ufffd\u00b10subscript\u011f\ufffd\u0153\u20210{ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u00e2\u02c6\u00bc italic_\u00ce\u00bc start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT with the unknown \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ and \u011f\ufffd\ufffd\u2014^\u00e2\ufffd\u00a2(\u011f\ufffd\u2019\u2021^,\u011f\ufffd\ufffd\u00b10,T)={\u011f\ufffd\ufffd\u00b1^t}t\u00e2\u02c6\u02c6[0,T]^\u011f\ufffd\ufffd\u2014^\u011f\ufffd\u2019\u2021subscript\u011f\ufffd\ufffd\u00b10\u011f\ufffd\u2018\u2021subscriptsubscript^\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a10\u011f\ufffd\u2018\u2021 start_ARG bold_X end_ARG ( over^ start_ARG bold_italic_f end_ARG , bold_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_T ) = { over^ start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_t \u00e2\u02c6\u02c6 [ 0 , italic_T ] end_POSTSUBSCRIPT (the estimated trajectory that evolves from the same \u011f\ufffd\ufffd\u00b10subscript\u011f\ufffd\ufffd\u00b10{ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT with the learned \u011f\ufffd\u2019\u2021^^\u011f\ufffd\u2019\u2021 start_ARG bold_italic_f end_ARG and driven by the same realized random noise as used by the original dynamics). Then, the difference between the two trajectories is measured as follows However, comparing two sets of trajectories (even with the same initial condition) on the same random noise is not realistic. We compare the distribution of the trajectories over different initial conditions and all possible noise at some chosen time snapshots using the Wasserstein distance at any given time t\u00e2\u02c6\u02c6[0,T]\u011f\ufffd\u2018\u00a10\u011f\ufffd\u2018\u2021t \u00e2\u02c6\u02c6 [ 0 , italic_T ]. Let \u00ce\u00bctMsubscriptsuperscript\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u00a1 start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT be the empirical distribution at time t\u011f\ufffd\u2018\u00a1titalic_t for the simulation under \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ with M\u011f\ufffd\u2018\u20acMitalic_M trajectories, and \u00ce\u00bc^tMsubscriptsuperscript^\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u00a1 start_ARG italic_\u00ce\u00bc end_ARG start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT be the empirical distribution at time t\u011f\ufffd\u2018\u00a1titalic_t for the simulation with M\u011f\ufffd\u2018\u20acMitalic_M trajectories under \u011f\ufffd\u2019\u2021^^\u011f\ufffd\u2019\u2021 start_ARG bold_italic_f end_ARG where: Then the Wasserstein distance of order two between \u00ce\u00bctMsubscriptsuperscript\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u00a1 start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT and \u00ce\u00bc^tMsubscriptsuperscript^\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u00a1 start_ARG italic_\u00ce\u00bc end_ARG start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is calculated as Here, \u00ce \u00e2\ufffd\u00a2(\u00ce\u00bctM,\u00ce\u00bc^tM|\u00ce\u00bc0)\u00ce subscriptsuperscript\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u00a1conditionalsubscriptsuperscript^\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u0153\u20210 ( italic_\u00ce\u00bc start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , over^ start_ARG italic_\u00ce\u00bc end_ARG start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_\u00ce\u00bc start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) is the set of all joint distributions on \u00e2\u201e\ufffdd\u00c3\u2014\u00e2\u201e\ufffddsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018 start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \u00c3\u2014 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT with marginals \u00ce\u00bctMsubscriptsuperscript\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u00a1 start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT and \u00ce\u00bc^tMsubscriptsuperscript^\u011f\ufffd\u0153\u2021\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u00a1 start_ARG italic_\u00ce\u00bc end_ARG start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, and with the additional constraint that the joint distribution must be consistent with the initial distribution of \u011f\ufffd\ufffd\u00b10subscript\u011f\ufffd\ufffd\u00b10{ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT following \u00ce\u00bc0subscript\u011f\ufffd\u0153\u20210 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. We discuss the theoretical foundation of our methods in this section. Consider two It\u00c3\u00b4 processes defined over measurable space (\u00ce\u00a9,\u011f\ufffd\u201d\u00bd)\u00ce\u00a9\u011f\ufffd\u201d\u00bd( roman_\u00ce\u00a9 , blackboard_F ) and let \u00e2\u201e\u2122Xsubscript\u00e2\u201e\u2122\u011f\ufffd\u2018\u2039 start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT, \u00e2\u201e\u2122Ysubscript\u00e2\u201e\u2122\u011f\ufffd\u2018\u0152 start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT be probability measures corresponding to processes \u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b1{ and \u011f\ufffd\ufffd\u00b2\u011f\ufffd\ufffd\u00b2{ where satisfying all assumptions in [20, Theorem\u00c2 7.18] and its following corollary. Then, the Radon-Nikodym derivative, or the likelihood ratio, takes the form where \u00ce\u00a3\u00e2\u20ac superscript\u00ce\u00a3\u00e2\u20ac start_POSTSUPERSCRIPT \u00e2\u20ac end_POSTSUPERSCRIPT is the pseudo-inverse of \u00ce\u00a3=\u00cf\u0192\u00e2\ufffd\u00a2\u00cf\u0192\u00e2\u0160\u00ba\u00ce\u00a3\u011f\ufffd\u0153\ufffdsuperscript\u011f\ufffd\u0153\ufffd\u00e2\u0160\u00ba = italic_\u00cf\u0192 italic_\u00cf\u0192 start_POSTSUPERSCRIPT \u00e2\u0160\u00ba end_POSTSUPERSCRIPT. Denote the observation as {\u011f\ufffd\ufffd\u00b1t}t\u00e2\u02c6\u02c6[0,T]subscriptsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a10\u011f\ufffd\u2018\u2021 bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_t \u00e2\u02c6\u02c6 [ 0 , italic_T ] end_POSTSUBSCRIPT. Since the assumptions of [20, Theorem\u00c2 7.18] are satisfied, \u00ce\u02dc=\u00cf\u0192\u00e2\u20ac \u00e2\ufffd\u00a2(\u011f\ufffd\u2019\u2021\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1t)\u00e2\u02c6\u2019\u011f\ufffd\u2019\u02c6\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1t))\u00ce\u02dcsuperscript\u011f\ufffd\u0153\ufffd\u00e2\u20ac \u011f\ufffd\u2019\u2021subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2019\u02c6subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1 = italic_\u00cf\u0192 start_POSTSUPERSCRIPT \u00e2\u20ac end_POSTSUPERSCRIPT ( bold_italic_f ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) - bold_italic_g ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ) is an n\u011f\ufffd\u2018\u203anitalic_n-dimensional adapted process and \u00e2\u02c6\u00ab0T\u00e2\u20ac\u2013\u00ce\u02dc\u00e2\u20ac\u20132\u00e2\ufffd\u00a2d\u00e2\ufffd\u00a1t<\u00e2\u02c6\ufffdsuperscriptsubscript0\u011f\ufffd\u2018\u2021superscriptnorm\u00ce\u02dc2d\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT | | roman_\u00ce\u02dc | | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_OPFUNCTION roman_d end_OPFUNCTION italic_t < \u00e2\u02c6\ufffd. By Girsanov theorem, \u011f\ufffd\ufffd\u00b0t~=\u011f\ufffd\ufffd\u00b0t+\u00e2\u02c6\u00ab0T\u00ce\u02dcs\u00e2\ufffd\u00a2d\u00e2\ufffd\u00a1s~subscript\u011f\ufffd\ufffd\u00b0\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\ufffd\u00b0\u011f\ufffd\u2018\u00a1superscriptsubscript0\u011f\ufffd\u2018\u2021subscript\u00ce\u02dc\u011f\ufffd\u2018 d\u011f\ufffd\u2018 start_ARG bold_w start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG = bold_w start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + \u00e2\u02c6\u00ab start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT roman_\u00ce\u02dc start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_OPFUNCTION roman_d end_OPFUNCTION italic_s is an n\u011f\ufffd\u2018\u203anitalic_n-dimensional standard Brownian motion under probability measure \u00e2\u201e\u2122Ysubscript\u00e2\u201e\u2122\u011f\ufffd\u2018\u0152 start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT. Hence, d\u00e2\ufffd\u00a1\u011f\ufffd\ufffd\u00b1t=\u011f\ufffd\u2019\u2021\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1t)\u00e2\ufffd\u00a2d\u00e2\ufffd\u00a1t+\u00cf\u0192\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1t)\u00e2\ufffd\u00a2(d\u00e2\ufffd\u00a1\u011f\ufffd\ufffd\u00b0t~\u00e2\u02c6\u2019\u00ce\u02dct\u00e2\ufffd\u00a2d\u00e2\ufffd\u00a1t)=\u011f\ufffd\u2019\u02c6\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1t)\u00e2\ufffd\u00a2d\u00e2\ufffd\u00a1t+\u00cf\u0192\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1t)\u00e2\ufffd\u00a2d\u00e2\ufffd\u00a1\u011f\ufffd\ufffd\u00b0t~dsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2019\u2021subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1d\u011f\ufffd\u2018\u00a1\u011f\ufffd\u0153\ufffdsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1d~subscript\u011f\ufffd\ufffd\u00b0\u011f\ufffd\u2018\u00a1subscript\u00ce\u02dc\u011f\ufffd\u2018\u00a1d\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2019\u02c6subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1d\u011f\ufffd\u2018\u00a1\u011f\ufffd\u0153\ufffdsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1d~subscript\u011f\ufffd\ufffd\u00b0\u011f\ufffd\u2018\u00a1 }t+ {t} roman_d end_OPFUNCTION bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = bold_italic_f ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) start_OPFUNCTION roman_d end_OPFUNCTION italic_t + italic_\u00cf\u0192 ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ( start_OPFUNCTION roman_d end_OPFUNCTION over~ start_ARG bold_w start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG - roman_\u00ce\u02dc start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_OPFUNCTION roman_d end_OPFUNCTION italic_t ) = bold_italic_g ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) start_OPFUNCTION roman_d end_OPFUNCTION italic_t + italic_\u00cf\u0192 ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) start_OPFUNCTION roman_d end_OPFUNCTION over~ start_ARG bold_w start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG. To simplify calculation, we set \u011f\ufffd\u2019\u02c6=0\u011f\ufffd\u2019\u02c60{ = 0. Then \u011f\ufffd\ufffd\u00b1tsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1{ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT becomes a Brownian process under \u00e2\u201e\u2122Ysubscript\u00e2\u201e\u2122\u011f\ufffd\u2018\u0152 start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT therefore \u00e2\u201e\u2122Y\u00e2\ufffd\u00a2({\u011f\ufffd\ufffd\u00b1t}t\u00e2\u02c6\u02c6[0,T]|\u011f\ufffd\u2019\u2021)subscript\u00e2\u201e\u2122\u011f\ufffd\u2018\u0152conditionalsubscriptsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a10\u011f\ufffd\u2018\u2021\u011f\ufffd\u2019\u2021 start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT ( { bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_t \u00e2\u02c6\u02c6 [ 0 , italic_T ] end_POSTSUBSCRIPT | bold_italic_f ) is now independent from \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ since \u011f\ufffd\ufffd\u00b1tsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1{ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT has no drift term under \u00e2\u201e\u2122Ysubscript\u00e2\u201e\u2122\u011f\ufffd\u2018\u0152 start_POSTSUBSCRIPT italic_Y end_POSTSUBSCRIPT. Then we derive our loss function as the negative log likelihood function In this subsection, we will discuss in details how the algorithm is implemented for our learning framework. Practically speaking, data is rarely sampled continuously in time. Instead, observers typically have access to fragmented data sets, gathered from multiple independently sampled trajectories at specific, discrete time points{\u011f\ufffd\ufffd\u00b1lm}l,m=1L,Msuperscriptsubscriptsuperscriptsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u01611\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\u20ac bold_x start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT } start_POSTSUBSCRIPT italic_l , italic_m = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_L , italic_M end_POSTSUPERSCRIPT, where \u011f\ufffd\ufffd\u00b1lm=\u011f\ufffd\ufffd\u00b1(m)\u00e2\ufffd\u00a2(tl)superscriptsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u0161superscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u0161subscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2122{ start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT = bold_x start_POSTSUPERSCRIPT ( italic_m ) end_POSTSUPERSCRIPT ( italic_t start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT ) with 0=t1<\u00e2\u2039\u00af<tL=T0subscript\u011f\ufffd\u2018\u00a11\u00e2\u2039\u00afsubscript\u011f\ufffd\u2018\u00a1\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\u20210=t_{1}< = italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < \u00e2\u2039\u00af < italic_t start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT = italic_T and \u011f\ufffd\ufffd\u00b10msuperscriptsubscript\u011f\ufffd\ufffd\u00b10\u011f\ufffd\u2018\u0161{ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT is an i.i.d sample from \u00ce\u00bc0subscript\u011f\ufffd\u0153\u20210 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. We use a discretized version of 2, for \u011f\ufffd\u2019\u2021~\u00e2\u02c6\u02c6\u00e2\u201e\u2039~\u011f\ufffd\u2019\u2021\u00e2\u201e\u2039 start_ARG bold_italic_f end_ARG \u00e2\u02c6\u02c6 caligraphic_H. Moreover, we also assume that \u00e2\u201e\u2039\u00e2\u201e\u2039{ is a finite-dimensional function space, i.e. dim\u00e2\ufffd\u00a1(\u00e2\u201e\u2039)=n<\u00e2\u02c6\ufffddim\u00e2\u201e\u2039\u011f\ufffd\u2018\u203a ( caligraphic_H ) = italic_n < \u00e2\u02c6\ufffd. Then for any \u011f\ufffd\u2019\u2021~\u00e2\u02c6\u02c6\u00e2\u201e\u2039~\u011f\ufffd\u2019\u2021\u00e2\u201e\u2039 start_ARG bold_italic_f end_ARG \u00e2\u02c6\u02c6 caligraphic_H, \u011f\ufffd\u2019\u2021~\u00e2\ufffd\u00a2(\u011f\ufffd\u2019\u2122)=\u00e2\u02c6\u2018i=1n\u011f\ufffd\u2019\u201ai\u00e2\ufffd\u00a2\u00cf\u02c6i\u00e2\ufffd\u00a2(\u011f\ufffd\u2019\u2122)~\u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2122superscriptsubscript\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\u2019\u201a\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u0153\u201c\u011f\ufffd\u2018\u2013\u011f\ufffd\u2019\u2122 start_ARG bold_italic_f end_ARG ( bold_italic_x ) = \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT bold_italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_\u00cf\u02c6 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( bold_italic_x ), where \u011f\ufffd\u2019\u201ai\u00e2\u02c6\u02c6\u00e2\u201e\ufffddsubscript\u011f\ufffd\u2019\u201a\u011f\ufffd\u2018\u2013superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT is a constant vector coefficient and \u00cf\u02c6i:\u011f\ufffd\u2018\u00ab\u00e2\u0160\u201a\u00e2\u201e\ufffdd\u00e2\u2020\u2019\u00e2\u201e\ufffd:subscript\u011f\ufffd\u0153\u201c\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u00absuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018\u00e2\u2020\u2019\u00e2\u201e\ufffd start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : bold_italic_D \u00e2\u0160\u201a blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \u00e2\u2020\u2019 blackboard_R is a basis of \u00e2\u201e\u2039\u00e2\u201e\u2039{ and the domain \u011f\ufffd\u2018\u00ab\u011f\ufffd\u2018\u00ab{ is constructed by finding out the min/max / roman_max of the components of \u011f\ufffd\ufffd\u00b1t\u00e2\u02c6\u02c6\u00e2\u201e\ufffddsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018{ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT for t\u00e2\u02c6\u02c6[0,T]\u011f\ufffd\u2018\u00a10\u011f\ufffd\u2018\u2021t \u00e2\u02c6\u02c6 [ 0 , italic_T ]. We consider two methods for constructing \u00cf\u02c6isubscript\u011f\ufffd\u0153\u201c\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT: i) use pre-determined basis such as piecewise polynomials or Clamped B-spline, Fourier basis, or a mixture of all of the aforementioned ones; ii) use neural networks, where the basis functions are also trained from data. Next, we can put the basis representation of \u011f\ufffd\u2019\u2021~~\u011f\ufffd\u2019\u2021 start_ARG bold_italic_f end_ARG back to equation\u00c2 12, we obtain the following loss based on the coefficients In the case of diagonal covariance matrix \u00ce\u00a3\u00ce\u00a3 i.e. we can re-write equation\u00c2 13 as Here (\u011f\ufffd\u2019\u2122)ksubscript\u011f\ufffd\u2019\u2122\u011f\ufffd\u2018\u02dc({ bold_italic_x ) start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT is the kt\u00e2\ufffd\u00a2hsuperscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u00a1\u00e2\u201e\ufffdk^{th}italic_k start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT component of any vector \u011f\ufffd\u2019\u2122\u00e2\u02c6\u02c6\u00e2\u201e\ufffdd\u011f\ufffd\u2019\u2122superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018{ \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT. We define \u011f\ufffd\u0153\u00b6k=[(\u011f\ufffd\u2019\u201a1)k\u00e2\u2039\u00af(\u011f\ufffd\u2019\u201an)k]\u00e2\u0160\u00a4\u00e2\u02c6\u02c6\u00e2\u201e\ufffdnsubscript\u011f\ufffd\u0153\u00b6\u011f\ufffd\u2018\u02dcsuperscriptmatrixsubscriptsubscript\u011f\ufffd\u2019\u201a1\u011f\ufffd\u2018\u02dc\u00e2\u2039\u00afsubscriptsubscript\u011f\ufffd\u2019\u201a\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dctopsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u203a start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = [ start_ARG start_ROW start_CELL ( bold_italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_CELL start_CELL \u00e2\u2039\u00af end_CELL start_CELL ( bold_italic_a start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_CELL end_ROW end_ARG ] start_POSTSUPERSCRIPT \u00e2\u0160\u00a4 end_POSTSUPERSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, and Ak\u00e2\u02c6\u02c6\u00e2\u201e\ufffdn\u00c3\u2014nsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u02dcsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u203aA_{k} n}italic_A start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_n \u00c3\u2014 italic_n end_POSTSUPERSCRIPT as and \u011f\ufffd\u2019\u0192k\u00e2\u02c6\u02c6\u00e2\u201e\ufffdnsubscript\u011f\ufffd\u2019\u0192\u011f\ufffd\u2018\u02dcsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u203a{ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT as Then equation\u00c2 13 can be re-written as Since each \u011f\ufffd\u0153\u00b6k\u00e2\u0160\u00a4\u00e2\ufffd\u00a2Ak\u00e2\ufffd\u00a2\u011f\ufffd\u0153\u00b6k\u00e2\u02c6\u20192\u00e2\ufffd\u00a2\u011f\ufffd\u0153\u00b6k\u00e2\u0160\u00a4\u00e2\ufffd\u00a2\u011f\ufffd\u2019\u0192ksuperscriptsubscript\u011f\ufffd\u0153\u00b6\u011f\ufffd\u2018\u02dctopsubscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u02dcsubscript\u011f\ufffd\u0153\u00b6\u011f\ufffd\u2018\u02dc2superscriptsubscript\u011f\ufffd\u0153\u00b6\u011f\ufffd\u2018\u02dctopsubscript\u011f\ufffd\u2019\u0192\u011f\ufffd\u2018\u02dc start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u0160\u00a4 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT bold_italic_\u00ce\u00b1 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT - 2 bold_italic_\u00ce\u00b1 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u0160\u00a4 end_POSTSUPERSCRIPT bold_italic_b start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT is decoupled from each other, we just need to solve simultaneously Then we can obtain \u011f\ufffd\u2019\u2021^\u00e2\ufffd\u00a2(\u011f\ufffd\u2019\u2122)=\u00e2\u02c6\u2018i=1n\u011f\ufffd\u2019\u201a^i\u00e2\ufffd\u00a2\u00cf\u02c6k\u00e2\ufffd\u00a2(\u011f\ufffd\u2019\u2122)^\u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2122superscriptsubscript\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\u203asubscript^\u011f\ufffd\u2019\u201a\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u0153\u201c\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2019\u2122 start_ARG bold_italic_f end_ARG ( bold_italic_x ) = \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT over^ start_ARG bold_italic_a end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_\u00cf\u02c6 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_x ). However when \u00ce\u00a3\u00ce\u00a3 does not have a diagonal structure, we will have to resolve to gradient descent methods to minimize equation\u00c2 13 in order to find the coefficients {\u011f\ufffd\u2019\u201ai}i=1nsuperscriptsubscriptsubscript\u011f\ufffd\u2019\u201a\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20131\u011f\ufffd\u2018\u203a bold_italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT for a total number of n\u00e2\ufffd\u00a2d\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2018nditalic_n italic_d parameters. If a data-driven basis is desired, we set \u00e2\u201e\u2039\u00e2\u201e\u2039{ to be the space of neural networks with the same depth, number of neurons, and activation functions in the hidden layers. Furthermore, we find \u011f\ufffd\u2019\u2021^^\u011f\ufffd\u2019\u2021 start_ARG bold_italic_f end_ARG by minimizing equation\u00c2 12 using any deep learning optimizer, such as Stochastic Gradient Descent or Adam, from well-known deep learning packages. Similarly, we employ a discretized form of equation\u00c2 4 for estimating \u00ce\u00a3\u00ce\u00a3 The estimation involves approximating (1+d)\u00e2\ufffd\u00a2d21\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u20182 start_ARG ( 1 + italic_d ) italic_d end_ARG start_ARG 2 end_ARG functions, corresponding to the components of the symmetric covariance matrix \u00ce\u00a3\u00ce\u00a3 We denote the j\u011f\ufffd\u2018\u2014jitalic_j-th entry of the vector \u011f\ufffd\ufffd\u00b1lmsuperscriptsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u0161{ start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT as \u011f\ufffd\ufffd\u00b1l,jmsuperscriptsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u0161{ start_POSTSUBSCRIPT italic_l , italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT and the (k,j)\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2014(k,j)( italic_k , italic_j ) component of \u00ce\u00a3\u00ce\u00a3 as \u00ce\u00a3k\u00e2\ufffd\u00a2jsubscript\u00ce\u00a3\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2014 start_POSTSUBSCRIPT italic_k italic_j end_POSTSUBSCRIPT. The component \u00ce\u00a3~k\u00e2\ufffd\u00a2jsubscript~\u00ce\u00a3\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2014 start_ARG roman_\u00ce\u00a3 end_ARG start_POSTSUBSCRIPT italic_k italic_j end_POSTSUBSCRIPT is estimated by minimizing the loss function using a neural network approach, defined as The estimation of \u00ce\u00a3~~\u00ce\u00a3 start_ARG roman_\u00ce\u00a3 end_ARG is completed by assembling the estimated components for each k,j=1,\u00e2\u20ac\u00a6,dformulae-sequence\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u20141\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u2018k,j=1, , italic_j = 1 , \u00e2\u20ac\u00a6 , italic_d. In this section, we demonstrate the application of our trajectory-based method for estimating drift functions and noise structures, showcasing a variety of examples. We explore drift functions ranging from polynomials to trigonometric functions. We also tested our method on various types of covariance matrices, including constant, non-diagonal, and state-dependent covariance matrices. Our function estimation job is carried out in both basis method and deep learning method with 2 and 4 being loss functions for estimating drift and covariance, respectively. The observations, serving as the input dataset for testing our method, are generated by the Euler-Maruyama scheme [15], utilizing the drift functions as we just mentioned. The basis space \u00e2\u201e\u2039\u00e2\u201e\u2039{ is constructed employing either B-spline or piecewise polynomial methods for maximum degree p-max equals 2222. For higher order dimensions where d\u00e2\u2030\u00a52\u011f\ufffd\u2018\u20182d 2italic_d \u00e2\u2030\u00a5 2, each basis function is derived through a tensor grid product, utilizing one-dimensional basis defined by knots that segment the domain in each dimension. The common parameters for the following examples are listed in Table 1. Other parameters will be specified in each subsection of examples. The estimation results are evaluated using several different metrics. We record the noise terms, d\u00e2\ufffd\u00a1\u011f\ufffd\ufffd\u00b0tdsubscript\u011f\ufffd\ufffd\u00b0\u011f\ufffd\u2018\u00a1 roman_d end_OPFUNCTION bold_w start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, from the trajectory generation process and compare the trajectories produced by the estimated drift functions, \u011f\ufffd\u2019\u2021^^\u011f\ufffd\u2019\u2021 start_ARG bold_italic_f end_ARG, under identical noise conditions. We examine trajectory-wise errors using equation 7 with relative trajectory error and plot both \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ and \u011f\ufffd\u2019\u2021^^\u011f\ufffd\u2019\u2021 start_ARG bold_italic_f end_ARG to calculate the relative L2superscript\u011f\ufffd\ufffd\u00bf2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error using 5, where \u00cf\ufffd\u011f\ufffd\u0153\u0152 is derived by 6. When plotting, trajectories with different initial conditions are represented by distinct colors. In trajectory-wise comparisons, solid lines depict the true trajectories, while dashed lines represent those generated by the estimated drift functions. Additionally, the empirical measure \u00cf\ufffd\u011f\ufffd\u0153\u0152 is shown in the background of each 1d plot. Furthermore, we assess the distribution-wise discrepancies between observed and estimated results, computing the Wasserstein distance at various time steps with equation\u00c2 9. For d=1\u011f\ufffd\u2018\u20181d=1italic_d = 1, we first test our learning scheme on polynomial drift function \u011f\ufffd\u2019\u2021=2+0.08\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b1\u00e2\u02c6\u20190.01\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b12\u011f\ufffd\u2019\u202120.08\u011f\ufffd\ufffd\u00b10.01superscript\u011f\ufffd\ufffd\u00b12{ = 2 + 0.08 bold_x - 0.01 bold_x start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT. The estimation results are depicted in 1 and detailed in Table 2. We initiate our numerical study with the estimation of a one-dimensional (d=1\u011f\ufffd\u2018\u20181d=1italic_d = 1) drift function that incorporates both polynomial and trigonometric components, given by \u011f\ufffd\u2019\u2021=2+0.08\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b1\u00e2\u02c6\u20190.05\u00e2\ufffd\u00a2sin\u00e2\ufffd\u00a1(\u011f\ufffd\ufffd\u00b1)+0.02\u00e2\ufffd\u00a2cos2\u00e2\ufffd\u00a1(\u011f\ufffd\ufffd\u00b1)\u011f\ufffd\u2019\u202120.08\u011f\ufffd\ufffd\u00b10.05\u011f\ufffd\ufffd\u00b10.02superscript2\u011f\ufffd\ufffd\u00b1{ = 2 + 0.08 bold_x - 0.05 roman_sin ( bold_x ) + 0.02 roman_cos start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( bold_x ). In this example, we assume the diffusion coefficient is a known constant and set \u00cf\u0192=0.6\u011f\ufffd\u0153\ufffd0.6 = 0.6. Figure 2 illustrates the comparison between the true drift function \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ and the estimated drift function \u011f\ufffd\u2019\u2021^^\u011f\ufffd\u2019\u2021 start_ARG bold_italic_f end_ARG, alongside a comparison of trajectories. Notably, Figure 2(a) on the left includes a background region depicting the histogram of empirical \u00cf\ufffd\u011f\ufffd\u0153\u0152 as defined in equation\u00c2 6. This visualization reveals that in regions where \u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b1{ has a higher density of observations\u00e2\u20ac\u201dindicated by higher histogram values\u00e2\u20ac\u201dthe estimation of \u011f\ufffd\u2019\u2021^^\u011f\ufffd\u2019\u2021 start_ARG bold_italic_f end_ARG tends to be more accurate. Conversely, in less dense regions of the dataset (two ends of the domain), the estimation accuracy of \u011f\ufffd\u2019\u2021^^\u011f\ufffd\u2019\u2021 start_ARG bold_italic_f end_ARG diminishes. Table 3 presents a detailed quantitative analysis of the estimation results, including the L2superscript\u011f\ufffd\ufffd\u00bf2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT norm difference between \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ and \u011f\ufffd\u2019\u2021^^\u011f\ufffd\u2019\u2021 start_ARG bold_italic_f end_ARG, as well as the trajectory error. Furthermore, the table compares the distributional distances between \u011f\ufffd\ufffd\u00b1tsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1{ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT and \u011f\ufffd\ufffd\u00b1^tsubscript^\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1 start_ARG bold_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT at selected time steps, with the Wasserstein distance results included. We continue our numerical investigation with a one-dimensional (d=1\u011f\ufffd\u2018\u20181d=1italic_d = 1) drift function which is given by \u011f\ufffd\u2019\u2021=0.08\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2019\u20210.08\u011f\ufffd\ufffd\u00b1{ = 0.08 bold_x. Figure 3 illustrates the comparison between the true drift function \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ and the estimated drift function \u011f\ufffd\u2019\u2021^^\u011f\ufffd\u2019\u2021 start_ARG bold_italic_f end_ARG, alongside a comparison of trajectories. The setup of figures are similar to the ones presented in previous section. The error for learning \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ turns out to be bigger, especially towards the two end points of the interval. However, the errors happen mostly during the two end points of the data interval, where the distribution of the data appears to be small, i.e. few data present in the learning. We are able to recover most of the trajectory. For d=2\u011f\ufffd\u2018\u20182d=2italic_d = 2, we test two types of drift function \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ polynomial and trigonometric. Denote where \u011f\ufffd\u2019\u2021i:\u00e2\u201e\ufffd2\u00e2\u2020\u2019\u00e2\u201e\ufffd:subscript\u011f\ufffd\u2019\u2021\u011f\ufffd\u2018\u2013\u00e2\u2020\u2019superscript\u00e2\u201e\ufffd2\u00e2\u201e\ufffd{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : blackboard_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT \u00e2\u2020\u2019 blackboard_R and \u011f\ufffd\ufffd\u00b1i\u00e2\u02c6\u02c6\u00e2\u201e\ufffdsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u00e2\u201e\ufffd{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R for i\u00e2\u02c6\u02c6{1,2}\u011f\ufffd\u2018\u201312i \u00e2\u02c6\u02c6 { 1 , 2 }. For polynomial drift function \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ we set Figure 4, Figure 5(a), 5(b) and Table 4 shows evaluation of the polynomial drift function estimation result. For trigonometric drift function \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ we set Figure 6, Figure 7(a), 7(b) and Table 5 shows evaluation of the trigonometric drift function estimation result. In this example, we incorporate a non-diagonal covariance matrix into a two-dimensional (d=2\u011f\ufffd\u2018\u20182d=2italic_d = 2) SDE system. As specified in table 1, all parameters remain unchanged except for M\u011f\ufffd\u2018\u20acMitalic_M. We change total trajectory observation number M\u011f\ufffd\u2018\u20acMitalic_M to 1000100010001000 for faster calculation. And we assume covariance matrix is known and set This change in \u00cf\u0192\u011f\ufffd\u0153\ufffd implies that the Brownian motions within the system are correlated. The drift function is defined using the notation, \u011f\ufffd\u2019\u2021=[f1\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1)f2\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1)]\u00e2\u0160\u00a4\u011f\ufffd\u2019\u2021superscriptmatrixsubscript\u011f\ufffd\u2018\u201c1\u011f\ufffd\ufffd\u00b1subscript\u011f\ufffd\u2018\u201c2\u011f\ufffd\ufffd\u00b1top{ = [ start_ARG start_ROW start_CELL italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( bold_x ) end_CELL start_CELL italic_f start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( bold_x ) end_CELL end_ROW end_ARG ] start_POSTSUPERSCRIPT \u00e2\u0160\u00a4 end_POSTSUPERSCRIPT and \u011f\ufffd\ufffd\u00b1=[\u011f\ufffd\ufffd\u00b11\u011f\ufffd\ufffd\u00b12]\u00e2\u0160\u00a4\u011f\ufffd\ufffd\u00b1superscriptmatrixsubscript\u011f\ufffd\ufffd\u00b11subscript\u011f\ufffd\ufffd\u00b12top{ = [ start_ARG start_ROW start_CELL bold_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_CELL start_CELL bold_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_CELL end_ROW end_ARG ] start_POSTSUPERSCRIPT \u00e2\u0160\u00a4 end_POSTSUPERSCRIPT, where \u011f\ufffd\u2019\u2021i:\u00e2\u201e\ufffd2\u00e2\u2020\u2019\u00e2\u201e\ufffd:subscript\u011f\ufffd\u2019\u2021\u011f\ufffd\u2018\u2013\u00e2\u2020\u2019superscript\u00e2\u201e\ufffd2\u00e2\u201e\ufffd{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : blackboard_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT \u00e2\u2020\u2019 blackboard_R and \u011f\ufffd\ufffd\u00b1i\u00e2\u02c6\u02c6\u00e2\u201e\ufffdsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u00e2\u201e\ufffd{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R for i\u00e2\u02c6\u02c6{1,2}\u011f\ufffd\u2018\u201312i \u00e2\u02c6\u02c6 { 1 , 2 }. For polynomial drift function \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ we set f1=0.4\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b11\u00e2\u02c6\u20190.1\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b11\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b12subscript\u011f\ufffd\u2018\u201c10.4subscript\u011f\ufffd\ufffd\u00b110.1subscript\u011f\ufffd\ufffd\u00b11subscript\u011f\ufffd\ufffd\u00b12f_{1}=0.4{ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.4 bold_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - 0.1 bold_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT bold_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT and f2=\u00e2\u02c6\u20190.8\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b12+0.2\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b112subscript\u011f\ufffd\u2018\u201c20.8subscript\u011f\ufffd\ufffd\u00b120.2superscriptsubscript\u011f\ufffd\ufffd\u00b112f_{2}=-0.8{ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = - 0.8 bold_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + 0.2 bold_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT. The estimation results are presented in figure 8(a) and 8(b) and table 6. Note that differences in boundary values of \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ and \u011f\ufffd\u2019\u2021^^\u011f\ufffd\u2019\u2021 start_ARG bold_italic_f end_ARG are attributed to less density of observations, similar to what we discussed in the 1\u00e2\ufffd\u00a2d1\u011f\ufffd\u2018\u20181d1 italic_d case at both endpoints. In this example, we assume that both the drift function \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ and the variance \u00ce\u00a3\u00ce\u00a3 are unknown. We define \u00cf\u0192=0.2\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u0153\ufffd0.2\u011f\ufffd\ufffd\u00b1 = 0.2 bold_x. In the one-dimensional (d=1\u011f\ufffd\u2018\u20181d=1italic_d = 1) case, the covariance matrix \u00ce\u00a3\u00ce\u00a3 reduces to the variance \u00cf\u01922=0.04\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b12superscript\u011f\ufffd\u0153\ufffd20.04superscript\u011f\ufffd\ufffd\u00b12 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = 0.04 bold_x start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT. The estimation of \u00cf\u01922superscript\u011f\ufffd\u0153\ufffd2 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT is conducted via deep learning, using the loss function defined in equation 4. Figure 9 shows the estimation result. The background of the figure is the histogram of \u011f\ufffd\ufffd\u00b1tsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1{ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, indicating regions with higher and lower observation densities. In the regions with more observations, the estimated variance closely follows the true variance, which validates our learning theory. We push forward our estimation of covariance matrix \u00ce\u00a3\u00ce\u00a3 to the two-dimensional (d=2\u011f\ufffd\u2018\u20182d=2italic_d = 2) case. We keep the assumption that both \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ and \u00ce\u00a3\u00ce\u00a3 are unknown. We set \u00cf\u0192\u011f\ufffd\u0153\ufffd as: where the components \u00cf\u019211=0.4\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b11subscript\u011f\ufffd\u0153\ufffd110.4subscript\u011f\ufffd\ufffd\u00b11 start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT = 0.4 bold_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, \u00cf\u019212=\u00cf\u019221=0.025\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b11\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b12subscript\u011f\ufffd\u0153\ufffd12subscript\u011f\ufffd\u0153\ufffd210.025subscript\u011f\ufffd\ufffd\u00b11subscript\u011f\ufffd\ufffd\u00b12 start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT = italic_\u00cf\u0192 start_POSTSUBSCRIPT 21 end_POSTSUBSCRIPT = 0.025 bold_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT bold_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, \u00cf\u019222=0.6\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b12subscript\u011f\ufffd\u0153\ufffd220.6subscript\u011f\ufffd\ufffd\u00b12 start_POSTSUBSCRIPT 22 end_POSTSUBSCRIPT = 0.6 bold_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT are all state dependent and \u011f\ufffd\ufffd\u00b1=[x1x2]\u00e2\u0160\u00a4\u011f\ufffd\ufffd\u00b1superscriptmatrixsubscript\u011f\ufffd\u2018\u00a51subscript\u011f\ufffd\u2018\u00a52top{ = [ start_ARG start_ROW start_CELL italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_CELL start_CELL italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_CELL end_ROW end_ARG ] start_POSTSUPERSCRIPT \u00e2\u0160\u00a4 end_POSTSUPERSCRIPT. Figure 10 shows the estimation results where the first row displays the true surfaces of the components of \u00ce\u00a3\u00ce\u00a3 and the second row presents the corresponding estimated surfaces. The estimated surfaces show only slight differences from the true ones, demonstrating the accuracy of our method. We extend our numerical test to the three-dimensional (d=3\u011f\ufffd\u2018\u20183d=3italic_d = 3) case. In this scenario, we assume that \u00cf\u0192\u011f\ufffd\u0153\ufffd is a known constant matrix where It is changeling to visualize three-dimensional function in a clear and neat way. Therefore, estimation result for this example is evaluated by the measures outlined in Section 2.1. The drift function is defined using the notation, \u011f\ufffd\u2019\u2021=[f1\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1)f2\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1)f3\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1)]\u00e2\u0160\u00a4\u011f\ufffd\u2019\u2021superscriptmatrixsubscript\u011f\ufffd\u2018\u201c1\u011f\ufffd\ufffd\u00b1subscript\u011f\ufffd\u2018\u201c2\u011f\ufffd\ufffd\u00b1subscript\u011f\ufffd\u2018\u201c3\u011f\ufffd\ufffd\u00b1top{ {x}}) = [ start_ARG start_ROW start_CELL italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( bold_x ) end_CELL start_CELL italic_f start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( bold_x ) end_CELL start_CELL italic_f start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( bold_x ) end_CELL end_ROW end_ARG ] start_POSTSUPERSCRIPT \u00e2\u0160\u00a4 end_POSTSUPERSCRIPT and \u011f\ufffd\ufffd\u00b1=[x1x2x3]\u00e2\u0160\u00a4\u011f\ufffd\ufffd\u00b1superscriptmatrixsubscript\u011f\ufffd\u2018\u00a51subscript\u011f\ufffd\u2018\u00a52subscript\u011f\ufffd\u2018\u00a53top{ = [ start_ARG start_ROW start_CELL italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_CELL start_CELL italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_CELL start_CELL italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_CELL end_ROW end_ARG ] start_POSTSUPERSCRIPT \u00e2\u0160\u00a4 end_POSTSUPERSCRIPT, where \u011f\ufffd\u2019\u2021i:\u00e2\u201e\ufffd3\u00e2\u2020\u2019\u00e2\u201e\ufffd:subscript\u011f\ufffd\u2019\u2021\u011f\ufffd\u2018\u2013\u00e2\u2020\u2019superscript\u00e2\u201e\ufffd3\u00e2\u201e\ufffd{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : blackboard_R start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT \u00e2\u2020\u2019 blackboard_R and \u011f\ufffd\ufffd\u00b1i\u00e2\u02c6\u02c6\u00e2\u201e\ufffdsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013\u00e2\u201e\ufffd{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R for i\u00e2\u02c6\u02c6{1,2,3}\u011f\ufffd\u2018\u2013123i \u00e2\u02c6\u02c6 { 1 , 2 , 3 }. For drift function \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ we set f1=0.05\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b11\u00e2\u02c6\u20190.01\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b11\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b12subscript\u011f\ufffd\u2018\u201c10.05subscript\u011f\ufffd\ufffd\u00b110.01subscript\u011f\ufffd\ufffd\u00b11subscript\u011f\ufffd\ufffd\u00b12f_{1}=0.05{ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.05 bold_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - 0.01 bold_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT bold_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, f2=0.08\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b12\u00e2\u02c6\u20190.05\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b122subscript\u011f\ufffd\u2018\u201c20.08subscript\u011f\ufffd\ufffd\u00b120.05superscriptsubscript\u011f\ufffd\ufffd\u00b122f_{2}=0.08{ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.08 bold_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - 0.05 bold_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT and f3=0.05\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b13\u00e2\u02c6\u20190.02\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b12\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b13subscript\u011f\ufffd\u2018\u201c30.05subscript\u011f\ufffd\ufffd\u00b130.02subscript\u011f\ufffd\ufffd\u00b12subscript\u011f\ufffd\ufffd\u00b13f_{3}=0.05{ start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.05 bold_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT - 0.02 bold_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT bold_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT. We change total trajectory observation number M\u011f\ufffd\u2018\u20acMitalic_M to 1000100010001000 for faster calculation. The estimation result is displayed in table 7. We consider a high dimensional SDE case where the drift term has a special structure. Such special structure will allow us to learn the high-dimensional SDE more effectively through an innate dimension reduction approach. This high dimensional SDE case is a presentation of an interacting agent system. Learning of such systems without stochastic noise terms had been investigated in\u00c2 [23, 39, 24, 11, 12]. We consider such system with correlated stochastic noise, i.e. for a system of N\u011f\ufffd\u2018\ufffdNitalic_N agents, where each agent is associated with a state vector \u011f\ufffd\ufffd\u00b1i\u00e2\u02c6\u02c6\u00e2\u201e\ufffdd\u00e2\u20ac\u00b2subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u2013superscript\u00e2\u201e\ufffdsuperscript\u011f\ufffd\u2018\u2018\u00e2\u20ac\u00b2{ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_d start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT. The agents\u00e2\u20ac\u2122 states are governed by the following SDEs Here \u00cf\u2022:\u00e2\u201e\ufffd+\u00e2\u2020\u2019\u00e2\u201e\ufffd:italic-\u00cf\u2022\u00e2\u2020\u2019superscript\u00e2\u201e\ufffd\u00e2\u201e\ufffd : blackboard_R start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT \u00e2\u2020\u2019 blackboard_R is an interaction kernel that governs how agent j\u011f\ufffd\u2018\u2014jitalic_j influences the behavior of agent i\u011f\ufffd\u2018\u2013iitalic_i, and \u00cf\u0192:\u00e2\u201e\ufffdd\u00e2\u20ac\u00b2\u00e2\u2020\u2019\u00e2\u201e\ufffdd\u00e2\u20ac\u00b2:\u011f\ufffd\u0153\ufffd\u00e2\u2020\u2019superscript\u00e2\u201e\ufffdsuperscript\u011f\ufffd\u2018\u2018\u00e2\u20ac\u00b2superscript\u00e2\u201e\ufffdsuperscript\u011f\ufffd\u2018\u2018\u00e2\u20ac\u00b2 : blackboard_R start_POSTSUPERSCRIPT italic_d start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT \u00e2\u2020\u2019 blackboard_R start_POSTSUPERSCRIPT italic_d start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT is a symmetric positive definite matrix that represents the noise. If we define the vectorized notations, i.e. \u011f\ufffd\ufffd\u00b1=[\u011f\ufffd\ufffd\u00b11\u00e2\u0160\u00a4\u00e2\u2039\u00af\u011f\ufffd\ufffd\u00b1N\u00e2\u0160\u00a4]\u00e2\u0160\u00a4\u011f\ufffd\ufffd\u00b1superscriptmatrixsuperscriptsubscript\u011f\ufffd\ufffd\u00b11top\u00e2\u2039\u00afsuperscriptsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\ufffdtoptop{ = [ start_ARG start_ROW start_CELL bold_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u0160\u00a4 end_POSTSUPERSCRIPT end_CELL start_CELL \u00e2\u2039\u00af end_CELL start_CELL bold_x start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u0160\u00a4 end_POSTSUPERSCRIPT end_CELL end_ROW end_ARG ] start_POSTSUPERSCRIPT \u00e2\u0160\u00a4 end_POSTSUPERSCRIPT, \u011f\ufffd\ufffd\u00b0=[\u011f\ufffd\ufffd\u00b01\u00e2\u0160\u00a4\u00e2\u2039\u00af\u011f\ufffd\ufffd\u00b0N\u00e2\u0160\u00a4]\u00e2\u0160\u00a4\u00e2\u02c6\u02c6\u00e2\u201e\ufffdd=N\u00e2\ufffd\u00a2d\u00e2\u20ac\u00b2\u011f\ufffd\ufffd\u00b0superscriptmatrixsuperscriptsubscript\u011f\ufffd\ufffd\u00b01top\u00e2\u2039\u00afsuperscriptsubscript\u011f\ufffd\ufffd\u00b0\u011f\ufffd\u2018\ufffdtoptopsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u2018\u00e2\u20ac\u00b2{ = [ start_ARG start_ROW start_CELL bold_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u0160\u00a4 end_POSTSUPERSCRIPT end_CELL start_CELL \u00e2\u2039\u00af end_CELL start_CELL bold_w start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u0160\u00a4 end_POSTSUPERSCRIPT end_CELL end_ROW end_ARG ] start_POSTSUPERSCRIPT \u00e2\u0160\u00a4 end_POSTSUPERSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_d = italic_N italic_d start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT and Here \u011f\ufffd\u2019\u2021:\u00e2\u201e\ufffdd\u00e2\u2020\u2019\u00e2\u201e\ufffdd:\u011f\ufffd\u2019\u2021\u00e2\u2020\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018{ : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \u00e2\u2020\u2019 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT and \u00cf\u0192~:\u00e2\u201e\ufffdd\u00e2\u2020\u2019\u00e2\u201e\ufffdd\u00c3\u2014d:~\u011f\ufffd\u0153\ufffd\u00e2\u2020\u2019superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018superscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u2018 d}over~ start_ARG italic_\u00cf\u0192 end_ARG : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \u00e2\u2020\u2019 blackboard_R start_POSTSUPERSCRIPT italic_d \u00c3\u2014 italic_d end_POSTSUPERSCRIPT. Then the system can be put into one single SDE of the form d\u00e2\ufffd\u00a1\u011f\ufffd\ufffd\u00b1t=\u011f\ufffd\u2019\u2021\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1t)\u00e2\ufffd\u00a2d\u00e2\ufffd\u00a1t+\u00cf\u0192~\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1t)\u00e2\ufffd\u00a2d\u00e2\ufffd\u00a1\u011f\ufffd\ufffd\u00b0tdsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2019\u2021subscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1d\u011f\ufffd\u2018\u00a1~\u011f\ufffd\u0153\ufffdsubscript\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u00a1dsubscript\u011f\ufffd\ufffd\u00b0\u011f\ufffd\u2018\u00a1 }t+ roman_d end_OPFUNCTION bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = bold_italic_f ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) start_OPFUNCTION roman_d end_OPFUNCTION italic_t + over~ start_ARG italic_\u00cf\u0192 end_ARG ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) start_OPFUNCTION roman_d end_OPFUNCTION bold_w start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT. We will consider a slightly changed \u00e2\u201e\u201c2subscript\u00e2\u201e\u201c2 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT inner product for these vectors, i.e. for \u011f\ufffd\ufffd\u00ae,\u011f\ufffd\ufffd\u00af\u00e2\u02c6\u02c6\u00e2\u201e\ufffdd\u011f\ufffd\ufffd\u00ae\u011f\ufffd\ufffd\u00afsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018{ , bold_v \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT with then Here the \u00e2\u0178\u00a8\u00e2\u2039\u2026,\u00e2\u2039\u2026\u00e2\u0178\u00a9\u00e2\u2039\u2026\u00e2\u2039\u2026 \u00e2\u2039\u2026 , \u00e2\u2039\u2026 \u00e2\u0178\u00a9 is the usual \u00e2\u201e\u201c2subscript\u00e2\u201e\u201c2 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT inner product for vectors in \u00e2\u201e\ufffdd\u00e2\u20ac\u00b2superscript\u00e2\u201e\ufffdsuperscript\u011f\ufffd\u2018\u2018\u00e2\u20ac\u00b2 start_POSTSUPERSCRIPT italic_d start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT. With this new norm, we can carry out the learning as usual in \u00e2\u201e\ufffddsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018 start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT yet with a lower dimensional structure for \u011f\ufffd\u2019\u2021\u00cf\u2022subscript\u011f\ufffd\u2019\u2021italic-\u00cf\u2022{ start_POSTSUBSCRIPT italic_\u00cf\u2022 end_POSTSUBSCRIPT. We test our learning with the following parameters N=20\u011f\ufffd\u2018\ufffd20N=20italic_N = 20, d\u00e2\u20ac\u00b2=2superscript\u011f\ufffd\u2018\u2018\u00e2\u20ac\u00b22d^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT = 2 (hence d=N\u00e2\ufffd\u00a2d\u00e2\u20ac\u00b2=40\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u2018\u00e2\u20ac\u00b240d=Nd^{ = italic_N italic_d start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT = 40), \u00cf\u2022\u00e2\ufffd\u00a2(r)=r\u00e2\u02c6\u20191italic-\u00cf\u2022\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u01781 ( italic_r ) = italic_r - 1, T=1\u011f\ufffd\u2018\u20211T=1italic_T = 1, \u00ce\u201d\u00e2\ufffd\u00a2t=0.004\u00ce\u201d\u011f\ufffd\u2018\u00a10.004 t=0.004roman_\u00ce\u201d italic_t = 0.004, and M=500\u011f\ufffd\u2018\u20ac500M=500italic_M = 500, and obtained the following comparison of the \u00cf\u2022italic-\u00cf\u2022 instead of the high-dimensional \u011f\ufffd\u2019\u2021\u011f\ufffd\u2019\u2021{ in figure 11. Our method can be also extended to special case of Stochastic Partial Differential Equation (SPDE) estimation. Consider the stochastic heat equation driven by an additive noise on a smooth bounded domain \u011f\ufffd\ufffd\u00b1\u00e2\u02c6\u02c6G\u00e2\u0160\u201a\u00e2\u201e\ufffdd\u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00basuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018{ G \u00e2\u02c6\u02c6 italic_G \u00e2\u0160\u201a blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, with initial condition \u011f\ufffd\ufffd\u00ae\u00e2\ufffd\u00a2(0,\u011f\ufffd\ufffd\u00b1)=0\u011f\ufffd\ufffd\u00ae0\u011f\ufffd\ufffd\u00b10{ ( 0 , bold_x ) = 0, zero boundary condition, and \u00ce\u201d\u00ce\u201d being the Laplace operator with zero boundary conditions in a suitable underlying Hilbert space H\u011f\ufffd\ufffd\u00bbHitalic_H, and where \u011f\ufffd\ufffd\u00b0\u011f\ufffd\ufffd\u00b0{ is a Gaussian noise, white in time and possible colored in space. The existence, uniqueness and other analytical properties of the solution \u011f\ufffd\ufffd\u00ae\u011f\ufffd\ufffd\u00ae{ are well understood, and we refer to [21]. In this case there exists a complete orthonormal system {hk}k\u00e2\u02c6\u02c6\u00e2\u201e\u2022\u00e2\u0160\u201aHsubscriptsubscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u02dc\u00e2\u201e\u2022\u011f\ufffd\ufffd\u00bb H{ italic_h start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_k \u00e2\u02c6\u02c6 blackboard_N end_POSTSUBSCRIPT \u00e2\u0160\u201a italic_H, such that hksubscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u02dch_{k}italic_h start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT is an eigenfunction of \u00ce\u201d\u00ce\u201d We denote by \u00e2\u02c6\u2019\u00ce\u00bbksubscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u02dc- italic_\u00ce\u00bb start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT the corresponding eigenvalue, i.e. \u00ce\u201d\u00e2\ufffd\u00a2hk=\u00e2\u02c6\u2019\u00ce\u00bbj\u00e2\ufffd\u00a2hk\u00ce\u201dsubscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u02dcsubscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u2014subscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u02dc h_{k}=- italic_h start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = - italic_\u00ce\u00bb start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_h start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT. The noise term can be written, informally, as \u011f\ufffd\ufffd\u00b0\u00e2\ufffd\u00a2(t,\u011f\ufffd\ufffd\u00b1)=\u00e2\u02c6\u2018k\u00e2\u02c6\u02c6\u00e2\u201e\u2022qk\u00e2\ufffd\u00a2hk\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1)\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00b0k\u00e2\ufffd\u00a2(t)\u011f\ufffd\ufffd\u00b0\u011f\ufffd\u2018\u00a1\u011f\ufffd\ufffd\u00b1subscript\u011f\ufffd\u2018\u02dc\u00e2\u201e\u2022subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02dcsubscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u02dc\u011f\ufffd\ufffd\u00b1subscript\u011f\ufffd\ufffd\u00b0\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u00a1{ ( italic_t , bold_x ) = \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_k \u00e2\u02c6\u02c6 blackboard_N end_POSTSUBSCRIPT italic_q start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT italic_h start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_x ) bold_w start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_t ), with qksubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02dcq_{k}italic_q start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT some positive scalars, and \u011f\ufffd\ufffd\u00b0k,k\u00e2\u02c6\u02c6\u00e2\u201e\u2022subscript\u011f\ufffd\ufffd\u00b0\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u02dc\u00e2\u201e\u2022{ k start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_k \u00e2\u02c6\u02c6 blackboard_N, independent one dimensional Brownian motions. Assume that \u00ce\u00b8\u011f\ufffd\u0153\u0192 and \u00cf\u0192\u011f\ufffd\u0153\ufffd are some positive constant and we are interested in the estimation of parameter \u00ce\u00b8\u011f\ufffd\u0153\u0192 Following the spectral approach surveyed in [5], we define the projection operator P:H\u00e2\u2020\u2019HN:\u011f\ufffd\u2018\u0192\u00e2\u2020\u2019\u011f\ufffd\ufffd\u00bbsuperscript\u011f\ufffd\ufffd\u00bb\u011f\ufffd\u2018\ufffdP:H H^{N}italic_P : italic_H \u00e2\u2020\u2019 italic_H start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT, where HN=span\u00e2\ufffd\u00a1{h1,\u00e2\u20ac\u00a6,hN}superscript\u011f\ufffd\ufffd\u00bb\u011f\ufffd\u2018\ufffdspansubscript\u00e2\u201e\ufffd1\u00e2\u20ac\u00a6subscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffdH^{N}= start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT = roman_span { italic_h start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_h start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT }. Then \u011f\ufffd\ufffd\u00aeN=PN\u00e2\ufffd\u00a2\u011f\ufffd\ufffd\u00ae=\u00e2\u02c6\u2018k=1N\u011f\ufffd\ufffd\u00aek\u00e2\ufffd\u00a2(t)\u00e2\ufffd\u00a2hk\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1)superscript\u011f\ufffd\ufffd\u00ae\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00aesuperscriptsubscript\u011f\ufffd\u2018\u02dc1\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\ufffd\u00ae\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u00a1subscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u02dc\u011f\ufffd\ufffd\u00b1{ start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT = italic_P start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT bold_u = \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT bold_u start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_t ) italic_h start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_x ) is the Fourier approximation of the solution \u011f\ufffd\ufffd\u00ae\u011f\ufffd\ufffd\u00ae{ by the first N\u011f\ufffd\u2018\ufffdNitalic_N eigenmodes, that satisfies the following equation Since {hk\u00e2\ufffd\u00a2(\u011f\ufffd\ufffd\u00b1)}k=1Nsuperscriptsubscriptsubscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u02dc\u011f\ufffd\ufffd\u00b1\u011f\ufffd\u2018\u02dc1\u011f\ufffd\u2018\ufffd italic_h start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_x ) } start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT are orthogonal to each other, we get that Then \u00ce\u00b8\u011f\ufffd\u0153\u0192 can be estimated by 2 and we obtain the loss function Since this is a simple scalar quadratic optimization problem, the estimator \u00ce\u00b8^^\u011f\ufffd\u0153\u0192 start_ARG italic_\u00ce\u00b8 end_ARG can be calculated explicitly. Assuming that M\u011f\ufffd\u2018\u20acMitalic_M trajectories of each eigenmode \u011f\ufffd\ufffd\u00aeksubscript\u011f\ufffd\ufffd\u00ae\u011f\ufffd\u2018\u02dc{ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT can be observed, we derive that following estimator In the implementation, we focus on one dimensional stochastic heat equation, d=1\u011f\ufffd\u2018\u20181d=1italic_d = 1, and take the domain G=[0,\u00cf\u20ac]\u011f\ufffd\ufffd\u00ba0\u011f\ufffd\u0153\u2039G=[0, = [ 0 , italic_\u00cf\u20ac ]. In this case hk\u00e2\ufffd\u00a2(x)=sin\u00e2\ufffd\u00a1(k\u00e2\ufffd\u00a2x)subscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u00a5h_{k}(x)= start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_x ) = roman_sin ( italic_k italic_x ) and \u00ce\u00bbk=k2subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u02dcsuperscript\u011f\ufffd\u2018\u02dc2 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = italic_k start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT. The parameters are set as follows: T=1\u011f\ufffd\u2018\u20211T=1italic_T = 1, \u00ce\u201d\u00e2\ufffd\u00a2t=0.01\u00ce\u201d\u011f\ufffd\u2018\u00a10.01 t=0.01roman_\u00ce\u201d italic_t = 0.01, \u00cf\u0192=0.1\u011f\ufffd\u0153\ufffd0.1 = 0.1, and qk=1subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02dc1q_{k}=1italic_q start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = 1, that corresponds to space-time white noise. We set the parameter of interest \u00ce\u00b8=2\u011f\ufffd\u0153\u01922 = 2. The estimation result is displayed in table 8 where we applied our estimation method to an SPDE with various numbers of modes N and trajectories M. The results shows that as N\u011f\ufffd\u2018\ufffdNitalic_N increases, the estimation of \u00ce\u00b8=2\u011f\ufffd\u0153\u01922 = 2 converges rapidly to the true value even with a small number of trajectories. The power of the proposed method lies in the fact that \u00ce\u00b8\u011f\ufffd\u0153\u0192 can depend on spatial variable \u011f\ufffd\ufffd\u00b1\u011f\ufffd\ufffd\u00b1{ and/or time. We explore next our method when \u00ce\u00b8\u011f\ufffd\u0153\u0192 is a piecewise function, with initial and boundary conditions staying the same and where we assume \u00ce\u00b81subscript\u011f\ufffd\u0153\u01921 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and \u00ce\u00b82subscript\u011f\ufffd\u0153\u01922 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT are unknown. With the same approach, we obtain Note that in contrast to previous (diagonalizable) case, each Fourier mode \u011f\ufffd\ufffd\u00aejsubscript\u011f\ufffd\ufffd\u00ae\u011f\ufffd\u2018\u2014{ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT is coupled with all other modes. Hence, we consider a Galerkin type projection, i.e. and Then the stochastic processes with dynamics becomes where \u011f\ufffd\ufffd\u00ae^j,\u011f\ufffd\ufffd\u00b0^jsubscript^\u011f\ufffd\ufffd\u00ae\u011f\ufffd\u2018\u2014subscript^\u011f\ufffd\ufffd\u00b0\u011f\ufffd\u2018\u2014 start_ARG bold_u end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , over^ start_ARG bold_w end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT are approximations of true Fourier modes \u011f\ufffd\ufffd\u00aej,\u011f\ufffd\ufffd\u00b0jsubscript\u011f\ufffd\ufffd\u00ae\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\ufffd\u00b0\u011f\ufffd\u2018\u2014{ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , bold_w start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT for j\u00e2\u02c6\u02c6\u00e2\u201e\u2022\u011f\ufffd\u2018\u2014\u00e2\u201e\u2022j \u00e2\u02c6\u02c6 blackboard_N. Since We can define two matrices \u011f\ufffd\u2018\u00a9N(1),\u011f\ufffd\u2018\u00a9N(2)\u00e2\u02c6\u02c6\u00e2\u201e\ufffdN\u00c3\u2014Nsubscriptsuperscript\u011f\ufffd\u2018\u00a91\u011f\ufffd\u2018\ufffdsubscriptsuperscript\u011f\ufffd\u2018\u00a92\u011f\ufffd\u2018\ufffdsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd{ N}bold_italic_B start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT , bold_italic_B start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_N \u00c3\u2014 italic_N end_POSTSUPERSCRIPT, given by and with the vectors we can rewrite SDE system 20 into where \u00ce\u203aNsubscript\u00ce\u203a\u011f\ufffd\u2018\ufffd start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT and \u011f\ufffd\u2018\u00b8Nsubscript\u011f\ufffd\u2018\u00b8\u011f\ufffd\u2018\ufffd{ start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT are diagonal matrices with diagonal entries being \u00ce\u203aN\u00e2\ufffd\u00a2(i,i)=\u00ce\u00bbisubscript\u00ce\u203a\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ( italic_i , italic_i ) = italic_\u00ce\u00bb start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and \u011f\ufffd\u2018\u00b8N\u00e2\ufffd\u00a2(i,i)=\u00cf\u0192\u00e2\ufffd\u00a2qisubscript\u011f\ufffd\u2018\u00b8\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2013\u011f\ufffd\u0153\ufffdsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013{ q_{i}bold_italic_Q start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ( italic_i , italic_i ) = italic_\u00cf\u0192 italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT for i=1,\u00e2\u20ac\u00a6,N\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00a6\u011f\ufffd\u2018\ufffdi=1, = 1 , \u00e2\u20ac\u00a6 , italic_N respectively. Notice now \u00ce\u00a3N=\u011f\ufffd\u2018\u00b8N2subscript\u00ce\u00a3\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u00b8\u011f\ufffd\u2018\ufffd2 start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT = bold_italic_Q start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT is non-singular and diagonal. In view of 2, we deduce the following loss function Define Then we have our estimator We have theoretical guarantee that the matrix (I11I12I21I22)matrixsubscript\u011f\ufffd\ufffd\u00bc11subscript\u011f\ufffd\ufffd\u00bc12subscript\u011f\ufffd\ufffd\u00bc21subscript\u011f\ufffd\ufffd\u00bc22 I_{21}&I_{22} start_ARG start_ROW start_CELL italic_I start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT end_CELL start_CELL italic_I start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL italic_I start_POSTSUBSCRIPT 21 end_POSTSUBSCRIPT end_CELL start_CELL italic_I start_POSTSUBSCRIPT 22 end_POSTSUBSCRIPT end_CELL end_ROW end_ARG ) is invertible, indicating the loss defined by equation\u00c2 22 has a unique minimizer. The convergence theory is in our future work. However, for numerical experiments, we set the parameters as follows: T=1\u011f\ufffd\u2018\u20211T=1italic_T = 1, \u00ce\u00b4\u00e2\ufffd\u00a2t=0.01\u011f\ufffd\u203a\u00bf\u011f\ufffd\u2018\u00a10.01 t=0.01italic_\u00ce\u00b4 italic_t = 0.01, \u00cf\u0192=0.5\u011f\ufffd\u0153\ufffd0.5 = 0.5, qk=1subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02dc1q_{k}=1italic_q start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = 1, \u00ce\u00bbk=k24subscript\u011f\ufffd\u0153\u2020\u011f\ufffd\u2018\u02dcsuperscript\u011f\ufffd\u2018\u02dc24 start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = divide start_ARG italic_k start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG 4 end_ARG and M=1\u011f\ufffd\u2018\u20ac1M=1italic_M = 1. We obtain the following results in table 9. The estimation of the piecewise function \u00ce\u00b8\u011f\ufffd\u0153\u0192 converges fast to the true values, even with only one trajectory, as the number of modes increases to a moderate level. Furthermore, the L2superscript\u011f\ufffd\ufffd\u00bf2L^{2}italic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT error rapidly shrinks toward zero as the number of modes increases to a moderate level. We have demonstrated a novel learning methodology for inferring the drift term and diffusion coefficient in a general SDE system driven by Brownian noise. Our estimation approach, rooted in the statistical analysis of continuous time stochastic systems, does not assume a specific functional structure for the drift or diffusion term of SDE system, thereby enhancing its applicability across a diverse range of SDE models. This approach can efficiently handle high-dimensional SDE systems by leveraging deep learning and vectorization techniques. We estimate both the drift term and diffusion coefficient using a trajectory-based loss function, which is itself guided by noise. The loss function for the drift is derived from the negative logarithm of the ratio of likelihood functions, quantifying the probability ratios of observing two stochastic processes that originate from the same initial condition. For the diffusion coefficient, the loss function is based on the quadratic variation, which operates independently of the drift function. This independence makes our method particularly effective in scenarios where only trajectory observations are available, without prior knowledge of the drift or diffusion. Additionally, our approach is adaptable to various noise structures, including constant, non-diagonal, and state-dependent covariance matrices. The limitation and strength of our algorithm is caused by the introduction of the diffusion matrix \u00ce\u00a3\u00ce\u00a3 of the noise into the loss function. Although \u00ce\u00a3\u00ce\u00a3 is assumed to be invertible, the inversion of a possibly high-dimensional matrix at every epoch of training will cause significant delay in the computation. When \u00ce\u00a3\u00e2\u02c6\u20191superscript\u00ce\u00a31 start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT can be computed component-wise (or block-wise), then a parallel algorithm can be implemented to easily handle the high-dimensional observation data. We have shown a possible way to get around such limitation by using the special structure of the drift/noise term in section 3.7. This will be the next focus of our future research. Another possible direction is combining our learning of SDE with the learning of SPDEs, where the SPDEs are expressed as a systems of SDEs\u00c2 [5], as shown in section 3.8. ZG developed the algorithm, analyzed the data and implemented the software package. ZG develops the theory with IC and MZ. MZ designed the research. All authors wrote the manuscript. IC research was partially supported by NSF Grant DMS-2407549. MZ gratefully acknowledges funding provided by the Oak Ridge Associated Universities (ORAU) Ralph E Powe Junior Faculty Enhancement Award and NSF Grant CCF-AF-2225507222550722255072225507.",
        "keywords": ""
    },
    {
        "id": 23,
        "title": "IC/DC: Surpassing Heuristic Solvers in \nCombinatorial Optimization with Diffusion Models",
        "abstract": "AbstractRecent advancements in learning-based combinatorial optimization (CO) methods have shown promising results in solving NP-hard problems without the need for expert-crafted heuristics. However, high performance of these approaches often rely on problem-specific human-expertise-based search after generating candidate solutions, limiting their applicability to commonly solved CO problems such as Travelling Salesman Problem (TSP).\nIn this paper, we present IC/DC, a CO framework that operates without any supervision. IC/DC is specialized in addressing problems involving two distinct sets of items, and it does not need problem-specific search processes to generate valid solutions.\nIC/DC employs a novel architecture capable of capturing the intricate relationships between items, and thereby enabling effective optimization in challenging CO scenarios. We train our\nmodel in a self-supervised way to minimize the cost of the solution while adhering to the problem-specific constraints.\nIC/DC not only achieves state-of-the-art performance compared to previous learning methods, but also surpasses well-known solvers and heuristic approaches on Asymmetric Traveling Salesman Problem (ATSP).",
        "corpus": "Recent advancements in learning-based combinatorial optimization (CO) methods have shown promising results in solving NP-hard problems without the need for expert-crafted heuristics. However, high performance of these approaches often rely on problem-specific human-expertise-based search after generating candidate solutions, limiting their applicability to commonly solved CO problems such as Travelling Salesman Problem (TSP). In this paper, we present IC/DC, a CO framework that operates without any supervision. IC/DC is specialized in addressing problems involving two distinct sets of items, and it does not need problem-specific search processes to generate valid solutions. IC/DC employs a novel architecture capable of capturing the intricate relationships between items, and thereby enabling effective optimization in challenging CO scenarios. We train our model in a self-supervised way to minimize the cost of the solution while adhering to the problem-specific constraints. IC/DC not only achieves state-of-the-art performance compared to previous learning methods, but also surpasses well-known solvers and heuristic approaches on Asymmetric Traveling Salesman Problem (ATSP). Combinatorial optimization (CO) aims to find the optimal solution that maximizes or minimizes an objective function from a large, discrete set of feasible solutions. This field has been extensively studied due to its broad industrial applications, including logistics, supply chain optimization, job allocation, and more\u00c2 (Zhang et\u00c2 al. 2023). Despite its significance, many CO problems are NP-complete, and developing efficient approximation algorithms is essential. Traditionally, approximation algorithms for CO have been developed using mathematical programming or hand-crafted heuristics\u00c2 (Miller, Tucker, and Zemlin 1960; Helsgaun 2023). However, the need for problem-specific expertise and the high computational demands of these methods has sparked increasing interest in applying deep learning techniques to CO problems. Early deep learning approaches framed CO problems as sequential decision-making tasks, generating solutions in an auto-regressive manner\u00c2 (Bello et\u00c2 al. 2016; Kool, Van\u00c2 Hoof, and Welling 2018). However, these methods were relatively limited in performance due to their inability to revise previously made decisions. In contrast, diffusion-based methods generate complete solutions in a single diffusion timestep and then iteratively refine them during the denoising process\u00c2 (Sun and Yang 2023; Min, Bai, and Gomes 2024). This iterative refinement enhances the overall quality of the solutions through corrections and adjustments. By allowing for the revision of earlier decisions, diffusion-based methods overcome the limitations of auto-regressive approaches and avoid the compounding errors typically associated with early decisions. Despite the impressive performance of diffusion-based methods, previously proposed algorithms had several significant drawbacks, such as the need for costly supervision\u00c2 (Sun and Yang 2023), or use of problem-specific objective that are applicable to other CO problems\u00c2 (Min, Bai, and Gomes 2024). Additionally, due to the challenges in imposing constraint within a diffusion model, previous studies relied on problem-specific search process to extract feasible solutions from the diffusion model\u00e2\u20ac\u2122s generations. Designing these problem-specific search requires specialized knowledge and cannot be easily adapted to different CO problems. In this work, we propose a novel method for training a diffusion model in a self-supervised manner, eliminating the need for costly supervision, problem-specific objectives, or problem-specific search process. We demonstrate our approach on two distinct and challenging CO problems\u00e2\u20ac\u201dthe parallel machine scheduling problem (PMSP) and the asymmetric travelling salesman problem (ATSP)\u00e2\u20ac\u201dwhich have received less attention\u00c2 (Kwon et\u00c2 al. 2021). Our method not only achieves state-of-the-art performance among deep learning approaches, but also surpasses well-known solvers and heuristic methods on ATSP instances by a significant margin. For widely-studied CO problems like the travelling salesman problem (TSP), several off-the-shelf solvers are available, such as CPLEX\u00c2 (IBM 2022) and OR-tools\u00c2 (Google 2024). These solvers are build on a variety of heuristics, incorporating search methods\u00c2 (Helsgaun 2023), mathematical programming\u00c2 (Arora 1996), and graph algorithms\u00c2 (Christofides 2022). Typically, these approaches rely on problem-specific, handcrafted techniques, which limits their flexibility in adapting to diverse variants encountered in real-world scenarios. To overcome this limitation, learning-based solvers have been developed, with early studies primarily focusing on auto-regressive approaches. Bello et\u00c2 al. (2016) were the first to propose solving CO problems using a pointer network trained via reinforcement learning (RL). Kwon et\u00c2 al. (2021) introduced an architecture called MatNet, which builds on the graph attention network (GAT) to encode various types of objects, enabling it to tackle more complex CO problems. While these auto-regressive models offer fast solution generation and can manage intricate CO problems, they are limited by their inability to revise previously made decisions and have been outperformed by methods utilizing diffusion-based methods. To the best of our knowledge, two notable works have effectively addressed CO problems using diffusion models, both achieving solution quality comparable to off-the-shelf solvers while significantly reducing generation time. DIFUSCO\u00c2 (Sun and Yang 2023) is a graph neural network (GNN)-based diffusion model trained in a supervised manner to replicate solutions generated by solvers. Similarly, UTSP\u00c2 (Min, Bai, and Gomes 2024) employs a GNN-based diffusion model trained in an unsupervised manner, eliminating the need for costly solution generation from traditional solvers. However, UTSP\u00e2\u20ac\u2122s objective is based on the concept of the Hamiltonian cycle, limiting its applicability to TSP. However, these algorithms fall into the category of heatmap-generating approaches. While CO problems typically impose strict constraints on solutions, such as forming a Hamiltonian cycle, these algorithms are not trained to inherently satisfy those constraints. Instead, they rely on additional heatmap search techniques, such as active search methods\u00c2 (Qiu, Sun, and Yang 2022) or Monte Carlo Tree Search (MCTS)\u00c2 (Silver et\u00c2 al. 2016; Fu, Qiu, and Zha 2021), to produce feasible solutions. This reliance limits their applicability to CO problems with varying constraints on solutions. To combine the high-quality solutions of diffusion-based methods with the flexibility of auto-regressive approaches, we propose Improving Combinatorial optimization through Diffusion with Constraints (IC/DC). This approach ensures the feasibility of solutions while training diffusion model in a self-supervised manner, eliminating the need for costly supervision and problem-specific search processes. We consider a family of CO problems \u011f\ufffd\u2019\ufffd\u011f\ufffd\u2019\ufffd which involve two distinct sets of items. Each problem c\u00e2\u02c6\u02c6\u011f\ufffd\u2019\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2019\ufffdc \u00e2\u02c6\u02c6 caligraphic_C is defined by two sets of items \u011f\ufffd\u2019\u0153\u011f\ufffd\u2019\u0153 and \u00e2\u201e\u00ac\u00e2\u201e\u00ac and matrices that describe the relationships between these two sets of items, as illustrated on the left side of Figure\u00c2 1. The solution to a CO problem c\u011f\ufffd\u2018\ufffdcitalic_c is represented by a binary matrix X\u00e2\u02c6\u02c6\u011f\ufffd\u2019\u00b3={0,1}|\u011f\ufffd\u2019\u0153|\u00c3\u2014|\u00e2\u201e\u00ac|\u011f\ufffd\u2018\u2039\u011f\ufffd\u2019\u00b3superscript01\u011f\ufffd\u2019\u0153\u00e2\u201e\u00acX \u00e2\u02c6\u02c6 caligraphic_X = { 0 , 1 } start_POSTSUPERSCRIPT | caligraphic_A | \u00c3\u2014 | caligraphic_B | end_POSTSUPERSCRIPT. Typically, for each problem c\u011f\ufffd\u2018\ufffdcitalic_c, there exists a feasible set of solutions, and a particular solution X\u011f\ufffd\u2018\u2039Xitalic_X is evaluated using a problem-specific scoring function score:\u011f\ufffd\u2019\u00b3\u00c3\u2014\u011f\ufffd\u2019\ufffd\u00e2\u2020\u2019\u00e2\u201e\ufffd:score\u00e2\u2020\u2019\u011f\ufffd\u2019\u00b3\u011f\ufffd\u2019\ufffd\u00e2\u201e\ufffd : caligraphic_X \u00c3\u2014 caligraphic_C \u00e2\u2020\u2019 blackboard_R when it is feasible. For clarity, we define the reward function R:\u011f\ufffd\u2019\u00b3\u00c3\u2014\u011f\ufffd\u2019\ufffd\u00e2\u2020\u2019\u00e2\u201e\ufffd:\u011f\ufffd\u2018\u2026\u00e2\u2020\u2019\u011f\ufffd\u2019\u00b3\u011f\ufffd\u2019\ufffd\u00e2\u201e\ufffdR: : caligraphic_X \u00c3\u2014 caligraphic_C \u00e2\u2020\u2019 blackboard_R as follows: which allows us to express the objective of the CO problem c\u011f\ufffd\u2018\ufffdcitalic_c as maxX\u00e2\u02c6\u02c6\u011f\ufffd\u2019\u00b3\u00e2\ufffd\u00a1R\u00e2\ufffd\u00a2(X,c)subscript\u011f\ufffd\u2018\u2039\u011f\ufffd\u2019\u00b3\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\ufffd start_POSTSUBSCRIPT italic_X \u00e2\u02c6\u02c6 caligraphic_X end_POSTSUBSCRIPT italic_R ( italic_X , italic_c ). We build upon a discrete diffusion model with categorical corruption processes\u00c2 (Austin et\u00c2 al. 2021). We represent the uncorrupted solution that we aim to generate as X0subscript\u011f\ufffd\u2018\u20390X_{0}italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, with the corrupted latent variables denoted as X1,\u00e2\u20ac\u00a6,XTsubscript\u011f\ufffd\u2018\u20391\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u2021X_{1},...,X_{T}italic_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_X start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT. We use lowercase x\u011f\ufffd\u2018\u00a5xitalic_x to represent the vectorized forms of X\u011f\ufffd\u2018\u2039Xitalic_X, where xt=vec\u00e2\ufffd\u00a1(Xt)\u00e2\u02c6\u02c6{0,1}|\u011f\ufffd\u2019\u0153|\u00e2\ufffd\u00a2|\u00e2\u201e\u00ac|subscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a1vecsubscript\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1superscript01\u011f\ufffd\u2019\u0153\u00e2\u201e\u00acx_{t}= start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = roman_vec ( italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) \u00e2\u02c6\u02c6 { 0 , 1 } start_POSTSUPERSCRIPT | caligraphic_A | | caligraphic_B | end_POSTSUPERSCRIPT, and tilded x~~\u011f\ufffd\u2018\u00a5 start_ARG italic_x end_ARG to denote the one-hot encoded versions, x~t\u00e2\u02c6\u02c6{0,1}|\u011f\ufffd\u2019\u0153|\u00e2\ufffd\u00a2|\u00e2\u201e\u00ac|\u00c3\u20142subscript~\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a1superscript01\u011f\ufffd\u2019\u0153\u00e2\u201e\u00ac2 2}over~ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 { 0 , 1 } start_POSTSUPERSCRIPT | caligraphic_A | | caligraphic_B | \u00c3\u2014 2 end_POSTSUPERSCRIPT. In line with diffusion model conventions, we use q\u00e2\ufffd\u00a2(\u00e2\u2039\u2026)\u011f\ufffd\u2018\ufffd\u00e2\u2039\u2026q( ( \u00e2\u2039\u2026 ) to denote the data distribution/generative forward process, while p\u00ce\u00b8\u00e2\ufffd\u00a2(\u00e2\u2039\u2026)subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192\u00e2\u2039\u2026p_{ start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT ( \u00e2\u2039\u2026 ) represents the denoising reverse process, which is learned to generate the solutions. Our forward process is defined as: where Q1:t=Q1\u00e2\ufffd\u00a2Q2\u00e2\ufffd\u00a2\u00e2\u20ac\u00a6\u00e2\ufffd\u00a2Qtsubscript\u011f\ufffd\u2018\u201e:1\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\u201e1subscript\u011f\ufffd\u2018\u201e2\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u201e\u011f\ufffd\u2018\u00a1Q_{1:t}=Q_{1}Q_{2}...Q_{t}italic_Q start_POSTSUBSCRIPT 1 : italic_t end_POSTSUBSCRIPT = italic_Q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_Q start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u00e2\u20ac\u00a6 italic_Q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, \u00e2\u0160\u2122direct-product denotes the element-wise multiplication, and vec\u00e2\u02c6\u20191superscriptvec1 start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT reshapes the input to the shape |\u011f\ufffd\u2019\u0153|\u00c3\u2014|\u00e2\u201e\u00ac|\u00c3\u20142\u011f\ufffd\u2019\u0153\u00e2\u201e\u00ac2| 2| caligraphic_A | \u00c3\u2014 | caligraphic_B | \u00c3\u2014 2. The matrix Qt\u00e2\u02c6\u02c6[0,1]2\u00c3\u20142subscript\u011f\ufffd\u2018\u201e\u011f\ufffd\u2018\u00a1superscript0122Q_{t} 2}italic_Q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 [ 0 , 1 ] start_POSTSUPERSCRIPT 2 \u00c3\u2014 2 end_POSTSUPERSCRIPT is a noise transition matrix that independently applies noise to each element of the solution matrix. We design this noise transition matrix to align with the prior distribution of feasible solutions q\u00c2\u00af\u00c2\u00af\u011f\ufffd\u2018\ufffd start_ARG italic_q end_ARG in the limit\u00c2 (Vignac et\u00c2 al. 2022), such that limT\u00e2\u2020\u2019\u00e2\u02c6\ufffdQ1:T\u00e2\ufffd\u00a2z=q\u00c2\u00afsubscript\u00e2\u2020\u2019\u011f\ufffd\u2018\u2021subscript\u011f\ufffd\u2018\u201e:1\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\u00a7\u00c2\u00af\u011f\ufffd\u2018\ufffd start_POSTSUBSCRIPT italic_T \u00e2\u2020\u2019 \u00e2\u02c6\ufffd end_POSTSUBSCRIPT italic_Q start_POSTSUBSCRIPT 1 : italic_T end_POSTSUBSCRIPT italic_z = over\u00c2\u00af start_ARG italic_q end_ARG for any vector z\u011f\ufffd\u2018\u00a7zitalic_z. This is achieved by defining: where 11 is vector of ones, and \u00ce\u00b1tsubscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT and \u00ce\u00b2tsubscript\u011f\ufffd\u203a\u00bd\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT are scheduled appropriately with typical diffusion schedulers. The formulas for computing q\u00c2\u00af\u00c2\u00af\u011f\ufffd\u2018\ufffd start_ARG italic_q end_ARG for the CO problems demonstrated in the experiments are detailed in Appendix\u00c2 B.1. We follow the parametrization of\u00c2 Austin et\u00c2 al. (2021), where neural network f\u00ce\u00b8\u00e2\ufffd\u00a2(\u00e2\u2039\u2026)subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u0153\u0192\u00e2\u2039\u2026f_{ start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT ( \u00e2\u2039\u2026 ) is trained to directly predict logits of X0subscript\u011f\ufffd\u2018\u20390X_{0}italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT from each Xtsubscript\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1X_{t}italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, as follows: Although this parameterization facilitates the easy computation of diffusion loss when a target dataset is provided, samples from p\u00ce\u00b8subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192p_{ start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT may not satisfy the constraints since each element of the solution matrix is independently sampled from a Categorical distribution. This limitation required the use of a feasibility-enforcing search process in previous diffusion-based studies on CO\u00c2 (Sun and Yang 2023; Min, Bai, and Gomes 2024). However, this approach requires a search process specifically tailored to each CO problem, and there is no assurance that the search process will preserve the quality of the solution that the diffusion model aims to generate. To ensure the generation of feasible solutions, we design a process inspired by auto-regressive methods, which we call the feasibility-enforced generation process. In this approach, we sample one element of the solution matrix at a time, ensuring its feasibility based on the previously sampled elements, as follows: This approach, similar to the flexibility of auto-regressive methods, allows for the straightforward enforcement of feasibility in the generated samples. However, p^\u00ce\u00b8subscript^\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192 start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT cannot be directly utilized as the reverse process because it involves discrete sampling, which prevents the use of the reparameterization trick, thereby making conventional and efficient variational training methods inapplicable. When using p\u00ce\u00b8subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192p_{ start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT as the reverse process, the connection between p\u00ce\u00b8subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192p_{ start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT and p^\u00ce\u00b8subscript^\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192 start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT becomes weak, leading to a lack of guarantee that samples from p^\u00ce\u00b8subscript^\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192 start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT will retain the desired characteristics. To this end, we propose an iterative training approach that alternates between the CLONING step and the IMPROVEMENT step. In the CLONING step, we update the reverse process p\u00ce\u00b8subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192p_{ start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT by maximizing the (lower bound of the) log likelihood of a set of high scoring feasible solutions: the surrogate targets. This guides p\u00ce\u00b8subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192p_{ start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT toward generating high-quality feasible solutions, and strengthen its alignment with p^\u00ce\u00b8subscript^\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192 start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT, as they become identical when p\u00ce\u00b8subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192p_{ start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT generates feasible samples only. In the IMPROVEMENT step, we directly update p^\u00ce\u00b8subscript^\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192 start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT using reinforcement learning to maximize the scores of generated solutions. These two steps work in tandem, the IMPROVEMENT step is direct but computationally intensive, and CLONING step is more efficient but is only an indirect method of improving samples from p^\u00ce\u00b8subscript^\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192 start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT. In standard diffusion model training, the target distribution q\u00e2\ufffd\u00a2(X0|c)\u011f\ufffd\u2018\ufffdconditionalsubscript\u011f\ufffd\u2018\u20390\u011f\ufffd\u2018\ufffdq(X_{0}|c)italic_q ( italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT | italic_c ), which represents the distribution of optimal solutions given a problem c\u011f\ufffd\u2018\ufffdcitalic_c, is typically available. However, in CO problems, obtaining such supervised dataset is often prohibitively expensive. To address this, we propose training our diffusion model in a self-supervised manner using a surrogate target distribution q~\u00e2\ufffd\u00a2(X0|c)~\u011f\ufffd\u2018\ufffdconditionalsubscript\u011f\ufffd\u2018\u20390\u011f\ufffd\u2018\ufffd start_ARG italic_q end_ARG ( italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT | italic_c ) instead. This surrogate distribution is progressively refined during training and is defined as a reward-weighted mixture of two distributions: where the mixture is controlled by the hyperparameter \u00ce\u00b1\u00e2\u02c6\u02c6[0,1]\u011f\ufffd\u203a\u00bc01 \u00e2\u02c6\u02c6 [ 0 , 1 ]. In the initial stage of training, the solutions generated by reverse process p\u00ce\u00b8\u00e2\ufffd\u00a2(X0|c)subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192conditionalsubscript\u011f\ufffd\u2018\u20390\u011f\ufffd\u2018\ufffdp_{ start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT ( italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT | italic_c ) are not feasible in general. This leads to using more samples from the prior distribution of feasible solutions q\u00e2\ufffd\u00a2(X0)\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u20390q(X_{0})italic_q ( italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ), and guide the diffusion model to more generate feasible solutions. As training progresses and as p\u00ce\u00b8\u00e2\ufffd\u00a2(X0|c)subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192conditionalsubscript\u011f\ufffd\u2018\u20390\u011f\ufffd\u2018\ufffdp_{ start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT ( italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT | italic_c ) begins to generate feasible solutions, the reward-weighting allows the diffusion model to refine itself by focusing on its high-scoring, feasible generations. Meanwhile, the inclusion of prior distribution of feasible solutions q\u00e2\ufffd\u00a2(X0)\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u20390q(X_{0})italic_q ( italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) introduces diversity to the training, counteracting the tendency of p\u00ce\u00b8subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192p_{ start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT to become too narrow as training progresses. With the surrogate target distribution defined above, we perform standard diffusion training by minimizing the KL-divergence between the model\u00e2\u20ac\u2122s generative distribution and the surrogate target distribution: which results in a variational bound objective (see Appendix\u00c2 A.2 for detailed derivations), \u00e2\u201e\u2019VB\u00e2\ufffd\u00a2(\u00ce\u00b8):=assignsubscript\u00e2\u201e\u2019VB\u011f\ufffd\u0153\u0192absent start_POSTSUBSCRIPT VB end_POSTSUBSCRIPT ( italic_\u00ce\u00b8 ) := Inspired by recent practices\u00c2 (Austin et\u00c2 al. 2021), we also incorporate the following auxiliary losses: where \u00e2\u201e\u2019prdsubscript\u00e2\u201e\u2019prd start_POSTSUBSCRIPT prd end_POSTSUBSCRIPT encourages accurate predictions of the data X0subscript\u011f\ufffd\u2018\u20390X_{0}italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT at each time step, and \u00e2\u201e\u2019cstsubscript\u00e2\u201e\u2019cst start_POSTSUBSCRIPT cst end_POSTSUBSCRIPT discourages infeasible predictions, with C\u00e2\ufffd\u00a2(\u00e2\u2039\u2026)\u011f\ufffd\ufffd\u00b6\u00e2\u2039\u2026C( ( \u00e2\u2039\u2026 ) being a differentiable function that approximately measures constraint violations of samples using the Gumbel-softmax trick (see Appendix.\u00c2 A.3 for details on C\u011f\ufffd\ufffd\u00b6Citalic_C). In summary, during the CLONING step, we minimize: To directly improve the feasibility-enforced generations, we minimize the following objective: Similar to auto-regressive methods, the feasibility-enforced generation process can be viewed as a sequential decision making task, where each element of the solution matrix X0subscript\u011f\ufffd\u2018\u20390X_{0}italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT is determined step by step. This perspective allows us to compute the gradient of the above objective using the REINFORCE algorithm\u00c2 (Williams 1992). After sampling a set of solutions {X0(1),X0(2),\u00e2\u20ac\u00a6,X0(N)}superscriptsubscript\u011f\ufffd\u2018\u203901superscriptsubscript\u011f\ufffd\u2018\u203902\u00e2\u20ac\u00a6superscriptsubscript\u011f\ufffd\u2018\u20390\u011f\ufffd\u2018\ufffd italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( 2 ) end_POSTSUPERSCRIPT , \u00e2\u20ac\u00a6 , italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_N ) end_POSTSUPERSCRIPT } using p^\u00ce\u00b8\u00e2\ufffd\u00a2(X0|c)subscript^\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192conditionalsubscript\u011f\ufffd\u2018\u20390\u011f\ufffd\u2018\ufffd start_ARG italic_p end_ARG start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT ( italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT | italic_c ), we approximate the gradient as follows: \u00e2\u02c6\u2021\u00ce\u00b8\u00e2\u201e\u2019IMP\u00e2\ufffd\u00a2(\u00ce\u00b8)\u00e2\u2030\u02c6subscript\u00e2\u02c6\u2021\u011f\ufffd\u0153\u0192subscript\u00e2\u201e\u2019IMP\u011f\ufffd\u0153\u0192absent start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT IMP end_POSTSUBSCRIPT ( italic_\u00ce\u00b8 ) \u00e2\u2030\u02c6 where R(i)=R\u00e2\ufffd\u00a2(X0(i),c)superscript\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2026superscriptsubscript\u011f\ufffd\u2018\u20390\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffdR^{(i)}=R(X_{0}^{(i)},c)italic_R start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT = italic_R ( italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT , italic_c ). This approach is adapted from the baseline estimation method of POMO\u00c2 (Kwon et\u00c2 al. 2020). We train IC/DC by alternating between the CLONING step\u00e2\u20ac\u201cdiffusion model training with surrogate targets\u00e2\u20ac\u201cand the IMPROVEMENT step\u00e2\u20ac\u201creinforcement learning of feasibility-enforced generation, as shown in Algorithm\u00c2 1. In practice, we use a replay memory \u011f\ufffd\u2019\u0178q~subscript\u011f\ufffd\u2019\u0178~\u011f\ufffd\u2018\ufffd start_POSTSUBSCRIPT over~ start_ARG italic_q end_ARG end_POSTSUBSCRIPT to implement a surrogate target distribution, and perform multiple CLONING steps for each IMPROVEMENT step. This is because CLONING updates only a single timestep of the diffusion model, and IMPROVEMENT is significantly slower due to the online generations. Input: A set of CO problems \u011f\ufffd\u2019\ufffd\u011f\ufffd\u2019\ufffd learning late \u00ce\u00b3\u011f\ufffd\u203a\u00be diffusion step T\u011f\ufffd\u2018\u2021Titalic_T, target mix ratio \u00ce\u00b1\u011f\ufffd\u203a\u00bc The neural network we need is f:\u011f\ufffd\u2019\u00b3\u00c3\u2014\u011f\ufffd\u2019\ufffd\u00e2\u2020\u2019\u011f\ufffd\u2019\u00b3:\u011f\ufffd\u2018\u201c\u00e2\u2020\u2019\u011f\ufffd\u2019\u00b3\u011f\ufffd\u2019\ufffd\u011f\ufffd\u2019\u00b3f: : caligraphic_X \u00c3\u2014 caligraphic_C \u00e2\u2020\u2019 caligraphic_X, which encodes the CO problem and outputs a distribution over binary matrices given an input binary matrix. To achieve this, we propose a problem encoder that effectively encodes CO problem, and a denoiser, a specialized variant of GNN that processes the bipartite graph between two sets of items. For the CO problems we consider, a problem instance c\u011f\ufffd\u2018\ufffdcitalic_c consists of information about two sets of items and their relationships. For simplicity, let\u00e2\u20ac\u2122s assume that all items share the same number of features d\u011f\ufffd\u2018\u2018ditalic_d; if not, different embedding layers can be used to standardize the feature dimensions. The information for the items in set \u011f\ufffd\u2019\u0153\u011f\ufffd\u2019\u0153 is represented by the matrix A\u00e2\u02c6\u02c6\u00e2\u201e\ufffd|\u011f\ufffd\u2019\u0153|\u00c3\u2014d\u011f\ufffd\ufffd\u00b4superscript\u00e2\u201e\ufffd\u011f\ufffd\u2019\u0153\u011f\ufffd\u2018\u2018A d}italic_A \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT | caligraphic_A | \u00c3\u2014 italic_d end_POSTSUPERSCRIPT, and similarly, the items in set \u00e2\u201e\u00ac\u00e2\u201e\u00ac are represented by the matrix B\u00e2\u02c6\u02c6\u00e2\u201e\ufffd|\u00e2\u201e\u00ac|\u00c3\u2014d\u011f\ufffd\ufffd\u00b5superscript\u00e2\u201e\ufffd\u00e2\u201e\u00ac\u011f\ufffd\u2018\u2018B d}italic_B \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT | caligraphic_B | \u00c3\u2014 italic_d end_POSTSUPERSCRIPT. There relationship between these items is captured by the matrix D\u00e2\u02c6\u02c6\u00e2\u201e\ufffd|\u011f\ufffd\u2019\u0153|\u00c3\u2014|\u00e2\u201e\u00ac|\u011f\ufffd\ufffd\u00b7superscript\u00e2\u201e\ufffd\u011f\ufffd\u2019\u0153\u00e2\u201e\u00acD \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT | caligraphic_A | \u00c3\u2014 | caligraphic_B | end_POSTSUPERSCRIPT. Together, these matrices define the problem instance, i.e., c=(A,B,D)\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b5\u011f\ufffd\ufffd\u00b7c=(A,B,D)italic_c = ( italic_A , italic_B , italic_D ). To effectively encode the problem represented by these matrices, we adopt the dual graph attentional layer structure from MatNet\u00c2 (Kwon et\u00c2 al. 2021), but replace the attention layer with a modified version of graph attention networks (GAT, Veli\u00c4\ufffdkovi\u00c4\u2021 et\u00c2 al. 2017) that is specifically designed to process a bipartite graph. The problem encoder consists of L\u011f\ufffd\ufffd\u00bfLitalic_L layers, where each layer takes (A,B,D)\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b5\u011f\ufffd\ufffd\u00b7(A,B,D)( italic_A , italic_B , italic_D ) as input and outputs updated features (A\u00e2\u20ac\u00b2,B\u00e2\u20ac\u00b2)superscript\u011f\ufffd\ufffd\u00b4\u00e2\u20ac\u00b2superscript\u011f\ufffd\ufffd\u00b5\u00e2\u20ac\u00b2(A^{ italic_A start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT , italic_B start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ). The outputs of the final layer are then passed to the denoiser. The bottom-right side of Figure\u00c2 2 illustrates this problem encoder. Detailed equations of problem encoder layer are provided in Appendix\u00c2 B.2. Building on recent empirical successes\u00c2 (Joshi et\u00c2 al. 2020; Qiu, Sun, and Yang 2022), we extend the anisotropic graph neural network (AGNN) to handle bipartite graphs, allowing us to consider two distinct sets of items, and use it as the denoiser. The input embedding layer maps each element of the noisy solution matrix Xtsubscript\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1X_{t}italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT and the timestep t\u011f\ufffd\u2018\u00a1titalic_t into d\u011f\ufffd\u2018\u2018ditalic_d-dimensional features. These embeddings are then passed to the AGNN, along with the problem embedding A\u00e2\u20ac\u00b2superscript\u011f\ufffd\ufffd\u00b4\u00e2\u20ac\u00b2A^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT and B\u00e2\u20ac\u00b2superscript\u011f\ufffd\ufffd\u00b5\u00e2\u20ac\u00b2B^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT. After L\u00e2\u20ac\u00b2superscript\u011f\ufffd\ufffd\u00bf\u00e2\u20ac\u00b2L^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT layers of AGNN, the embedded solution matrix with updated features is passed through a linear layer to produce the denoised solution matrix X0subscript\u011f\ufffd\u2018\u20390X_{0}italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. The bottom-left side of Figure\u00c2 2 illustrates this denoiser. Detailed equations of denoiser layer are provided in Appendix\u00c2 B.3. We begin by describing the combinatorial optimization (CO) problems on which we conducted experiments: the Parallel Machine Scheduling Problem (PMSP) and the Asymmetric Travelling Salesman Problem (ATSP). In PMSP, a problem instance c\u011f\ufffd\u2018\ufffdcitalic_c consists of |\u011f\ufffd\u2019\u00a5|\u011f\ufffd\u2019\u00a5| caligraphic_J | jobs and |\u00e2\u201e\u00b3|\u00e2\u201e\u00b3| caligraphic_M | machines. Each job j\u00e2\u02c6\u02c6\u011f\ufffd\u2019\u00a5\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00a5j \u00e2\u02c6\u02c6 caligraphic_J must be scheduled on a machine m\u00e2\u02c6\u02c6\u00e2\u201e\u00b3\u011f\ufffd\u2018\u0161\u00e2\u201e\u00b3m \u00e2\u02c6\u02c6 caligraphic_M, with varying workloads for each job and different processing capabilities for each machine. The primary objective in PMSP is to minimize the makespan, which is the total length of the schedule upon the completion of all jobs. In this context, having [X0]j,m=1subscriptdelimited-[]subscript\u011f\ufffd\u2018\u20390\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u01611[X_{0}]_{j,m}=1[ italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ] start_POSTSUBSCRIPT italic_j , italic_m end_POSTSUBSCRIPT = 1 indicates that job j\u011f\ufffd\u2018\u2014jitalic_j is assigned to machine m\u011f\ufffd\u2018\u0161mitalic_m, which takes a processing time of [P]j,msubscriptdelimited-[]\u011f\ufffd\u2018\u0192\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u0161[P]_{j,m}[ italic_P ] start_POSTSUBSCRIPT italic_j , italic_m end_POSTSUBSCRIPT where P\u00e2\u02c6\u02c6\u00e2\u201e\ufffd+|\u011f\ufffd\u2019\u00a5|\u00c3\u2014|\u00e2\u201e\u00b3|\u011f\ufffd\u2018\u0192superscriptsubscript\u00e2\u201e\ufffd\u011f\ufffd\u2019\u00a5\u00e2\u201e\u00b3P \u00e2\u02c6\u02c6 blackboard_R start_POSTSUBSCRIPT + end_POSTSUBSCRIPT start_POSTSUPERSCRIPT | caligraphic_J | \u00c3\u2014 | caligraphic_M | end_POSTSUPERSCRIPT is a matrix of processing times for all combinations. The goal is to determine the solution matrix X0={0,1}|\u011f\ufffd\u2019\u00a5|\u00c3\u2014|\u00e2\u201e\u00b3|subscript\u011f\ufffd\u2018\u20390superscript01\u011f\ufffd\u2019\u00a5\u00e2\u201e\u00b3X_{0}= start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = { 0 , 1 } start_POSTSUPERSCRIPT | caligraphic_J | \u00c3\u2014 | caligraphic_M | end_POSTSUPERSCRIPT that minimizes the makespan for a given problem c=(\u00e2\u201e\u00b3,\u011f\ufffd\u2019\u00a5,P)\u011f\ufffd\u2018\ufffd\u00e2\u201e\u00b3\u011f\ufffd\u2019\u00a5\u011f\ufffd\u2018\u0192c=( = ( caligraphic_M , caligraphic_J , italic_P ): The solution matrix that assigns a job to multiple machines is considered infeasible. An ATSP instance c=(|\u011f\ufffd\u2019\u00a9|,D)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2019\u00a9\u011f\ufffd\ufffd\u00b7c=(| = ( | caligraphic_N | , italic_D ) comprises |\u011f\ufffd\u2019\u00a9|\u011f\ufffd\u2019\u00a9| caligraphic_N | cities and an asymmetric distance matrix D\u00e2\u02c6\u02c6\u00e2\u201e\ufffd+|\u011f\ufffd\u2019\u00a9|\u00c3\u2014|\u011f\ufffd\u2019\u00a9|\u011f\ufffd\ufffd\u00b7superscriptsubscript\u00e2\u201e\ufffd\u011f\ufffd\u2019\u00a9\u011f\ufffd\u2019\u00a9D \u00e2\u02c6\u02c6 blackboard_R start_POSTSUBSCRIPT + end_POSTSUBSCRIPT start_POSTSUPERSCRIPT | caligraphic_N | \u00c3\u2014 | caligraphic_N | end_POSTSUPERSCRIPT where each element of it specifies the distance between two cities. The solution to ATSP is a tour, which is an adjacency matrix X0={0,1}|\u011f\ufffd\u2019\u00a9|\u00c3\u2014|\u011f\ufffd\u2019\u00a9|subscript\u011f\ufffd\u2018\u20390superscript01\u011f\ufffd\u2019\u00a9\u011f\ufffd\u2019\u00a9X_{0}= start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = { 0 , 1 } start_POSTSUPERSCRIPT | caligraphic_N | \u00c3\u2014 | caligraphic_N | end_POSTSUPERSCRIPT for a directed graph visiting all cities once. The goal is find a solution that minimizes the tour length: The solution matrix that is not a Hamiltonian cycle is considered infeasible. In accordance with\u00c2 Kwon et\u00c2 al. (2021) we employ tmat-class ATSP instances (see Appendix\u00c2 D.1). We evaluated the baselines and the proposed algorithm using two Intel Xeon Gold 6330 CPUs and an RTX 3090 GPU for both PMSP and ATSP. For the evaluation, 1000 problem instances were randomly generated using a standard generation process (see appendix\u00c2 D.1). To fully leverage the stochastic nature of generative learning-based methods, we also evaluated these methods by generating multiple samples (\u00c3\u2014nabsent\u011f\ufffd\u2018\u203a n\u00c3\u2014 italic_n) for each problem instance and selecting the one with the best score. For MatNet\u00c2 (Kwon et\u00c2 al. 2021), we followed the authors\u00e2\u20ac\u2122 implementation, including instance augmentation, which yielded better result. As a problem-specific search process has not been studied on PMSP and ATSP, for diffusion-based methods, we report simple discrete diffusion models, either trained with supervised learning\u00c2 (Sun and Yang 2023) or with reinforcement learning\u00c2 (Black et\u00c2 al. 2023). For further experimental details, please refer to Appendix\u00c2 C and Appendix\u00c2 D. We evaluated our method on PMSP-20 and PMSP-50, where the numbers 20 and 50 correspond to the number of jobs in each instance, with the number of machines fixed at 4. Our approach is compared against various baselines, including (meta-)heuristics, auto-regressive, and diffusion-based methods. Details of these baselines can be found in Appendix\u00c2 C.2. As shown in Table\u00c2 1, IC/DC achieves the smallest optimality gap among learning-based methods. IC/DC demonstrates a 0.142%percent0.1420.142 % performance gap compared to CP-SAT, whereas the previous SOTA, MatNet, shows a 0.615%percent0.6150.615 % gap on PMSP-20. On PSMP-50 IC/DC reduces the gap from MaNet\u00e2\u20ac\u2122s 0.182%percent0.1820.182 % to 0.112%percent0.1120.112 %. Although IC/DC has a slower inference speed compared to auto-regressive methods, its high-quality solutions remain highly competitive with other baselines. We evaluated our method on ATSP-20 and ATSP-50, where the number 20 and 50 correspond to the number of cities. IC/DC generates solutions that not only surpass those generated by SOTA learning-based methods but also outperform those obtained through (meta-)heuristics and off-the-shelf solvers. IC/DC achieves a \u00e2\u02c6\u20190.235%percent0.235-0.235 0.235 % gap on ATSP-20 and a \u00e2\u02c6\u20190.532%percent0.532-0.532 0.532 % gap on ATSP-50, demonstrating a negative gap compared to a powerful CPLEX solver\u00e2\u20ac\u201dwhich no other learning-based method has achieved. This substantial improvement positions IC/DC as a new SOTA method for addressing these less-studied CO problems, highlighting its potential. As discussed earlier, the performance of auto-regressive models is limited by their sequential decision-making process, which locks in previously made decisions, preventing any revisions. While IC/DC employs a similar auto-regressive approach for feasibility-enforced generation, it also benefits from the accuracy of diffusion-based methods by iteratively refining the solution through T\u00e2\u02c6\u20191\u011f\ufffd\u2018\u20211T-1italic_T - 1 denoising steps before the final auto-regressive generation. Moreover, this two-stage generation process enables IC/DC to achieve much greater sample diversity compared to auto-regressive models, as the denoising process provides varied foundations for solutions before the auto-regressive generation. The results that support these arguments can be found in both tables, particularly in Table\u00c2 2. While IC/DC\u00e2\u20ac\u2122s performance lags behind MatNet when using a single generation to solve the problem, its quickly surpasses MatNet as the number of samples increases, highlighting the high diversity of IC/DC\u00e2\u20ac\u2122s samples. Upon closer examination, we observed that the stochasticity of MatNet primarily stems from the starting point of the auto-regressive generation (i.e., the selection of the initial city to begin the tour). In contrast, IC/DC\u00e2\u20ac\u2122s denoising process offers diverse backbones for the auto-regressive generation, resulting in varied samples even when starting from the same initial city. Previously proposed diffusion-based methods\u00c2 (Qiu, Sun, and Yang 2022; Sun and Yang 2023; Min, Bai, and Gomes 2024) have employed problem-specific search processes to enforce feasibility and enhance performance. However, developing such search processes with strong performance and feasibility guarantees typically requires significant expertise in the specific CO problem being addressed. As the complexity of CO problem increases, such as with ATSP or more complex TSP variants compared to TSP, the cost of implementing these search algorithms becomes even greater. As shown in Table\u00c2 1 and Table\u00c2 2, simple implementations of diffusion models, whether trained with supervised learning\u00c2 (Sun and Yang 2023) or reinforcement learning\u00c2 (Black et\u00c2 al. 2023), struggle to generate feasible solutions without the aid of problem-specific search processes, which have not been studied for these particular CO problems. This highlights the critical importance of our feasibility-enforced generation process, which integrates the flexibility of auto-regressive methods into diffusion-based methods, allowing for the straightforward imposition of various constraints. In this regard, the proposed IC/DC approach not only demonstrates superior performance compared to previous learning-based methods, but also significantly broadens the applicability of diffusion-based methods to a wide range of less-explored CO problems with diverse constraints. We propose a diffusion-based approach named IC/DC to tackle the CO problems involving two distinct sets of items. Our algorithm demonstrates superior performance in both PMSP and ATSP, outperforming existing baselines and successfully generating feasible solutions that cannot be easily achieved with simple diffusion-based methods. We emphasize that this is the first study to successfully adapt a diffusion-based method for CO problems involving two distinct sets of items. We believe the proposed IC/DC framework has significant potential for generlizability. For example, in Appendix\u00c2 D.4, we demonstrate its capability to address real-world CO problems with sophisticated item and relationship features. Despite its strong performance, IC/DC has a notable limitation: the GAT-based encoder we use requires O(max(|\u011f\ufffd\u2019\u0153|,|\u00e2\u201e\u00ac|)2)O( ( roman_max ( | caligraphic_A | , | caligraphic_B | ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) memory complexity. This demands substantial memory resources when training on large instances. To address these challenges, we plan to explore memory-efficient techniques in future work, such as those introduced by\u00c2 Zhu et\u00c2 al. (2024). We derive the upper bound using the Evidence Upper Bound (EUBO)\u00c2 (Ji and Shen 2019) The inequality is established by the Gibbs\u00e2\u20ac\u2122 inequality: \u00e2\u02c6\u2019\u00e2\u02c6\u00abq~\u00e2\ufffd\u00a2(Z|X,c)\u00e2\ufffd\u00a2log\u00e2\ufffd\u00a1q~\u00e2\ufffd\u00a2(Z|X,c)\u00e2\u2030\u00a4\u00e2\u02c6\u2019\u00e2\u02c6\u00abq~\u00e2\ufffd\u00a2(Z|X,c)\u00e2\ufffd\u00a2log\u00e2\ufffd\u00a1p\u00ce\u00b8\u00e2\ufffd\u00a2(Z|X,c)~\u011f\ufffd\u2018\ufffdconditional\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\ufffd~\u011f\ufffd\u2018\ufffdconditional\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\ufffd~\u011f\ufffd\u2018\ufffdconditional\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192conditional\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\ufffd- p_{% \u00e2\u02c6\u00ab over~ start_ARG italic_q end_ARG ( italic_Z | italic_X , italic_c ) roman_log over~ start_ARG italic_q end_ARG ( italic_Z | italic_X , italic_c ) \u00e2\u2030\u00a4 - \u00e2\u02c6\u00ab over~ start_ARG italic_q end_ARG ( italic_Z | italic_X , italic_c ) roman_log italic_p start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT ( italic_Z | italic_X , italic_c ). The last inequality is derived from \u00e2\u02c6\u00abq~\u00e2\ufffd\u00a2(X|c)\u00e2\ufffd\u00a2log\u00e2\ufffd\u00a1p\u00ce\u00b8\u00e2\ufffd\u00a2(X|c)\u00e2\ufffd\u00a2\u011f\ufffd\u2018\u2018X=\u00e2\u02c6\u00abq~\u00e2\ufffd\u00a2(X,Z|c)\u00e2\ufffd\u00a2log\u00e2\ufffd\u00a1p\u00ce\u00b8\u00e2\ufffd\u00a2(X,Z|c)\u00e2\ufffd\u00a2\u011f\ufffd\u2018\u2018Z\u00e2\ufffd\u00a2\u011f\ufffd\u2018\u2018X~\u011f\ufffd\u2018\ufffdconditional\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192conditional\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\ufffddifferential-d\u011f\ufffd\u2018\u2039~\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2039conditional\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192\u011f\ufffd\u2018\u2039conditional\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffddifferential-d\u011f\ufffd\u2018\ufffddifferential-d\u011f\ufffd\u2018\u2039 p_{ p_{ ,Z|c)dZdX\u00e2\u02c6\u00ab over~ start_ARG italic_q end_ARG ( italic_X | italic_c ) roman_log italic_p start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT ( italic_X | italic_c ) italic_d italic_X = \u00e2\u02c6\u00ab over~ start_ARG italic_q end_ARG ( italic_X , italic_Z | italic_c ) roman_log italic_p start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT ( italic_X , italic_Z | italic_c ) italic_d italic_Z italic_d italic_X. We derive the reward-weighted diffusion loss from the objective in CLONING step. We aim to minimize the Kullback-Leibler (KL) divergence DK\u00e2\ufffd\u00a2L(q~(X|c)\u00e2\u02c6\u00a5p\u00ce\u00b8(X|c))D_{KL}( p_{ start_POSTSUBSCRIPT italic_K italic_L end_POSTSUBSCRIPT ( over~ start_ARG italic_q end_ARG ( italic_X | italic_c ) \u00e2\u02c6\u00a5 italic_p start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT ( italic_X | italic_c ) ) between the surrogate target and the distribution p\u011f\ufffd\u2018\ufffdpitalic_p parameterized by \u00ce\u00b8\u011f\ufffd\u0153\u0192 however since evaluating the log-likelihood of the generative model p\u00ce\u00b8\u00e2\ufffd\u00a2(X|c)subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192conditional\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\ufffdp_{ start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT ( italic_X | italic_c ) is difficult\u00c2 (Kingma and Welling 2013), we instead utilize a joint variational upper bound (see App.\u00c2 A.1): According to Gibbs\u00e2\u20ac\u2122 inequality if the right-hand side of the inequality is zero, the inequality becomes an equality. In this case, the surrogate target is exactly approximated. Therefore, we focus on minimizing the right-hand side of eq\u00c2 (A.2). By applying the diffusion process where Z=X1:T\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u2039:1\u011f\ufffd\u2018\u2021Z=X_{1:T}italic_Z = italic_X start_POSTSUBSCRIPT 1 : italic_T end_POSTSUBSCRIPT, X=X0\u011f\ufffd\u2018\u2039subscript\u011f\ufffd\u2018\u20390X=X_{0}italic_X = italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, and T\u011f\ufffd\u2018\u2021Titalic_T is the diffusion step, the forward process is defined by q\u00e2\ufffd\u00a2(X1:T|X0)\u011f\ufffd\u2018\ufffdconditionalsubscript\u011f\ufffd\u2018\u2039:1\u011f\ufffd\u2018\u2021subscript\u011f\ufffd\u2018\u20390q(X_{1:T}|X_{0})italic_q ( italic_X start_POSTSUBSCRIPT 1 : italic_T end_POSTSUBSCRIPT | italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) with X0\u00e2\u02c6\u00bcq~\u00e2\ufffd\u00a2(X0|c)similar-tosubscript\u011f\ufffd\u2018\u20390~\u011f\ufffd\u2018\ufffdconditionalsubscript\u011f\ufffd\u2018\u20390\u011f\ufffd\u2018\ufffdX_{0} start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u00e2\u02c6\u00bc over~ start_ARG italic_q end_ARG ( italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT | italic_c ). We minimize the Reward-weighted Diffusion Loss \u00e2\u201e\u2019RWDsubscript\u00e2\u201e\u2019RWD start_POSTSUBSCRIPT RWD end_POSTSUBSCRIPT: If T\u011f\ufffd\u2018\u2021Titalic_T is sufficiently large, LTsubscript\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\u2021L_{T}italic_L start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT will approach zero\u00c2 (Austin et\u00c2 al. 2021). Also, L0subscript\u011f\ufffd\ufffd\u00bf0L_{0}italic_L start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT can be derived as CE loss: Cross-entropy loss is equal to \u00e2\u201e\u2019prdsubscript\u00e2\u201e\u2019prd start_POSTSUBSCRIPT prd end_POSTSUBSCRIPT at t=1\u011f\ufffd\u2018\u00a11t=1italic_t = 1. As H\u00e2\ufffd\u00a2(p~)\u011f\ufffd\ufffd\u00bb~\u011f\ufffd\u2018\ufffdH( ( over~ start_ARG italic_p end_ARG ) is independent to p\u00ce\u00b8subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192p_{ start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT, it can be ignored for training. As f\u00ce\u00b8subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u0153\u0192f_{ start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT predicts the logit of X0subscript\u011f\ufffd\u2018\u20390X_{0}italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, we use the Cross-entropy loss for every timestep Lpredsubscript\u011f\ufffd\ufffd\u00bfpredL_{ start_POSTSUBSCRIPT pred end_POSTSUBSCRIPT instead of Cross-entropy loss at t=1\u011f\ufffd\u2018\u00a11t=1italic_t = 1. Training with this loss function results in an enhancement of solution quality. In CO problems, solutions must strictly satisfy specific constraints. To discourages infeasible predictions X0\u00e2\u02c6\u00bcp\u00ce\u00b8\u00e2\ufffd\u00a2(X0|Xt,c)similar-tosubscript\u011f\ufffd\u2018\u20390subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192conditionalsubscript\u011f\ufffd\u2018\u20390subscript\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffdX_{0} p_{ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u00e2\u02c6\u00bc italic_p start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT ( italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT | italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c ), we introduce a constraint loss: where C\u00e2\ufffd\u00a2(\u00e2\u2039\u2026)\u011f\ufffd\ufffd\u00b6\u00e2\u2039\u2026C( ( \u00e2\u2039\u2026 ) is a differentiable function that approximately measures constraint violations of samples In the Asymmetric Travelling Salesman Problem (ATSP), each node is required to travel to a distinct city other than itself. Consequently, in the resulting solution matrix, each row and each column must contain exactly one entry of \u00e2\u20ac\u21221\u00e2\u20ac\u2122: In the Parallel Machine Scheduling Problem (PMSP), each job is required to be assigned to a single machine. Accordingly, in the solution matrix, each column must contain exactly one entry of \u00e2\u20ac\u21221\u00e2\u20ac\u2122, with all other entries in that column being \u00e2\u20ac\u21220\u00e2\u20ac\u2122: where Gumbel-Softmax\u00e2\ufffd\u00a2(x)i=exp\u00e2\ufffd\u00a1((xi+gi)/\u00cf\u201e)\u00e2\u02c6\u2018j=12exp\u00e2\ufffd\u00a1((xj+gj)/\u00cf\u201e)Gumbel-Softmaxsubscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u2013\u011f\ufffd\u0153\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u201412subscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u2014\u011f\ufffd\u0153\ufffd ( italic_x ) start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = divide start_ARG roman_exp ( ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) / italic_\u00cf\u201e ) end_ARG start_ARG \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT roman_exp ( ( italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT + italic_g start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) / italic_\u00cf\u201e ) end_ARG, and gisubscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u2013g_{i}italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is a value sampled from the Gumbel(0,1) distribution, and \u00cf\u201e\u011f\ufffd\u0153\ufffd is the temperature parameter. By combining reward-weighted diffusion loss A.2 and constraint loss A.3, our diffusion objective: where \u00ce\u00bb1subscript\u011f\ufffd\u0153\u20201 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and \u00ce\u00bb2subscript\u011f\ufffd\u0153\u20202 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT are hyper parameter. According to\u00c2 (Austin et\u00c2 al. 2021), it is argued that incorporating domain-specific structures into the transition matrices Qtsubscript\u011f\ufffd\u2018\u201e\u011f\ufffd\u2018\u00a1Q_{t}italic_Q start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT within the diffusion process is a reasonable approach. In our case, due to the inherent sparsity in the solution matrices of CO problems, the marginal distribution of feasible solutions significantly deviates from the uniform distribution commonly used in standard diffusion processes. Therefore, we design this noise transition matrix to align with the prior distribution of feasible solutions q\u00c2\u00af\u00c2\u00af\u011f\ufffd\u2018\ufffd start_ARG italic_q end_ARG. Depending on what CO problem we are aiming to solve, we are often able to compute the prior distribution, averaged over solution elements q\u00c2\u00af\u00e2\ufffd\u00a2(x~)=q\u00c2\u00af\u00e2\ufffd\u00a2(1|\u011f\ufffd\u2019\u0153|\u00e2\ufffd\u00a2|\u00e2\u201e\u00ac|\u00e2\ufffd\u00a2\u00e2\u02c6\u2018i=1|\u011f\ufffd\u2019\u0153|\u00e2\ufffd\u00a2|\u00e2\u201e\u00ac|[x~0]i)\u00c2\u00af\u011f\ufffd\u2018\ufffd~\u011f\ufffd\u2018\u00a5\u00c2\u00af\u011f\ufffd\u2018\ufffd1\u011f\ufffd\u2019\u0153\u00e2\u201e\u00acsuperscriptsubscript\u011f\ufffd\u2018\u20131\u011f\ufffd\u2019\u0153\u00e2\u201e\u00acsubscriptdelimited-[]subscript~\u011f\ufffd\u2018\u00a50\u011f\ufffd\u2018\u2013 ^{| start_ARG italic_q end_ARG ( over~ start_ARG italic_x end_ARG ) = over\u00c2\u00af start_ARG italic_q end_ARG ( divide start_ARG 1 end_ARG start_ARG | caligraphic_A | | caligraphic_B | end_ARG \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT | caligraphic_A | | caligraphic_B | end_POSTSUPERSCRIPT [ over~ start_ARG italic_x end_ARG start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ] start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ). The marginal probability of x=1\u011f\ufffd\u2018\u00a51x=1italic_x = 1 over a set of feasible solutions can be expressed as q\u00c2\u00af\u00e2\ufffd\u00a2(x=1)\u00c2\u00af\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a51 start_ARG italic_q end_ARG ( italic_x = 1 ). In ATSP, when considering |\u011f\ufffd\u2019\u00a9|\u011f\ufffd\u2019\u00a9| caligraphic_N | cities, the solution involves travelling through all |\u011f\ufffd\u2019\u00a9|\u011f\ufffd\u2019\u00a9| caligraphic_N | cities. The prior distribution follows the following: In PMSP, when considering |\u011f\ufffd\u2019\u00a5|\u011f\ufffd\u2019\u00a5| caligraphic_J | jobs and |\u00e2\u201e\u00b3|\u00e2\u201e\u00b3| caligraphic_M | machines, the solution involves assigning all |\u011f\ufffd\u2019\u00a5|\u011f\ufffd\u2019\u00a5| caligraphic_J | jobs to the machines. The prior distribution is as follows: In most combinatorial optimization problems, the marginal distribution q\u00c2\u00af\u00c2\u00af\u011f\ufffd\u2018\ufffd start_ARG italic_q end_ARG is typically known. However, in cases where the marginal distribution is not available, an alternative approach is to utilize a uniform distribution. As a substitute for q\u00c2\u00af\u00c2\u00af\u011f\ufffd\u2018\ufffd start_ARG italic_q end_ARG, one may consider using u\u00c2\u00af=[0.5,0.5]\u00c2\u00af\u011f\ufffd\u2018\u00a20.50.5 start_ARG italic_u end_ARG = [ 0.5 , 0.5 ]. Denoting each row of A\u011f\ufffd\ufffd\u00b4Aitalic_A as A=[a1,\u00e2\u20ac\u00a6,a|\u011f\ufffd\u2019\u0153|]\u00e2\u0160\u00a4\u011f\ufffd\ufffd\u00b4superscriptsubscript\u011f\ufffd\u2018\ufffd1\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2019\u0153topA=[a_{1},...,a_{| = [ italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_a start_POSTSUBSCRIPT | caligraphic_A | end_POSTSUBSCRIPT ] start_POSTSUPERSCRIPT \u00e2\u0160\u00a4 end_POSTSUPERSCRIPT, an attention block within each layer processes the input as: where Wintersubscript\u011f\ufffd\u2018\u0160interW_{ start_POSTSUBSCRIPT inter end_POSTSUBSCRIPT, Wintrasubscript\u011f\ufffd\u2018\u0160intraW_{ start_POSTSUBSCRIPT intra end_POSTSUBSCRIPT, and Wvsubscript\u011f\ufffd\u2018\u0160vW_{ start_POSTSUBSCRIPT v end_POSTSUBSCRIPT are weight matrices of dimension \u00e2\u201e\ufffdd\u00c3\u2014dsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u2018 d}blackboard_R start_POSTSUPERSCRIPT italic_d \u00c3\u2014 italic_d end_POSTSUPERSCRIPT, and MLP\u00e2\ufffd\u00a2(\u00e2\u2039\u2026)MLP\u00e2\u2039\u2026 ( \u00e2\u2039\u2026 ) is a fully-connected neural network that maps 2222-dimensional inputs to 1111-dimensional outputs. The matrices Sintersubscript\u011f\ufffd\u2018\u2020interS_{ start_POSTSUBSCRIPT inter end_POSTSUBSCRIPT and Sintrasubscript\u011f\ufffd\u2018\u2020intraS_{ start_POSTSUBSCRIPT intra end_POSTSUBSCRIPT are designed to capture the inter-relationships within set \u011f\ufffd\u2019\u0153\u011f\ufffd\u2019\u0153 and the intra-relationships and between sets \u011f\ufffd\u2019\u0153\u011f\ufffd\u2019\u0153 and \u00e2\u201e\u00ac\u00e2\u201e\u00ac These matrices, along with D\u011f\ufffd\ufffd\u00b7Ditalic_D, are combined to form the attention score D~~\u011f\ufffd\ufffd\u00b7 start_ARG italic_D end_ARG, which produces the output A~~\u011f\ufffd\ufffd\u00b4 start_ARG italic_A end_ARG. Using the described attention block, the layer outputs A\u00e2\u20ac\u00b2superscript\u011f\ufffd\ufffd\u00b4\u00e2\u20ac\u00b2A^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT as follows: where BN refers to a batch normalization\u00c2 (Ioffe and Szegedy 2015). The process for updating B\u011f\ufffd\ufffd\u00b5Bitalic_B to B\u00e2\u20ac\u00b2superscript\u011f\ufffd\ufffd\u00b5\u00e2\u20ac\u00b2B^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT is computed in the same way. As illustrated in the bottom-left side of Figure\u00c2 2, the denoiser consists of L\u00e2\u20ac\u00b2superscript\u011f\ufffd\ufffd\u00bf\u00e2\u20ac\u00b2L^{ start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT layers, where each layer gets input of (A,B,X,t)\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b5\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1(A,B,X,t)( italic_A , italic_B , italic_X , italic_t ) and outputs (A\u00e2\u20ac\u00b2,B\u00e2\u20ac\u00b2,X\u00e2\u20ac\u00b2)superscript\u011f\ufffd\ufffd\u00b4\u00e2\u20ac\u00b2superscript\u011f\ufffd\ufffd\u00b5\u00e2\u20ac\u00b2superscript\u011f\ufffd\u2018\u2039\u00e2\u20ac\u00b2(A^{ italic_A start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT , italic_B start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT , italic_X start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT ), which is processed as follows: Where hi\u00e2\u201e\u201c=0=hiLsubscriptsuperscript\u00e2\u201e\ufffd\u00e2\u201e\u201c0\u011f\ufffd\u2018\u2013subscriptsuperscript\u00e2\u201e\ufffd\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\u2013h^{ start_POSTSUPERSCRIPT roman_\u00e2\u201e\u201c = 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_h start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and hj\u00e2\u201e\u201c=0=hjLsubscriptsuperscript\u00e2\u201e\ufffd\u00e2\u201e\u201c0\u011f\ufffd\u2018\u2014subscriptsuperscript\u00e2\u201e\ufffd\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\u2014h^{ start_POSTSUPERSCRIPT roman_\u00e2\u201e\u201c = 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = italic_h start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT. For simplicity, the vector representation xi,j\u00e2\u201e\u201c=0subscriptsuperscript\u011f\ufffd\u2018\u00a5\u00e2\u201e\u201c0\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014x^{ start_POSTSUPERSCRIPT roman_\u00e2\u201e\u201c = 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT at the (i,j)\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014(i,j)( italic_i , italic_j )-th Xtsubscript\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1X_{t}italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is denoted without t\u011f\ufffd\u2018\u00a1titalic_t. The matrices Ua\u00e2\u201e\u201c,Ub\u00e2\u201e\u201c,Va\u00e2\u201e\u201c,Vb\u00e2\u201e\u201c,P\u00e2\u201e\u201c,Q\u00e2\u201e\u201c,R\u00e2\u201e\u201c\u00e2\u02c6\u02c6\u00e2\u201e\ufffdd\u00c3\u2014dsubscriptsuperscript\u011f\ufffd\u2018\u02c6\u00e2\u201e\u201c\u011f\ufffd\u2018\ufffdsubscriptsuperscript\u011f\ufffd\u2018\u02c6\u00e2\u201e\u201c\u011f\ufffd\u2018\ufffdsubscriptsuperscript\u011f\ufffd\u2018\u2030\u00e2\u201e\u201c\u011f\ufffd\u2018\ufffdsubscriptsuperscript\u011f\ufffd\u2018\u2030\u00e2\u201e\u201c\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u0192\u00e2\u201e\u201csuperscript\u011f\ufffd\u2018\u201e\u00e2\u201e\u201csuperscript\u011f\ufffd\u2018\u2026\u00e2\u201e\u201csuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u2018U^{ d}italic_U start_POSTSUPERSCRIPT roman_\u00e2\u201e\u201c end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT , italic_U start_POSTSUPERSCRIPT roman_\u00e2\u201e\u201c end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT , italic_V start_POSTSUPERSCRIPT roman_\u00e2\u201e\u201c end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT , italic_V start_POSTSUPERSCRIPT roman_\u00e2\u201e\u201c end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT , italic_P start_POSTSUPERSCRIPT roman_\u00e2\u201e\u201c end_POSTSUPERSCRIPT , italic_Q start_POSTSUPERSCRIPT roman_\u00e2\u201e\u201c end_POSTSUPERSCRIPT , italic_R start_POSTSUPERSCRIPT roman_\u00e2\u201e\u201c end_POSTSUPERSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT italic_d \u00c3\u2014 italic_d end_POSTSUPERSCRIPT are learnable parameters of the \u00e2\u201e\u201c\u00e2\u201e\u201c layer. SUM pooling is denoted by \u00e2\u02c6\u2018 (Xu et\u00c2 al. 2018), the sigmoid function is represented by \u00cf\u0192\u011f\ufffd\u0153\ufffd and the Hadamard product is denoted by \u00e2\u0160\u2122direct-product \u011f\ufffd\u2019\u00a9isubscript\u011f\ufffd\u2019\u00a9\u011f\ufffd\u2018\u2013 start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT denotes the neighborhood of node i\u011f\ufffd\u2018\u2013iitalic_i among the B\u011f\ufffd\ufffd\u00b5Bitalic_B items, while \u011f\ufffd\u2019\u00a9jsubscript\u011f\ufffd\u2019\u00a9\u011f\ufffd\u2018\u2014 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT denotes the neighborhood of node j\u011f\ufffd\u2018\u2014jitalic_j among the A\u011f\ufffd\ufffd\u00b4Aitalic_A items. Additionally, the variable \u011f\ufffd\u2022\u00a5\u011f\ufffd\u2022\u00a5 denotes the sinusoidal features\u00c2 (Vaswani et\u00c2 al. 2017) corresponding to the denoising timestep t\u011f\ufffd\u2018\u00a1titalic_t. After the final layer \u011f\ufffd\u201d\ufffd\u011f\ufffd\u201d\ufffd the output xi,j\u011f\ufffd\u201d\ufffdsubscriptsuperscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u201d\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014x^{ start_POSTSUPERSCRIPT fraktur_L end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT is passed through a linear layer to obtain clean matrix X0={x0,0,\u00e2\u20ac\u00a6,xI,J}subscript\u011f\ufffd\u2018\u20390subscript\u011f\ufffd\u2018\u00a500\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\ufffd\u00bc\u011f\ufffd\ufffd\u00bdX_{0}= start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = { italic_x start_POSTSUBSCRIPT 0 , 0 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_x start_POSTSUBSCRIPT italic_I , italic_J end_POSTSUBSCRIPT }. In the literature on the parallel machine scheduling problem, most studies focus on a simplified variant where the processing time for a job is consistent across all machines, commonly referred to as \u00e2\u20ac\ufffduniform parallel machines\u00e2\u20ac\ufffd. In contrast, we examine a more complex scenario where the processing times for each machine are entirely independent to one another. For our study, we generate the processing time matrix randomly and use it as our instance. Constraint Programming with Satisfiability (CP-SAT) is a highly efficient solver developed as part of the OR-Tools suite, designed for solving integer programming problems. It is particularly effective for solving scheduling problems, including PMSP. For PMSP our MIP model is based on Avalos-Rosales, Alvarez, and Angel-Bello (2013) Constraints\u00c2 (9) and (10) ensure that each job has exactly one predecessor on one of the machines. Constraint(12) specifies that if a job has a predecessor on a machine, it must also have a successor on that same machine. Constraint\u00c2 (13) guarantees that a valid sequence of jobs is scheduled on each machine, with no overlap in processing times. Constraint\u00c2 (8) ensures that only one job can be scheduled as the first job on each machine. Constraint\u00c2 (7) sets the completion time of job 0, an auxiliary job used to define the start of the schedule, to zero. Finally, constraint\u00c2 (11) establishes the relationship between the makespan of individual machines and the overall schedule makespan. CP-SAT is run on CPUs. Random and Shortest Job First (SJF) are greedy-selection algorithms designed to generate valid schedules using the Gantt chart completion strategy. SJF specifically prioritizes tasks by scheduling the shortest available jobs in ascending order at each time step t\u011f\ufffd\u2018\u00a1titalic_t. Although simple, these methods can serve as effective baselines, providing a comparison point for evaluating more sophisticated scheduling algorithms. The greedy-selection algorithms run on CPUs. CO problems often require sophisticated methods to find high-quality solutions, particularly when traditional approaches like Mixed Integer Programming (MIP) are impractical due to complexity. In such cases, meta-heuristics provide a robust alternative. Genetic Algorithm (GA) and Particle Swarm Optimization (PSO) are two widely adopted meta-heuristics, known for their versatility and effectiveness across a range of problem domains. GA iteratively updates multiple candidate solutions, referred to as chromosomes. New child chromosomes are produced by combining two parent chromosomes through crossover methods, and mutations are applied to the chromosomes to enhance exploration. PSO iteratively updates multiple candidate solutions, referred to as particles. For every iteration each particles are updated based on the local best known and the global best known particles. We utilize the implementations provided by Kwon et al.\u00c2 (Kwon et\u00c2 al. 2021) and follow their setting. Both GA and PSO run on GPUs. MatNet, proposed by\u00c2 (Kwon et\u00c2 al. 2021), adapts the attention model\u00c2 (Kool, Van\u00c2 Hoof, and Welling 2018) to be applicable to bipartite graphs. It employs cross-attention mechanisms in place of self-attention to facilitate message passing between the two set of nodes, thereby encoding relationship information more effectively. The model is trained using reinforcement learning. Solution are generated in an auto-regressive manner, where each node is sequentially selected based on the current state of the solution. We trained the diffusion model to estimate solution matrices using a supervised learning approach, similar to Difusco\u00c2 (Sun and Yang 2023). This method adapts graph-based denoising diffusion models to more naturally formulate combinatorial optimization problems and generate high-quality solutions. By explicitly modeling the node and edge selection process through corresponding random variables, the model effectively captures the problem\u00e2\u20ac\u2122s structure. The model is trained through supervised learning. Similar to DDPO, as proposed by \u00c2 (Black et\u00c2 al. 2023), which demonstrates that framing the denoising process as a multi-step decision-making problem enables policy gradient algorithms to directly optimize diffusion models for downstream objectives, we trained our diffusion model within the reinforcement learning framework. We used the REINFORCE algorithm\u00c2 (Williams 1992) to map the denoising process to the MDP framework. Following the implementation of\u00c2 (Kwon et\u00c2 al. 2021), we utilize 25 chromosomes with a mutation rate and crossover ratio both set to 0.3. Among the 25 initial chromosomes, one is initialized with the solution from the SJF heuristic. The best-performing chromosome is retained across all iterations. We run 1000 iterations per instance. Following the implementation of \u00c2 (Kwon et\u00c2 al. 2021), we utilize 25 particles with an inertial weight of 0.7. Both the cognitive and social constants are set to 1.5. Additionally, one particle is initialized with the solution from the SJF heuristic. We run 1000 iterations per instance. We use the same hyperparameters reported in \u00c2 (Kwon et\u00c2 al. 2021), with the exception that the number of stages is set to 1 instead of 3. Using CP-SAT, we generate 128,000 training samples for supervised learning. Since the solution matrices for PMSP are not square matrices, we use IC/DC\u00e2\u20ac\u2122s encoder in combination with Difusco\u00e2\u20ac\u2122s decoder, employing 12 layers for both encoder and the decoder. The denoising timestep is set to 1000 during training but reduced to 20 for faster inference. All other hyperparameters, follow those reported in \u00c2 (Sun and Yang 2023). We train our diffusion model with the objective function \u00e2\u02c6\u2021\u00ce\u00b8\u011f\ufffd\u2019\u00a5DDRL=\u011f\ufffd\u201d\u00bc\u00e2\ufffd\u00a2[\u00e2\u02c6\u2018t=0T\u00e2\u02c6\u2021\u00ce\u00b8log\u00e2\ufffd\u00a1p\u00ce\u00b8\u00e2\ufffd\u00a2(Xt\u00e2\u02c6\u20191|Xt,c)\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2(X0,c)]subscript\u00e2\u02c6\u2021\u011f\ufffd\u0153\u0192subscript\u011f\ufffd\u2019\u00a5DDRL\u011f\ufffd\u201d\u00bcdelimited-[]superscriptsubscript\u011f\ufffd\u2018\u00a10\u011f\ufffd\u2018\u2021subscript\u00e2\u02c6\u2021\u011f\ufffd\u0153\u0192subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192conditionalsubscript\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a11subscript\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u20390\u011f\ufffd\u2018\ufffd { p_{ start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT caligraphic_J start_POSTSUBSCRIPT DDRL end_POSTSUBSCRIPT = blackboard_E [ \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT \u00e2\u02c6\u2021 start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT roman_log italic_p start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT ( italic_X start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT | italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c ) italic_r ( italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_c ) ] proposed by\u00c2 (Black et\u00c2 al. 2023). We use the same encoder and decoder architecture as IC/DC, consisting of 5 encoder layers and 2 decoder layers. Apart from setting the denoising timestep to 20, all other hyperparameters are consistent with those used in IC/DC (ours). For PMSP-20 instances, we use 3 layers for both the encoder and the decoder, with the denoising timestep set to 10. For PMSP-50 instances, we utilize 5 encoder layers and 3 decoder layers, with the denoising timestep set to 15. The hyperparameters l\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2m\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2d\u00e2\ufffd\u00a2a1\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2018subscript\u011f\ufffd\u2018\ufffd1lambda_{1}italic_l italic_a italic_m italic_b italic_d italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and \u00ce\u00bb2subscript\u011f\ufffd\u0153\u20202 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT are set to 1e-3 and 1e-6, respectively. The IMPROVEMENT step is executed every 30 epochs. Our model is trained using the Adam optimizer, with a batch size of 512 and a learning rate of 4e-4. Our code is available at: While random distance matrices can be generated by choosing random integers, such matrices lack meaningful correlations between distances and doesn\u00e2\u20ac\u2122t reflect practical scenarios. Instead we are interested in problems which ATSP instances have the triangle inequality so called \u00e2\u20ac\ufffdTmat class\u00e2\u20ac\ufffd\u00c2 (Kwon et\u00c2 al. 2021; Cirasella et\u00c2 al. 2001). That is, for a distance matrix D\u011f\ufffd\ufffd\u00b7Ditalic_D with elements di\u00e2\ufffd\u00a2jsubscript\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014d_{ij}italic_d start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT representing the distance between city cisubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013c_{i}italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and cjsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2014c_{j}italic_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, if d\u00e2\ufffd\u00a2(ci,cj)\u00e2\u2030\u00a5d\u00e2\ufffd\u00a2(ci,ck)+d\u00e2\ufffd\u00a2(ck,cj)\u011f\ufffd\u2018\u2018subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u2018subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2018subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02dcsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2014d(c_{i},c_{j}) d(c_{i},c_{k})+d(c_{k},c_{j})italic_d ( italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) \u00e2\u2030\u00a5 italic_d ( italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) + italic_d ( italic_c start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) then we set d\u00e2\ufffd\u00a2(ci,cj)=d\u00e2\ufffd\u00a2(ci,cj)+d\u00e2\ufffd\u00a2(ck,cj)\u011f\ufffd\u2018\u2018subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u2018subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u2018subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02dcsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2014d(c_{i},c_{j})=d(c_{i},c_{j})+d(c_{k},c_{j})italic_d ( italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) = italic_d ( italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) + italic_d ( italic_c start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ), while diagonal elements are maintained as d\u00e2\ufffd\u00a2(ci,ci)=0\u011f\ufffd\u2018\u2018subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20130d(c_{i},c_{i})=0italic_d ( italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = 0. We repeat this procedure until no more changes can be made. Mixed integer programming (MIP) is an optimization technique used to solve problems where some of the variables are required to be integers while others can be continuous. Solution methods such as branch and bound, branch and cut etc. are used to solve these kind of problems. To we use CPLEX\u00c2 (IBM 2022; Bliek1\u00c3\u00ba, Bonami, and Lodi 2014), one of the popular commercial optimization software use by the OR community and solve our test instances through benders decomposition\u00c2 (Rahmaniani et\u00c2 al. 2017). The MIP model serves as the mathematical representation of the problem. For ATSP, our MIP model is based on the formulation presented by Miller, Tucker, and Zemlin (1960). The constraints\u00c2 (15) and \u00c2 (16) ensure that each city is visited exactly once. Constraint\u00c2 (17) prevents subtours, ensuring that all cities are included in a single tours of length n\u011f\ufffd\u2018\u203anitalic_n. As the name suggests, Nearest Neighbor (NN), Nearest Insertion (NI), and Furthest Insertion (FI) are straightforward simple greedy-selection algorithms frequently used as baselines for TSP algorithms. We use the implementations provided by \u00c2 (Kwon et\u00c2 al. 2021) which are implemented in C++. LKH3 is a widely recognized state-of-the-art algorithm for addressing constrained TSP and Vehicle Routing Problems (VRP). It employs a local search approach utilizing k\u011f\ufffd\u2018\u02dckitalic_k-opt operations to enhance its solutions. For solving the ATSP instances, we utilize version 3.0.6. We utilize the checkpoints provided by.\u00c2 (Kwon et\u00c2 al. 2021) and evaluate them on the same problem instances. Using LKH-3, we generate 128,000 training samples for supervised learning. We use Difusco\u00e2\u20ac\u2122s encoder and decoder, employing 12 layers for both encoder and the decoder. The denoising timestep is set to 1000 during training but reduced to 20 for faster inference. All other hyperparameters, follow those reported in \u00c2 (Sun and Yang 2023). We train our diffusion model with the objective function \u00e2\u02c6\u2021\u00ce\u00b8\u011f\ufffd\u2019\u00a5DDRL=\u011f\ufffd\u201d\u00bc\u00e2\ufffd\u00a2[\u00e2\u02c6\u2018t=0T\u00e2\u02c6\u2021\u00ce\u00b8log\u00e2\ufffd\u00a1p\u00ce\u00b8\u00e2\ufffd\u00a2(Xt\u00e2\u02c6\u20191|Xt,c)\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2(X0,c)]subscript\u00e2\u02c6\u2021\u011f\ufffd\u0153\u0192subscript\u011f\ufffd\u2019\u00a5DDRL\u011f\ufffd\u201d\u00bcdelimited-[]superscriptsubscript\u011f\ufffd\u2018\u00a10\u011f\ufffd\u2018\u2021subscript\u00e2\u02c6\u2021\u011f\ufffd\u0153\u0192subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u0192conditionalsubscript\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a11subscript\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u20390\u011f\ufffd\u2018\ufffd { p_{ start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT caligraphic_J start_POSTSUBSCRIPT DDRL end_POSTSUBSCRIPT = blackboard_E [ \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT \u00e2\u02c6\u2021 start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT roman_log italic_p start_POSTSUBSCRIPT italic_\u00ce\u00b8 end_POSTSUBSCRIPT ( italic_X start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT | italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_c ) italic_r ( italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_c ) ] proposed by\u00c2 (Black et\u00c2 al. 2023). We use the same encoder and decoder architecture as IC/DC, consisting of 5 encoder layers and 2 decoder layers. Apart from setting the denoising timestep to 20, all other hyperparameters are consistent with those used in IC/DC. For ATSP-20 instances, we use 3 layers for both the encoder and the decoder, with the denoising timestep set to 10. For ATSP-50 instances, we utilize 5 encoder layers and 3 decoder layers, with the denoising timestep set to 15. The hyperparameters \u00ce\u00bb1subscript\u011f\ufffd\u0153\u20201 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and \u00ce\u00bb2subscript\u011f\ufffd\u0153\u20202 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT are set to 1e-3 and 1e-6, respectively. The IMPROVEMENT step is executed every 30 epochs. Our model is trained using the Adam optimizer, with a batch size of 256 for 20 node instances and 64 for 50 node instances and a learning rate of 4e-4. In real-world combinatorial optimization (CO) problems, direct problem data, such as the distance matrix in ATSP or the processing time matrix in PMSP, may not always be explicitly provided. In such cases, solving the problem may require processing a broader range of data. For example, consider a navigation problem (NP) similar to ATSP, where the objective is to minimize the total travel time rather than distance. In this scenario, various types of information that influence travel time must be considered, including the coordinates of each city, time-per-distance data representing the relationships between cities, and traffic information. We define the actual travel time between |\u011f\ufffd\u2019\u00a9|\u011f\ufffd\u2019\u00a9| caligraphic_N | cities as follows: where, for each i,j\u00e2\u02c6\u02c6\u011f\ufffd\u2019\u00a9\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2019\u00a9i,j , italic_j \u00e2\u02c6\u02c6 caligraphic_N, Ta\u00e2\u02c6\u02c6\u00e2\u201e\ufffd+|\u011f\ufffd\u2019\u00a9|\u00c3\u2014|\u011f\ufffd\u2019\u00a9|superscript\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\ufffdsubscriptsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2019\u00a9\u011f\ufffd\u2019\u00a9T^{a} start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT | caligraphic_N | \u00c3\u2014 | caligraphic_N | end_POSTSUPERSCRIPT start_POSTSUBSCRIPT + end_POSTSUBSCRIPT represents the actual travel time matrix, R\u00e2\u02c6\u02c6\u00e2\u201e\ufffd+|\u011f\ufffd\u2019\u00a9|\u00c3\u20142\u011f\ufffd\u2018\u2026subscriptsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2019\u00a92R 2}_{+}italic_R \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT | caligraphic_N | \u00c3\u2014 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT + end_POSTSUBSCRIPT is the coordinate matrix of all cities, S\u00e2\u02c6\u02c6\u00e2\u201e\ufffd+|\u011f\ufffd\u2019\u00a9|\u00c3\u2014|\u011f\ufffd\u2019\u00a9|\u011f\ufffd\u2018\u2020subscriptsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2019\u00a9\u011f\ufffd\u2019\u00a9S \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT | caligraphic_N | \u00c3\u2014 | caligraphic_N | end_POSTSUPERSCRIPT start_POSTSUBSCRIPT + end_POSTSUBSCRIPT is the reciprocal speed matrix, and F\u00e2\u02c6\u02c6\u00e2\u201e\ufffd|\u011f\ufffd\u2019\u00a9|\u00c3\u2014|\u011f\ufffd\u2019\u00a9|\u011f\ufffd\ufffd\u00b9superscript\u00e2\u201e\ufffd\u011f\ufffd\u2019\u00a9\u011f\ufffd\u2019\u00a9F \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT | caligraphic_N | \u00c3\u2014 | caligraphic_N | end_POSTSUPERSCRIPT is the traffic matrix. The goal is to minimize the total [T]i,jasubscriptsuperscriptdelimited-[]\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014[T]^{a}_{i,j}[ italic_T ] start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT across the entire route. In this case, instead of the direct problem data Tasuperscript\u011f\ufffd\u2018\u2021\u011f\ufffd\u2018\ufffdT^{a}italic_T start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT, we need to consider the complex problem instance c=(\u011f\ufffd\u2019\u00a9,R,S,F)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2019\u00a9\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u2020\u011f\ufffd\ufffd\u00b9c=( = ( caligraphic_N , italic_R , italic_S , italic_F ). Typically, methods such as solvers or heuristics require significant expert effort to process such data. On the other hand, IC/DC is capable of handling these diverse types of data and demonstrates strong generalization performance. By the problem encoder, the information R\u011f\ufffd\u2018\u2026Ritalic_R for each city is processed through an embedding layer with dimension d\u011f\ufffd\u2018\u2018ditalic_d and then sent to A\u011f\ufffd\ufffd\u00b4Aitalic_A and B\u011f\ufffd\ufffd\u00b5Bitalic_B. The relational information between cities, S\u011f\ufffd\u2018\u2020Sitalic_S and F\u011f\ufffd\ufffd\u00b9Fitalic_F, is input as D=S||F\u00e2\u02c6\u02c6\u00e2\u201e\ufffd|\u011f\ufffd\u2019\u00a9|\u00c3\u2014|\u011f\ufffd\u2019\u00a9|\u00c3\u20142D=S||F 2}italic_D = italic_S | | italic_F \u00e2\u02c6\u02c6 blackboard_R start_POSTSUPERSCRIPT | caligraphic_N | \u00c3\u2014 | caligraphic_N | \u00c3\u2014 2 end_POSTSUPERSCRIPT. As shown in Table\u00c2 3, IC/DC outperforms other baselines and demonstrates strong potential for generalizability. Additionally, an example of the NP is illustrated in Figure\u00c2 5.",
        "keywords": ""
    },
    {
        "id": 24,
        "title": "Generalization of Arithmetico-Geometric Series and the Expectation Value of a k\u011f\ufffd\u2018\u02dckitalic_k-Run of a Bernoulli Trial",
        "abstract": "AbstractThe article uses an Arithmetic-Geometric Fibonacci series to find the expected value, denotedE\u00e2\ufffd\u00a2(\u00cf\u2021)\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u0153\u2019E(\\chi)italic_E ( italic_\u00cf\u2021 ), of trials needed to observek\u011f\ufffd\u2018\u02dckitalic_kconsecutive successes for the first time in a Bernoulli experiment using a recurrence relation. The article establishes thatE\u00e2\ufffd\u00a2(\u00cf\u2021)=2\u00e2\ufffd\u00a2(2k\u00e2\u02c6\u20191)\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u0153\u20192superscript2\u011f\ufffd\u2018\u02dc1E(\\chi)=2(2^{k}-1)italic_E ( italic_\u00cf\u2021 ) = 2 ( 2 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT - 1 ). It is important to note that this is not a new result, but to the best of my knowledge, this is a novel derivation of a well-established result. The other derivations of this result are cited in the references section.",
        "corpus": "The article uses an Arithmetic-Geometric Fibonacci series to find the expected value, denoted E\u00e2\ufffd\u00a2(\u00cf\u2021)\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u0153\u2019E( ( italic_\u00cf\u2021 ), of trials needed to observe k\u011f\ufffd\u2018\u02dckitalic_k consecutive successes for the first time in a Bernoulli experiment using a recurrence relation. The article establishes that E\u00e2\ufffd\u00a2(\u00cf\u2021)=2\u00e2\ufffd\u00a2(2k\u00e2\u02c6\u20191)\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u0153\u20192superscript2\u011f\ufffd\u2018\u02dc1E( ( italic_\u00cf\u2021 ) = 2 ( 2 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT - 1 ). It is important to note that this is not a new result, but to the best of my knowledge, this is a novel derivation of a well-established result. The other derivations of this result are cited in the references section. Consider a coin-tossing experiment where the probability of success (i.e., getting heads) is p\u011f\ufffd\u2018\ufffdpitalic_p, and the probability of failure (i.e., getting tails) is 1\u00e2\u02c6\u2019p1\u011f\ufffd\u2018\ufffd1-p1 - italic_p. For a fair coin, p=12\u011f\ufffd\u2018\ufffd12p= = divide start_ARG 1 end_ARG start_ARG 2 end_ARG. This article explores the general case where p\u011f\ufffd\u2018\ufffdpitalic_p is any real number within the interval (0,1)01(0,1)( 0 , 1 ). We perform trials and record the outcome of each trial\u00e2\u20ac\u201dheads or tails\u00e2\u20ac\u201dsequentially. For instance, a possible outcome sequence in a 4444-trial experiment could be \u00e2\u20ac\u0153h\u00e2\ufffd\u00a2h\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2h\u00e2\u201e\ufffd\u00e2\u201e\ufffd\u011f\ufffd\u2018\u00a1\u00e2\u201e\ufffdhhthitalic_h italic_h italic_t italic_h,\u00e2\u20ac\ufffd where h\u00e2\u201e\ufffdhitalic_h represents heads and t\u011f\ufffd\u2018\u00a1titalic_t represents tails. Our goal is to determine the average number of trials required to achieve k\u011f\ufffd\u2018\u02dckitalic_k-consecutive successes for any positive integer k\u011f\ufffd\u2018\u02dckitalic_k. For example, when k=3\u011f\ufffd\u2018\u02dc3k=3italic_k = 3, a successful experiment may conclude in as few as 3333 trials with the outcome \u00e2\u20ac\u0153h\u00e2\ufffd\u00a2h\u00e2\ufffd\u00a2h\u00e2\u201e\ufffd\u00e2\u201e\ufffd\u00e2\u201e\ufffdhhhitalic_h italic_h italic_h.\u00e2\u20ac\ufffd However, in other cases, it may take many more trials. For instance, the sequence \u00e2\u20ac\u0153h\u00e2\ufffd\u00a2h\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2h\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2h\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2h\u00e2\u201e\ufffd\u00e2\u201e\ufffd\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a1\u00e2\u201e\ufffd\u011f\ufffd\u2018\u00a1\u00e2\u201e\ufffd\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u00a1\u00e2\u201e\ufffdhhtththttthitalic_h italic_h italic_t italic_t italic_h italic_t italic_h italic_t italic_t italic_t italic_h\u00e2\u20ac\ufffd contains no occurrence of 3333-consecutive heads, so additional trials would be needed to achieve the first instance of 3333-consecutive heads. A Bernoulli experiment consists of a series of independent Bernoulli trials, where each trial has a random outcome with two possible results: success or failure. The probability of success remains constant throughout the trials. Common examples of Bernoulli trials include tossing a coin, where the outcome is either heads or tails, or rolling a die, where one outcome is designated as success, while the others represent failure. The aim of this article is to determine the expected number of trials (i.e., the average) needed to observe k\u011f\ufffd\u2018\u02dckitalic_k-consecutive successes for the first time in a Bernoulli experiment. For the purposes of this paper, we refer to successes as \u00e2\u20ac\u0153heads\u00e2\u20ac\ufffd and failures as \u00e2\u20ac\u0153tails,\u00e2\u20ac\ufffd analogous to a coin toss experiment. Using a generalized form of arithmetic, geometric, and Fibonacci series, we calculate the expected value of trials needed to observe k\u011f\ufffd\u2018\u02dckitalic_k-consecutive successes for the first time. While the results discussed here are not new and can be found in sources such as [3], [4], and [5], this article is written by a high school student with the goal of making these concepts accessible to other high school students. It aims to demonstrate how basic ideas from arithmetic, geometric, and Fibonacci series, along with recurrence relations, can be applied to solve an intriguing problem: determining the average number of trials required to observe k\u011f\ufffd\u2018\u02dckitalic_k-consecutive heads for the first time in a coin-tossing experiment. In the next section, we discuss some preliminary concepts necessary to achieve our goal. For any positive integers k\u011f\ufffd\u2018\u02dckitalic_k and n\u011f\ufffd\u2018\u203anitalic_n, let \u00e2\u201e\u00b1n,ksubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dc start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT be the set of sequences of heads and tails over n\u011f\ufffd\u2018\u203anitalic_n trials, such that the first occurrence of k\u011f\ufffd\u2018\u02dckitalic_k consecutive heads appears in the n\u011f\ufffd\u2018\u203anitalic_n-th trial (i.e., the last k\u011f\ufffd\u2018\u02dckitalic_k symbols in the sequence are all heads). Denote the cardinality of \u00e2\u201e\u00b1n,ksubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dc start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT by |\u00e2\u201e\u00b1n,k|=gn,ksubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dcsubscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dc| caligraphic_F start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT | = italic_g start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT. As implied by the above definition, we require gn,k=0subscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dc0g_{n,k}=0italic_g start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT = 0 whenever n<k\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dcn<kitalic_n < italic_k and gn,k=1subscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dc1g_{n,k}=1italic_g start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT = 1 whenever n=k\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dcn=kitalic_n = italic_k. Furthermore, define g0,k=0subscript\u011f\ufffd\u2018\u201d0\u011f\ufffd\u2018\u02dc0g_{0,k}=0italic_g start_POSTSUBSCRIPT 0 , italic_k end_POSTSUBSCRIPT = 0 for all positive integers k\u011f\ufffd\u2018\u02dckitalic_k. For any positive integers k\u011f\ufffd\u2018\u02dckitalic_k and n\u011f\ufffd\u2018\u203anitalic_n with n\u00e2\u2030\u00a5k\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dcn kitalic_n \u00e2\u2030\u00a5 italic_k, the following holds: Proof. To demonstrate that gn,k=\u00e2\u02c6\u2018m=1kgn\u00e2\u02c6\u2019m,ksubscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dcsuperscriptsubscript\u011f\ufffd\u2018\u01611\u011f\ufffd\u2018\u02dcsubscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u02dcg_{n,k}= start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT = \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_m = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT italic_g start_POSTSUBSCRIPT italic_n - italic_m , italic_k end_POSTSUBSCRIPT, we will establish a bijection between the set \u00e2\u201e\u00b1n,ksubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dc start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT and the union of the sets {\u00e2\u201e\u00b1n\u00e2\u02c6\u2019i,k\u00e2\u02c6\u00a31\u00e2\u2030\u00a4i\u00e2\u2030\u00a4k}conditional-setsubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dc1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dc 1 i k caligraphic_F start_POSTSUBSCRIPT italic_n - italic_i , italic_k end_POSTSUBSCRIPT \u00e2\u02c6\u00a3 1 \u00e2\u2030\u00a4 italic_i \u00e2\u2030\u00a4 italic_k }. Note that by definition of \u00e2\u201e\u00b1n,ksubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dc start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT, \u00e2\u201e\u00b1n\u00e2\u02c6\u2019i,ksubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dc start_POSTSUBSCRIPT italic_n - italic_i , italic_k end_POSTSUBSCRIPT and \u00e2\u201e\u00b1n\u00e2\u02c6\u2019j,ksubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u02dc start_POSTSUBSCRIPT italic_n - italic_j , italic_k end_POSTSUBSCRIPT are disjoint for positive integers i\u00e2\u2030\u00a4k\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dci kitalic_i \u00e2\u2030\u00a4 italic_k and j\u00e2\u2030\u00a4k\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u02dcj kitalic_j \u00e2\u2030\u00a4 italic_k whenever i\u00e2\u2030 j\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014i jitalic_i \u00e2\u2030 italic_j. Consider any valid sequence (i.e., an element) from \u00e2\u201e\u00b1n,ksubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dc start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT. In this sequence, let i\u011f\ufffd\u2018\u2013iitalic_i be the position of the first appearance of tails. If the first tails appears at position i\u011f\ufffd\u2018\u2013iitalic_i, then the segment of the sequence followed by this tails has the length n\u00e2\u02c6\u2019i\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2013n-iitalic_n - italic_i. This segment must be a valid sequence in \u00e2\u201e\u00b1n\u00e2\u02c6\u2019i,ksubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dc start_POSTSUBSCRIPT italic_n - italic_i , italic_k end_POSTSUBSCRIPT. Now, consider a sequence in \u00e2\u201e\u00b1n\u00e2\u02c6\u2019i,ksubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dc start_POSTSUBSCRIPT italic_n - italic_i , italic_k end_POSTSUBSCRIPT. This sequence has k\u011f\ufffd\u2018\u02dckitalic_k consecutive heads in the end by definition. These k\u011f\ufffd\u2018\u02dckitalic_k heads occupy positions beginning at the position n\u00e2\u02c6\u2019i\u00e2\u02c6\u2019k+1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dc1n-i-k+1italic_n - italic_i - italic_k + 1. By placing i\u011f\ufffd\u2018\u2013iitalic_i tails in the beginning of this sequence, we obtain a sequence of length n\u011f\ufffd\u2018\u203anitalic_n where the first occurrence of k\u011f\ufffd\u2018\u02dckitalic_k consecutive heads appears exactly at the n\u011f\ufffd\u2018\u203anitalic_n-th position. Thus, this extended sequence belongs to \u00e2\u201e\u00b1n,ksubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dc start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT. We have thus defined a bijection between \u00e2\u201e\u00b1n,ksubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dc start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT and the union of the sets {\u00e2\u201e\u00b1n\u00e2\u02c6\u2019i,k\u00e2\u02c6\u00a31\u00e2\u2030\u00a4i\u00e2\u2030\u00a4k}conditional-setsubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dc1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dc 1 i k caligraphic_F start_POSTSUBSCRIPT italic_n - italic_i , italic_k end_POSTSUBSCRIPT \u00e2\u02c6\u00a3 1 \u00e2\u2030\u00a4 italic_i \u00e2\u2030\u00a4 italic_k }. Each sequence in \u00e2\u201e\u00b1n,ksubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dc start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT uniquely corresponds to one in \u00e2\u201e\u00b1n\u00e2\u02c6\u2019i,ksubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dc start_POSTSUBSCRIPT italic_n - italic_i , italic_k end_POSTSUBSCRIPT for some i\u011f\ufffd\u2018\u2013iitalic_i, and each sequence in \u00e2\u201e\u00b1n\u00e2\u02c6\u2019i,ksubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dc start_POSTSUBSCRIPT italic_n - italic_i , italic_k end_POSTSUBSCRIPT can be uniquely extended to one in \u00e2\u201e\u00b1n,ksubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dc start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT by concatenating a sequence of i\u011f\ufffd\u2018\u2013iitalic_i tails in the beginning. As \u00e2\u201e\u00b1n\u00e2\u02c6\u2019i,ksubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dc start_POSTSUBSCRIPT italic_n - italic_i , italic_k end_POSTSUBSCRIPT and \u00e2\u201e\u00b1n\u00e2\u02c6\u2019j,ksubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u02dc start_POSTSUBSCRIPT italic_n - italic_j , italic_k end_POSTSUBSCRIPT are disjoint whenever i\u00e2\u2030 j\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014i jitalic_i \u00e2\u2030 italic_j and there is bijection between \u00e2\u201e\u00b1n,ksubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dc start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT and the set {\u00e2\u201e\u00b1n\u00e2\u02c6\u2019i,k\u00e2\u02c6\u00a31\u00e2\u2030\u00a4i\u00e2\u2030\u00a4k}conditional-setsubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dc1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dc 1 i k caligraphic_F start_POSTSUBSCRIPT italic_n - italic_i , italic_k end_POSTSUBSCRIPT \u00e2\u02c6\u00a3 1 \u00e2\u2030\u00a4 italic_i \u00e2\u2030\u00a4 italic_k }, the number of elements in \u00e2\u201e\u00b1n,ksubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dc start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT equals the sum of the number of elements in the sets \u00e2\u201e\u00b1n\u00e2\u02c6\u2019i,ksubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dc start_POSTSUBSCRIPT italic_n - italic_i , italic_k end_POSTSUBSCRIPT for i\u011f\ufffd\u2018\u2013iitalic_i from 1 to k\u011f\ufffd\u2018\u02dckitalic_k: Since |\u00e2\u201e\u00b1n\u00e2\u02c6\u2019i,k|=gn\u00e2\u02c6\u2019i,ksubscript\u00e2\u201e\u00b1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dcsubscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dc| caligraphic_F start_POSTSUBSCRIPT italic_n - italic_i , italic_k end_POSTSUBSCRIPT | = italic_g start_POSTSUBSCRIPT italic_n - italic_i , italic_k end_POSTSUBSCRIPT, it follows that: \u00e2\u02c6\ufffd For any positive integer k\u011f\ufffd\u2018\u02dckitalic_k, consider performing a Bernoulli experiment, such as repeatedly tossing a coin, until we achieve k\u011f\ufffd\u2018\u02dckitalic_k consecutive successes for the first time. Let Sksubscript\u011f\ufffd\u2018\u2020\u011f\ufffd\u2018\u02dcS_{k}italic_S start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT represent the set of all outcome sequences from this experiment. Specifically, these sequences end with exactly k\u011f\ufffd\u2018\u02dckitalic_k consecutive successes and contain no occurrence of k\u011f\ufffd\u2018\u02dckitalic_k consecutive successes prior to the final trial. Let \u00cf\u2021\u011f\ufffd\u0153\u2019 be the random variable that maps a sequence in Sksubscript\u011f\ufffd\u2018\u2020\u011f\ufffd\u2018\u02dcS_{k}italic_S start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT to its length (i.e., to the number of trials in the sequence). Let p\u00e2\ufffd\u00a2(\u00cf\u2021=i)\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u2019\u011f\ufffd\u2018\u2013p( ( italic_\u00cf\u2021 = italic_i ) denote the probability that a sequence in Sksubscript\u011f\ufffd\u2018\u2020\u011f\ufffd\u2018\u02dcS_{k}italic_S start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT is of length i\u011f\ufffd\u2018\u2013iitalic_i. For i=n\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u203ai=nitalic_i = italic_n by definition of Fn,ksubscript\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dcF_{n,k}italic_F start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT, for a fair coin with success probability in each trial p=12\u011f\ufffd\u2018\ufffd12p= = divide start_ARG 1 end_ARG start_ARG 2 end_ARG, each sequence in Fn,ksubscript\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dcF_{n,k}italic_F start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT is equally likely. That is each sequence in Fn,ksubscript\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u02dcF_{n,k}italic_F start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT is equally likely independent of number of heads or tails in the sequence. Hence, The expectation value E\u00e2\ufffd\u00a2(\u00cf\u2021)\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u0153\u2019E( ( italic_\u00cf\u2021 ) is expressed as: We now define the series y=\u00e2\u02c6\u2018i=1\u00e2\u02c6\ufffdgi,k\u00e2\u2039\u2026ri\u011f\ufffd\u2018\u00a6superscriptsubscript\u011f\ufffd\u2018\u20131\u00e2\u2039\u2026subscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dcsuperscript\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u2013y= r^{i}italic_y = \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\ufffd end_POSTSUPERSCRIPT italic_g start_POSTSUBSCRIPT italic_i , italic_k end_POSTSUBSCRIPT \u00e2\u2039\u2026 italic_r start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT. Note that the term-by-term differentiation of the series y\u011f\ufffd\u2018\u00a6yitalic_y with respect to r\u011f\ufffd\u2018\u0178ritalic_r results in: To prove that the series y\u011f\ufffd\u2018\u00a6yitalic_y can be term-by-term differentiated, we must establish that it converges absolutely. Consider the series y\u00e2\ufffd\u00a2(r)=\u00e2\u02c6\u2018i=k\u00e2\u02c6\ufffdgi,k\u00e2\u2039\u2026ri\u011f\ufffd\u2018\u00a6\u011f\ufffd\u2018\u0178superscriptsubscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dc\u00e2\u2039\u2026subscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dcsuperscript\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u2013y(r)= r^{i}italic_y ( italic_r ) = \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_i = italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\ufffd end_POSTSUPERSCRIPT italic_g start_POSTSUBSCRIPT italic_i , italic_k end_POSTSUBSCRIPT \u00e2\u2039\u2026 italic_r start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT, with gi,ksubscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dcg_{i,k}italic_g start_POSTSUBSCRIPT italic_i , italic_k end_POSTSUBSCRIPT defined recursively. Let ai=gi,k\u00e2\u2039\u2026risubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u00e2\u2039\u2026subscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dcsuperscript\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u2013a_{i}=g_{i,k} r^{i}italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_g start_POSTSUBSCRIPT italic_i , italic_k end_POSTSUBSCRIPT \u00e2\u2039\u2026 italic_r start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT. Applying the ratio test, we compute: Substituting r=12\u011f\ufffd\u2018\u017812r= = divide start_ARG 1 end_ARG start_ARG 2 end_ARG, we obtain: Thus, we conclusively establish L<1\u011f\ufffd\ufffd\u00bf1L<1italic_L < 1 and prove that y\u011f\ufffd\u2018\u00a6yitalic_y converges absolutely via the ratio test. \u00e2\u02c6\ufffd Let where 0<r<10\u011f\ufffd\u2018\u017810<r<10 < italic_r < 1. As gi,k=0subscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dc0g_{i,k}=0italic_g start_POSTSUBSCRIPT italic_i , italic_k end_POSTSUBSCRIPT = 0 for integers i<k\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dci<kitalic_i < italic_k, we get To find a solution, we multiply the equation by successive powers of r\u011f\ufffd\u2018\u0178ritalic_r up to rksuperscript\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u02dcr^{k}italic_r start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT: Next, we subtract these equations from the original expression of y\u011f\ufffd\u2018\u00a6yitalic_y. As gi,k=\u00e2\u02c6\u2018j=1kgi\u00e2\u02c6\u2019j,ksubscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dcsuperscriptsubscript\u011f\ufffd\u2018\u20141\u011f\ufffd\u2018\u02dcsubscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u02dcg_{i,k}= start_POSTSUBSCRIPT italic_i , italic_k end_POSTSUBSCRIPT = \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT italic_g start_POSTSUBSCRIPT italic_i - italic_j , italic_k end_POSTSUBSCRIPT and gi,k=0subscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dc0g_{i,k}=0italic_g start_POSTSUBSCRIPT italic_i , italic_k end_POSTSUBSCRIPT = 0 for integers i<k\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dci<kitalic_i < italic_k, we get Note that all g\u00e2\ufffd\u00a2(i,k)\u00e2\u02c6\u2019\u00e2\u02c6\u2018j=1kgi\u00e2\u02c6\u2019j,k=0\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dcsuperscriptsubscript\u011f\ufffd\u2018\u20141\u011f\ufffd\u2018\u02dcsubscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u02dc0g(i,k)- ( italic_i , italic_k ) - \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT italic_g start_POSTSUBSCRIPT italic_i - italic_j , italic_k end_POSTSUBSCRIPT = 0 for all i>k\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dci>kitalic_i > italic_k in the right side of the above equation. Evaluating the geometric series on the left side of the equation: Therefore, Finally, substituting the value of E\u00e2\ufffd\u00a2(\u00cf\u2021)\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u0153\u2019E( ( italic_\u00cf\u2021 ), we obtain: Below are some evaluations of expected values for k\u011f\ufffd\u2018\u02dckitalic_k-run for various values of k\u011f\ufffd\u2018\u02dckitalic_k for a fair coin (i.e., r=12\u011f\ufffd\u2018\u017812r= = divide start_ARG 1 end_ARG start_ARG 2 end_ARG) based on the above obtained formula. It can be easily shown using mathematical induction that for r=12\u011f\ufffd\u2018\u017812r= = divide start_ARG 1 end_ARG start_ARG 2 end_ARG, for any positive integer k\u011f\ufffd\u2018\u02dckitalic_k the value of E\u00e2\ufffd\u00a2(\u00cf\u2021)\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u0153\u2019E( ( italic_\u00cf\u2021 ) simplifies to: .\u00e2\u02c6\ufffd This paper derived the expectation value for the length of the first k\u011f\ufffd\u2018\u02dckitalic_k-consecutive successes in a Bernoulli trial using arithmetic-geometric generalized Fibonacci series. By applying recurrence relations and some basic calculus, we established a formula for the expected number of trials required. Our final expression is: Deriving an analogous formula becomes significantly more challenging when the probability of success in a Bernoulli trial deviates from 1212 start_ARG 1 end_ARG start_ARG 2 end_ARG (i.e., when the coin is not fair), and no simplified closed-form solution exists. Note that for r\u00e2\u2030 12\u011f\ufffd\u2018\u017812r \u00e2\u2030 divide start_ARG 1 end_ARG start_ARG 2 end_ARG, all sequences in the set Fi,ksubscript\u011f\ufffd\ufffd\u00b9\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dcF_{i,k}italic_F start_POSTSUBSCRIPT italic_i , italic_k end_POSTSUBSCRIPT are equally likely, which implies that p\u00e2\ufffd\u00a2(\u00cf\u2021=i)\u00e2\u2030 gi,k2i\u011f\ufffd\u2018\ufffd\u011f\ufffd\u0153\u2019\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dcsuperscript2\u011f\ufffd\u2018\u2013p( ( italic_\u00cf\u2021 = italic_i ) \u00e2\u2030 divide start_ARG italic_g start_POSTSUBSCRIPT italic_i , italic_k end_POSTSUBSCRIPT end_ARG start_ARG 2 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT end_ARG as given in equation (1). Besides r\u00e2\u2030 12\u011f\ufffd\u2018\u017812r \u00e2\u2030 divide start_ARG 1 end_ARG start_ARG 2 end_ARG, another promising direction for further research could involve extending these findings to other stochastic processes. I would like to extend my gratitude to Dr. Stoyan Dimitrov for introducing me to the problem, his advice, steering the direction and deciding the scope of this exploration. This paper would not have been possible without his support. I would also like to express my special thanks to Dr. Niraj Khare for putting me in touch with Dr. Stoyan Dimitrov and nurturing my love for mathematics.",
        "keywords": ""
    },
    {
        "id": 25,
        "title": "Inverse Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrices with the bi-diagonal south-west structure",
        "abstract": "Abstract.Two new matrix classes are introduced; inverse cyclic matrices and bi-diagonal south-west matrices. An interesting relation is established between these classes. Applications to two classes of inverseZ\u011f\ufffd\u2018\ufffdZitalic_Z-matrices are provided.",
        "corpus": "Two new matrix classes are introduced; inverse cyclic matrices and bi-diagonal south-west matrices. An interesting relation is established between these classes. Applications to two classes of inverse Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrices are provided. The objective of this article is twofold. One is to present a brief survey on the class of inverse Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrices, with specific reference to its nonnegativity/nonpositivity properties. The second aim is to propose two matrix classes, motivated by a result on inverse M\u011f\ufffd\u2018\u20acMitalic_M-matrices, and to understand their relationship. We start with a short survey of the literature on inverse Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrices. The set of real square matrices of order n\u011f\ufffd\u2018\u203anitalic_n is denoted by \u011f\ufffd\ufffd\u0152n\u00e2\ufffd\u00a2(\u00e2\u201e\ufffd)subscript\u011f\ufffd\ufffd\u0152\u011f\ufffd\u2018\u203a\u00e2\u201e\ufffd start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( blackboard_R ). We refer to a matrix each of whose entry is nonzero as a full matrix. For any matrix A\u011f\ufffd\ufffd\u00b4Aitalic_A, we use A\u00e2\u2030\u00a50\u011f\ufffd\ufffd\u00b40A 0italic_A \u00e2\u2030\u00a5 0 to denote the fact that all the entries of A\u011f\ufffd\ufffd\u00b4Aitalic_A are nonnegative; A>0\u00e2\ufffd\u00a2(A<0)\u011f\ufffd\ufffd\u00b40\u011f\ufffd\ufffd\u00b40A>0~{}(A<0)italic_A > 0 ( italic_A < 0 ) will signify that all the entries of A\u011f\ufffd\ufffd\u00b4Aitalic_A are positive (negative). The determinant of A\u011f\ufffd\ufffd\u00b4Aitalic_A is denoted by detA\u011f\ufffd\ufffd\u00b4 Aroman_det italic_A. For \u00ce\u00b1,\u00ce\u00b2\u00e2\u0160\u2020{1,2,\u00e2\u20ac\u00a6,n}\u011f\ufffd\u203a\u00bc\u011f\ufffd\u203a\u00bd12\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u203a , italic_\u00ce\u00b2 \u00e2\u0160\u2020 { 1 , 2 , \u00e2\u20ac\u00a6 , italic_n }, whose elements are in the ascending order, we use A\u00e2\ufffd\u00a2[\u00ce\u00b1\u00ce\u00b2]\u011f\ufffd\ufffd\u00b4matrix\u011f\ufffd\u203a\u00bc\u011f\ufffd\u203a\u00bdA [ start_ARG start_ROW start_CELL italic_\u00ce\u00b1 end_CELL end_ROW start_ROW start_CELL italic_\u00ce\u00b2 end_CELL end_ROW end_ARG ] to denote the submatrix of A\u011f\ufffd\ufffd\u00b4Aitalic_A containing the rows and columns indexed by \u00ce\u00b1\u011f\ufffd\u203a\u00bc and \u00ce\u00b2\u011f\ufffd\u203a\u00bd respectively. A\u00e2\ufffd\u00a2[\u00ce\u00b1]\u011f\ufffd\ufffd\u00b4delimited-[]\u011f\ufffd\u203a\u00bcA[ [ italic_\u00ce\u00b1 ] is referred to as a principal submatrix of A\u011f\ufffd\ufffd\u00b4Aitalic_A. If \u00ce\u00b1\u00e2\u0160\u0160{1,2,\u00e2\u20ac\u00a6,n}\u011f\ufffd\u203a\u00bc12\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u203a \u00e2\u0160\u0160 { 1 , 2 , \u00e2\u20ac\u00a6 , italic_n }, then A\u00e2\ufffd\u00a2[\u00ce\u00b1]\u011f\ufffd\ufffd\u00b4delimited-[]\u011f\ufffd\u203a\u00bcA[ [ italic_\u00ce\u00b1 ] will be called a proper principal submatrix. Finally, A\u00e2\ufffd\u00a2(\u00ce\u00b1)\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u203a\u00bcA( ( italic_\u00ce\u00b1 ) denotes the principal submatrix in the rows and columns defined by the complement \u00ce\u00b1\u00e2\u20ac\u00b2superscript\u011f\ufffd\u203a\u00bc\u00e2\u20ac\u00b2 start_POSTSUPERSCRIPT \u00e2\u20ac\u00b2 end_POSTSUPERSCRIPT of \u00ce\u00b1\u011f\ufffd\u203a\u00bc in {1,2,\u00e2\u20ac\u00a6,n}12\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u203a 1 , 2 , \u00e2\u20ac\u00a6 , italic_n }. We use \u00cf\ufffd\u00e2\ufffd\u00a2(A)\u011f\ufffd\u0153\u0152\u011f\ufffd\ufffd\u00b4 ( italic_A ) to denote the spectral radius of A,\u011f\ufffd\ufffd\u00b4A,italic_A , which by definition is the maximum of the modulii of the eigenvalues of A\u011f\ufffd\ufffd\u00b4Aitalic_A. We shall be concerned with the notion of irreducibility of matrices, which we recall, next. For a matrix A=(ai\u00e2\ufffd\u00a2j)\u00e2\u02c6\u02c6\u011f\ufffd\ufffd\u0152n\u00e2\ufffd\u00a2(\u00e2\u201e\ufffd)\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\ufffd\u0152\u011f\ufffd\u2018\u203a\u00e2\u201e\ufffdA=(a_{ij}) = ( italic_a start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ) \u00e2\u02c6\u02c6 bold_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( blackboard_R ), the digraph (directed graph) \u011f\ufffd\u2019\u0178\u00e2\ufffd\u00a2(A)\u011f\ufffd\u2019\u0178\u011f\ufffd\ufffd\u00b4 ( italic_A ) of A\u011f\ufffd\ufffd\u00b4Aitalic_A, has {v1,v2,\u00e2\u20ac\u00a6,vn}subscript\u011f\ufffd\u2018\u00a31subscript\u011f\ufffd\u2018\u00a32\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u203a italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_v start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } as the vertex set, and whose edge set consists of those ordered pairs (vi,vj),subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2014(v_{i},v_{j}),( italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) , if the corresponding entry ai\u00e2\ufffd\u00a2j\u00e2\u2030 0subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140a_{ij} 0italic_a start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT \u00e2\u2030 0. Note that the above definition allows the digraph to have loops. A (directed) path in \u011f\ufffd\u2019\u0178\u00e2\ufffd\u00a2(A)\u011f\ufffd\u2019\u0178\u011f\ufffd\ufffd\u00b4 ( italic_A ) from vertex visubscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2013v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT to vertex vjsubscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2014v_{j}italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, is a set of distinct vertices {vi,vi1,\u00e2\u20ac\u00a6,vir,vj}subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\u00a3subscript\u011f\ufffd\u2018\u20131\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u00a3subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2014 italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_v start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT } such that (vi,vi1),(vi1,vi2),\u00e2\u20ac\u00a6,(vir,vj)subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\u00a3subscript\u011f\ufffd\u2018\u20131subscript\u011f\ufffd\u2018\u00a3subscript\u011f\ufffd\u2018\u20131subscript\u011f\ufffd\u2018\u00a3subscript\u011f\ufffd\u2018\u20132\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u00a3subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2014(v_{i},v_{i_{1}}),(v_{i_{1}},v_{i_{2}}), italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) , ( italic_v start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) , \u00e2\u20ac\u00a6 , ( italic_v start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) are (directed) edges. A matrix A\u011f\ufffd\ufffd\u00b4Aitalic_A is called irreducible if its associated digraph \u011f\ufffd\u2019\u0178\u00e2\ufffd\u00a2(A)\u011f\ufffd\u2019\u0178\u011f\ufffd\ufffd\u00b4 ( italic_A ) is strongly connected, i.e., there is at least one directed path between any two vertices in \u011f\ufffd\u2019\u0178\u00e2\ufffd\u00a2(A)\u011f\ufffd\u2019\u0178\u011f\ufffd\ufffd\u00b4 ( italic_A ). We shall be interested in the following class of sign pattern matrices. A matrix A=(ai\u00e2\ufffd\u00a2j)\u00e2\u02c6\u02c6\u011f\ufffd\ufffd\u0152n\u00e2\ufffd\u00a2(\u00e2\u201e\ufffd)\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\ufffd\u0152\u011f\ufffd\u2018\u203a\u00e2\u201e\ufffdA=(a_{ij}) = ( italic_a start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ) \u00e2\u02c6\u02c6 bold_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( blackboard_R ) is said to be a Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrix if ai\u00e2\ufffd\u00a2j\u00e2\u2030\u00a40subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140a_{ij} 0italic_a start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT \u00e2\u2030\u00a4 0, for all i\u00e2\u2030 j\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014i jitalic_i \u00e2\u2030 italic_j (so that all the off-diagonal entries of A\u011f\ufffd\ufffd\u00b4Aitalic_A are nonpositive). Any such matrix A\u011f\ufffd\ufffd\u00b4Aitalic_A can be represented as Denote for r=1,2,\u00e2\u20ac\u00a6,n\u011f\ufffd\u2018\u017812\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u203ar=1,2, = 1 , 2 , \u00e2\u20ac\u00a6 , italic_n, with the convention that \u00cf\ufffd0\u00e2\ufffd\u00a2(B):=\u00e2\u02c6\u2019\u00e2\u02c6\ufffdassignsubscript\u011f\ufffd\u0153\u01520\u011f\ufffd\ufffd\u00b5 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ( italic_B ) := - \u00e2\u02c6\ufffd and \u00cf\ufffdn+1\u00e2\ufffd\u00a2(B):=\u00e2\u02c6\ufffdassignsubscript\u011f\ufffd\u0153\u0152\u011f\ufffd\u2018\u203a1\u011f\ufffd\ufffd\u00b5 start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT ( italic_B ) := \u00e2\u02c6\ufffd. The following classification of Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrices was introduced in [4]. Let Ls\u00e2\ufffd\u00a2(s=0,1,2,\u00e2\u20ac\u00a6,n)subscript\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018 \u011f\ufffd\u2018 012\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u203aL_{s}(s=0,1,2, start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ( italic_s = 0 , 1 , 2 , \u00e2\u20ac\u00a6 , italic_n ) denote the class of real n\u00c3\u2014n\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u203an nitalic_n \u00c3\u2014 italic_n matrices having the form A nonsingular matrix A\u011f\ufffd\ufffd\u00b4Aitalic_A is called an inverse Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrix, if A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT is a Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrix. In order to understand the behaviour of those inverse Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrices that will be considered here, first we recall the corresponding classes of Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrices. First, we recall the notion of an M\u011f\ufffd\u2018\u20acMitalic_M-matrix. Consider a Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrix represented as above. If, in addition, one has t\u00e2\u2030\u00a5\u00cf\ufffd\u00e2\ufffd\u00a2(B)\u011f\ufffd\u2018\u00a1\u011f\ufffd\u0153\u0152\u011f\ufffd\ufffd\u00b5t \u00e2\u2030\u00a5 italic_\u00cf\ufffd ( italic_B ), then A\u011f\ufffd\ufffd\u00b4Aitalic_A is called an M\u011f\ufffd\u2018\u20acMitalic_M-matrix. Such a matrix A\u011f\ufffd\ufffd\u00b4Aitalic_A is invertible, if t>\u00cf\ufffd\u00e2\ufffd\u00a2(B)\u011f\ufffd\u2018\u00a1\u011f\ufffd\u0153\u0152\u011f\ufffd\ufffd\u00b5t> > italic_\u00cf\ufffd ( italic_B ). In that case, it is well known that A\u00e2\u02c6\u20191\u00e2\u2030\u00a50.superscript\u011f\ufffd\ufffd\u00b410A^{-1} 0.italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT \u00e2\u2030\u00a5 0 . There is a variety of results that identify when a Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrix is an M\u011f\ufffd\u2018\u20acMitalic_M-matrix. In the book [1] more than fifty characterizations are presented. Two of them are recalled here. [1, Theorem 2.3] Let A\u011f\ufffd\ufffd\u00b4Aitalic_A be any Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrix. Then the following are equivalent: A\u011f\ufffd\ufffd\u00b4Aitalic_A is a nonsingular M\u011f\ufffd\u2018\u20acMitalic_M-matrix; all the principal minors of A\u011f\ufffd\ufffd\u00b4Aitalic_A are positive; A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT exists and A\u00e2\u02c6\u20191\u00e2\u2030\u00a50superscript\u011f\ufffd\ufffd\u00b410A^{-1} 0italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT \u00e2\u2030\u00a5 0. It follows that the diagonal entries of any nonsingular M\u011f\ufffd\u2018\u20acMitalic_M-matrix are positive. For the case of irreducible matrices, there is something more to say. [1, Thorem 2.7] Let A\u011f\ufffd\ufffd\u00b4Aitalic_A be any Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrix. Then A\u011f\ufffd\ufffd\u00b4Aitalic_A is a nonsingular irreducible M\u011f\ufffd\u2018\u20acMitalic_M-matrix if and only if A\u00e2\u02c6\u20191>0superscript\u011f\ufffd\ufffd\u00b410A^{-1}>0italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT > 0. The other classes of Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrices are obtained if the number t\u011f\ufffd\u2018\u00a1titalic_t in the representation A=t\u00e2\ufffd\u00a2I\u00e2\u02c6\u2019B\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u00a1\u011f\ufffd\ufffd\u00bc\u011f\ufffd\ufffd\u00b5A=tI-Bitalic_A = italic_t italic_I - italic_B, for B\u00e2\u2030\u00a50\u011f\ufffd\ufffd\u00b50B 0italic_B \u00e2\u2030\u00a5 0, lies to the left of \u00cf\ufffd\u00e2\ufffd\u00a2(B).\u011f\ufffd\u0153\u0152\u011f\ufffd\ufffd\u00b5 ( italic_B ) . Let us recall one such class, viz., N\u011f\ufffd\u2018\ufffdNitalic_N-matrices. Once again, let A\u011f\ufffd\ufffd\u00b4Aitalic_A be given as above. If t\u011f\ufffd\u2018\u00a1titalic_t satisfies the inequalities \u00cf\ufffdn\u00e2\u02c6\u20191\u00e2\ufffd\u00a2(B)<t<\u00cf\ufffd\u00e2\ufffd\u00a2(B),subscript\u011f\ufffd\u0153\u0152\u011f\ufffd\u2018\u203a1\u011f\ufffd\ufffd\u00b5\u011f\ufffd\u2018\u00a1\u011f\ufffd\u0153\u0152\u011f\ufffd\ufffd\u00b5 start_POSTSUBSCRIPT italic_n - 1 end_POSTSUBSCRIPT ( italic_B ) < italic_t < italic_\u00cf\ufffd ( italic_B ) , for n\u00e2\u2030\u00a52\u011f\ufffd\u2018\u203a2n 2italic_n \u00e2\u2030\u00a5 2 then A\u011f\ufffd\ufffd\u00b4Aitalic_A is referred to as an N\u011f\ufffd\u2018\ufffdNitalic_N-matrix. This matrix class was introduced and investigated in [3]. The determinant of an N\u011f\ufffd\u2018\ufffdNitalic_N-matrix is negative and each proper principal submatrix is an invertible M\u011f\ufffd\u2018\u20acMitalic_M-matrix (so that all its diagonal entries are positive). While an invertible M\u011f\ufffd\u2018\u20acMitalic_M-matrix is inverse nonnegative, an invertible N\u011f\ufffd\u2018\ufffdNitalic_N-matrix is inverse negative. In particular, it follows that an N\u011f\ufffd\u2018\ufffdNitalic_N-matrix is irreducible. We record this result. [6, Corollary 2.8] Let A\u011f\ufffd\ufffd\u00b4Aitalic_A be a Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrix. Then A\u011f\ufffd\ufffd\u00b4Aitalic_A is a N\u011f\ufffd\u2018\ufffdNitalic_N-matrix if and only if A\u00e2\u02c6\u20191<0superscript\u011f\ufffd\ufffd\u00b410A^{-1}<0italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT < 0. If equality is allowed in the strict inequality in the definition of an N\u011f\ufffd\u2018\ufffdNitalic_N-matrix i.e., in the given representation of A\u011f\ufffd\ufffd\u00b4Aitalic_A, if t\u011f\ufffd\u2018\u00a1titalic_t satisfies the inequalities \u00cf\ufffdn\u00e2\u02c6\u20191\u00e2\ufffd\u00a2(B)\u00e2\u2030\u00a4t<\u00cf\ufffd\u00e2\ufffd\u00a2(B)subscript\u011f\ufffd\u0153\u0152\u011f\ufffd\u2018\u203a1\u011f\ufffd\ufffd\u00b5\u011f\ufffd\u2018\u00a1\u011f\ufffd\u0153\u0152\u011f\ufffd\ufffd\u00b5 t< start_POSTSUBSCRIPT italic_n - 1 end_POSTSUBSCRIPT ( italic_B ) \u00e2\u2030\u00a4 italic_t < italic_\u00cf\ufffd ( italic_B ), then A\u011f\ufffd\ufffd\u00b4Aitalic_A is referred to as an N0subscript\u011f\ufffd\u2018\ufffd0N_{0}italic_N start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-matrix. This matrix class was investigated in [6] and a number of interesting properties were proved. Clearly, every N\u011f\ufffd\u2018\ufffdNitalic_N-matrix is an N0subscript\u011f\ufffd\u2018\ufffd0N_{0}italic_N start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-matrix and that the latter matrix class is the topological closure of the former. Interestingly, analogous to the property of any matrix belonging to the class of N\u011f\ufffd\u2018\ufffdNitalic_N-matrices, we have the following result: A matrix A\u011f\ufffd\ufffd\u00b4Aitalic_A is an N0subscript\u011f\ufffd\u2018\ufffd0N_{0}italic_N start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-matrix precisely if A\u011f\ufffd\ufffd\u00b4Aitalic_A is a Z\u011f\ufffd\u2018\ufffdZitalic_Z matrix with the property that all proper principal submatrices are (not necessarily invertible) M\u011f\ufffd\u2018\u20acMitalic_M-matrices, and the determinant of A\u011f\ufffd\ufffd\u00b4Aitalic_A is negative [6, Lemma 2.1]. Here is another result: If A\u011f\ufffd\ufffd\u00b4Aitalic_A is a Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrix, then A\u011f\ufffd\ufffd\u00b4Aitalic_A is an N0subscript\u011f\ufffd\u2018\ufffd0N_{0}italic_N start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-matrix if and only if A\u00e2\u02c6\u20191\u00e2\u2030\u00a40superscript\u011f\ufffd\ufffd\u00b410A^{-1} 0italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT \u00e2\u2030\u00a4 0 and is irreducible [6, Theorem 2.7]. Note that a nonsingular matrix is irreducible if and only if its inverse is irreducible. We turn our attention to yet another class which has received considerable attention. A matrix A\u00e2\u02c6\u02c6\u011f\ufffd\ufffd\u0152n\u00e2\ufffd\u00a2(\u00e2\u201e\ufffd)\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\ufffd\u0152\u011f\ufffd\u2018\u203a\u00e2\u201e\ufffdA \u00e2\u02c6\u02c6 bold_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( blackboard_R ) with n\u00e2\u2030\u00a53\u011f\ufffd\u2018\u203a3n 3italic_n \u00e2\u2030\u00a5 3, is an F0subscript\u011f\ufffd\ufffd\u00b90F_{0}italic_F start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-matrix if A=t\u00e2\ufffd\u00a2I\u00e2\u02c6\u2019B,\u011f\ufffd\ufffd\u00b4\u011f\ufffd\u2018\u00a1\u011f\ufffd\ufffd\u00bc\u011f\ufffd\ufffd\u00b5A=tI-B,italic_A = italic_t italic_I - italic_B , with B\u00e2\u2030\u00a50\u011f\ufffd\ufffd\u00b50B 0italic_B \u00e2\u2030\u00a5 0 and \u00cf\ufffdn\u00e2\u02c6\u20192\u00e2\ufffd\u00a2(B)\u00e2\u2030\u00a4t<\u00cf\ufffdn\u00e2\u02c6\u20191\u00e2\ufffd\u00a2(B)subscript\u011f\ufffd\u0153\u0152\u011f\ufffd\u2018\u203a2\u011f\ufffd\ufffd\u00b5\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u0153\u0152\u011f\ufffd\u2018\u203a1\u011f\ufffd\ufffd\u00b5 t< start_POSTSUBSCRIPT italic_n - 2 end_POSTSUBSCRIPT ( italic_B ) \u00e2\u2030\u00a4 italic_t < italic_\u00cf\ufffd start_POSTSUBSCRIPT italic_n - 1 end_POSTSUBSCRIPT ( italic_B ). An equivalent manner in which this class is defined is given by the following. Let A\u00e2\u02c6\u02c6\u011f\ufffd\ufffd\u0152n\u00e2\ufffd\u00a2(\u00e2\u201e\ufffd)\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\ufffd\u0152\u011f\ufffd\u2018\u203a\u00e2\u201e\ufffdA \u00e2\u02c6\u02c6 bold_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( blackboard_R ) be a Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrix. Then A\u011f\ufffd\ufffd\u00b4Aitalic_A is an F0subscript\u011f\ufffd\ufffd\u00b90F_{0}italic_F start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-matrix if and only if, it satisfies the following conditions: (1) all principal submatrices of order at most n\u00e2\u02c6\u20192\u011f\ufffd\u2018\u203a2n-2italic_n - 2 are M\u011f\ufffd\u2018\u20acMitalic_M-matrices; (2) at least one principal submatrix of order n\u00e2\u02c6\u20191\u011f\ufffd\u2018\u203a1n-1italic_n - 1 is an N0subscript\u011f\ufffd\u2018\ufffd0N_{0}italic_N start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-matrix. While there is no nonpositivity or nonnegativity result that is true, in general, for F0subscript\u011f\ufffd\ufffd\u00b90F_{0}italic_F start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-matrices, we have: [2, Theorem 2.4] Let A\u011f\ufffd\ufffd\u00b4Aitalic_A be a Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrix. Then A\u011f\ufffd\ufffd\u00b4Aitalic_A is an F0subscript\u011f\ufffd\ufffd\u00b90F_{0}italic_F start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-matrix if and only if: (1) d\u00e2\ufffd\u00a2e\u00e2\ufffd\u00a2t\u00e2\ufffd\u00a2(A)<0;\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u00a1\u011f\ufffd\ufffd\u00b40det(A)<0;italic_d italic_e italic_t ( italic_A ) < 0 ; (2) all principal minors of A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT of order at least two are nonpositive; (3) at least one diagonal entry of A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT is positive. For more details, we refer the reader to [2] and [6]. Recalling the definition of Lssubscript\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018 L_{s}italic_L start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT, it now clear that, for s=n\u011f\ufffd\u2018 \u011f\ufffd\u2018\u203as=nitalic_s = italic_n, we obtain the M\u011f\ufffd\u2018\u20acMitalic_M-matrix class, the N0subscript\u011f\ufffd\u2018\ufffd0N_{0}italic_N start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-matrix class corresponds to s=n\u00e2\u02c6\u20191\u011f\ufffd\u2018 \u011f\ufffd\u2018\u203a1s=n-1italic_s = italic_n - 1, while for s=n\u00e2\u02c6\u20192\u011f\ufffd\u2018 \u011f\ufffd\u2018\u203a2s=n-2italic_s = italic_n - 2, it is the F0subscript\u011f\ufffd\ufffd\u00b90F_{0}italic_F start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-matrix class that one obtains. Next, we revisit a matrix class, historically important, due to its relevance to inverse Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrices. Let real numbers a1,a2,\u00e2\u20ac\u00a6,ansubscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203aa_{1},a_{2}, start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_a start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT be such that an>an\u00e2\u02c6\u20191>\u00e2\u20ac\u00a6>a1.subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a1\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\ufffd1a_{n}>a_{n-1}> start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT > italic_a start_POSTSUBSCRIPT italic_n - 1 end_POSTSUBSCRIPT > \u00e2\u20ac\u00a6 > italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT . A matrix A:=(ai\u00e2\ufffd\u00a2j)assign\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014A:=(a_{ij})italic_A := ( italic_a start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ) is called a matrix of type D\u011f\ufffd\ufffd\u00b7Ditalic_D, if A matrix of type D\u011f\ufffd\ufffd\u00b7Ditalic_D of order n\u00c3\u2014n\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u203an nitalic_n \u00c3\u2014 italic_n will be denoted by Dn.subscript\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u203aD_{n}.italic_D start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT . For instance, We also have the following recurrence relation: where b=(a1,a2,\u00e2\u20ac\u00a6,an)T.\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2021b=(a_{1},a_{2}, = ( italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_a start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT . Type D\u011f\ufffd\ufffd\u00b7Ditalic_D matrices were introduced in [9], where the first item below was proved. Let A\u00e2\u02c6\u02c6\u011f\ufffd\ufffd\u0152n\u00e2\ufffd\u00a2(\u00e2\u201e\ufffd)\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\ufffd\u0152\u011f\ufffd\u2018\u203a\u00e2\u201e\ufffdA \u00e2\u02c6\u02c6 bold_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( blackboard_R ) be a type D\u011f\ufffd\ufffd\u00b7Ditalic_D-matrix. If a1>0,subscript\u011f\ufffd\u2018\ufffd10a_{1}>0,italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT > 0 , then A\u011f\ufffd\ufffd\u00b4Aitalic_A is an inverse M\u011f\ufffd\u2018\u20acMitalic_M-matrix and A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT is tridiagonal [9, Theorem 2.3]. If an<0,subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a0a_{n}<0,italic_a start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT < 0 , then A\u011f\ufffd\ufffd\u00b4Aitalic_A is an inverse N0subscript\u011f\ufffd\u2018\ufffd0N_{0}italic_N start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-matrix such that A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT is tridiagonal [7, Theorem 2.4]. If an>0subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a0a_{n}>0italic_a start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT > 0 and an\u00e2\u02c6\u20191<0,subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a10a_{n-1}<0,italic_a start_POSTSUBSCRIPT italic_n - 1 end_POSTSUBSCRIPT < 0 , then A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT is a tridiagonal F0subscript\u011f\ufffd\ufffd\u00b90F_{0}italic_F start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-matrix [13, Theorem 4.21]. The results above, obtained for three special classes of inverse Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrices, were extended to the full class Lssubscript\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018 L_{s}italic_L start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT, which we recall. We set L\u00e2\u02c6\u20191:=Ln.assignsubscript\u011f\ufffd\ufffd\u00bf1subscript\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018\u203aL_{-1}:=L_{n}.italic_L start_POSTSUBSCRIPT - 1 end_POSTSUBSCRIPT := italic_L start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT . [12, Theorem 3.12] Let A\u00e2\u02c6\u02c6\u011f\ufffd\ufffd\u0152n\u00e2\ufffd\u00a2(\u00e2\u201e\ufffd)\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\ufffd\u0152\u011f\ufffd\u2018\u203a\u00e2\u201e\ufffdA \u00e2\u02c6\u02c6 bold_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( blackboard_R ) be a matrix of type D\u011f\ufffd\ufffd\u00b7Ditalic_D with a1\u00e2\u2030 0subscript\u011f\ufffd\u2018\ufffd10a_{1} 0italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030 0. Let s\u011f\ufffd\u2018 sitalic_s denote the number of nonpositive parameters in the sequence an>an\u00e2\u02c6\u20191>\u00e2\u2039\u00af>a1subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a1\u00e2\u2039\u00afsubscript\u011f\ufffd\u2018\ufffd1a_{n}>a_{n-1}> start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT > italic_a start_POSTSUBSCRIPT italic_n - 1 end_POSTSUBSCRIPT > \u00e2\u2039\u00af > italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. Then A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT is a tridiagonal Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrix and A\u00e2\u02c6\u20191\u00e2\u02c6\u02c6Ls\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41subscript\u011f\ufffd\ufffd\u00bf\u011f\ufffd\u2018 1A^{-1} L_{s-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT \u00e2\u02c6\u02c6 italic_L start_POSTSUBSCRIPT italic_s - 1 end_POSTSUBSCRIPT. In the next result, we obtain specific consequences, presented explicitly, for the three classes: N\u011f\ufffd\u2018\ufffdNitalic_N-matrices, N0subscript\u011f\ufffd\u2018\ufffd0N_{0}italic_N start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-matrices and F0subscript\u011f\ufffd\ufffd\u00b90F_{0}italic_F start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-matrices. It appears that these have not been noticed before (see the para after Theorem 3.12, [12]). We skip their proofs. Note that the number of nonpositive parameters in the first and the second items is n\u011f\ufffd\u2018\u203anitalic_n, while in the third instance, this number is n\u00e2\u02c6\u20191.\u011f\ufffd\u2018\u203a1n-1.italic_n - 1 . Observe that the second item below, strengthens the first item above. Let A\u00e2\u02c6\u02c6\u011f\ufffd\ufffd\u0152n\u00e2\ufffd\u00a2(\u00e2\u201e\ufffd)\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\ufffd\u0152\u011f\ufffd\u2018\u203a\u00e2\u201e\ufffdA \u00e2\u02c6\u02c6 bold_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( blackboard_R ) be a type D\u011f\ufffd\ufffd\u00b7Ditalic_D-matrix. If an<0subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a0a_{n}<0italic_a start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT < 0, then A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT is a tridiagonal N\u011f\ufffd\u2018\ufffdNitalic_N-matrix (and hence a tridiagonal N0subscript\u011f\ufffd\u2018\ufffd0N_{0}italic_N start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-matrix). If an=0subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a0a_{n}=0italic_a start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = 0, then A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT is a tridiagonal N0subscript\u011f\ufffd\u2018\ufffd0N_{0}italic_N start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-matrix, which is not an N\u011f\ufffd\u2018\ufffdNitalic_N-matrix. If an\u00e2\u02c6\u20191=0subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a10a_{n-1}=0italic_a start_POSTSUBSCRIPT italic_n - 1 end_POSTSUBSCRIPT = 0, then A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT is a tridiagonal F0subscript\u011f\ufffd\ufffd\u00b90F_{0}italic_F start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-matrix. In this article, we prove a result each for inverse M\u011f\ufffd\u2018\u20acMitalic_M-matrices and inverse N\u011f\ufffd\u2018\ufffdNitalic_N-matrices. While the inverse M\u011f\ufffd\u2018\u20acMitalic_M-matrix result is the same as what is stated in Theorem 1.9 to follow, we prove it as a consequence of the main result of this article. The result for inverse N\u011f\ufffd\u2018\ufffdNitalic_N-matrices is new. It is pertinent to note that the inverse M\u011f\ufffd\u2018\u20acMitalic_M-matrix problem is to characterize those nonsingular nonnegative matrices that are inverses of M\u011f\ufffd\u2018\u20acMitalic_M-matrices. While a number of matrix classes have been shown to be inverse M\u011f\ufffd\u2018\u20acMitalic_M-matrices, the problem in its full generality remains open. We refer the reader to the recent monograph [5] for a comprehensive treatment. Consider the following two results. [11, Theorem 4.3] Let A=(ai\u00e2\ufffd\u00a2j)\u00e2\u02c6\u02c6\u011f\ufffd\ufffd\u0152n\u00e2\ufffd\u00a2(\u00e2\u201e\ufffd)\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\ufffd\u0152\u011f\ufffd\u2018\u203a\u00e2\u201e\ufffdA=(a_{ij}) = ( italic_a start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ) \u00e2\u02c6\u02c6 bold_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( blackboard_R ). Then the following statements are equivalent: A\u011f\ufffd\ufffd\u00b4Aitalic_A is an inverse M\u011f\ufffd\u2018\u20acMitalic_M-matrix such that \u011f\ufffd\u2019\u0178\u00e2\ufffd\u00a2(A\u00e2\u02c6\u20191)\u011f\ufffd\u2019\u0178superscript\u011f\ufffd\ufffd\u00b41 ( italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) is the simple n\u011f\ufffd\u2018\u203anitalic_n-cycle v1\u00e2\u2020\u2019v2\u00e2\u2020\u2019\u00e2\u20ac\u00a6\u00e2\u2020\u2019vn\u00e2\u2020\u2019v1\u00e2\u2020\u2019subscript\u011f\ufffd\u2018\u00a31subscript\u011f\ufffd\u2018\u00a32\u00e2\u2020\u2019\u00e2\u20ac\u00a6\u00e2\u2020\u2019subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u203a\u00e2\u2020\u2019subscript\u011f\ufffd\u2018\u00a31v_{1} v_{2} v_{n} v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2020\u2019 italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u00e2\u2020\u2019 \u00e2\u20ac\u00a6 \u00e2\u2020\u2019 italic_v start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT \u00e2\u2020\u2019 italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT (with loops). A>0\u011f\ufffd\ufffd\u00b40A>0italic_A > 0 and the following hold: a11\u00e2\ufffd\u00a2a22\u00e2\ufffd\u00a2\u00e2\u2039\u00af\u00e2\ufffd\u00a2an\u00e2\ufffd\u00a2n>a12\u00e2\ufffd\u00a2a23\u00e2\ufffd\u00a2\u00e2\u2039\u00af\u00e2\ufffd\u00a2a(n\u00e2\u02c6\u20191)\u00e2\ufffd\u00a2n\u00e2\ufffd\u00a2an\u00e2\ufffd\u00a21subscript\u011f\ufffd\u2018\ufffd11subscript\u011f\ufffd\u2018\ufffd22\u00e2\u2039\u00afsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\u2018\ufffd12subscript\u011f\ufffd\u2018\ufffd23\u00e2\u2039\u00afsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a1\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a1a_{11}a_{22} a_{nn}>a_{12}a_{23} a_{(n-1)n}a_{n1}italic_a start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 22 end_POSTSUBSCRIPT \u00e2\u2039\u00af italic_a start_POSTSUBSCRIPT italic_n italic_n end_POSTSUBSCRIPT > italic_a start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 23 end_POSTSUBSCRIPT \u00e2\u2039\u00af italic_a start_POSTSUBSCRIPT ( italic_n - 1 ) italic_n end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT italic_n 1 end_POSTSUBSCRIPT, ai\u00e2\ufffd\u00a2j=ai\u00e2\ufffd\u00a2k\u00e2\ufffd\u00a2ak\u00e2\ufffd\u00a2jak\u00e2\ufffd\u00a2k,subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dcsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u02dca_{ij}= start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = divide start_ARG italic_a start_POSTSUBSCRIPT italic_i italic_k end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT italic_k italic_j end_POSTSUBSCRIPT end_ARG start_ARG italic_a start_POSTSUBSCRIPT italic_k italic_k end_POSTSUBSCRIPT end_ARG , for all distinct vertices vi,vj,vksubscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u02dcv_{i},v_{j},v_{k}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT such that vksubscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u02dcv_{k}italic_v start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT lies on the path from visubscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2013v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT to vjsubscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2014v_{j}italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT. Set Z:=(en,e1,e2,\u00e2\u20ac\u00a6,en\u00e2\u02c6\u20191)assign\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u203asuperscript\u011f\ufffd\u2018\u20191superscript\u011f\ufffd\u2018\u20192\u00e2\u20ac\u00a6superscript\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u203a1Z:=(e^{n},e^{1},e^{2}, := ( italic_e start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT , italic_e start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , italic_e start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , \u00e2\u20ac\u00a6 , italic_e start_POSTSUPERSCRIPT italic_n - 1 end_POSTSUPERSCRIPT ), where eksuperscript\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u02dce^{k}italic_e start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT denotes the kt\u00e2\ufffd\u00a2hsuperscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u00a1\u00e2\u201e\ufffdk^{th}italic_k start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT standard basis vector of \u00e2\u201e\ufffdnsuperscript\u00e2\u201e\ufffd\u011f\ufffd\u2018\u203a start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. [11, Corollary 4.5] Let Z\u011f\ufffd\u2018\ufffdZitalic_Z be the matrix defined as above. Let \u00ce\u00b11,\u00ce\u00b12,\u00e2\u20ac\u00a6,\u00ce\u00b1nsubscript\u011f\ufffd\u203a\u00bc1subscript\u011f\ufffd\u203a\u00bc2\u00e2\u20ac\u00a6subscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u203a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u00ce\u00b1 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_\u00ce\u00b1 start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT be nonnegative numbers and Then the following are equivalent: A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT is an M\u011f\ufffd\u2018\u20acMitalic_M-matrix with \u011f\ufffd\u2019\u0178\u00e2\ufffd\u00a2(A\u00e2\u02c6\u20191)\u011f\ufffd\u2019\u0178superscript\u011f\ufffd\ufffd\u00b41 ( italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) being the simple n\u011f\ufffd\u2018\u203anitalic_n-cycle v1\u00e2\u2020\u2019v2\u00e2\u2020\u2019\u00e2\u20ac\u00a6\u00e2\u2020\u2019vn\u00e2\u2020\u2019v1\u00e2\u2020\u2019subscript\u011f\ufffd\u2018\u00a31subscript\u011f\ufffd\u2018\u00a32\u00e2\u2020\u2019\u00e2\u20ac\u00a6\u00e2\u2020\u2019subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u203a\u00e2\u2020\u2019subscript\u011f\ufffd\u2018\u00a31v_{1} v_{2} v_{n} v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2020\u2019 italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u00e2\u2020\u2019 \u00e2\u20ac\u00a6 \u00e2\u2020\u2019 italic_v start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT \u00e2\u2020\u2019 italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, with loops. A>0\u011f\ufffd\ufffd\u00b40A>0italic_A > 0 satisfies \u00ce\u00b11>\u00ce\u00b12>0subscript\u011f\ufffd\u203a\u00bc1subscript\u011f\ufffd\u203a\u00bc20 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT > italic_\u00ce\u00b1 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT > 0, \u00ce\u00b1r=(\u00ce\u00b12)r\u00e2\u02c6\u20191/(\u00ce\u00b11)r\u00e2\u02c6\u20192,subscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u0178superscriptsubscript\u011f\ufffd\u203a\u00bc2\u011f\ufffd\u2018\u01781superscriptsubscript\u011f\ufffd\u203a\u00bc1\u011f\ufffd\u2018\u01782 start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT = ( italic_\u00ce\u00b1 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT italic_r - 1 end_POSTSUPERSCRIPT / ( italic_\u00ce\u00b1 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT italic_r - 2 end_POSTSUPERSCRIPT , for r=3,\u00e2\u20ac\u00a6,n\u011f\ufffd\u2018\u01783\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u203ar=3, = 3 , \u00e2\u20ac\u00a6 , italic_n. The motivation for the article comes from the question as to what lies in the background of Theorem 1.9, which when applied to matrices satisfying the second condition, gives rise to the special class of inverse M\u011f\ufffd\u2018\u20acMitalic_M-matrices, described in the first item. Specifically, inspired by the first item above, we introduce a matrix class, without requiring it to be an M\u011f\ufffd\u2018\u20acMitalic_M-matrix. We call such a matrix a bi-diagonal south-west matrix. Simultaneously, another new class is identified, taking cue from the second item, giving rise to what we refer to as an inverse cyclic matrix. A relationship is established between these two matrix classes in Theorem 2.11. This result, while enabling us to recover Theorem 1.9 as a particular case, further allows us to obtain a new result on inverse N\u011f\ufffd\u2018\ufffdNitalic_N-matrices, which is presented in Theorem 3.1. An analogue of Theorem 1.10 is obtained in Theorem 3.6, for inverse N\u011f\ufffd\u2018\ufffdNitalic_N-matrices. We propose two matrix classes and study their relationship. The first notion is that of the inverse cyclic property of a matrix. Let A=(ai\u00e2\ufffd\u00a2j)\u00e2\u02c6\u02c6\u011f\ufffd\ufffd\u0152n\u00e2\ufffd\u00a2(\u00e2\u201e\ufffd)\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\ufffd\u0152\u011f\ufffd\u2018\u203a\u00e2\u201e\ufffdA=(a_{ij}) = ( italic_a start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ) \u00e2\u02c6\u02c6 bold_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( blackboard_R ) be such that ai\u00e2\ufffd\u00a2i\u00e2\u2030 0,1\u00e2\u2030\u00a4i\u00e2\u2030\u00a4n.formulae-sequencesubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u201301\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u203aa_{ii} 0,1 i n.italic_a start_POSTSUBSCRIPT italic_i italic_i end_POSTSUBSCRIPT \u00e2\u2030 0 , 1 \u00e2\u2030\u00a4 italic_i \u00e2\u2030\u00a4 italic_n . Then A\u011f\ufffd\ufffd\u00b4Aitalic_A is said to have the inverse cyclic property (or is called an inverse cyclic matrix), if the entries of A\u011f\ufffd\ufffd\u00b4Aitalic_A satisfy the following conditions: The requirement on the entries above can also be written equivalently, as For an inverse cyclic matrix, it follows that all the elements in the upper triangular part are determined by the elements on the main diagonal and the super diagonal, while the elements in the lower triangular part are determined by those on the main diagonal, the super diagonal and the entry lying in the intersection of the first column and the last row of the matrix. It may be verified that the matrix A=(2\u00e2\u02c6\u20192\u00e2\u02c6\u201940012000\u00e2\u02c6\u2019202\u00e2\u02c6\u20192\u00e2\u02c6\u201941)\u011f\ufffd\ufffd\u00b4matrix2240012000202241A= ~{}~{}0&~{}~{}1&~{}~{}2&~{}~{}0 ~{}~{}0&~{}~{}0&-2&~{}~{}0 ~{}~{}2&-2&-4&~{}~{}1 = ( start_ARG start_ROW start_CELL 2 end_CELL start_CELL - 2 end_CELL start_CELL - 4 end_CELL start_CELL 0 end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL 1 end_CELL start_CELL 2 end_CELL start_CELL 0 end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL 0 end_CELL start_CELL - 2 end_CELL start_CELL 0 end_CELL end_ROW start_ROW start_CELL 2 end_CELL start_CELL - 2 end_CELL start_CELL - 4 end_CELL start_CELL 1 end_CELL end_ROW end_ARG ) has the inverse cyclic property. For A=(ai\u00e2\ufffd\u00a2j)\u00e2\u02c6\u02c6\u011f\ufffd\ufffd\u0152n\u00e2\ufffd\u00a2(\u00e2\u201e\ufffd)\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\ufffd\u0152\u011f\ufffd\u2018\u203a\u00e2\u201e\ufffdA=(a_{ij}) = ( italic_a start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ) \u00e2\u02c6\u02c6 bold_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( blackboard_R ), set i.e. the product of the diagonal entries of A\u011f\ufffd\ufffd\u00b4Aitalic_A, which we may refer to as the cyclic product. Let us denote by xksuperscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u02dcx^{k}italic_x start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT, the kt\u00e2\ufffd\u00a2hsuperscript\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u00a1\u00e2\u201e\ufffdk^{th}italic_k start_POSTSUPERSCRIPT italic_t italic_h end_POSTSUPERSCRIPT column of the matrix X=(xi\u00e2\ufffd\u00a2j)\u011f\ufffd\u2018\u2039subscript\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014X=(x_{ij})italic_X = ( italic_x start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ). Let A\u00e2\u02c6\u02c6\u011f\ufffd\ufffd\u0152n\u00e2\ufffd\u00a2(\u00e2\u201e\ufffd)\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\ufffd\u0152\u011f\ufffd\u2018\u203a\u00e2\u201e\ufffdA \u00e2\u02c6\u02c6 bold_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( blackboard_R ) be an inverse cyclic matrix. Then First, note that an inverse cyclic matrix is one where all the diagonal entries are nonzero. Thus, d\u00e2\u2030 0.\u011f\ufffd\u2018\u20180d 0.italic_d \u00e2\u2030 0 . Let C\u011f\ufffd\ufffd\u00b6Citalic_C be the matrix obtained from A\u011f\ufffd\ufffd\u00b4Aitalic_A, after employing the following column operations: It is easy to see that C\u011f\ufffd\ufffd\u00b6Citalic_C is a lower triangular matrix with diagonal entries Thus, we have Then, \u00e2\u02c6\ufffd Next, we introduce the second new class of matrices called bi-diagonal south-west matrices. Let A\u00e2\u02c6\u02c6\u011f\ufffd\ufffd\u0152n\u00e2\ufffd\u00a2(\u00e2\u201e\ufffd)\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\ufffd\u0152\u011f\ufffd\u2018\u203a\u00e2\u201e\ufffdA \u00e2\u02c6\u02c6 bold_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( blackboard_R ). Suppose that all the entries of A\u011f\ufffd\ufffd\u00b4Aitalic_A that lie on the main diagonal, the super diagonal and the entry in the south-west corner, are nonzero, while all the other entries are zero. Then A\u011f\ufffd\ufffd\u00b4Aitalic_A is called a bi-diagonal south-west matrix, or bdsw, for short. As an illustration, a pattern of the bdsw matrix (for n=4\u011f\ufffd\u2018\u203a4n=4italic_n = 4), is given by where the symbol \u00e2\u02c6\u2014*\u00e2\u02c6\u2014 stands for a nonzero entry. Let A\u011f\ufffd\ufffd\u00b4Aitalic_A be a bdsw matrix. Then every proper principal submatrix of A\u011f\ufffd\ufffd\u00b4Aitalic_A is either an upper triangular matrix or a block lower triangular matrix. Moreover, every proper principal submatrix of a bdsw matrix is nonsingular. The motivation for considering the class of bdsw matrices arises from the structure of the digraph associated with it. The digraph corresponding to a bdsw matrix (of order n\u00c3\u2014n\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u203an nitalic_n \u00c3\u2014 italic_n) is the simple directed n\u011f\ufffd\u2018\u203anitalic_n-cycle v1\u00e2\u2020\u2019v2\u00e2\u2020\u2019\u00e2\u20ac\u00a6\u00e2\u2020\u2019vn\u00e2\u2020\u2019v1\u00e2\u2020\u2019subscript\u011f\ufffd\u2018\u00a31subscript\u011f\ufffd\u2018\u00a32\u00e2\u2020\u2019\u00e2\u20ac\u00a6\u00e2\u2020\u2019subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u203a\u00e2\u2020\u2019subscript\u011f\ufffd\u2018\u00a31v_{1} v_{2} v_{n} v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2020\u2019 italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u00e2\u2020\u2019 \u00e2\u20ac\u00a6 \u00e2\u2020\u2019 italic_v start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT \u00e2\u2020\u2019 italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, with loops. The digraph for a bdsw matrix of order 4444 is given below. Recall that unipathic digraphs are those digraphs in which there is at most one (directed) path between any two vertices. However, matrices A\u011f\ufffd\ufffd\u00b4Aitalic_A possessing the bdsw structure are examples of irreducible unipathic matrices. This means that, in \u011f\ufffd\u2019\u0178\u00e2\ufffd\u00a2(A)\u011f\ufffd\u2019\u0178\u011f\ufffd\ufffd\u00b4 ( italic_A ), there is exactly one path between any two vertices. We will make use of an auxiliary result, which presents a graph theoretic formula for the inverse of a nonsingular matrix. Let us recall some terminology, in this context. Let p\u00e2\ufffd\u00a2(vi\u00e2\u2020\u2019vj)\u011f\ufffd\u2018\ufffd\u00e2\u2020\u2019subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2014p(v_{i} v_{j})italic_p ( italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u2020\u2019 italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) denote any (directed) path from visubscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2013v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT to vjsubscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2014v_{j}italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT and l\u00e2\ufffd\u00a2(p),\u011f\ufffd\u2018\u2122\u011f\ufffd\u2018\ufffdl(p),italic_l ( italic_p ) , the length of the path p\u011f\ufffd\u2018\ufffdpitalic_p. The set of vertices of \u011f\ufffd\u2019\u0178\u00e2\ufffd\u00a2(A)\u011f\ufffd\u2019\u0178\u011f\ufffd\ufffd\u00b4 ( italic_A ) not belonging to the path p\u011f\ufffd\u2018\ufffdpitalic_p will be denoted by V\u00e2\ufffd\u00a2(p)\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\ufffdV(p)italic_V ( italic_p ), and by A\u00e2\ufffd\u00a2[p\u00e2\ufffd\u00a2(vi\u00e2\u2020\u2019vj)]\u011f\ufffd\ufffd\u00b4delimited-[]\u011f\ufffd\u2018\ufffd\u00e2\u2020\u2019subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2014A[p(v_{i} v_{j})]italic_A [ italic_p ( italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u2020\u2019 italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) ] we signify the product of those elements of A\u011f\ufffd\ufffd\u00b4Aitalic_A, that lie along the given path p\u011f\ufffd\u2018\ufffdpitalic_p of \u011f\ufffd\u2019\u0178\u00e2\ufffd\u00a2(A)\u011f\ufffd\u2019\u0178\u011f\ufffd\ufffd\u00b4 ( italic_A ), from vertex visubscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2013v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT to vertex vjsubscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2014v_{j}italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT. We set, A\u00e2\ufffd\u00a2[p\u00e2\ufffd\u00a2(vi\u00e2\u2020\u2019vj)]=0\u011f\ufffd\ufffd\u00b4delimited-[]\u011f\ufffd\u2018\ufffd\u00e2\u2020\u2019subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u20140A[p(v_{i} v_{j})]=0italic_A [ italic_p ( italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u2020\u2019 italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) ] = 0 if there is no path from vertex visubscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2013v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT to vertex vjsubscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2014v_{j}italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT. [10, Corollary 9.1] Let A=(ai\u00e2\ufffd\u00a2j)\u00e2\u02c6\u02c6\u011f\ufffd\ufffd\u0152n\u00e2\ufffd\u00a2(\u00e2\u201e\ufffd)\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014subscript\u011f\ufffd\ufffd\u0152\u011f\ufffd\u2018\u203a\u00e2\u201e\ufffdA=(a_{ij}) = ( italic_a start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ) \u00e2\u02c6\u02c6 bold_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( blackboard_R ) be nonsingular. Set A\u00e2\u02c6\u20191=(a~i\u00e2\ufffd\u00a2j)superscript\u011f\ufffd\ufffd\u00b41subscript~\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014A^{-1}=( start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT = ( over~ start_ARG italic_a end_ARG start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ). Then, we have and We will make use of the following particular case. Let A\u011f\ufffd\ufffd\u00b4Aitalic_A be a nonsingular unipathic matrix. Then, the off-diagonal entries of A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT are given by where p\u011f\ufffd\u2018\ufffdpitalic_p is the unique path from vertex visubscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2013v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT to vertex vjsubscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2014v_{j}italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, if it exists. The inverse of a nonsingular bdsw matrix is a full matrix. Let A\u011f\ufffd\ufffd\u00b4Aitalic_A be a nonsingular bdsw matrix. Then A\u011f\ufffd\ufffd\u00b4Aitalic_A is a unipathic matrix, so that the entries of A\u00e2\u02c6\u20191=(a~i\u00e2\ufffd\u00a2j)superscript\u011f\ufffd\ufffd\u00b41subscript~\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014A^{-1}=( start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT = ( over~ start_ARG italic_a end_ARG start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ) satisfy (2.5). Moreover, A\u011f\ufffd\ufffd\u00b4Aitalic_A is irreducible and so A\u00e2\ufffd\u00a2[p\u00e2\ufffd\u00a2(vi\u00e2\u2020\u2019vj)]\u00e2\u2030 0\u011f\ufffd\ufffd\u00b4delimited-[]\u011f\ufffd\u2018\ufffd\u00e2\u2020\u2019subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u20140A[p(v_{i} v_{j})] 0italic_A [ italic_p ( italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT \u00e2\u2020\u2019 italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) ] \u00e2\u2030 0, for all i,j\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014i,jitalic_i , italic_j. Also, from Remark 2.5, detA\u00e2\ufffd\u00a2[V\u00e2\ufffd\u00a2(p)]\u00e2\u2030 0\u011f\ufffd\ufffd\u00b4delimited-[]\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\ufffd0 A[V(p)] 0roman_det italic_A [ italic_V ( italic_p ) ] \u00e2\u2030 0, for any path p\u011f\ufffd\u2018\ufffdpitalic_p. In particular, all the diagonal entries of A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT are nonzero and hence a~i\u00e2\ufffd\u00a2j\u00e2\u2030 0,\u00c2 for all\u00c2 \u00e2\ufffd\u00a2i,j.subscript~\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140\u00c2 for all\u00c2 \u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014 0, for all }i,j.over~ start_ARG italic_a end_ARG start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT \u00e2\u2030 0 , for all italic_i , italic_j . Thus, A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT is a full matrix. \u00e2\u02c6\ufffd The converse of Lemma 2.8 is false. For example, the matrix is a nonsingular full matrix, But its inverse is not a bdsw matrix. Now, we prove the main result of this article. This brings about the relationship between nonsingular matrices possessing the inverse cyclic property and bdsw matrices. This result also justifies the nomenclature \u00e2\u20ac\u0153inverse cyclic matrix\u00e2\u20ac\ufffd. We shall make use of the following auxiliary result, which presents a formula for the determinant of a submatrix of a nonsingular matrix and a related submatrix of its inverse. ([8], pp. 5) Let A\u00e2\u02c6\u02c6\u011f\ufffd\ufffd\u0152n\u00e2\ufffd\u00a2(\u00e2\u201e\ufffd)\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\ufffd\u0152\u011f\ufffd\u2018\u203a\u00e2\u201e\ufffdA \u00e2\u02c6\u02c6 bold_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( blackboard_R ) be nonsingular and B:=A\u00e2\u02c6\u20191assign\u011f\ufffd\ufffd\u00b5superscript\u011f\ufffd\ufffd\u00b41B:=A^{-1}italic_B := italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT. Let \u00ce\u00b1={i1,i2,\u00e2\u20ac\u00a6,ip}\u011f\ufffd\u203a\u00bcsubscript\u011f\ufffd\u2018\u20131subscript\u011f\ufffd\u2018\u20132\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd = { italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_i start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_i start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT } and \u00ce\u00b2={j1,j2,\u00e2\u20ac\u00a6,jp}\u011f\ufffd\u203a\u00bdsubscript\u011f\ufffd\u2018\u20141subscript\u011f\ufffd\u2018\u20142\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\ufffd = { italic_j start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_j start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_j start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT } with 1\u00e2\u2030\u00a4i1<i2<\u00e2\u2039\u00af<ip\u00e2\u2030\u00a4n1subscript\u011f\ufffd\u2018\u20131subscript\u011f\ufffd\u2018\u20132\u00e2\u2039\u00afsubscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a1 i_{1}<i_{2}< n1 \u00e2\u2030\u00a4 italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < italic_i start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT < \u00e2\u2039\u00af < italic_i start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_n and 1\u00e2\u2030\u00a4j1<j2<\u00e2\u2039\u00af<jp\u00e2\u2030\u00a4n1subscript\u011f\ufffd\u2018\u20141subscript\u011f\ufffd\u2018\u20142\u00e2\u2039\u00afsubscript\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a1 j_{1}<j_{2}< n1 \u00e2\u2030\u00a4 italic_j start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < italic_j start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT < \u00e2\u2039\u00af < italic_j start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_n. Set \u00ce\u00b3p:=(\u00e2\u02c6\u20191)\u00e2\u02c6\u2018m=1p(im+jm).assignsubscript\u011f\ufffd\u203a\u00be\u011f\ufffd\u2018\ufffdsuperscript1superscriptsubscript\u011f\ufffd\u2018\u01611\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u0161subscript\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u0161 start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT := ( - 1 ) start_POSTSUPERSCRIPT \u00e2\u02c6\u2018 start_POSTSUBSCRIPT italic_m = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT ( italic_i start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT + italic_j start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT . We then have: Suppose that A\u00e2\u02c6\u02c6\u011f\ufffd\ufffd\u0152n\u00e2\ufffd\u00a2(\u00e2\u201e\ufffd)\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\ufffd\u0152\u011f\ufffd\u2018\u203a\u00e2\u201e\ufffdA \u00e2\u02c6\u02c6 bold_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( blackboard_R ) is nonsingular. Then A\u011f\ufffd\ufffd\u00b4Aitalic_A is a full matrix and has the inverse cyclic property, if and only if A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT is a bdsw matrix. Let us assume that A\u011f\ufffd\ufffd\u00b4Aitalic_A is a full matrix and has the inverse cyclic property. Since A\u011f\ufffd\ufffd\u00b4Aitalic_A is nonsingular, by Theorem 2.3, d\u00e2\u02c6\u2019c\u00e2\u2030 0\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\ufffd0d-c 0italic_d - italic_c \u00e2\u2030 0. Define B=(bi\u00e2\ufffd\u00a2j)\u011f\ufffd\ufffd\u00b5subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014B=(b_{ij})italic_B = ( italic_b start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ), where We claim that B=A\u00e2\u02c6\u20191\u011f\ufffd\ufffd\u00b5superscript\u011f\ufffd\ufffd\u00b41B=A^{-1}italic_B = italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT. Since A\u011f\ufffd\ufffd\u00b4Aitalic_A is a full matrix, it is clear that B\u011f\ufffd\ufffd\u00b5Bitalic_B is a bdsw matrix. Now, for all i\u00e2\u02c6\u02c6{1,2,\u00e2\u20ac\u00a6,n}\u011f\ufffd\u2018\u201312\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u203ai \u00e2\u02c6\u02c6 { 1 , 2 , \u00e2\u20ac\u00a6 , italic_n }, We have, for 2\u00e2\u2030\u00a4j\u00e2\u2030\u00a4n2\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u203a2 j n2 \u00e2\u2030\u00a4 italic_j \u00e2\u2030\u00a4 italic_n, and Incorporating these in (2.8), we obtain Case 1: i=j\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014i=jitalic_i = italic_j. First, let i=j=1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20141i=j=1italic_i = italic_j = 1. Then, using (2.2), we have Next, let i=j\u00e2\u2030 1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20141i=j 1italic_i = italic_j \u00e2\u2030 1. Then, using (2.2) again, we have Case 2: i\u00e2\u2030 j\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014i jitalic_i \u00e2\u2030 italic_j. First, let j=1\u011f\ufffd\u2018\u20141j=1italic_j = 1. We have ai\u00e2\ufffd\u00a21=ai\u00e2\ufffd\u00a2n\u00e2\ufffd\u00a2an\u00e2\ufffd\u00a21an\u00e2\ufffd\u00a2nsubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20131subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a1subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u203aa_{i1}= start_POSTSUBSCRIPT italic_i 1 end_POSTSUBSCRIPT = divide start_ARG italic_a start_POSTSUBSCRIPT italic_i italic_n end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT italic_n 1 end_POSTSUBSCRIPT end_ARG start_ARG italic_a start_POSTSUBSCRIPT italic_n italic_n end_POSTSUBSCRIPT end_ARG, so that (A\u00e2\ufffd\u00a2B)i\u00e2\ufffd\u00a21=0subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b5\u011f\ufffd\u2018\u201310(AB)_{i1}=0( italic_A italic_B ) start_POSTSUBSCRIPT italic_i 1 end_POSTSUBSCRIPT = 0. Next, we consider j\u00e2\u2030 1\u011f\ufffd\u2018\u20141j 1italic_j \u00e2\u2030 1. We have two cases. First, let i<j\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014i<jitalic_i < italic_j. Then Also for j<i<n\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u203aj<i<nitalic_j < italic_i < italic_n, and for j<i=n\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u203aj<i=nitalic_j < italic_i = italic_n, Then from (2.9), it follows that (A\u00e2\ufffd\u00a2B)i\u00e2\ufffd\u00a2j=0,subscript\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b5\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140(AB)_{ij}=0,( italic_A italic_B ) start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 0 , in this case, too. This completes the proof that A\u00e2\ufffd\u00a2B=I\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b5\u011f\ufffd\ufffd\u00bcAB=Iitalic_A italic_B = italic_I. Conversely, suppose that B=A\u00e2\u02c6\u20191\u011f\ufffd\ufffd\u00b5superscript\u011f\ufffd\ufffd\u00b41B=A^{-1}italic_B = italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT is a bdsw matrix. Then from Lemma 2.8, A\u011f\ufffd\ufffd\u00b4Aitalic_A is a full matrix and so, in particular all the diagonal entries of A\u011f\ufffd\ufffd\u00b4Aitalic_A are nonzero. Now, using Lemma 2.10, we will show that A\u011f\ufffd\ufffd\u00b4Aitalic_A has the inverse cyclic property. This is equivalent to proving that the following are true: and In view of Lemma 2.10, it suffices to show that the following hold, for the matrix B\u011f\ufffd\ufffd\u00b5Bitalic_B: Consider the case i<k<j\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u02dc\u011f\ufffd\u2018\u2014i<k<jitalic_i < italic_k < italic_j. Let E1subscript\u011f\ufffd\ufffd\u00b81E_{1}italic_E start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT be the submatrix of B\u011f\ufffd\ufffd\u00b5Bitalic_B of order n\u00e2\u02c6\u20192\u011f\ufffd\u2018\u203a2n-2italic_n - 2, corresponding to the left hand side of (2.13). Let C1subscript\u011f\ufffd\ufffd\u00b61C_{1}italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT be the submatrix of E1subscript\u011f\ufffd\ufffd\u00b81E_{1}italic_E start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT obtained by taking the first k\u00e2\u02c6\u20191\u011f\ufffd\u2018\u02dc1k-1italic_k - 1 rows and all the n\u00e2\u02c6\u20192\u011f\ufffd\u2018\u203a2n-2italic_n - 2 columns. Consider the submatrix F1subscript\u011f\ufffd\ufffd\u00b91F_{1}italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT of C1subscript\u011f\ufffd\ufffd\u00b61C_{1}italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, obtained by taking all the k\u00e2\u02c6\u20191\u011f\ufffd\u2018\u02dc1k-1italic_k - 1 rows and the first k\u00e2\u02c6\u20192\u011f\ufffd\u2018\u02dc2k-2italic_k - 2 columns of C1subscript\u011f\ufffd\ufffd\u00b61C_{1}italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. The rank of F1subscript\u011f\ufffd\ufffd\u00b91F_{1}italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT does not exceed k\u00e2\u02c6\u20192.\u011f\ufffd\u2018\u02dc2k-2.italic_k - 2 . Since B\u011f\ufffd\ufffd\u00b5Bitalic_B is a bdsw matrix, and since the entries along all the other columns of C1subscript\u011f\ufffd\ufffd\u00b61C_{1}italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, not being in the submatrix F1subscript\u011f\ufffd\ufffd\u00b91F_{1}italic_F start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, are zero, it follows that the k\u00e2\u02c6\u20191\u011f\ufffd\u2018\u02dc1k-1italic_k - 1 rows of C1subscript\u011f\ufffd\ufffd\u00b61C_{1}italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT are linearly dependent. Thus, detE1=0,subscript\u011f\ufffd\ufffd\u00b810 E_{1}=0,roman_det italic_E start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0 , showing that (2.13) holds. Next, let j<i\u00e2\u2030 n\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u203aj<i nitalic_j < italic_i \u00e2\u2030 italic_n. Suppose that E2subscript\u011f\ufffd\ufffd\u00b82E_{2}italic_E start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT is the submatrix of B\u011f\ufffd\ufffd\u00b5Bitalic_B of order n\u00e2\u02c6\u20192\u011f\ufffd\u2018\u203a2n-2italic_n - 2, corresponding to the left hand side of (2.14). Let C2subscript\u011f\ufffd\ufffd\u00b62C_{2}italic_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT be the submatrix of E2subscript\u011f\ufffd\ufffd\u00b82E_{2}italic_E start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT obtained by taking the last n\u00e2\u02c6\u2019i\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2013n-iitalic_n - italic_i rows and all the n\u00e2\u02c6\u20192\u011f\ufffd\u2018\u203a2n-2italic_n - 2 columns. Consider the submatrix F2subscript\u011f\ufffd\ufffd\u00b92F_{2}italic_F start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT of C2subscript\u011f\ufffd\ufffd\u00b62C_{2}italic_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, obtained by taking all the n\u00e2\u02c6\u2019i\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2013n-iitalic_n - italic_i rows and the last n\u00e2\u02c6\u2019i\u00e2\u02c6\u20191\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u20131n-i-1italic_n - italic_i - 1 columns of C2subscript\u011f\ufffd\ufffd\u00b62C_{2}italic_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. The rank of F2subscript\u011f\ufffd\ufffd\u00b92F_{2}italic_F start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT does not exceed n\u00e2\u02c6\u2019i\u00e2\u02c6\u20191.\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u20131n-i-1.italic_n - italic_i - 1 . Moreover, since the entries along all the other columns of C2subscript\u011f\ufffd\ufffd\u00b62C_{2}italic_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, not being in the submatrix F2subscript\u011f\ufffd\ufffd\u00b92F_{2}italic_F start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, are zero (since B\u011f\ufffd\ufffd\u00b5Bitalic_B is a bdsw matrix), it follows that the n\u00e2\u02c6\u2019i\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u2013n-iitalic_n - italic_i rows of C2subscript\u011f\ufffd\ufffd\u00b62C_{2}italic_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT are linearly dependent. Thus, detE2=0,subscript\u011f\ufffd\ufffd\u00b820 E_{2}=0,roman_det italic_E start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0 , showing that (2.14) holds. Finally, let j<i=n\u011f\ufffd\u2018\u2014\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u203aj<i=nitalic_j < italic_i = italic_n. Denote by E3subscript\u011f\ufffd\ufffd\u00b83E_{3}italic_E start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT, the submatrix of B\u011f\ufffd\ufffd\u00b5Bitalic_B of order n\u00e2\u02c6\u20192\u011f\ufffd\u2018\u203a2n-2italic_n - 2, corresponding to the left hand side of (2.15). Again, since B\u011f\ufffd\ufffd\u00b5Bitalic_B is a bdsw matrix, all the entries in its last row except the first and the last entries, are zero. Thus, all the entries in the last row of E3subscript\u011f\ufffd\ufffd\u00b83E_{3}italic_E start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT are zero, so that detE3=0subscript\u011f\ufffd\ufffd\u00b830 E_{3}=0roman_det italic_E start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0. Thus (2.15) holds. We have shown that A\u011f\ufffd\ufffd\u00b4Aitalic_A has the inverse cyclic property, completing the proof. \u00e2\u02c6\ufffd Let A=(1\u00e2\u02c6\u20191\u00e2\u02c6\u20191\u00e2\u02c6\u20192112\u00e2\u02c6\u20192\u00e2\u02c6\u20191)\u011f\ufffd\ufffd\u00b4matrix111211221A= -2&~{}~{}1&~{}~{}1 ~{}~{}2&-2&-1 = ( start_ARG start_ROW start_CELL 1 end_CELL start_CELL - 1 end_CELL start_CELL - 1 end_CELL end_ROW start_ROW start_CELL - 2 end_CELL start_CELL 1 end_CELL start_CELL 1 end_CELL end_ROW start_ROW start_CELL 2 end_CELL start_CELL - 2 end_CELL start_CELL - 1 end_CELL end_ROW end_ARG ). Then A\u011f\ufffd\ufffd\u00b4Aitalic_A satisfies the inverse cyclic property. Also, is a bdsw matrix. Consider the matrix C,\u011f\ufffd\ufffd\u00b6C,italic_C , obtained by changing A\u011f\ufffd\ufffd\u00b4Aitalic_A in precisely one entry (a32subscript\u011f\ufffd\u2018\ufffd32a_{32}italic_a start_POSTSUBSCRIPT 32 end_POSTSUBSCRIPT), given by Since c32\u00e2\u2030 c31\u00e2\ufffd\u00a2c12c11subscript\u011f\ufffd\u2018\ufffd32subscript\u011f\ufffd\u2018\ufffd31subscript\u011f\ufffd\u2018\ufffd12subscript\u011f\ufffd\u2018\ufffd11c_{32} start_POSTSUBSCRIPT 32 end_POSTSUBSCRIPT \u00e2\u2030 divide start_ARG italic_c start_POSTSUBSCRIPT 31 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT end_ARG start_ARG italic_c start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT end_ARG, the matrix C\u011f\ufffd\ufffd\u00b6Citalic_C does not possess the inverse cyclic property. Here, is not a bdsw matrix. It is easy to verify that any principal submatrix of an inverse cyclic matrix inherits the property. Also, if A\u011f\ufffd\ufffd\u00b4Aitalic_A is a nonsingular matrix having the inverse cyclic property and B=A\u00e2\u02c6\u20191,\u011f\ufffd\ufffd\u00b5superscript\u011f\ufffd\ufffd\u00b41B=A^{-1},italic_B = italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT , then for all 1\u00e2\u2030\u00a4i\u00e2\u2030\u00a4n\u00e2\u02c6\u20191,1\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u203a11 i n-1,1 \u00e2\u2030\u00a4 italic_i \u00e2\u2030\u00a4 italic_n - 1 , In this section, we present applications of Theorem 2.11 to the two classes of nonsingular Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrices under study here, viz., inverse M\u011f\ufffd\u2018\u20acMitalic_M-matrices and inverse N\u011f\ufffd\u2018\ufffdNitalic_N-matrices. For A\u00e2\u02c6\u02c6\u011f\ufffd\ufffd\u0152n\u00e2\ufffd\u00a2(\u00e2\u201e\ufffd),\u011f\ufffd\ufffd\u00b4subscript\u011f\ufffd\ufffd\u0152\u011f\ufffd\u2018\u203a\u00e2\u201e\ufffdA \u00e2\u02c6\u02c6 bold_M start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( blackboard_R ) , we have the following: A\u011f\ufffd\ufffd\u00b4Aitalic_A is an inverse M\u011f\ufffd\u2018\u20acMitalic_M-matrix such that A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT possesses the bdsw structure if and only if A>0\u011f\ufffd\ufffd\u00b40A>0italic_A > 0, d\u00e2\u02c6\u2019c>0\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\ufffd0d-c>0italic_d - italic_c > 0 and A\u011f\ufffd\ufffd\u00b4Aitalic_A has the inverse cyclic property. Let A\u011f\ufffd\ufffd\u00b4Aitalic_A be an even order matrix. Then A\u011f\ufffd\ufffd\u00b4Aitalic_A is an inverse N\u011f\ufffd\u2018\ufffdNitalic_N-matrix, A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT has the bdsw pattern if and only if A<0\u011f\ufffd\ufffd\u00b40A<0italic_A < 0, has the inverse cyclic property with d\u00e2\u02c6\u2019c<0\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\ufffd0d-c<0italic_d - italic_c < 0. Let A\u011f\ufffd\ufffd\u00b4Aitalic_A be an odd order matrix. Then A\u011f\ufffd\ufffd\u00b4Aitalic_A is an inverse N\u011f\ufffd\u2018\ufffdNitalic_N-matrix such that A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT is endowed with the bdsw structure if and only if A<0\u011f\ufffd\ufffd\u00b40A<0italic_A < 0 has the inverse cyclic property and d\u00e2\u02c6\u2019c>0\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\ufffd0d-c>0italic_d - italic_c > 0. (1) Let A\u011f\ufffd\ufffd\u00b4Aitalic_A be an inverse M\u011f\ufffd\u2018\u20acMitalic_M-matrix such that A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT has the bdsw structure. Since A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT is an M\u011f\ufffd\u2018\u20acMitalic_M-matrix, then all the diagonal entries of A\u011f\ufffd\ufffd\u00b4Aitalic_A are nonzero and A=(A\u00e2\u02c6\u20191)\u00e2\u02c6\u20191\u00e2\u2030\u00a50\u011f\ufffd\ufffd\u00b4superscriptsuperscript\u011f\ufffd\ufffd\u00b4110A=(A^{-1})^{-1} 0italic_A = ( italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT \u00e2\u2030\u00a5 0. Moreover, the bdsw structure of A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT, implies that A\u011f\ufffd\ufffd\u00b4Aitalic_A is a full matrix i.e., A>0\u011f\ufffd\ufffd\u00b40A>0italic_A > 0 and A\u011f\ufffd\ufffd\u00b4Aitalic_A has the inverse cyclic property (by Theorem 2.11). Also, the entries of A\u00e2\u02c6\u20191=:B=(bi\u00e2\ufffd\u00a2j)A^{-1}=:B=(b_{ij})italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT = : italic_B = ( italic_b start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ) are given by formula (2.7). Since B\u011f\ufffd\ufffd\u00b5Bitalic_B is an M\u011f\ufffd\u2018\u20acMitalic_M-matrix, i.e., bi\u00e2\ufffd\u00a2j\u00e2\u2030\u00a40subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u20140b_{ij} 0italic_b start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT \u00e2\u2030\u00a4 0, for i\u00e2\u2030 j,\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u2014i j,italic_i \u00e2\u2030 italic_j , and the entries of A\u011f\ufffd\ufffd\u00b4Aitalic_A are positive, it follows from (2.7) that d\u00e2\u02c6\u2019c>0\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\ufffd0d-c>0italic_d - italic_c > 0. Conversely, assume that A>0\u011f\ufffd\ufffd\u00b40A>0italic_A > 0 has the inverse cyclic property and d\u00e2\u02c6\u2019c>0\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\ufffd0d-c>0italic_d - italic_c > 0. Then A\u011f\ufffd\ufffd\u00b4Aitalic_A is nonsingular and by Theorem 2.11, A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT is a bdsw matrix. To show that A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT also an M\u011f\ufffd\u2018\u20acMitalic_M-matrix, it is enough to show that A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT is a Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrix, since A>0\u011f\ufffd\ufffd\u00b40A>0italic_A > 0. However, this is easy to see, by the formula for A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT given in (2.7). Items (2) and (3) follow in an entirely similar manner, with the additional observation that the sign of the products appearing in the inverse formula depend on the odd-even parity of the number of factors. \u00e2\u02c6\ufffd The following examples illustrate the above Theorem. Consider the matrix It may be verified that A\u011f\ufffd\ufffd\u00b4Aitalic_A has the inverse cyclic property and d\u00e2\u02c6\u2019c>0\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\ufffd0d-c>0italic_d - italic_c > 0. Also a bdsw M\u011f\ufffd\u2018\u20acMitalic_M-matrix. Consider the (even order) matrix Then, A\u011f\ufffd\ufffd\u00b4Aitalic_A has the inverse cyclic property and d\u00e2\u02c6\u2019c<0\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\ufffd0d-c<0italic_d - italic_c < 0. Its inverse is given by which is a bdsw N\u011f\ufffd\u2018\ufffdNitalic_N-matrix. The odd order matrix is an inverse cyclic matrix, with d\u00e2\u02c6\u2019c>0\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\ufffd0d-c>0italic_d - italic_c > 0. Here, is a bdsw N\u011f\ufffd\u2018\ufffdNitalic_N-matrix. The following examples illustrate that the odd-even parity in the order of the matrix is indispensable in Theorem 3.1. The matrix of even order has the inverse cyclic property with d\u00e2\u02c6\u2019c>0\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\ufffd0d-c>0italic_d - italic_c > 0. While is a bdsw matrix, it is not an N\u011f\ufffd\u2018\ufffdNitalic_N-matrix. On the other hand, if then A\u011f\ufffd\ufffd\u00b4Aitalic_A is of odd order, d\u00e2\u02c6\u2019c<0\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\ufffd0d-c<0italic_d - italic_c < 0 and has the inverse cyclic property. Here is not even a Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrix. We conclude this article with a result for inverse N\u011f\ufffd\u2018\ufffdNitalic_N-matrices, analogous to Theorem 1.10. Let Z\u011f\ufffd\u2018\ufffdZitalic_Z be defined as in Theorem 1.10. Let \u00ce\u00b11,\u00ce\u00b12,\u00e2\u20ac\u00a6,\u00ce\u00b1nsubscript\u011f\ufffd\u203a\u00bc1subscript\u011f\ufffd\u203a\u00bc2\u00e2\u20ac\u00a6subscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u203a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u00ce\u00b1 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_\u00ce\u00b1 start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT be nonpositive numbers and Then the following are equivalent: A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT is an N\u011f\ufffd\u2018\ufffdNitalic_N-matrix with \u011f\ufffd\u2019\u0178\u00e2\ufffd\u00a2(A\u00e2\u02c6\u20191)\u011f\ufffd\u2019\u0178superscript\u011f\ufffd\ufffd\u00b41 ( italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) being the simple n\u011f\ufffd\u2018\u203anitalic_n-cycle v1\u00e2\u2020\u2019v2\u00e2\u2020\u2019\u00e2\u20ac\u00a6\u00e2\u2020\u2019vn\u00e2\u2020\u2019v1\u00e2\u2020\u2019subscript\u011f\ufffd\u2018\u00a31subscript\u011f\ufffd\u2018\u00a32\u00e2\u2020\u2019\u00e2\u20ac\u00a6\u00e2\u2020\u2019subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u203a\u00e2\u2020\u2019subscript\u011f\ufffd\u2018\u00a31v_{1} v_{2} v_{n} v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2020\u2019 italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u00e2\u2020\u2019 \u00e2\u20ac\u00a6 \u00e2\u2020\u2019 italic_v start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT \u00e2\u2020\u2019 italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, with loops. A<0\u011f\ufffd\ufffd\u00b40A<0italic_A < 0 satisfies \u00ce\u00b12<\u00ce\u00b11<0subscript\u011f\ufffd\u203a\u00bc2subscript\u011f\ufffd\u203a\u00bc10 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT < italic_\u00ce\u00b1 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < 0, \u00ce\u00b1r=(\u00ce\u00b12)r\u00e2\u02c6\u20191/(\u00ce\u00b11)r\u00e2\u02c6\u20192,subscript\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u0178superscriptsubscript\u011f\ufffd\u203a\u00bc2\u011f\ufffd\u2018\u01781superscriptsubscript\u011f\ufffd\u203a\u00bc1\u011f\ufffd\u2018\u01782 start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT = ( italic_\u00ce\u00b1 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT italic_r - 1 end_POSTSUPERSCRIPT / ( italic_\u00ce\u00b1 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT italic_r - 2 end_POSTSUPERSCRIPT , for r=3,\u00e2\u20ac\u00a6,n\u011f\ufffd\u2018\u01783\u00e2\u20ac\u00a6\u011f\ufffd\u2018\u203ar=3, = 3 , \u00e2\u20ac\u00a6 , italic_n. It may be verified that Suppose that (1) holds. Then A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT is an N\u011f\ufffd\u2018\ufffdNitalic_N-matrix with the bdsw structure. By Theorem 3.1, we then have A<0\u011f\ufffd\ufffd\u00b40A<0italic_A < 0 and A\u011f\ufffd\ufffd\u00b4Aitalic_A possesses the inverse cyclic property. Further, d\u00e2\u02c6\u2019c<0\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\ufffd0d-c<0italic_d - italic_c < 0, if n\u011f\ufffd\u2018\u203anitalic_n even and d\u00e2\u02c6\u2019c>0\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\ufffd0d-c>0italic_d - italic_c > 0, for n\u011f\ufffd\u2018\u203anitalic_n odd. Moreover, the inverse cyclic property of A\u011f\ufffd\ufffd\u00b4Aitalic_A yields (b). Finally, the sign of d\u00e2\u02c6\u2019c\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\ufffdd-citalic_d - italic_c for the odd-even parity of the order of the matrix, yields the inequality \u00ce\u00b12<\u00ce\u00b11<0subscript\u011f\ufffd\u203a\u00bc2subscript\u011f\ufffd\u203a\u00bc10 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT < italic_\u00ce\u00b1 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < 0. Conversely, suppose that A<0\u011f\ufffd\ufffd\u00b40A<0italic_A < 0 satisfies the conditions (a)\u011f\ufffd\u2018\ufffd(a)( italic_a ) and (b)\u011f\ufffd\u2018\ufffd(b)( italic_b ). Then, A\u011f\ufffd\ufffd\u00b4Aitalic_A is a full matrix with the inverse cyclic property. The inequalities \u00ce\u00b12<\u00ce\u00b11<0subscript\u011f\ufffd\u203a\u00bc2subscript\u011f\ufffd\u203a\u00bc10 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT < italic_\u00ce\u00b1 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < 0 imply that d\u00e2\u02c6\u2019c<0\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\ufffd0d-c<0italic_d - italic_c < 0, if n\u011f\ufffd\u2018\u203anitalic_n even and d\u00e2\u02c6\u2019c>0\u011f\ufffd\u2018\u2018\u011f\ufffd\u2018\ufffd0d-c>0italic_d - italic_c > 0, for n\u011f\ufffd\u2018\u203anitalic_n odd. By Theorem 3.1 again, A\u00e2\u02c6\u20191superscript\u011f\ufffd\ufffd\u00b41A^{-1}italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT is an N\u011f\ufffd\u2018\ufffdNitalic_N-matrix, with the bdsw structure, so that \u011f\ufffd\u2019\u0178\u00e2\ufffd\u00a2(A\u00e2\u02c6\u20191)\u011f\ufffd\u2019\u0178superscript\u011f\ufffd\ufffd\u00b41 ( italic_A start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) is a simple cycle v1\u00e2\u2020\u2019v2\u00e2\u2020\u2019\u00e2\u20ac\u00a6\u00e2\u2020\u2019vn\u00e2\u2020\u2019v1\u00e2\u2020\u2019subscript\u011f\ufffd\u2018\u00a31subscript\u011f\ufffd\u2018\u00a32\u00e2\u2020\u2019\u00e2\u20ac\u00a6\u00e2\u2020\u2019subscript\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u203a\u00e2\u2020\u2019subscript\u011f\ufffd\u2018\u00a31v_{1} v_{2} v_{n} v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2020\u2019 italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u00e2\u2020\u2019 \u00e2\u20ac\u00a6 \u00e2\u2020\u2019 italic_v start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT \u00e2\u2020\u2019 italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, with loops, completing the proof. \u00e2\u02c6\ufffd We propose two new classes of nonsingular matrices and establish a relationship between them. We obtain consequences for two subclasses of inverse Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrices. It is natural to ask what versions of these results apply to other inverse Z-matrices, in general and the classes of N0subscript\u011f\ufffd\u2018\ufffd0N_{0}italic_N start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-matrices and F0subscript\u011f\ufffd\ufffd\u00b90F_{0}italic_F start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-matrices, in particular. This is a problem for a future study.",
        "keywords": "Key words and phrases: Digraph, Z\u011f\ufffd\u2018\ufffdZitalic_Z-matrix, M\u011f\ufffd\u2018\u20acMitalic_M-matrix, inverse M\u011f\ufffd\u2018\u20acMitalic_M-matrix, N\u011f\ufffd\u2018\ufffdNitalic_N-matrix, inverse N\u011f\ufffd\u2018\ufffdNitalic_N-matrix"
    },
    {
        "id": 26,
        "title": "Exploring the refuge-induced bubbling phenomenon and harvesting in a three species food chain model that incorporates memory effect and odour effect",
        "abstract": "AbstractIn this study, an odour-mediated system is developed and studied. In an odor-mediated systems, the sense of smell or odour of species plays a critical role in the interactions between predators and prey. It is widely recognised in scientific literature that these systems are very common and essential across natural ecosystems. These systems are crucial for various behaviors, including foraging, mating, and avoiding predators. In this paper, it is assumed that the presence of prey odour aids the predator in its hunting efforts. It is assumed that both prey and intermediate predators seek refuge against their respective predators upon detecting the odour of their predators. In other words, the odour of predators assists prey species in evaluating the danger and seeking refuge for hiding. This model incorporates the prey species\u00e2\u20ac\u2122 harvesting as well. We also explore the impact of fading memory on the system by incorporating fractional derivatives into the model. The conditions for both the existence and local stability of the non-negative equilibria are derived. The current model system undergoes both Hopf and transcritical bifurcation when the parameter values are appropriately chosen. The dynamic behaviour of the system is showcased and thoroughly analysed using a range of diagrams, highlighting the the impact of prey refuge and predator odour parameters. This paper extensively examines the long-term impacts of harvesting within the system. The extent to which prey odour influences the system is investigated, and it emerges that prey odour can play a significant function within the system. Many special circumstances are also comprehensively addressed, including the following: a) the absence of refuge, b) the absence of harvesting, and c) the absence of the prey odour. It has been noted that when the refuge for intermediate predators gets bigger, it becomes more challenging for all three populations to coexist within the system. Interestingly, when prey does not exhibit refuge behaviour, it is still possible for all three species to coexist. Furthermore, it is apparent that the prey refuge parameterm1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPTinduces bubbling phenomena in the system. In addition, population fluctuations can be observed in all three species in the system when there is no harvesting. The presence of prey odour plays a significant role in promoting a long-term cohabitation dynamic within this specific system. It has been observed that when individuals within the system have a strong memory, it positively affects the stability of the system. Numerical simulations are conducted in order to demonstrate and validate the usefulness of the model being considered, therefore supporting the analytical conclusions.",
        "corpus": "In this study, an odour-mediated system is developed and studied. In an odor-mediated systems, the sense of smell or odour of species plays a critical role in the interactions between predators and prey. It is widely recognised in scientific literature that these systems are very common and essential across natural ecosystems. These systems are crucial for various behaviors, including foraging, mating, and avoiding predators. In this paper, it is assumed that the presence of prey odour aids the predator in its hunting efforts. It is assumed that both prey and intermediate predators seek refuge against their respective predators upon detecting the odour of their predators. In other words, the odour of predators assists prey species in evaluating the danger and seeking refuge for hiding. This model incorporates the prey species\u00e2\u20ac\u2122 harvesting as well. We also explore the impact of fading memory on the system by incorporating fractional derivatives into the model. The conditions for both the existence and local stability of the non-negative equilibria are derived. The current model system undergoes both Hopf and transcritical bifurcation when the parameter values are appropriately chosen. The dynamic behaviour of the system is showcased and thoroughly analysed using a range of diagrams, highlighting the the impact of prey refuge and predator odour parameters. This paper extensively examines the long-term impacts of harvesting within the system. The extent to which prey odour influences the system is investigated, and it emerges that prey odour can play a significant function within the system. Many special circumstances are also comprehensively addressed, including the following: a) the absence of refuge, b) the absence of harvesting, and c) the absence of the prey odour. It has been noted that when the refuge for intermediate predators gets bigger, it becomes more challenging for all three populations to coexist within the system. Interestingly, when prey does not exhibit refuge behaviour, it is still possible for all three species to coexist. Furthermore, it is apparent that the prey refuge parameter m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT induces bubbling phenomena in the system. In addition, population fluctuations can be observed in all three species in the system when there is no harvesting. The presence of prey odour plays a significant role in promoting a long-term cohabitation dynamic within this specific system. It has been observed that when individuals within the system have a strong memory, it positively affects the stability of the system. Numerical simulations are conducted in order to demonstrate and validate the usefulness of the model being considered, therefore supporting the analytical conclusions. AMS subject classifications: 92B05; 92D25; 34D23; 34C25; 34A08. Keywords: Predator\u00e2\u20ac\u201cprey; memory effect; odour effect, refuge; harvesting; stability; bifurcation In ecology, odour-mediated predator-prey systems can be distinguished by the pivotal function of the odour in the interactions between predators and prey. The odour of a species is one of the key elements that significantly affects the functional response in a predator-prey system. The olfactory sense plays a vital part in essential biological activities such as predator evasion, mate selection, trail and territory identification, and food acquisition [1]. It has been noticed that a considerable proportion of animal species heavily depend on olfaction as a means to capture and analyse environmental information. Marsupials (Marsupialia) have been observed utilising feather odour signals of crimson rosella (Platycercus elegans) as a means to evaluate the condition of nest hollows. This knowledge may assist them in detecting avian prey or enhancing their vigilance when competing with parrots (Psittaciformes) for nest hollows [2]. Insects possess the ability to detect plants by olfactory cues. The olfactory cues emitted by plants are also significant in the process of identifying and choosing food sources among mammals[3]. The parasitoid species Microplitis croceipes relies on kairomones emitted by the host organism for the purpose of locating it [4]. Female moths (Lepidoptera) have been observed to employ a fascinating mechanism involving the release of odorant compounds. These compounds, which are known to contain specialised enzymes, play a crucial role in the transmission of vital information among individuals of the same species [5]. Also, the use of olfactory cues by wolves (Canis lupus) in the pursuit of prey is a well-documented phenomenon [6]. The odours secreted by prey aid the grasshopper mouse (Onychomys leucogaster) in its predation efforts [7]. Although the impact of species\u00e2\u20ac\u2122 odour is widely recognised in ecological literature, there is a limited amount of research that explores its effect in mathematical models of predator-prey systems. Bhattacharjee et al.[8] discussed a three species food chain model incorporating the effect of prey odour. Xu et al. [5] studied the effect of predator odour on prey species in a predator-prey system. Shen et al. [9] investigated a predator-prey model in the presence of predator odour disturbance. Odour-mediated systems exhibit significant diversity and are present in various ecological interactions. There are numerous diverse effects that can occur in an odor-mediated system. It is found that the odour of predators can elicit defence mechanisms or anti-predator behaviours in prey species, which is widely recognised in ecological literature [10, 11, 12, 13, 14, 15, 16]. One such defensive behaviour frequently observed in nature is the refuge phenomenon. Therefore, the existence of prey refuge in an odor-mediated system is a prevalent kind of diversification. The notion of refuges is extensively acknowledged and examined within the disciplines of biology and ecology [17, 18, 19, 20, 21, 22]. The term \u00e2\u20ac\ufffdrefuge-seeking behaviour\u00e2\u20ac\ufffd pertains to a phenomenon observed in organisms whereby they actively place themselves in areas that are either secluded or inaccessible to predators as a means of seeking protection from predation. This particular method enables the organisms to efficiently avoid predation and improve their likelihood of survival. The phenomenon of prey hiding has been observed to potentially exert a stabilising effect on predator-prey dynamics [21, 23]. However, as far as the authors are aware, no study has been undertaken that explores the connection between a prey\u00e2\u20ac\u2122s refuge behaviour and the odour of its predator. The prevalence of harvesting is an intriguing diversity among these odour-mediated systems. For instance, hunters utilise various scents, like doe urine, to effectively attract bucks and increase their chances of a successful hunt [24, 25]. Trappers use baits with potent scents, such as fish or honey, to entice bears into traps [26, 27], etc.. Throughout the course of human history, the practice of harvesting different kinds of animals and insects, whether through fishing, hunting, or resource extraction, has been a vital and indispensable endeavour. Nevertheless, the expansion of human populations, developments in technology, and the increasing worldwide need for food and resources have resulted in heightened harvesting practices that have the potential to exert pressure on ecological systems and pose a threat to biodiversity [31]. Intensive harvesting can harm populations, destabilise ecosystems, and lead to species extinction [32]. Thus, it makes sense to investigate the effect of harvesting in an odour-mediated predator prey system. Despite the presence of varied odour-mediated systems in ecological settings, there has been scant research conducted in the field of mathematical modelling considering the influence of odour on predator-prey systems. This study aims to examine the impact of prey odour on predators as well as the influence of predator odour on prey in a food chain that includes harvesting. To the best of the authors\u00e2\u20ac\u2122 knowledge, there is currently no mathematical model in the literature that can accomplish the same objective. There is a general consensus [34, 35, 36] that living organisms possess memory that is connected to their physical structure or mental processes . The role of species memories in shaping ecological systems is of great importance. Thus, it is essential for a predator-prey mathematical model to consider this memory effect in order to enhance its relevance. Fractional order differential equations (FDEs) have additional benefits over integer order differential equations (ODEs) when it comes to modelling these processes. Fractional differential equations (FDEs) are operators that exhibit non-local behaviour, indicating that the future state of a function is influenced not exclusively by its current state but also by all of its prior states. On the other hand, integer order differential equations (ODEs) are limited to capturing only particular changes or features at a specific step of the process [37, 38]. Thus, fractional calculus has emerged as a crucial field of study for comprehending real-world problems throughout the years [21, 22, 37, 38, 39, 40]. The integration of fractional calculus has had a significant impact on intricate dynamic systems, leading to remarkable advancements in the field of ecology. Multiple fractional derivatives have been thoroughly discussed in the literature on fractional calculus, one of which is Caputo\u00e2\u20ac\u2122s derivative. Given the limitations of the integer-order derivative (ODE) in collecting full memory and fully portraying the physical behaviour of the model, we will also examine our biological system by employing a fractional derivative in this paper. Based on the aforementioned discussion and literature review, we developed an odour-mediated food chain model comprising three species in this work. Predators are presumed to derive advantages from the odour of their prey species. Both prey and intermediate predators are believed to profit from the presence of predator odour, as they utilise refuge-seeking as a strategic reaction to predator odour in order to reduce predation rates. The act of harvesting of prey is also considered. We will analyse the same model from two distinct ecological perspectives: (1) Utilising fractional order derivatives to integrate the memory effect into the system. (2) Utilising integer order derivatives that indicate the absence of memory in the system. The paper is structured in the following manner: The paper\u00e2\u20ac\u2122s primary contributions to the scientific literature are covered in Section (2). In Section (3), the problem is mathematically modelled. The Section (4) provides a comprehensive discussion on all the necessary prerequisites for the Caputo fractional order derivative. The concept of well-posedness, including properties such as positivity and boundedness, is addressed in Section (5). The paper discusses the existence and local stability of all ecologically feasible equilibrium points in Section (6). The occurrence of different bifurcations is explored in Section (7). The analytical findings are validated using numerical simulations in Section (8). Conclusions are drawn in Section (9). Furthermore, the visual representation of the paper\u00e2\u20ac\u2122s structure may be seen in figure (1). Based on the aforementioned literature review and subsequent study, it becomes evident that in an odour-mediated predator-prey system, the species\u00e2\u20ac\u2122 odour has a direct influence on the population dynamics of the system, and it is a prevalent phenomenon in predator-prey interactions. These odour-mediated systems exhibit significant diversity and are present in various ecological interactions. Even though a substantial amount of research has been conducted in the field of mathematical modelling of a predator-prey system, there are still substantial voids in the field that need to be addressed. The following outline highlights some of these gaps: (1) Although the ecological literature broadly recognises the influence of prey odour on predator species as well as the influence of predator odour on prey, the investigation of these effects within a mathematical model of predator-prey dynamics has been fairly limited. As far as the authors are aware, no mathematical model currently exists that examines an odour-mediated predator-prey system in which the odour of both species influences each other. 2) To the best of the authors knowledge, no research has been conducted in the realm of mathematical modelling of a predator-prey system that incorporates the concept of predator-odour induced refuge in prey. (3) Although it is well acknowledged in existing literature [41, 42, 43, 44] that a relationship exists between the odour of a species and the memory of its predators or prey, there has been a lack of exploration into an odour-mediated predator-prey system in relation to the memory effect within the context of mathematical modelling of population dynamics. To address these research gaps in the existing literature, an odour-mediated three species food chain model is proposed that examines the dynamics of a predator-prey system in the presence of prey odour, predator odour-induced prey refuge, and harvesting. It is proposed that the odour of prey aids predators in their predation efforts, but prey also get benefited from the odour of their predators since they instinctively seek refuge upon detecting their predator\u00e2\u20ac\u2122s odour. In other words, the predator odour directly aids in prey refuge. The harvesting of the prey is also taken into account. The model aims to provide insights into the population dynamics of an odour-mediated predator-prey system. In this paper, we will explore the same model using both an ODE (system of Ordinary differential equations) framework and an FDE (system of Fractional differential equations) framework. The ODE framework of the system offers insights into the system in the absence of memory effect, whereas the FDE framework provides insights into the system in the presence of memory effect. This paper aims to investigate an odour-mediated predator-prey system, where organisms communicate and interact through odour signals, a common and essential feature across natural ecosystems. In these systems, an important type of diversity is the use of predator odour signals by prey to seek refuge and evade predation. Within the animal kingdom, the phenomenon of seeking refuge as a prey species in response to the odour of the predator is a commonly observed occurrence to avoid predation. Thus, it is crucial to incorporate prey refuge into the mathematical modelling of an odour-mediated predator-prey system in order to enhance its realism. Another notable diversification within an odour-mediated predator-prey system is the use of harvesting practices. It is observed that odour of a species can be used for efficient and effective resource extraction from the environment. Thus, when examining an odour mediated predator prey system, it is logical to incorporate the concept of harvesting. Thus, in this paper, our objective is to analyse the influence of odour on a prey harvested three-species food chain model, specifically considering the effects of prey odour on predators and predator odour on prey. Through this investigation, valuable insights into the ecological dynamics of refuge and odour effect in a prey harvested food chain can be gained. Inspired by the research undertaken by Bhattacharjee et al. [8], we put forward the following model: with initial conditions: . For simplicity, taking m1=mf\u00e2\ufffd\u00a2p\u00e2\ufffd\u00a2a1subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd1m_{1}=m_{fp}a_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_m start_POSTSUBSCRIPT italic_f italic_p end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and m2=ms\u00e2\ufffd\u00a2p\u00e2\ufffd\u00a2a2subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018 \u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd2m_{2}=m_{sp}a_{2}italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = italic_m start_POSTSUBSCRIPT italic_s italic_p end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, the system (1) becomes with initial conditions: . The system under consideration, as described in equation (2), involves a food chain consisting of three species. The variables x1subscript\u011f\ufffd\u2018\u00a51x_{1}italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, x2subscript\u011f\ufffd\u2018\u00a52x_{2}italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, and x3subscript\u011f\ufffd\u2018\u00a53x_{3}italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT represent the population densities of the prey, intermediate predator, and top predator, respectively. It is considered that the top predator (of density x3subscript\u011f\ufffd\u2018\u00a53x_{3}italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT) preys upon the intermediate predator (of density x2subscript\u011f\ufffd\u2018\u00a52x_{2}italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT), while the intermediate predator, in turn, hunts upon prey (of density x1subscript\u011f\ufffd\u2018\u00a51x_{1}italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT). Logistic growth is considered for prey, with the parameter r1subscript\u011f\ufffd\u2018\u01781r_{1}italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT denoting the intrinsic growth rate. It is considered that prey odour helps intermediate predators in hunting, as discussed in [8] and \u00ce\u00b2\u011f\ufffd\u203a\u00bd is the coefficient of odour effect produced by a single prey. The harvesting of the prey is also considered. The variable q\u011f\ufffd\u2018\ufffdqitalic_q represents the catchability constant, while the parameter r\u011f\ufffd\u2018\u0178ritalic_r reflects the level of harvesting effort. The variable r2subscript\u011f\ufffd\u2018\u01782r_{2}italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT represents the feeding rate at which the intermediate predator consumes its prey, whereas r4subscript\u011f\ufffd\u2018\u01784r_{4}italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT represents the feeding rate at which the top predator consumes the intermediate predator. The conversion rates for the intermediate predator and top predator are denoted as r3subscript\u011f\ufffd\u2018\u01783r_{3}italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT and r5subscript\u011f\ufffd\u2018\u01785r_{5}italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT respectively. Prey and intermediate predators are considered to instinctively seek refuge when they detect the odour of their predators and it is hypothesised that the amount of predator odour is directly proportional to the number of prey individuals seeking refuge. Here, m1=mf\u00e2\ufffd\u00a2p\u00e2\ufffd\u00a2a1subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd1m_{1}=m_{fp}a_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_m start_POSTSUBSCRIPT italic_f italic_p end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and m2=ms\u00e2\ufffd\u00a2p\u00e2\ufffd\u00a2a2subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018 \u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd2m_{2}=m_{sp}a_{2}italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = italic_m start_POSTSUBSCRIPT italic_s italic_p end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT represent the quantity of prey and intermediate predators that take refuge when they detect the odour of their predators, rendering themselves unreachable. The prey\u00e2\u20ac\u2122s awareness of potential threats is presumed to rise with the heightened intensity of predator odours. This results in competition to locate refuges. Consequently, as the amount of predator odour escalates, the likelihood of prey obtaining refuge diminishes. The values mf\u00e2\ufffd\u00a2psubscript\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\ufffdm_{fp}italic_m start_POSTSUBSCRIPT italic_f italic_p end_POSTSUBSCRIPT and ms\u00e2\ufffd\u00a2psubscript\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018 \u011f\ufffd\u2018\ufffdm_{sp}italic_m start_POSTSUBSCRIPT italic_s italic_p end_POSTSUBSCRIPT denote the probability of prey and intermediate predator obtaining refuge in the presence of predator odour. Thus, 0<mf\u00e2\ufffd\u00a2p,ms\u00e2\ufffd\u00a2p<1formulae-sequence0subscript\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018 \u011f\ufffd\u2018\ufffd10<m_{fp},m_{sp}<10 < italic_m start_POSTSUBSCRIPT italic_f italic_p end_POSTSUBSCRIPT , italic_m start_POSTSUBSCRIPT italic_s italic_p end_POSTSUBSCRIPT < 1. The parameter a1subscript\u011f\ufffd\u2018\ufffd1a_{1}italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT represents the coefficient of intensity of the intermediate predator\u00e2\u20ac\u2122s odour. On the other hand, the value a2subscript\u011f\ufffd\u2018\ufffd2a_{2}italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT represents the coefficient of intensity of the top predator\u00e2\u20ac\u2122s odour. Here, it is assumed that 0<m1,m2<1formulae-sequence0subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u0161210<m_{1},m_{2}<10 < italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT < 1. The variables d1subscript\u011f\ufffd\u2018\u20181d_{1}italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and d2subscript\u011f\ufffd\u2018\u20182d_{2}italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT represent the natural death rates of the intermediate predator and top predator, respectively. Figure (2) provides a visual representation of an ecological system that closely resembles the system to be investigated. In order to integrate the memory effect into the system (2), we have introduced a Caputo-type fractional-order derivative with an order of \u00ce\u00b1\u011f\ufffd\u203a\u00bc into the model system. This modification results in the following revised model: with initial conditions: x1\u00e2\ufffd\u00a2(0)=x10>0subscript\u011f\ufffd\u2018\u00a510superscriptsubscript\u011f\ufffd\u2018\u00a5100x_{1}(0)=x_{1}^{0}>0italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( 0 ) = italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT > 0 , x2\u00e2\ufffd\u00a2(0)=x20>0subscript\u011f\ufffd\u2018\u00a520superscriptsubscript\u011f\ufffd\u2018\u00a5200x_{2}(0)=x_{2}^{0}>0italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 0 ) = italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT > 0 , x3\u00e2\ufffd\u00a2(0)=x30>0subscript\u011f\ufffd\u2018\u00a530superscriptsubscript\u011f\ufffd\u2018\u00a5300x_{3}(0)=x_{3}^{0}>0italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( 0 ) = italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT > 0. In this section, we provide a comprehensive review of various definitions, theorems, and lemmas that are pertinent to the Caputo fractional derivative. [48] The Caputo fractional derivative with order \u00ce\u00b1\u00e2\u2030\u00a50\u011f\ufffd\u203a\u00bc0 0italic_\u00ce\u00b1 \u00e2\u2030\u00a5 0 for the continuous function f\u00e2\ufffd\u00a2(t)\u00e2\u02c6\u02c6Cn\u00e2\ufffd\u00a2([t0,+\u00e2\u02c6\ufffd),R)\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u00a1superscript\u011f\ufffd\ufffd\u00b6\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\u2018\u00a10\u011f\ufffd\u2018\u2026f(t) C^{n}([t_{0},+ ( italic_t ) \u00e2\u02c6\u02c6 italic_C start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( [ italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , + \u00e2\u02c6\ufffd ) , italic_R ) is defined as where \u00ce\u201c\u00e2\ufffd\u00a2(\u00e2\u02c6\u2014)\u00ce\u201c ( \u00e2\u02c6\u2014 ) is the Gamma function and t0\u00e2\u2030\u00a4tsubscript\u011f\ufffd\u2018\u00a10\u011f\ufffd\u2018\u00a1t_{0} titalic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \u00e2\u2030\u00a4 italic_t. Here, the symbol \u00ce\u00b1\u011f\ufffd\u203a\u00bc represents the order of the fractional derivative and \u00ce\u00b1\u00e2\u02c6\u02c6(n\u00e2\u02c6\u20191,n),n\u00e2\u02c6\u02c6\u011f\ufffd\ufffd\ufffdformulae-sequence\u011f\ufffd\u203a\u00bc\u011f\ufffd\u2018\u203a1\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u203a\u011f\ufffd\ufffd\ufffd \u00e2\u02c6\u02c6 ( italic_n - 1 , italic_n ) , italic_n \u00e2\u02c6\u02c6 bold_N . For \u00ce\u00b1\u00e2\u02c6\u02c6(0,1)\u011f\ufffd\u203a\u00bc01 \u00e2\u02c6\u02c6 ( 0 , 1 ) and considering the specific case of n = 1, [39] A point x0subscript\u011f\ufffd\u2018\u00a50x_{0}italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT is said to be an equilibrium point of the following Caputo fractional order dynamical system Dt\u00ce\u00b1t0c\u00e2\ufffd\u00a2(x\u00e2\ufffd\u00a2(t))=\u00ce \u00e2\ufffd\u00a2(x),x\u00e2\ufffd\u00a2(t0)>0formulae-sequencesuperscriptsubscriptsuperscriptsubscript\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u00a1\u011f\ufffd\u203a\u00bcsubscript\u011f\ufffd\u2018\u00a10\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a1\u00ce \u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\u00a100{}^{c}_{t_{0}}D_{t}^{ italic_c end_FLOATSUPERSCRIPT start_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_D start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u00ce\u00b1 end_POSTSUPERSCRIPT ( italic_x ( italic_t ) ) = roman_\u00ce ( italic_x ) , italic_x ( italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) > 0 iff \u00ce \u00e2\ufffd\u00a2(x0)=0\u00ce subscript\u011f\ufffd\u2018\u00a500 ( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) = 0. [49] Let us assume, f(t) be a continuous function on (0,T] and satisfies Dt\u00ce\u00b1t0c\u00e2\ufffd\u00a2(f\u00e2\ufffd\u00a2(t))\u00e2\u2030\u00a4\u00e2\u02c6\u2019b1\u00e2\ufffd\u00a2f\u00e2\ufffd\u00a2(t)+b2superscriptsubscriptsuperscriptsubscript\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u00a1\u011f\ufffd\u203a\u00bcsubscript\u011f\ufffd\u2018\u00a10\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\ufffd1\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\ufffd2{}^{c}_{t_{0}}D_{t}^{ italic_c end_FLOATSUPERSCRIPT start_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_D start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u00ce\u00b1 end_POSTSUPERSCRIPT ( italic_f ( italic_t ) ) \u00e2\u2030\u00a4 - italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_f ( italic_t ) + italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, f\u00e2\ufffd\u00a2(0)=f0>0\u011f\ufffd\u2018\u201c0subscript\u011f\ufffd\u2018\u201c00f(0)=f_{0}>0italic_f ( 0 ) = italic_f start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT > 0, 0<\u00ce\u00b1<10\u011f\ufffd\u203a\u00bc10< < italic_\u00ce\u00b1 < 1, where b1\u00e2\u2030 0subscript\u011f\ufffd\u2018\ufffd10b_{1} 0italic_b start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030 0 and b1,b2\u00e2\u02c6\u02c6\u00e2\u201e\ufffdsubscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2\u00e2\u201e\ufffdb_{1},b_{2} start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 blackboard_R. Then Where, E\u00ce\u00b1subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u203a\u00bcE_{ start_POSTSUBSCRIPT italic_\u00ce\u00b1 end_POSTSUBSCRIPT is the Mittag\u00e2\u20ac\u201cLeffler function. [50] We consider a system denoted as Dt\u00ce\u00b1t0c\u00e2\ufffd\u00a2(H\u00e2\ufffd\u00a2(t))=\u00cf\u2022\u00e2\ufffd\u00a2(t,H)superscriptsubscriptsuperscriptsubscript\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u00a1\u011f\ufffd\u203a\u00bcsubscript\u011f\ufffd\u2018\u00a10\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00bb\u011f\ufffd\u2018\u00a1italic-\u00cf\u2022\u011f\ufffd\u2018\u00a1\u011f\ufffd\ufffd\u00bb{}^{c}_{t_{0}}D_{t}^{ italic_c end_FLOATSUPERSCRIPT start_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_D start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u00ce\u00b1 end_POSTSUPERSCRIPT ( italic_H ( italic_t ) ) = italic_\u00cf\u2022 ( italic_t , italic_H ), where t0>0subscript\u011f\ufffd\u2018\u00a100t_{0}>0italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT > 0 and H\u00e2\ufffd\u00a2(t0)=Ht0\u011f\ufffd\ufffd\u00bbsubscript\u011f\ufffd\u2018\u00a10subscript\u011f\ufffd\ufffd\u00bbsubscript\u011f\ufffd\u2018\u00a10H(t_{0})=H_{t_{0}}italic_H ( italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) = italic_H start_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT is the initial condition. The parameter \u00ce\u00b1\u011f\ufffd\u203a\u00bc belongs to the interval (0,1]01(0,1]( 0 , 1 ], and the function \u00cf\u2022:[t0,\u00e2\u02c6\ufffd)\u00c3\u2014\u00cf\u2026\u00e2\u2020\u2019\u011f\ufffd\ufffd\u2018n\u00c3\u2014n:italic-\u00cf\u2022\u00e2\u2020\u2019subscript\u011f\ufffd\u2018\u00a10\u011f\ufffd\u0153\ufffdsuperscript\u011f\ufffd\ufffd\u2018\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u203a n}italic_\u00cf\u2022 : [ italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , \u00e2\u02c6\ufffd ) \u00c3\u2014 italic_\u00cf\u2026 \u00e2\u2020\u2019 bold_R start_POSTSUPERSCRIPT italic_n \u00c3\u2014 italic_n end_POSTSUPERSCRIPT, where \u00cf\u2026\u011f\ufffd\u0153\ufffd is a subset of \u011f\ufffd\ufffd\u2018nsuperscript\u011f\ufffd\ufffd\u2018\u011f\ufffd\u2018\u203a start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. Now, when it satisfies the local Lipschitz condition with respect to H\u00e2\u02c6\u02c6\u011f\ufffd\ufffd\u2018n\u011f\ufffd\ufffd\u00bbsuperscript\u011f\ufffd\ufffd\u2018\u011f\ufffd\u2018\u203aH \u00e2\u02c6\u02c6 bold_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT then, the presence of a unique solution is confirmed on the interval [t0,\u00e2\u02c6\ufffd)\u00c3\u2014\u00cf\u2026\u00e2\u2020\u2019\u011f\ufffd\ufffd\u2018n\u00c3\u2014n\u00e2\u2020\u2019subscript\u011f\ufffd\u2018\u00a10\u011f\ufffd\u0153\ufffdsuperscript\u011f\ufffd\ufffd\u2018\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u203a[t_{0}, n}[ italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , \u00e2\u02c6\ufffd ) \u00c3\u2014 italic_\u00cf\u2026 \u00e2\u2020\u2019 bold_R start_POSTSUPERSCRIPT italic_n \u00c3\u2014 italic_n end_POSTSUPERSCRIPT, where [51] Let us suppose that f(t),t0cDt\u00ce\u00b1(w(t))\u00e2\u02c6\u02c6C[a,b]f(t),^{c}_{t_{0}}D_{t}^{ C[a,b]italic_f ( italic_t ) , start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_D start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u00ce\u00b1 end_POSTSUPERSCRIPT ( italic_w ( italic_t ) ) \u00e2\u02c6\u02c6 italic_C [ italic_a , italic_b ] and 0<\u00ce\u00b1\u00e2\u2030\u00a410\u011f\ufffd\u203a\u00bc10< 10 < italic_\u00ce\u00b1 \u00e2\u2030\u00a4 1, then ( f(t) is a non-increasing function, \u00e2\u02c6\u20act\u00e2\u02c6\u02c6[a,b]for-all\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd t italic_t \u00e2\u02c6\u02c6 [ italic_a , italic_b ], provided Dt\u00ce\u00b1t0c\u00e2\ufffd\u00a2(v\u00e2\ufffd\u00a2(t))\u00e2\u2030\u00a40superscriptsubscriptsuperscriptsubscript\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u00a1\u011f\ufffd\u203a\u00bcsubscript\u011f\ufffd\u2018\u00a10\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u00a10{}^{c}_{t_{0}}D_{t}^{ 0start_FLOATSUPERSCRIPT italic_c end_FLOATSUPERSCRIPT start_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_D start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u00ce\u00b1 end_POSTSUPERSCRIPT ( italic_v ( italic_t ) ) \u00e2\u2030\u00a4 0. ( f(t) is a non-decreasing function, \u00e2\u02c6\u20act\u00e2\u02c6\u02c6[a,b]for-all\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd t italic_t \u00e2\u02c6\u02c6 [ italic_a , italic_b ], provided Dt\u00ce\u00b1t0c\u00e2\ufffd\u00a2(v\u00e2\ufffd\u00a2(t))\u00e2\u2030\u00a50superscriptsubscriptsuperscriptsubscript\u011f\ufffd\ufffd\u00b7\u011f\ufffd\u2018\u00a1\u011f\ufffd\u203a\u00bcsubscript\u011f\ufffd\u2018\u00a10\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\u00a10{}^{c}_{t_{0}}D_{t}^{ 0start_FLOATSUPERSCRIPT italic_c end_FLOATSUPERSCRIPT start_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_D start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_\u00ce\u00b1 end_POSTSUPERSCRIPT ( italic_v ( italic_t ) ) \u00e2\u2030\u00a5 0. [48, 52] Let us consider, a Caputo fractional order dynamical system as follows: where, 0<\u00ce\u00b1<10\u011f\ufffd\u203a\u00bc10< < italic_\u00ce\u00b1 < 1, g\u00e2\ufffd\u00a2(t)=(g1\u00e2\ufffd\u00a2(t),\u00e2\u20ac\u00a6,gn\u00e2\ufffd\u00a2(t))T\u00e2\u02c6\u02c6Rn\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u00a1superscriptsubscript\u011f\ufffd\u2018\u201d1\u011f\ufffd\u2018\u00a1\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u201d\u011f\ufffd\u2018\u203a\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u2021superscript\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u203ag(t)=(g_{1}(t),...,g_{n}(t))^{T} R^{n}italic_g ( italic_t ) = ( italic_g start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_t ) , \u00e2\u20ac\u00a6 , italic_g start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_t ) ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT \u00e2\u02c6\u02c6 italic_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT and f:[f1,f2,\u00e2\u20ac\u00a6,fn]:Rn\u00e2\u2020\u2019Rn:\u011f\ufffd\u2018\u201csubscript\u011f\ufffd\u2018\u201c1subscript\u011f\ufffd\u2018\u201c2\u00e2\u20ac\u00a6subscript\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\u203a:\u00e2\u2020\u2019superscript\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u203asuperscript\u011f\ufffd\u2018\u2026\u011f\ufffd\u2018\u203af:[f_{1},f_{2},...,f_{n}]:R^{n} R^{n}italic_f : [ italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_f start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 , italic_f start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ] : italic_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT \u00e2\u2020\u2019 italic_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. Let, f\u00e2\ufffd\u00a2(g\u00e2\u02c6\u2014)=0\u011f\ufffd\u2018\u201csuperscript\u011f\ufffd\u2018\u201d0f(g^{*})=0italic_f ( italic_g start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT ) = 0, then g\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018\u201dg^{*}italic_g start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT is an equilibrium point of the abovementioned fractional system. Let us assunme J\u00e2\ufffd\u00a2(g\u00e2\u02c6\u2014)=\u00ce\u00b4(\u00cf\u20201,\u00cf\u20202,\u00e2\u20ac\u00a6.,\u00cf\u2020n)\u00ce\u00b4(g1,g2,\u00e2\u20ac\u00a6.,gn)J(g^{*})= g_{2},....,g_{n})}italic_J ( italic_g start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT ) = divide start_ARG italic_\u00ce\u00b4 ( italic_\u00cf\u2020 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_\u00cf\u2020 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 . , italic_\u00cf\u2020 start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) end_ARG start_ARG italic_\u00ce\u00b4 ( italic_g start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , \u00e2\u20ac\u00a6 . , italic_g start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) end_ARG be the Jacobian matrix of the above system at equilibrium point g=g\u00e2\u02c6\u2014\u011f\ufffd\u2018\u201dsuperscript\u011f\ufffd\u2018\u201dg=g^{*}italic_g = italic_g start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT and \u00cf\u201ejsubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2014 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, j=1,2,3,\u00e2\u20ac\u00a6,n are the eigenvalues of J\u00e2\ufffd\u00a2(g\u00e2\u02c6\u2014)\u011f\ufffd\ufffd\u00bdsuperscript\u011f\ufffd\u2018\u201dJ(g^{*})italic_J ( italic_g start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT ). Then the equilibrium point g\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018\u201dg^{*}italic_g start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT is stable if and only if |a\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2g\u00e2\ufffd\u00a2(\u00cf\u201ej)|\u00e2\u2030\u00a5\u00ce\u00b1\u00e2\ufffd\u00a2\u00cf\u20ac2\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u201dsubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2014\u011f\ufffd\u203a\u00bc\u011f\ufffd\u0153\u20392|arg( italic_a italic_r italic_g ( italic_\u00cf\u201e start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) | \u00e2\u2030\u00a5 divide start_ARG italic_\u00ce\u00b1 italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG and eigenvalues with |a\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2g\u00e2\ufffd\u00a2(\u00cf\u201ej)|=\u00ce\u00b1\u00e2\ufffd\u00a2\u00cf\u20ac2\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u201dsubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2014\u011f\ufffd\u203a\u00bc\u011f\ufffd\u0153\u20392|arg( italic_a italic_r italic_g ( italic_\u00cf\u201e start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) | = divide start_ARG italic_\u00ce\u00b1 italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG have the same geometric multiplicity and algebraic multiplicity. On the other hand, the equilibrium point g\u00e2\u02c6\u2014superscript\u011f\ufffd\u2018\u201dg^{*}italic_g start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT is locally asymptotically stable if and only if |a\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2g\u00e2\ufffd\u00a2(\u00cf\u201ej)|>\u00ce\u00b1\u00e2\ufffd\u00a2\u00cf\u20ac2\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u201dsubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2014\u011f\ufffd\u203a\u00bc\u011f\ufffd\u0153\u20392|arg( italic_a italic_r italic_g ( italic_\u00cf\u201e start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) | > divide start_ARG italic_\u00ce\u00b1 italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG and unstable if and only if there exists eigenvalue \u00cf\u201ejsubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2014 start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT of the Jacobian matrix J\u00e2\ufffd\u00a2(g\u00e2\u02c6\u2014)\u011f\ufffd\ufffd\u00bdsuperscript\u011f\ufffd\u2018\u201dJ(g^{*})italic_J ( italic_g start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT ) such that |a\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2g\u00e2\ufffd\u00a2(\u00cf\u201ej)|<\u00ce\u00b1\u00e2\ufffd\u00a2\u00cf\u20ac2\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u201dsubscript\u011f\ufffd\u0153\ufffd\u011f\ufffd\u2018\u2014\u011f\ufffd\u203a\u00bc\u011f\ufffd\u0153\u20392|arg( italic_a italic_r italic_g ( italic_\u00cf\u201e start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) | < divide start_ARG italic_\u00ce\u00b1 italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG. Establishing the well-posedness of a predator-prey system is essential to guarantee that the model is mathematically sound, biologically meaningful, and practically applicable. This ensures that the model will operate predictably, accurately represent real-world interactions, and function as a reliable instrument for scientific research and practical applications in ecology and conservation. In this section, we begin by examining the well-posedness of the system (2) and then proceed to analyse the system (3). All solutions of system (2) exhibit positivity. From the system (2), we have which gives d\u00e2\ufffd\u00a2x1x1=\u00ce\u00a8\u00e2\ufffd\u00a2(x1,x2,x3)\u011f\ufffd\u2018\u2018subscript\u011f\ufffd\u2018\u00a51subscript\u011f\ufffd\u2018\u00a51\u00ce\u00a8subscript\u011f\ufffd\u2018\u00a51subscript\u011f\ufffd\u2018\u00a52subscript\u011f\ufffd\u2018\u00a53 start_ARG italic_d italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG = roman_\u00ce\u00a8 ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ), d\u00e2\ufffd\u00a2x2x2=\u00cf\u02c6\u00e2\ufffd\u00a2(x1,x2,x3)\u011f\ufffd\u2018\u2018subscript\u011f\ufffd\u2018\u00a52subscript\u011f\ufffd\u2018\u00a52\u011f\ufffd\u0153\u201csubscript\u011f\ufffd\u2018\u00a51subscript\u011f\ufffd\u2018\u00a52subscript\u011f\ufffd\u2018\u00a53 start_ARG italic_d italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG start_ARG italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG = italic_\u00cf\u02c6 ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ), and d\u00e2\ufffd\u00a2x3x3=\u00ce\u00a9\u00e2\ufffd\u00a2(x1,x2,x3)\u011f\ufffd\u2018\u2018subscript\u011f\ufffd\u2018\u00a53subscript\u011f\ufffd\u2018\u00a53\u00ce\u00a9subscript\u011f\ufffd\u2018\u00a51subscript\u011f\ufffd\u2018\u00a52subscript\u011f\ufffd\u2018\u00a53 start_ARG italic_d italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG start_ARG italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG = roman_\u00ce\u00a9 ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ). Where, \u00ce\u00a8\u00e2\ufffd\u00a2(x1,x2,x3)=r1\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019x1)\u00e2\u02c6\u2019r2\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019m1)\u00e2\ufffd\u00a2(1+\u00ce\u00b2\u00e2\ufffd\u00a2x1)\u00e2\ufffd\u00a2x2\u00e2\u02c6\u2019q\u00e2\ufffd\u00a2r\u00ce\u00a8subscript\u011f\ufffd\u2018\u00a51subscript\u011f\ufffd\u2018\u00a52subscript\u011f\ufffd\u2018\u00a53subscript\u011f\ufffd\u2018\u017811subscript\u011f\ufffd\u2018\u00a51subscript\u011f\ufffd\u2018\u017821subscript\u011f\ufffd\u2018\u016111\u011f\ufffd\u203a\u00bdsubscript\u011f\ufffd\u2018\u00a51subscript\u011f\ufffd\u2018\u00a52\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178 x_{1})x_{2}-qrroman_\u00ce\u00a8 ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) = italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( 1 - italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) - italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 1 - italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ( 1 + italic_\u00ce\u00b2 italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_q italic_r, \u00cf\u02c6\u00e2\ufffd\u00a2(x1,x2,x3)=r3\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019m1)\u00e2\ufffd\u00a2(1+\u00ce\u00b2\u00e2\ufffd\u00a2x1)\u00e2\ufffd\u00a2x2\u00e2\u02c6\u2019r4\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019m2)\u00e2\ufffd\u00a2x3(1+b\u00e2\ufffd\u00a2x2)\u00e2\u02c6\u2019d1\u011f\ufffd\u0153\u201csubscript\u011f\ufffd\u2018\u00a51subscript\u011f\ufffd\u2018\u00a52subscript\u011f\ufffd\u2018\u00a53subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u2018\u017821subscript\u011f\ufffd\u2018\u016111\u011f\ufffd\u203a\u00bdsubscript\u011f\ufffd\u2018\u00a51subscript\u011f\ufffd\u2018\u00a52subscript\u011f\ufffd\u2018\u017841subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u00a531\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u00a52subscript\u011f\ufffd\u2018\u20181 x_{1})x_{2}- m_{2})x_{3}}{(1+bx_{2})}-d_{1}italic_\u00cf\u02c6 ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) = italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 1 - italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ( 1 + italic_\u00ce\u00b2 italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - divide start_ARG italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT ( 1 - italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG start_ARG ( 1 + italic_b italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) end_ARG - italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, and \u00ce\u00a9\u00e2\ufffd\u00a2(x1,x2,x3)=r5\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019m2)\u00e2\ufffd\u00a2x2(1+b\u00e2\ufffd\u00a2x2)\u00e2\u02c6\u2019d2.\u00ce\u00a9subscript\u011f\ufffd\u2018\u00a51subscript\u011f\ufffd\u2018\u00a52subscript\u011f\ufffd\u2018\u00a53subscript\u011f\ufffd\u2018\u01785subscript\u011f\ufffd\u2018\u017841subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u00a521\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u00a52subscript\u011f\ufffd\u2018\u20182 ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) = divide start_ARG italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT ( 1 - italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG start_ARG ( 1 + italic_b italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) end_ARG - italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT . Now, integrating we get x1\u00e2\ufffd\u00a2(t)subscript\u011f\ufffd\u2018\u00a51\u011f\ufffd\u2018\u00a1x_{1}(t)italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_t )=x1\u00e2\ufffd\u00a2(0)subscript\u011f\ufffd\u2018\u00a510x_{1}(0)italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( 0 ) exp [ \u00e2\u02c6\u00ab0t(\u00ce\u00a8\u00e2\ufffd\u00a2(x1,x2,x3))\u00e2\ufffd\u00a2\u011f\ufffd\u2018\u2018tsuperscriptsubscript0\u011f\ufffd\u2018\u00a1\u00ce\u00a8subscript\u011f\ufffd\u2018\u00a51subscript\u011f\ufffd\u2018\u00a52subscript\u011f\ufffd\u2018\u00a53differential-d\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT ( roman_\u00ce\u00a8 ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) ) italic_d italic_t ] , x2\u00e2\ufffd\u00a2(t)subscript\u011f\ufffd\u2018\u00a52\u011f\ufffd\u2018\u00a1x_{2}(t)italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_t )=x2\u00e2\ufffd\u00a2(0)subscript\u011f\ufffd\u2018\u00a520x_{2}(0)italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 0 )exp [ \u00e2\u02c6\u00ab0t(\u00cf\u02c6\u00e2\ufffd\u00a2(x1,x2,x3))\u00e2\ufffd\u00a2\u011f\ufffd\u2018\u2018tsuperscriptsubscript0\u011f\ufffd\u2018\u00a1\u011f\ufffd\u0153\u201csubscript\u011f\ufffd\u2018\u00a51subscript\u011f\ufffd\u2018\u00a52subscript\u011f\ufffd\u2018\u00a53differential-d\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT ( italic_\u00cf\u02c6 ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) ) italic_d italic_t ] , x3\u00e2\ufffd\u00a2(t)subscript\u011f\ufffd\u2018\u00a53\u011f\ufffd\u2018\u00a1x_{3}(t)italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_t )=x3\u00e2\ufffd\u00a2(0)subscript\u011f\ufffd\u2018\u00a530x_{3}(0)italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( 0 )exp [ \u00e2\u02c6\u00ab0t(\u00ce\u00a9\u00e2\ufffd\u00a2(x1,x2,x3))\u00e2\ufffd\u00a2\u011f\ufffd\u2018\u2018tsuperscriptsubscript0\u011f\ufffd\u2018\u00a1\u00ce\u00a9subscript\u011f\ufffd\u2018\u00a51subscript\u011f\ufffd\u2018\u00a52subscript\u011f\ufffd\u2018\u00a53differential-d\u011f\ufffd\u2018\u00a1 start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT ( roman_\u00ce\u00a9 ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) ) italic_d italic_t ]. Hence, x1\u00e2\ufffd\u00a2(t)>0subscript\u011f\ufffd\u2018\u00a51\u011f\ufffd\u2018\u00a10x_{1}(t)>0italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_t ) > 0, x2\u00e2\ufffd\u00a2(t)>0subscript\u011f\ufffd\u2018\u00a52\u011f\ufffd\u2018\u00a10x_{2}(t)>0italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_t ) > 0, and x3\u00e2\ufffd\u00a2(t)>0subscript\u011f\ufffd\u2018\u00a53\u011f\ufffd\u2018\u00a10x_{3}(t)>0italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_t ) > 0. Hence, the theorem. \u00e2\u02c6\ufffd All solutions of system (2) are bounded. To show the boundedness of all the solutions of the system (2), we define a function X\u00e2\ufffd\u00a2(t)=x1\u00e2\ufffd\u00a2(t)+x2\u00e2\ufffd\u00a2(t)r3+x3\u00e2\ufffd\u00a2(t)r3\u00e2\ufffd\u00a2r5\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\u00a51\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\u00a52\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u2018\u00a53\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u2018\u01785X(t)=x_{1}(t)+ ( italic_t ) = italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_t ) + divide start_ARG italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_t ) end_ARG start_ARG italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG + divide start_ARG italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_t ) end_ARG start_ARG italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT end_ARG. Now, by differentiating X with respect to time \u00e2\u20ac\u02dct\u00e2\u20ac\u2122 we get Now, using equations given in (2), we have Let V\u011f\ufffd\u2018\u2030Vitalic_V be any positive real number and V\u00e2\u2030\u00a4m\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2n\u00e2\ufffd\u00a2(d1,d2)\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u20182V min(d_{1},d_{2})italic_V \u00e2\u2030\u00a4 italic_m italic_i italic_n ( italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ). Then Now, by applying the notions of differential inequality, we obtain 0<X\u00e2\ufffd\u00a2(t)\u00e2\u2030\u00a4\u00ce\u00a9V\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019e\u00e2\u02c6\u2019V\u00e2\ufffd\u00a2t)+X\u00e2\ufffd\u00a2(0)\u00e2\ufffd\u00a2e\u00e2\u02c6\u2019V\u00e2\ufffd\u00a2t0\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1\u00ce\u00a9\u011f\ufffd\u2018\u20301superscript\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u20390superscript\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\u2030\u011f\ufffd\u2018\u00a10<X(t) < italic_X ( italic_t ) \u00e2\u2030\u00a4 divide start_ARG roman_\u00ce\u00a9 end_ARG start_ARG italic_V end_ARG ( 1 - italic_e start_POSTSUPERSCRIPT - italic_V italic_t end_POSTSUPERSCRIPT ) + italic_X ( 0 ) italic_e start_POSTSUPERSCRIPT - italic_V italic_t end_POSTSUPERSCRIPT. However, 0<X\u00e2\ufffd\u00a2(t)\u00e2\u2030\u00a4\u00ce\u00a9V0\u011f\ufffd\u2018\u2039\u011f\ufffd\u2018\u00a1\u00ce\u00a9\u011f\ufffd\u2018\u20300<X(t) < italic_X ( italic_t ) \u00e2\u2030\u00a4 divide start_ARG roman_\u00ce\u00a9 end_ARG start_ARG italic_V end_ARG, when t\u00e2\u2020\u2019\u00e2\u02c6\ufffd\u00e2\u2020\u2019\u011f\ufffd\u2018\u00a1t \u00e2\u2020\u2019 \u00e2\u02c6\ufffd. Therefore, all the solutions of the system (3) are restricted to the region \u00ce\u00b6=((x1,x2,x3):0\u00e2\u2030\u00a4x1+x2r3+x3r3\u00e2\ufffd\u00a2r5\u00e2\u2030\u00a4\u00ce\u00a9V+\u00ce\u02dc,\u00e2\u02c6\u20ac\u00ce\u02dc>0) x_{1}+ _{3}r_{5}} = ( ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) : 0 \u00e2\u2030\u00a4 italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + divide start_ARG italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG start_ARG italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG + divide start_ARG italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG start_ARG italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT end_ARG \u00e2\u2030\u00a4 divide start_ARG roman_\u00ce\u00a9 end_ARG start_ARG italic_V end_ARG + roman_\u00ce\u02dc , \u00e2\u02c6\u20ac roman_\u00ce\u02dc > 0 ). The boundedness of the system (2) is consequently established. \u00e2\u02c6\ufffd The solutions of the system (3) starting from (x1\u00e2\ufffd\u00a2(0),x2\u00e2\ufffd\u00a2(0),x3\u00e2\ufffd\u00a2(0))\u00e2\u02c6\u02c6R+3subscript\u011f\ufffd\u2018\u00a510subscript\u011f\ufffd\u2018\u00a520subscript\u011f\ufffd\u2018\u00a530subscriptsuperscript\u011f\ufffd\u2018\u20263(x_{1}(0),x_{2}(0),x_{3}(0)) R^{3}_{+}( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( 0 ) , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 0 ) , italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( 0 ) ) \u00e2\u02c6\u02c6 italic_R start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT + end_POSTSUBSCRIPT are non-negative and bounded in region D. To commence, let us demonstrate the non-negativity of the solutions x1\u00e2\ufffd\u00a2(t)subscript\u011f\ufffd\u2018\u00a51\u011f\ufffd\u2018\u00a1x_{1}(t)italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_t ) of the system (3) i.e., x1\u00e2\ufffd\u00a2(t)\u00e2\u2030\u00a50subscript\u011f\ufffd\u2018\u00a51\u011f\ufffd\u2018\u00a10x_{1}(t) 0italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_t ) \u00e2\u2030\u00a5 0, \u00e2\u02c6\u20act\u00e2\u2030\u00a5t0for-all\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\u00a10 t t_{0}\u00e2\u02c6\u20ac italic_t \u00e2\u2030\u00a5 italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. To prove the non-negativity of the solutions of the system (3), we follow the approach given in [39]. Now, let us assume that the above inequality is not true, then \u00e2\u02c6\u0192t>t0\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\u00a10 t>t_{0}\u00e2\u02c6\u0192 italic_t > italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT such that Now, using the first equation of the system (3) and the equation (6), we have By the use of Lemma (3), we find that This leads to a contradiction since x1\u00e2\ufffd\u00a2(t1+)<0subscript\u011f\ufffd\u2018\u00a51superscriptsubscript\u011f\ufffd\u2018\u00a110x_{1}(t_{1}^{+})<0italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ) < 0. Thus, x1\u00e2\ufffd\u00a2(t)\u00e2\u2030\u00a50subscript\u011f\ufffd\u2018\u00a51\u011f\ufffd\u2018\u00a10x_{1}(t) 0italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_t ) \u00e2\u2030\u00a5 0, \u00e2\u02c6\u20act\u00e2\u2030\u00a5t0for-all\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\u00a10 t t_{0}\u00e2\u02c6\u20ac italic_t \u00e2\u2030\u00a5 italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. In a similar manner, we can ensure x2\u00e2\ufffd\u00a2(t)\u00e2\u2030\u00a50subscript\u011f\ufffd\u2018\u00a52\u011f\ufffd\u2018\u00a10x_{2}(t) 0italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_t ) \u00e2\u2030\u00a5 0, x3\u00e2\ufffd\u00a2(t)\u00e2\u2030\u00a50,\u00e2\u02c6\u20act\u00e2\u2030\u00a5t0formulae-sequencesubscript\u011f\ufffd\u2018\u00a53\u011f\ufffd\u2018\u00a10for-all\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\u00a10x_{3}(t) 0, t t_{0}italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_t ) \u00e2\u2030\u00a5 0 , \u00e2\u02c6\u20ac italic_t \u00e2\u2030\u00a5 italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. Now, we have to prove the boundedness of the solutions of the system (3). To achieve this, we shall contemplate a function, W\u00e2\ufffd\u00a2(t)=x1\u00e2\ufffd\u00a2(t)+x2\u00e2\ufffd\u00a2(t)r3+x3\u00e2\ufffd\u00a2(t)r3\u00e2\ufffd\u00a2r5\u011f\ufffd\u2018\u0160\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\u00a51\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\u00a52\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u2018\u00a53\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u2018\u01785W(t)=x_{1}(t)+ ( italic_t ) = italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_t ) + divide start_ARG italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_t ) end_ARG start_ARG italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG + divide start_ARG italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_t ) end_ARG start_ARG italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT end_ARG. Thus, we have Now, considering any real number \u00ce\u201d\u00ce\u201d such that Let us consider, 0<\u00ce\u201d<m\u00e2\ufffd\u00a2i\u00e2\ufffd\u00a2n\u00e2\ufffd\u00a2(d1,d2)0\u00ce\u201d\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u2013\u011f\ufffd\u2018\u203asubscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u201820< < roman_\u00ce\u201d < italic_m italic_i italic_n ( italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) then we have, Now, utilising Lemma (1) provided in Section 3, we obtain where, E\u00ce\u00b1subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u203a\u00bcE_{ start_POSTSUBSCRIPT italic_\u00ce\u00b1 end_POSTSUBSCRIPT is the Mittag\u00e2\u20ac\u201cLeffler function. Hence, Therefore, all the solutions of the system described in equation (3) originating in region R+3subscriptsuperscript\u011f\ufffd\u2018\u20263R^{3}_{+}italic_R start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT + end_POSTSUBSCRIPT enters the region \u00ce\u00a5\u00ce\u00a5 defined by \u00e2\u02c6\ufffd For nonnegative initial conditions, system (3) always exhibits unique solutions. We will utilise the methodology described in [53] in order to prove the existence of unique solutions of the system (3). Let us consider, the region Let, x=(x1,x2,x3)\u00e2\u02c6\u02c6F\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\u00a51subscript\u011f\ufffd\u2018\u00a52subscript\u011f\ufffd\u2018\u00a53\u011f\ufffd\ufffd\u00b9x=(x_{1},x_{2},x_{3}) Fitalic_x = ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) \u00e2\u02c6\u02c6 italic_F and x\u00c2\u00af=(x1\u00c2\u00af,x2\u00c2\u00af,x3\u00c2\u00af)\u00e2\u02c6\u02c6F\u00c2\u00af\u011f\ufffd\u2018\u00a5\u00c2\u00afsubscript\u011f\ufffd\u2018\u00a51\u00c2\u00afsubscript\u011f\ufffd\u2018\u00a52\u00c2\u00afsubscript\u011f\ufffd\u2018\u00a53\u011f\ufffd\ufffd\u00b9 Fover\u00c2\u00af start_ARG italic_x end_ARG = ( over\u00c2\u00af start_ARG italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG , over\u00c2\u00af start_ARG italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG , over\u00c2\u00af start_ARG italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG ) \u00e2\u02c6\u02c6 italic_F. Now, let us consider, a function where, Now, we have we find, In a Similar way, we get From equations (7), (8), and (9), we get where, Y=m\u00e2\ufffd\u00a2a\u00e2\ufffd\u00a2x\u00e2\ufffd\u00a2{y1,y2,y3}\u011f\ufffd\u2018\u0152\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\u00a61subscript\u011f\ufffd\u2018\u00a62subscript\u011f\ufffd\u2018\u00a63Y=max = italic_m italic_a italic_x { italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT } and y1=r1+r1\u00e2\ufffd\u00a2|x1+x1\u00c2\u00af|+r2\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019m1)\u00e2\ufffd\u00a2(1+r3)\u00e2\ufffd\u00a2|x2\u00c2\u00af|+r2\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019m1)\u00e2\ufffd\u00a2\u00ce\u00b2\u00e2\ufffd\u00a2(1+r3)\u00e2\ufffd\u00a2|x1\u00e2\ufffd\u00a2x2|+r2\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019m1)\u00e2\ufffd\u00a2\u00ce\u00b2\u00e2\ufffd\u00a2(1+r3)\u00e2\ufffd\u00a2|x1\u00c2\u00af\u00e2\ufffd\u00a2x2|+|q\u00e2\ufffd\u00a2r|subscript\u011f\ufffd\u2018\u00a61subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u00a51\u00c2\u00afsubscript\u011f\ufffd\u2018\u00a51subscript\u011f\ufffd\u2018\u017821subscript\u011f\ufffd\u2018\u016111subscript\u011f\ufffd\u2018\u01783\u00c2\u00afsubscript\u011f\ufffd\u2018\u00a52subscript\u011f\ufffd\u2018\u017821subscript\u011f\ufffd\u2018\u01611\u011f\ufffd\u203a\u00bd1subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u2018\u00a51subscript\u011f\ufffd\u2018\u00a52subscript\u011f\ufffd\u2018\u017821subscript\u011f\ufffd\u2018\u01611\u011f\ufffd\u203a\u00bd1subscript\u011f\ufffd\u2018\u01783\u00c2\u00afsubscript\u011f\ufffd\u2018\u00a51subscript\u011f\ufffd\u2018\u00a52\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178y_{1}=r_{1}+r_{1}|x_{1}+ }(1-m_{1}) _{2}|+|qr|italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT | italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + over\u00c2\u00af start_ARG italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG | + italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 1 - italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ( 1 + italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) | over\u00c2\u00af start_ARG italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG | + italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 1 - italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_\u00ce\u00b2 ( 1 + italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) | italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | + italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 1 - italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_\u00ce\u00b2 ( 1 + italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) | over\u00c2\u00af start_ARG italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | + | italic_q italic_r |, y2=r2\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019m1)\u00e2\ufffd\u00a2(1+r3)\u00e2\ufffd\u00a2|x1|+r2\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019m1)\u00e2\ufffd\u00a2\u00ce\u00b2\u00e2\ufffd\u00a2(1+r3)\u00e2\ufffd\u00a2|x2\u00c2\u00af2|+r4\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019m2)\u00e2\ufffd\u00a2(1+r5)\u00e2\ufffd\u00a2|x3\u00c2\u00af\u00e2\ufffd\u00a2(x2\u00e2\u02c6\u2019x2\u00c2\u00af)(1+b\u00e2\ufffd\u00a2x2)\u00e2\ufffd\u00a2(1+b\u00e2\ufffd\u00a2x2\u00c2\u00af)|+|d1|subscript\u011f\ufffd\u2018\u00a62subscript\u011f\ufffd\u2018\u017821subscript\u011f\ufffd\u2018\u016111subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u2018\u00a51subscript\u011f\ufffd\u2018\u017821subscript\u011f\ufffd\u2018\u01611\u011f\ufffd\u203a\u00bd1subscript\u011f\ufffd\u2018\u01783superscript\u00c2\u00afsubscript\u011f\ufffd\u2018\u00a522subscript\u011f\ufffd\u2018\u017841subscript\u011f\ufffd\u2018\u016121subscript\u011f\ufffd\u2018\u01785\u00c2\u00afsubscript\u011f\ufffd\u2018\u00a53subscript\u011f\ufffd\u2018\u00a52\u00c2\u00afsubscript\u011f\ufffd\u2018\u00a521\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u00a521\u011f\ufffd\u2018\ufffd\u00c2\u00afsubscript\u011f\ufffd\u2018\u00a52subscript\u011f\ufffd\u2018\u20181y_{2}=r_{2}(1-m_{1})(1+r_{3})|x_{1}|+r_{2}(1-m_{1}) {2}|+r_{4}(1-m_{2})(1+r_{5})| 1+b start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 1 - italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ( 1 + italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) | italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT | + italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 1 - italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_\u00ce\u00b2 ( 1 + italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) | over\u00c2\u00af start_ARG italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT | + italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT ( 1 - italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ( 1 + italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ) | divide start_ARG over\u00c2\u00af start_ARG italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG ( italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - over\u00c2\u00af start_ARG italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG ) end_ARG start_ARG ( 1 + italic_b italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ( 1 + italic_b over\u00c2\u00af start_ARG italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG ) end_ARG | + | italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT |, and y3=r4\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019m2)\u00e2\ufffd\u00a2(1+r5)\u00e2\ufffd\u00a2|x2(1+b\u00e2\ufffd\u00a2x2)|+|d2|subscript\u011f\ufffd\u2018\u00a63subscript\u011f\ufffd\u2018\u017841subscript\u011f\ufffd\u2018\u016121subscript\u011f\ufffd\u2018\u01785subscript\u011f\ufffd\u2018\u00a521\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u00a52subscript\u011f\ufffd\u2018\u20182y_{3}=r_{4}(1-m_{2})(1+r_{5})| start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT ( 1 - italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ( 1 + italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ) | divide start_ARG italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG start_ARG ( 1 + italic_b italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) end_ARG | + | italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT |. Therefore, the function G(x) fulfils the Lipschitz condition. Therefore, based on Lemma (2), it may be inferred that the system described in equation (3) has a unique solution inside the specified domain F. \u00e2\u02c6\ufffd In the context of a predator-prey dynamical system, equilibrium points refer to specific values of the population sizes at which the rates of change of the populations cease to exist. These equilibrium points play a crucial role in understanding the dynamics of predator-prey interactions. These points delineate a state of equilibrium in which populations remain constant and exhibit no changes over time. A point (x1e\u00e2\ufffd\u00a2q,x2e\u00e2\ufffd\u00a2q,x3e\u00e2\ufffd\u00a2q)superscriptsubscript\u011f\ufffd\u2018\u00a51\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u00a52\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u00a53\u011f\ufffd\u2018\u2019\u011f\ufffd\u2018\ufffd(x_{1}^{eq},x_{2}^{eq},x_{3}^{eq})( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_e italic_q end_POSTSUPERSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_e italic_q end_POSTSUPERSCRIPT , italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_e italic_q end_POSTSUPERSCRIPT ) is said to be an equilibrium point of the system (2) if they satisfy the following equations: Now, solving these equations we get four biologically feasible equilibrium points and these are given by Vanishing equilibrium point Ev\u00e2\ufffd\u00a2(0,0,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a3000E_{v}(0,0,0)italic_E start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( 0 , 0 , 0 ), Axial equilibrium point Ea\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019q\u00e2\ufffd\u00a2rr1,0,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffd1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u0178100E_{a}(1- start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( 1 - divide start_ARG italic_q italic_r end_ARG start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG , 0 , 0 ), Top predator free equilibrium point Et\u00e2\ufffd\u00a2(A,B,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a1\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b50E_{t}(A,B,0)italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_A , italic_B , 0 ), and Coexisting equilibrium point Ec\u00e2\ufffd\u00a2(C,D,E)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b8E_{c}(C,D,E)italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( italic_C , italic_D , italic_E ). Here, vanishing equilibrium point Ev\u00e2\ufffd\u00a2(0,0,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a3000E_{v}(0,0,0)italic_E start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( 0 , 0 , 0 ) represents the situation in which all three species perish. Axial equilibrium point Ea\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019q\u00e2\ufffd\u00a2rr1,0,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffd1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u0178100E_{a}(1- start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( 1 - divide start_ARG italic_q italic_r end_ARG start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG , 0 , 0 ) represents a situation in which only the prey persists and all the predators vanish. Top predator free equilibrium point Et\u00e2\ufffd\u00a2(A,B,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a1\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b50E_{t}(A,B,0)italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_A , italic_B , 0 ) represents the situation in which only the top predator vanishes while coexisting equilibrium point Ec\u00e2\ufffd\u00a2(C,D,E)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b8E_{c}(C,D,E)italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( italic_C , italic_D , italic_E ) signifies the situation in which all three species coexist. Morever, and Here, \u00cf\u20301=(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r3\u00e2\ufffd\u00a2(\u00e2\u02c6\u20194\u00e2\ufffd\u00a2\u00ce\u00b2\u00e2\ufffd\u00a2d1\u00e2\u02c6\u2019r2\u00e2\ufffd\u00a2r3+m1\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r3)subscript\u011f\ufffd\u0153\u201d11subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u017834\u011f\ufffd\u203a\u00bdsubscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01783 d_{1}-r_{2}r_{3}+m_{1}r_{2}r_{3})}italic_\u00cf\u2030 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = square-root start_ARG ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( - 4 italic_\u00ce\u00b2 italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) end_ARG, \u00cf\u20302=(d1\u00e2\ufffd\u00a2r12+(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2(r\u00e2\ufffd\u00a2q\u00e2\u02c6\u2019r1)\u00e2\ufffd\u00a2(\u00ce\u00b2\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2q\u00e2\u02c6\u2019r1\u00e2\u02c6\u2019\u00ce\u00b2\u00e2\ufffd\u00a2r1)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r3)subscript\u011f\ufffd\u0153\u201d2subscript\u011f\ufffd\u2018\u20181superscriptsubscript\u011f\ufffd\u2018\u0178121subscript\u011f\ufffd\u2018\u01611\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u203a\u00bd\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u203a\u00bdsubscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01783 rq-r_{1}- r_{1})r_{% 2}r_{3})italic_\u00cf\u2030 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = ( italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ( italic_r italic_q - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ( italic_\u00ce\u00b2 italic_r italic_q - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - italic_\u00ce\u00b2 italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ), \u00cf\u20303=(d2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)2\u00e2\ufffd\u00a2r22\u00e2\ufffd\u00a2r3\u00e2\u02c6\u2019(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2(d1\u00e2\ufffd\u00a2r1\u00e2\u02c6\u2019(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2(r\u00e2\ufffd\u00a2q\u00e2\u02c6\u2019r1)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r3)\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5)subscript\u011f\ufffd\u0153\u201d3subscript\u011f\ufffd\u2018\u20182superscript1subscript\u011f\ufffd\u2018\u016112superscriptsubscript\u011f\ufffd\u2018\u017822subscript\u011f\ufffd\u2018\u017831subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u017811subscript\u011f\ufffd\u2018\u01611\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785 (rq-r_{1})r_{2}r_{3})r_{4}r_{5})italic_\u00cf\u2030 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = ( italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT - ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ( italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ( italic_r italic_q - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ), \u00cf\u20304=(2\u00e2\ufffd\u00a2d1\u00e2\ufffd\u00a2d2\u00e2\ufffd\u00a2r1+(r\u00e2\ufffd\u00a2q\u00e2\u02c6\u2019r1)\u00e2\ufffd\u00a2r3\u00e2\ufffd\u00a2(d2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2+(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2(r\u00e2\ufffd\u00a2q\u00e2\u02c6\u2019r1)\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5))subscript\u011f\ufffd\u0153\u201d42subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u20182subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u017821subscript\u011f\ufffd\u2018\u01612\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785 rq-r_{1})r_{4}r_{5}))italic_\u00cf\u2030 start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = ( 2 italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + ( italic_r italic_q - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ( italic_r italic_q - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ) ), \u00cf\u20305=(r1\u00e2\ufffd\u00a2(\u00e2\u02c6\u2019d2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)2\u00e2\ufffd\u00a2r22\u00e2\ufffd\u00a2r3+2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2(d1\u00e2\ufffd\u00a2r1\u00e2\u02c6\u2019(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2(r\u00e2\ufffd\u00a2q\u00e2\u02c6\u2019r1)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r3)\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5)+\u00ce\u00b2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2(2\u00e2\ufffd\u00a2d1\u00e2\ufffd\u00a2d2\u00e2\ufffd\u00a2r1+(r\u00e2\ufffd\u00a2q\u00e2\u02c6\u2019r1)\u00e2\ufffd\u00a2r3\u00e2\ufffd\u00a2(d2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2+2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2(r\u00e2\ufffd\u00a2q\u00e2\u02c6\u2019r\u00e2\u02c6\u20191)\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5)))subscript\u011f\ufffd\u0153\u201d5subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u20182superscript1subscript\u011f\ufffd\u2018\u016112superscriptsubscript\u011f\ufffd\u2018\u017822subscript\u011f\ufffd\u2018\u0178321subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u017811subscript\u011f\ufffd\u2018\u01611\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785\u011f\ufffd\u203a\u00bd1subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u017822subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u20182subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u0178221subscript\u011f\ufffd\u2018\u01612\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785 1+m_{1})(rq-r_{1})r_{2}r_{3})r_{4}r_{5})+ +(rq-r_{1})r_{3}(d_{2}(-1+m_{1})r_{2}+2(-1+m_{2})(rq-r-1)r_{4}r_{5})))italic_\u00cf\u2030 start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = ( italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( - italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + 2 ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ( italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ( italic_r italic_q - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ) + italic_\u00ce\u00b2 ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 2 italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + ( italic_r italic_q - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + 2 ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ( italic_r italic_q - italic_r - 1 ) italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ) ) ). Conditions of existence: Vanishing equilibrium point Ev\u00e2\ufffd\u00a2(0,0,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a3000E_{v}(0,0,0)italic_E start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( 0 , 0 , 0 ) always exists. Axial equilibrium point Ea\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019q\u00e2\ufffd\u00a2rr1,0,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffd1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u0178100E_{a}(1- start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( 1 - divide start_ARG italic_q italic_r end_ARG start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG , 0 , 0 ) exists iff r<r1q\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\ufffdr< < divide start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG italic_q end_ARG. Top predator free equilibrium point Et\u00e2\ufffd\u00a2(A,B,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a1\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b50E_{t}(A,B,0)italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_A , italic_B , 0 ) exists iff r<r1q\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\ufffdr< < divide start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG italic_q end_ARG and r2>\u00e2\u02c6\u2019d1\u00e2\ufffd\u00a2r12\u00e2\u02c6\u2019\u00ce\u00b2\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2q2\u00e2\ufffd\u00a2r3+\u00cf\u20306subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u20181superscriptsubscript\u011f\ufffd\u2018\u017812\u011f\ufffd\u203a\u00bdsuperscript\u011f\ufffd\u2018\u01782superscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u0153\u201d6r_{2}> r^{2}q^{2}r_{3}+ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT > divide start_ARG - italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG - italic_\u00ce\u00b2 italic_r start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_q start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + italic_\u00cf\u2030 start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT end_ARG. Coexisting equilibrium point Ec\u00e2\ufffd\u00a2(C,D,E)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b8E_{c}(C,D,E)italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( italic_C , italic_D , italic_E ) exists iff r1>d2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2c1\u00e2\ufffd\u00a2d2+(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785r_{1}> start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT > divide start_ARG italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG start_ARG italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT end_ARG, r3>\u00e2\u02c6\u2019d1\u00e2\ufffd\u00a2\u00cf\u203072(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2\u00cf\u20308\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2\u00cf\u20309subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u2018\u20181superscriptsubscript\u011f\ufffd\u0153\u201d721subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u0153\u201d8subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u0153\u201d9r_{3}>- start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT > - divide start_ARG italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_\u00cf\u2030 start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_\u00cf\u2030 start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_\u00cf\u2030 start_POSTSUBSCRIPT 9 end_POSTSUBSCRIPT end_ARG, r4>c1\u00e2\ufffd\u00a2d2r5\u00e2\u02c6\u2019m2\u00e2\ufffd\u00a2r5subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u20182subscript\u011f\ufffd\u2018\u01785subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01785r_{4}> start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT > divide start_ARG italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG start_ARG italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT - italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT end_ARG, and r<c1\u00e2\ufffd\u00a2d2\u00e2\ufffd\u00a2r1+d2\u00e2\ufffd\u00a2(r2\u00e2\u02c6\u2019m1\u00e2\ufffd\u00a2r2)+(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2r1\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5q\u00e2\ufffd\u00a2(c1\u00e2\ufffd\u00a2d2+(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5)\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u20182subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u20182subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u017821subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785r< _{1}d_{2}+(-1+m_{2})r_{4}r_{5})}italic_r < divide start_ARG italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) + ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT end_ARG start_ARG italic_q ( italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ) end_ARG. Here, \u00cf\u20306=\u00ce\u00b2\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2m1\u00e2\ufffd\u00a2q2\u00e2\ufffd\u00a2r3+r\u00e2\ufffd\u00a2q\u00e2\ufffd\u00a2r1\u00e2\ufffd\u00a2r3+2\u00e2\ufffd\u00a2\u00ce\u00b2\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2q\u00e2\ufffd\u00a2r1\u00e2\ufffd\u00a2r3\u00e2\u02c6\u2019r\u00e2\ufffd\u00a2m1\u00e2\ufffd\u00a2q\u00e2\ufffd\u00a2r1\u00e2\ufffd\u00a2r3\u00e2\u02c6\u20192\u00e2\ufffd\u00a2\u00ce\u00b2\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2m1\u00e2\ufffd\u00a2q\u00e2\ufffd\u00a2r1\u00e2\ufffd\u00a2r3\u00e2\u02c6\u2019r12\u00e2\ufffd\u00a2r3\u00e2\u02c6\u2019\u00ce\u00b2\u00e2\ufffd\u00a2r12\u00e2\ufffd\u00a2r3+m1\u00e2\ufffd\u00a2r12\u00e2\ufffd\u00a2r3+\u00ce\u00b2\u00e2\ufffd\u00a2m1\u00e2\ufffd\u00a2r12\u00e2\ufffd\u00a2r3subscript\u011f\ufffd\u0153\u201d6\u011f\ufffd\u203a\u00bdsuperscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01611superscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\u01783\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u017832\u011f\ufffd\u203a\u00bd\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01783\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01611\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u017832\u011f\ufffd\u203a\u00bd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01611\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01783superscriptsubscript\u011f\ufffd\u2018\u017812subscript\u011f\ufffd\u2018\u01783\u011f\ufffd\u203a\u00bdsuperscriptsubscript\u011f\ufffd\u2018\u017812subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u2018\u01611superscriptsubscript\u011f\ufffd\u2018\u017812subscript\u011f\ufffd\u2018\u01783\u011f\ufffd\u203a\u00bdsubscript\u011f\ufffd\u2018\u01611superscriptsubscript\u011f\ufffd\u2018\u017812subscript\u011f\ufffd\u2018\u01783 r^{2}m_{1}q^{2}r_{3}+rqr_{1}r_{3}+2 rqr_{1}r_{3}-rm_{1}% qr_{1}r_{3}-2 rm_{1}qr_{1}r_{3}-r_{1}^{2}r_{3}- r_{1}^{2}r_{3}+m_{1}% r_{1}^{2}r_{3}+ m_{1}r_{1}^{2}r_{3}italic_\u00cf\u2030 start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT = italic_\u00ce\u00b2 italic_r start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_q start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + italic_r italic_q italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + 2 italic_\u00ce\u00b2 italic_r italic_q italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT - italic_r italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_q italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT - 2 italic_\u00ce\u00b2 italic_r italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_q italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT - italic_\u00ce\u00b2 italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + italic_\u00ce\u00b2 italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT, \u00cf\u20307=(c1\u00e2\ufffd\u00a2d2\u00e2\ufffd\u00a2r1+\u00ce\u00b2\u00e2\ufffd\u00a2d2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2+(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2r1\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5)subscript\u011f\ufffd\u0153\u201d7subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u20182subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u203a\u00bdsubscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u017821subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785 d_{2}(-1+m_{1})r_{2}+(-1+m_{2})r_{1}r_{4}r_{% 5})italic_\u00cf\u2030 start_POSTSUBSCRIPT 7 end_POSTSUBSCRIPT = ( italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_\u00ce\u00b2 italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ), \u00cf\u20308=(\u00ce\u00b2\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2q\u00e2\u02c6\u2019r1\u00e2\u02c6\u2019\u00ce\u00b2\u00e2\ufffd\u00a2r1)subscript\u011f\ufffd\u0153\u201d8\u011f\ufffd\u203a\u00bd\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u203a\u00bdsubscript\u011f\ufffd\u2018\u01781 rq-r_{1}- r_{1})italic_\u00cf\u2030 start_POSTSUBSCRIPT 8 end_POSTSUBSCRIPT = ( italic_\u00ce\u00b2 italic_r italic_q - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - italic_\u00ce\u00b2 italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ), \u00cf\u20309=(c1\u00e2\ufffd\u00a2d2+(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5)\u00e2\ufffd\u00a2(c1\u00e2\ufffd\u00a2d2\u00e2\ufffd\u00a2(r\u00e2\ufffd\u00a2q\u00e2\u02c6\u2019r1)+d2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2+(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2(r\u00e2\ufffd\u00a2q\u00e2\u02c6\u2019r1)\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5)subscript\u011f\ufffd\u0153\u201d9subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u20182\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u017821subscript\u011f\ufffd\u2018\u01612\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785 1})r_{2}+(-1+m_{2})(rq-r_{1})r_{4}r_{5})italic_\u00cf\u2030 start_POSTSUBSCRIPT 9 end_POSTSUBSCRIPT = ( italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ) ( italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_r italic_q - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) + italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ( italic_r italic_q - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ). Local stability: The vanishing equilibrium point Ev\u00e2\ufffd\u00a2(0,0,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a3000E_{v}(0,0,0)italic_E start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( 0 , 0 , 0 ) is locally stable iff r>r1q\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\ufffdr> > divide start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG italic_q end_ARG. The eigenvalues of the Jacobian matrix at Ev\u00e2\ufffd\u00a2(0,0,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a3000E_{v}(0,0,0)italic_E start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( 0 , 0 , 0 ), denoted by Jv\u00e2\ufffd\u00a2asubscript\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\ufffdJ_{va}italic_J start_POSTSUBSCRIPT italic_v italic_a end_POSTSUBSCRIPT are \u00e2\u02c6\u2019d1subscript\u011f\ufffd\u2018\u20181-d_{1}- italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, \u00e2\u02c6\u2019d2subscript\u011f\ufffd\u2018\u20182-d_{2}- italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, and \u00e2\u02c6\u2019r\u00e2\ufffd\u00a2q+r1\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u01781-rq+r_{1}- italic_r italic_q + italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. The condition for all these eigenvalues to be negative is that r>r1q\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\ufffdr> > divide start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG italic_q end_ARG. Therefore, the result. \u00e2\u02c6\ufffd The axial equilibrium point Ea\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019q\u00e2\ufffd\u00a2rr1,0,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffd1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u0178100E_{a}(1- start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( 1 - divide start_ARG italic_q italic_r end_ARG start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG , 0 , 0 ) is locally stable iff r<r1q\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\ufffdr< < divide start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG italic_q end_ARG and r2<\u00e2\u02c6\u2019d1\u00e2\ufffd\u00a2r12\u00e2\u02c6\u2019\u00ce\u00b2\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2q2\u00e2\ufffd\u00a2r3+\u00cf\u20306subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u20181superscriptsubscript\u011f\ufffd\u2018\u017812\u011f\ufffd\u203a\u00bdsuperscript\u011f\ufffd\u2018\u01782superscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u0153\u201d6r_{2}< r^{2}q^{2}r_{3}+ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT < divide start_ARG - italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG - italic_\u00ce\u00b2 italic_r start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_q start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + italic_\u00cf\u2030 start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT end_ARG. The eigenvalues of the Jacobian matrix Ja\u00e2\ufffd\u00a2xsubscript\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5J_{ax}italic_J start_POSTSUBSCRIPT italic_a italic_x end_POSTSUBSCRIPT around Ea\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019q\u00e2\ufffd\u00a2rr1,0,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffd1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u0178100E_{a}(1- start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( 1 - divide start_ARG italic_q italic_r end_ARG start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG , 0 , 0 ) are \u00e2\u02c6\u2019d2subscript\u011f\ufffd\u2018\u20182-d_{2}- italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, r\u00e2\ufffd\u00a2q\u00e2\u02c6\u2019r1\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u01781rq-r_{1}italic_r italic_q - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, and \u00e2\u02c6\u2019d1\u00e2\ufffd\u00a2r12+\u00ce\u00b2\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2q2\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r3\u00e2\u02c6\u2019r2\u00e2\ufffd\u00a2\u00cf\u20306r12subscript\u011f\ufffd\u2018\u20181superscriptsubscript\u011f\ufffd\u2018\u017812\u011f\ufffd\u203a\u00bdsuperscript\u011f\ufffd\u2018\u01782superscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u0153\u201d6superscriptsubscript\u011f\ufffd\u2018\u017812 r^{2}q^{2}r_{2}r_{3}-r_{2} start_ARG - italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_\u00ce\u00b2 italic_r start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_q start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT - italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_\u00cf\u2030 start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT end_ARG start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG. Now, the axial equilibrium point Ea\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019q\u00e2\ufffd\u00a2rr1,0,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffd1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u0178100E_{a}(1- start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( 1 - divide start_ARG italic_q italic_r end_ARG start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG , 0 , 0 ) is locally stable iff all the eigenvalues of Ja\u00e2\ufffd\u00a2xsubscript\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5J_{ax}italic_J start_POSTSUBSCRIPT italic_a italic_x end_POSTSUBSCRIPT are negative and all the eigenvalues of Ja\u00e2\ufffd\u00a2xsubscript\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5J_{ax}italic_J start_POSTSUBSCRIPT italic_a italic_x end_POSTSUBSCRIPT are negative iff r<r1q\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\ufffdr< < divide start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG italic_q end_ARG and r2<\u00e2\u02c6\u2019d1\u00e2\ufffd\u00a2r12\u00e2\u02c6\u2019\u00ce\u00b2\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2q2\u00e2\ufffd\u00a2r3+\u00cf\u20306subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u20181superscriptsubscript\u011f\ufffd\u2018\u017812\u011f\ufffd\u203a\u00bdsuperscript\u011f\ufffd\u2018\u01782superscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u0153\u201d6r_{2}< r^{2}q^{2}r_{3}+ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT < divide start_ARG - italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG - italic_\u00ce\u00b2 italic_r start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_q start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + italic_\u00cf\u2030 start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT end_ARG. Hence, the proof. \u00e2\u02c6\ufffd The top predator free equilibrium point Et\u00e2\ufffd\u00a2(A,B,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a1\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b50E_{t}(A,B,0)italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_A , italic_B , 0 ) is locally stable iff M1>0subscript\u011f\ufffd\u2018\u20ac10M_{1}>0italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT > 0, M2>0subscript\u011f\ufffd\u2018\u20ac20M_{2}>0italic_M start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT > 0, M3>0subscript\u011f\ufffd\u2018\u20ac30M_{3}>0italic_M start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT > 0, and M1\u00e2\ufffd\u00a2M2\u00e2\u02c6\u2019M3>0subscript\u011f\ufffd\u2018\u20ac1subscript\u011f\ufffd\u2018\u20ac2subscript\u011f\ufffd\u2018\u20ac30M_{1}M_{2}-M_{3}>0italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_M start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_M start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT > 0. The definitions of the symbols Misubscript\u011f\ufffd\u2018\u20ac\u011f\ufffd\u2018\u2013M_{i}italic_M start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT are provided within the proof. The Routh-Hurwitz criterion is employed to assess the local stability of Et\u00e2\ufffd\u00a2(A,B,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a1\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b50E_{t}(A,B,0)italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_A , italic_B , 0 ). The Jacobian matrix of the system (2) around the top predator free equilibrium point Et\u00e2\ufffd\u00a2(A,B,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a1\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b50E_{t}(A,B,0)italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_A , italic_B , 0 ) is given by here, t11=(\u00ce\u00b2\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2q\u00e2\u02c6\u2019r1\u00e2\u02c6\u2019\u00ce\u00b2\u00e2\ufffd\u00a2r1)\u00e2\ufffd\u00a2(2\u00e2\ufffd\u00a2\u00ce\u00b2\u00e2\ufffd\u00a2d1+r2\u00e2\ufffd\u00a2r3\u00e2\u02c6\u2019m1\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r3\u00e2\u02c6\u2019\u00cf\u203010)(2\u00e2\ufffd\u00a2\u00ce\u00b22\u00e2\ufffd\u00a2d1)subscript\u011f\ufffd\u2018\u00a111\u011f\ufffd\u203a\u00bd\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u203a\u00bdsubscript\u011f\ufffd\u2018\u017812\u011f\ufffd\u203a\u00bdsubscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u0153\u201d102superscript\u011f\ufffd\u203a\u00bd2subscript\u011f\ufffd\u2018\u20181t_{11}= rq-r_{1}- r_{1})(2 d_{1}+r_{2}r_{3}-m_{1}r_{2}r_% {3}- start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT = divide start_ARG ( italic_\u00ce\u00b2 italic_r italic_q - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - italic_\u00ce\u00b2 italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ( 2 italic_\u00ce\u00b2 italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT - italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT - italic_\u00cf\u2030 start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT ) end_ARG start_ARG ( 2 italic_\u00ce\u00b2 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) end_ARG, t12=\u00e2\u02c6\u2019d1r3subscript\u011f\ufffd\u2018\u00a112subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u01783t_{12}=- start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT = - divide start_ARG italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG, t21=\u00e2\u02c6\u2019\u00cf\u203010\u00e2\ufffd\u00a2(r1\u00e2\ufffd\u00a2((\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r3+\u00cf\u203010)+\u00ce\u00b2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20192\u00e2\ufffd\u00a2d1\u00e2\ufffd\u00a2r1\u00e2\u02c6\u2019(r\u00e2\ufffd\u00a2q\u00e2\u02c6\u2019r1)\u00e2\ufffd\u00a2((\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r3+\u00cf\u203010)))2\u00e2\ufffd\u00a2\u00ce\u00b22\u00e2\ufffd\u00a2d1\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2subscript\u011f\ufffd\u2018\u00a121subscript\u011f\ufffd\u0153\u201d10subscript\u011f\ufffd\u2018\u017811subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u0153\u201d10\u011f\ufffd\u203a\u00bd2subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u017811subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u0153\u201d102superscript\u011f\ufffd\u203a\u00bd2subscript\u011f\ufffd\u2018\u201811subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01782t_{21}=- }r_{1}-(rq-r_{1})((-1+m_{1})r_{2}r_{3}+ })r_{2}}italic_t start_POSTSUBSCRIPT 21 end_POSTSUBSCRIPT = - divide start_ARG italic_\u00cf\u2030 start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT ( italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + italic_\u00cf\u2030 start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT ) + italic_\u00ce\u00b2 ( - 2 italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - ( italic_r italic_q - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ( ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + italic_\u00cf\u2030 start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT ) ) ) end_ARG start_ARG 2 italic_\u00ce\u00b2 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG, t23=(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2(\u00e2\u02c6\u2019r1\u00e2\ufffd\u00a2((\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r3+\u00cf\u203010)+\u00ce\u00b2\u00e2\ufffd\u00a2(2\u00e2\ufffd\u00a2d1\u00e2\ufffd\u00a2r1+(r\u00e2\ufffd\u00a2q\u00e2\u02c6\u2019r1)\u00e2\ufffd\u00a2((\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r3+\u00cf\u203010)))\u00e2\ufffd\u00a2r42\u00e2\ufffd\u00a2\u00ce\u00b22\u00e2\ufffd\u00a2d1\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2\u00e2\u02c6\u2019c1\u00e2\ufffd\u00a2r1\u00e2\ufffd\u00a2((\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r3+\u00cf\u203010)+\u00ce\u00b2\u00e2\ufffd\u00a2c1\u00e2\ufffd\u00a2(2\u00e2\ufffd\u00a2d1\u00e2\ufffd\u00a2r1+(r\u00e2\ufffd\u00a2q\u00e2\u02c6\u2019r1)\u00e2\ufffd\u00a2((\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r3+\u00cf\u203010))subscript\u011f\ufffd\u2018\u00a1231subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u017811subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u0153\u201d10\u011f\ufffd\u203a\u00bd2subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u017811subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u0153\u201d10subscript\u011f\ufffd\u2018\u017842superscript\u011f\ufffd\u203a\u00bd2subscript\u011f\ufffd\u2018\u201811subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u017811subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u0153\u201d10\u011f\ufffd\u203a\u00bdsubscript\u011f\ufffd\u2018\ufffd12subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u017811subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u0153\u201d10t_{23}= _{1}+(rq-r_{1})((-1+m_{1})r_{2}r_{3}+ _{1})r_{2}-c_{1}r_{1}((-1+m_{1})r_{2}r_{3}+ c_{1}(2d_{1}r_{1% }+(rq-r_{1})((-1+m_{1})r_{2}r_{3}+ start_POSTSUBSCRIPT 23 end_POSTSUBSCRIPT = divide start_ARG ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ( - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + italic_\u00cf\u2030 start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT ) + italic_\u00ce\u00b2 ( 2 italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + ( italic_r italic_q - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ( ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + italic_\u00cf\u2030 start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT ) ) ) italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT end_ARG start_ARG 2 italic_\u00ce\u00b2 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + italic_\u00cf\u2030 start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT ) + italic_\u00ce\u00b2 italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( 2 italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + ( italic_r italic_q - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ( ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + italic_\u00cf\u2030 start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT ) ) end_ARG, t33=\u00e2\u02c6\u2019d2+((\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2(r1\u00e2\ufffd\u00a2((\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r3+\u00cf\u203010)+\u00ce\u00b2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20192\u00e2\ufffd\u00a2d1\u00e2\ufffd\u00a2r1\u00e2\u02c6\u2019(r\u00e2\ufffd\u00a2q\u00e2\u02c6\u2019r1)\u00e2\ufffd\u00a2((\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r3+\u00cf\u203010)))\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5)2\u00e2\ufffd\u00a2\u00ce\u00b22\u00e2\ufffd\u00a2d1\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2\u00e2\u02c6\u2019c1\u00e2\ufffd\u00a2r1\u00e2\ufffd\u00a2((\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r3+\u00cf\u203010)+\u00ce\u00b2\u00e2\ufffd\u00a2c1\u00e2\ufffd\u00a2(2\u00e2\ufffd\u00a2d1\u00e2\ufffd\u00a2r1+(r\u00e2\ufffd\u00a2q\u00e2\u02c6\u2019r1)\u00e2\ufffd\u00a2((\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r3+\u00cf\u203010))subscript\u011f\ufffd\u2018\u00a133subscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u017811subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u0153\u201d10\u011f\ufffd\u203a\u00bd2subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u017811subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u0153\u201d10subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u017852superscript\u011f\ufffd\u203a\u00bd2subscript\u011f\ufffd\u2018\u201811subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u017811subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u0153\u201d10\u011f\ufffd\u203a\u00bdsubscript\u011f\ufffd\u2018\ufffd12subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u017811subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u0153\u201d10t_{33}=-d_{2}+ -2d_{1}r_{1}-(rq-r_{1})((-1+m_{1})r_{2}r_{3}+ ^{2}d_{1}(-1+m_{1})r_{2}-c_{1}r_{1}((-1+m_{1})r_{2}r_{3}+ c_% {1}(2d_{1}r_{1}+(rq-r_{1})((-1+m_{1})r_{2}r_{3}+ start_POSTSUBSCRIPT 33 end_POSTSUBSCRIPT = - italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + divide start_ARG ( ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ( italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + italic_\u00cf\u2030 start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT ) + italic_\u00ce\u00b2 ( - 2 italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - ( italic_r italic_q - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ( ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + italic_\u00cf\u2030 start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT ) ) ) italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ) end_ARG start_ARG 2 italic_\u00ce\u00b2 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + italic_\u00cf\u2030 start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT ) + italic_\u00ce\u00b2 italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( 2 italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + ( italic_r italic_q - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ( ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + italic_\u00cf\u2030 start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT ) ) end_ARG, and \u00cf\u203010=(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r3\u00e2\ufffd\u00a2(\u00e2\u02c6\u20194\u00e2\ufffd\u00a2\u00ce\u00b2\u00e2\ufffd\u00a2d1+(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r3)subscript\u011f\ufffd\u0153\u201d101subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u017834\u011f\ufffd\u203a\u00bdsubscript\u011f\ufffd\u2018\u201811subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01783 d_{1}+(-1+m_{1})r_{2}r_{3})}italic_\u00cf\u2030 start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT = square-root start_ARG ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( - 4 italic_\u00ce\u00b2 italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) end_ARG. Taking \u00cf\u01923+M1\u00e2\ufffd\u00a2\u00cf\u01922+M2\u00e2\ufffd\u00a2\u00cf\u0192+M3=0superscript\u011f\ufffd\u0153\ufffd3subscript\u011f\ufffd\u2018\u20ac1superscript\u011f\ufffd\u0153\ufffd2subscript\u011f\ufffd\u2018\u20ac2\u011f\ufffd\u0153\ufffdsubscript\u011f\ufffd\u2018\u20ac30 start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT + italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_\u00cf\u0192 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_M start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_\u00cf\u0192 + italic_M start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0 as the characteristic equation of Jt\u00e2\ufffd\u00a2osubscript\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u0153J_{to}italic_J start_POSTSUBSCRIPT italic_t italic_o end_POSTSUBSCRIPT, then M1=\u00e2\u02c6\u2019(t11+t33)subscript\u011f\ufffd\u2018\u20ac1subscript\u011f\ufffd\u2018\u00a111subscript\u011f\ufffd\u2018\u00a133M_{1}=-(t_{11}+t_{33})italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = - ( italic_t start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT + italic_t start_POSTSUBSCRIPT 33 end_POSTSUBSCRIPT ), M2=\u00e2\u02c6\u2019(t12\u00e2\ufffd\u00a2t21\u00e2\u02c6\u2019t11\u00e2\ufffd\u00a2t33)subscript\u011f\ufffd\u2018\u20ac2subscript\u011f\ufffd\u2018\u00a112subscript\u011f\ufffd\u2018\u00a121subscript\u011f\ufffd\u2018\u00a111subscript\u011f\ufffd\u2018\u00a133M_{2}=-(t_{12}t_{21}-t_{11}t_{33})italic_M start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = - ( italic_t start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT 21 end_POSTSUBSCRIPT - italic_t start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT 33 end_POSTSUBSCRIPT ), and M3=t12\u00e2\ufffd\u00a2t21\u00e2\ufffd\u00a2t33subscript\u011f\ufffd\u2018\u20ac3subscript\u011f\ufffd\u2018\u00a112subscript\u011f\ufffd\u2018\u00a121subscript\u011f\ufffd\u2018\u00a133M_{3}=t_{12}t_{21}t_{33}italic_M start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = italic_t start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT 21 end_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT 33 end_POSTSUBSCRIPT. Now, Et\u00e2\ufffd\u00a2(A,B,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a1\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b50E_{t}(A,B,0)italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_A , italic_B , 0 ) is locally asymptotically stable iff M1>0subscript\u011f\ufffd\u2018\u20ac10M_{1}>0italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT > 0, M2>0subscript\u011f\ufffd\u2018\u20ac20M_{2}>0italic_M start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT > 0, M3>0subscript\u011f\ufffd\u2018\u20ac30M_{3}>0italic_M start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT > 0, and M1\u00e2\ufffd\u00a2M2\u00e2\u02c6\u2019M3>0subscript\u011f\ufffd\u2018\u20ac1subscript\u011f\ufffd\u2018\u20ac2subscript\u011f\ufffd\u2018\u20ac30M_{1}M_{2}-M_{3}>0italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_M start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_M start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT > 0. Hence, proved. \u00e2\u02c6\ufffd The coexisting equilibrium point Ec\u00e2\ufffd\u00a2(C,D,E)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b8E_{c}(C,D,E)italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( italic_C , italic_D , italic_E ) is locally stable if and only if N1subscript\u011f\ufffd\u2018\ufffd1N_{1}italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, N2subscript\u011f\ufffd\u2018\ufffd2N_{2}italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, and N3subscript\u011f\ufffd\u2018\ufffd3N_{3}italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT are all positive, and if N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd3N_{1}N_{2}-N_{3}italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT is also positive. The symbols Nisubscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013N_{i}italic_N start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT are defined directly in the proof. The Jacobian matrix of the system (2) evaluated at the coexisting equilibrium point Ec\u00e2\ufffd\u00a2(C,D,E)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b8E_{c}(C,D,E)italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( italic_C , italic_D , italic_E ) is provided as follows: here, u11=c1\u00e2\ufffd\u00a2d2\u00e2\ufffd\u00a2(q\u00e2\ufffd\u00a2r\u00e2\u02c6\u2019r1)+d2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2+(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2(q\u00e2\ufffd\u00a2r\u00e2\u02c6\u2019r1)\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5c1\u00e2\ufffd\u00a2d2+(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5subscript\u011f\ufffd\u2018\u00a211subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u20182\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u017821subscript\u011f\ufffd\u2018\u01612\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785u_{11}= 4}r_{5}}{c_{1}d_{2}+(-1+m_{2})r_{4}r_{5}}italic_u start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT = divide start_ARG italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_q italic_r - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) + italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ( italic_q italic_r - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT end_ARG start_ARG italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT end_ARG, u12=(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2(\u00ce\u00b2\u00e2\ufffd\u00a2q\u00e2\ufffd\u00a2r\u00e2\u02c6\u2019r1\u00e2\u02c6\u2019\u00ce\u00b2\u00e2\ufffd\u00a2r1)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2(c1\u00e2\ufffd\u00a2d2+(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5)\u00e2\ufffd\u00a2(c1\u00e2\ufffd\u00a2d2\u00e2\ufffd\u00a2(q\u00e2\ufffd\u00a2r\u00e2\u02c6\u2019r1)+d2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2+(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2(q\u00e2\ufffd\u00a2r\u00e2\u02c6\u2019r1)\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5)(c1\u00e2\ufffd\u00a2d2\u00e2\ufffd\u00a2r1+\u00ce\u00b2\u00e2\ufffd\u00a2d2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2+(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2r1\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5)2subscript\u011f\ufffd\u2018\u00a2121subscript\u011f\ufffd\u2018\u01611\u011f\ufffd\u203a\u00bd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u203a\u00bdsubscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u20182\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u017821subscript\u011f\ufffd\u2018\u01612\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785superscriptsubscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u20182subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u203a\u00bdsubscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u017821subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u017852u_{12}= qr-r_{1}- r_{1})r_{2}(c_{1}d_{2}+(-1+m_{2})% r_{4}r_{5})(c_{1}d_{2}(qr-r_{1})+d_{2}(-1+m_{1})r_{2}+(-1+m_{2})(qr-r_{1})r_{4% }r_{5})}{(c_{1}d_{2}r_{1}+ d_{2}(-1+m_{1})r_{2}+(-1+m_{2})r_{1}r_{4}r_{5}% )^{2}}italic_u start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT = divide start_ARG ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ( italic_\u00ce\u00b2 italic_q italic_r - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - italic_\u00ce\u00b2 italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ) ( italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_q italic_r - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) + italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ( italic_q italic_r - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ) end_ARG start_ARG ( italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_\u00ce\u00b2 italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG, u21=\u00e2\u02c6\u2019d2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r3\u00e2\ufffd\u00a2(\u00e2\u02c6\u2019r1\u00e2\ufffd\u00a2(c1\u00e2\ufffd\u00a2d2+(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5)+\u00ce\u00b2\u00e2\ufffd\u00a2(2\u00e2\ufffd\u00a2c1\u00e2\ufffd\u00a2d2\u00e2\ufffd\u00a2(q\u00e2\ufffd\u00a2r\u00e2\u02c6\u2019r1)+d2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2+2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2(q\u00e2\ufffd\u00a2r\u00e2\u02c6\u2019r1)\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5))(c1\u00e2\ufffd\u00a2d2+(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5)\u00e2\ufffd\u00a2(c1\u00e2\ufffd\u00a2d2\u00e2\ufffd\u00a2r1+\u00ce\u00b2\u00e2\ufffd\u00a2d2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2+(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2r1\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5)subscript\u011f\ufffd\u2018\u00a221subscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785\u011f\ufffd\u203a\u00bd2subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u20182\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u0178221subscript\u011f\ufffd\u2018\u01612\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u20182subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u203a\u00bdsubscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u017821subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785u_{21}=- )+ _{5}))}{(c_{1}d_{2}+(-1+m_{2})r_{4}r_{5})(c_{1}d_{2}r_{1}+ d_{2}(-1+m_{1}% )r_{2}+(-1+m_{2})r_{1}r_{4}r_{5})}italic_u start_POSTSUBSCRIPT 21 end_POSTSUBSCRIPT = - divide start_ARG italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ) + italic_\u00ce\u00b2 ( 2 italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_q italic_r - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) + italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + 2 ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ( italic_q italic_r - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ) ) end_ARG start_ARG ( italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ) ( italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_\u00ce\u00b2 italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ) end_ARG, u22=c1\u00e2\ufffd\u00a2d2\u00e2\ufffd\u00a2(\u00ce\u00b22\u00e2\ufffd\u00a2d1\u00e2\ufffd\u00a2d22\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)2\u00e2\ufffd\u00a2r22+c12\u00e2\ufffd\u00a2d22\u00e2\ufffd\u00a2\u00cf\u203011\u00e2\u02c6\u2019(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2r1\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5\u00e2\ufffd\u00a2\u00cf\u203012+\u00ce\u00b2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5\u00e2\ufffd\u00a2\u00cf\u203013+c1\u00e2\ufffd\u00a2d2\u00e2\ufffd\u00a2\u00cf\u203014)((\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5\u00e2\ufffd\u00a2(c1\u00e2\ufffd\u00a2d2\u00e2\ufffd\u00a2r1+\u00ce\u00b2\u00e2\ufffd\u00a2d2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2+(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2r1\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5)2)subscript\u011f\ufffd\u2018\u00a222subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u20182superscript\u011f\ufffd\u203a\u00bd2subscript\u011f\ufffd\u2018\u20181superscriptsubscript\u011f\ufffd\u2018\u201822superscript1subscript\u011f\ufffd\u2018\u016112superscriptsubscript\u011f\ufffd\u2018\u017822superscriptsubscript\u011f\ufffd\u2018\ufffd12superscriptsubscript\u011f\ufffd\u2018\u201822subscript\u011f\ufffd\u0153\u201d111subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785subscript\u011f\ufffd\u0153\u201d12\u011f\ufffd\u203a\u00bd1subscript\u011f\ufffd\u2018\u016111subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785subscript\u011f\ufffd\u0153\u201d13subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u20182subscript\u011f\ufffd\u0153\u201d141subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785superscriptsubscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u20182subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u203a\u00bdsubscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u017821subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u017852u_{22}= 2}d_{2}^{2} +m_{2})r_{2}r_{4}r_{5} }(c_{1}d_{2}r_{1}+ d_{2}(-1+m_{1})r_{2}+(-1+m_{2})r_{1}r_{4}r_{5})^{2})}italic_u start_POSTSUBSCRIPT 22 end_POSTSUBSCRIPT = divide start_ARG italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_\u00ce\u00b2 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_\u00cf\u2030 start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT - ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT italic_\u00cf\u2030 start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT + italic_\u00ce\u00b2 ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT italic_\u00cf\u2030 start_POSTSUBSCRIPT 13 end_POSTSUBSCRIPT + italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_\u00cf\u2030 start_POSTSUBSCRIPT 14 end_POSTSUBSCRIPT ) end_ARG start_ARG ( ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ( italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_\u00ce\u00b2 italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) end_ARG, u23=\u00e2\u02c6\u2019d2r5subscript\u011f\ufffd\u2018\u00a223subscript\u011f\ufffd\u2018\u20182subscript\u011f\ufffd\u2018\u01785u_{23}=- start_POSTSUBSCRIPT 23 end_POSTSUBSCRIPT = - divide start_ARG italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG start_ARG italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT end_ARG, u32=(1\u00e2\u02c6\u2019m2)\u00e2\ufffd\u00a2(c1\u00e2\ufffd\u00a2d2+(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5)\u00e2\ufffd\u00a2(\u00ce\u00b22\u00e2\ufffd\u00a2d1\u00e2\ufffd\u00a2d22\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)2\u00e2\ufffd\u00a2r22+c12\u00e2\ufffd\u00a2d22\u00e2\ufffd\u00a2\u00cf\u203011\u00e2\u02c6\u2019(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2r1\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5\u00e2\ufffd\u00a2\u00cf\u203012+\u00ce\u00b2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5\u00e2\ufffd\u00a2\u00cf\u203013+c1\u00e2\ufffd\u00a2d2\u00e2\ufffd\u00a2\u00cf\u203014)(\u00e2\u02c6\u20191+m2)2\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2(c1\u00e2\ufffd\u00a2d2\u00e2\ufffd\u00a2r1+\u00ce\u00b2\u00e2\ufffd\u00a2d2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2+(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2r1\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5)2subscript\u011f\ufffd\u2018\u00a2321subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785superscript\u011f\ufffd\u203a\u00bd2subscript\u011f\ufffd\u2018\u20181superscriptsubscript\u011f\ufffd\u2018\u201822superscript1subscript\u011f\ufffd\u2018\u016112superscriptsubscript\u011f\ufffd\u2018\u017822superscriptsubscript\u011f\ufffd\u2018\ufffd12superscriptsubscript\u011f\ufffd\u2018\u201822subscript\u011f\ufffd\u0153\u201d111subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785subscript\u011f\ufffd\u0153\u201d12\u011f\ufffd\u203a\u00bd1subscript\u011f\ufffd\u2018\u016111subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785subscript\u011f\ufffd\u0153\u201d13subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u20182subscript\u011f\ufffd\u0153\u201d14superscript1subscript\u011f\ufffd\u2018\u016122subscript\u011f\ufffd\u2018\u01784superscriptsubscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u20182subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u203a\u00bdsubscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u017821subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u017852u_{32}= }(-1+m_{1})^{2}r_{2}^{2}+c_{1}^{2}d_{2}^{2} 5} d_{2}(-1+m_{1})r_{2}+(% -1+m_{2})r_{1}r_{4}r_{5})^{2}}italic_u start_POSTSUBSCRIPT 32 end_POSTSUBSCRIPT = divide start_ARG ( 1 - italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ( italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ) ( italic_\u00ce\u00b2 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_\u00cf\u2030 start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT - ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT italic_\u00cf\u2030 start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT + italic_\u00ce\u00b2 ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT italic_\u00cf\u2030 start_POSTSUBSCRIPT 13 end_POSTSUBSCRIPT + italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_\u00cf\u2030 start_POSTSUBSCRIPT 14 end_POSTSUBSCRIPT ) end_ARG start_ARG ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT ( italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_\u00ce\u00b2 italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG, and \u00cf\u203011=(d1\u00e2\ufffd\u00a2r12+(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2(q\u00e2\ufffd\u00a2r\u00e2\u02c6\u2019r1)\u00e2\ufffd\u00a2(\u00ce\u00b2\u00e2\ufffd\u00a2q\u00e2\ufffd\u00a2r\u00e2\u02c6\u2019r1\u00e2\u02c6\u2019\u00ce\u00b2\u00e2\ufffd\u00a2r1)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r3)subscript\u011f\ufffd\u0153\u201d11subscript\u011f\ufffd\u2018\u20181superscriptsubscript\u011f\ufffd\u2018\u0178121subscript\u011f\ufffd\u2018\u01611\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u203a\u00bd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u203a\u00bdsubscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01783 qr-r_{1}- r_{1})r_% {2}r_{3})italic_\u00cf\u2030 start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT = ( italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ( italic_q italic_r - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ( italic_\u00ce\u00b2 italic_q italic_r - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - italic_\u00ce\u00b2 italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ), \u00cf\u203012=(d2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)2\u00e2\ufffd\u00a2r22\u00e2\ufffd\u00a2r3\u00e2\u02c6\u2019(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2(d1\u00e2\ufffd\u00a2r1\u00e2\u02c6\u2019(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2(q\u00e2\ufffd\u00a2r\u00e2\u02c6\u2019r1)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r3)\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5)subscript\u011f\ufffd\u0153\u201d12subscript\u011f\ufffd\u2018\u20182superscript1subscript\u011f\ufffd\u2018\u016112superscriptsubscript\u011f\ufffd\u2018\u017822subscript\u011f\ufffd\u2018\u017831subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u017811subscript\u011f\ufffd\u2018\u01611\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785 )(qr-r_{1})r_{2}r_{3})r_{4}r_{5})italic_\u00cf\u2030 start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT = ( italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT - ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ( italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ( italic_q italic_r - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ), \u00cf\u203013=(2\u00e2\ufffd\u00a2d1\u00e2\ufffd\u00a2d2\u00e2\ufffd\u00a2r1+(q\u00e2\ufffd\u00a2r\u00e2\u02c6\u2019r1)\u00e2\ufffd\u00a2r3\u00e2\ufffd\u00a2(d2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2+(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2(q\u00e2\ufffd\u00a2r\u00e2\u02c6\u2019r1)\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5))subscript\u011f\ufffd\u0153\u201d132subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u20182subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u017821subscript\u011f\ufffd\u2018\u01612\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785 qr-r_{1})r_{4}r_{5}))italic_\u00cf\u2030 start_POSTSUBSCRIPT 13 end_POSTSUBSCRIPT = ( 2 italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + ( italic_q italic_r - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ( italic_q italic_r - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ) ), \u00cf\u203014=(r1\u00e2\ufffd\u00a2(\u00e2\u02c6\u2019d2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)2\u00e2\ufffd\u00a2r22\u00e2\ufffd\u00a2r3+2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2(d1\u00e2\ufffd\u00a2r1\u00e2\u02c6\u2019(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2(q\u00e2\ufffd\u00a2r\u00e2\u02c6\u2019r1)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r3)\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5)+\u00ce\u00b2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2(2\u00e2\ufffd\u00a2d1\u00e2\ufffd\u00a2d2\u00e2\ufffd\u00a2r1+(q\u00e2\ufffd\u00a2r\u00e2\u02c6\u2019r1)\u00e2\ufffd\u00a2r3\u00e2\ufffd\u00a2(d2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2+2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m2)\u00e2\ufffd\u00a2(q\u00e2\ufffd\u00a2r\u00e2\u02c6\u2019r1)\u00e2\ufffd\u00a2r4\u00e2\ufffd\u00a2r5)))subscript\u011f\ufffd\u0153\u201d14subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u20182superscript1subscript\u011f\ufffd\u2018\u016112superscriptsubscript\u011f\ufffd\u2018\u017822subscript\u011f\ufffd\u2018\u0178321subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u017811subscript\u011f\ufffd\u2018\u01611\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785\u011f\ufffd\u203a\u00bd1subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u017822subscript\u011f\ufffd\u2018\u20181subscript\u011f\ufffd\u2018\u20182subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u2018\u201821subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u0178221subscript\u011f\ufffd\u2018\u01612\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01785 -1+m_{1})(qr-r_{1})r_{2}r_{3})r_{4}r_{5})+ }+(qr-r_{1})r_{3}(d_{2}(-1+m_{1})r_{2}+2(-1+m_{2})(qr-r_{1})r_{4}r_{5})))italic_\u00cf\u2030 start_POSTSUBSCRIPT 14 end_POSTSUBSCRIPT = ( italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( - italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + 2 ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ( italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ( italic_q italic_r - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ) + italic_\u00ce\u00b2 ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 2 italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + ( italic_q italic_r - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT + 2 ( - 1 + italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) ( italic_q italic_r - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT ) ) ). Now, let us consider \u00cf\u20183+N1\u00e2\ufffd\u00a2\u00cf\u20182+N2\u00e2\ufffd\u00a2\u00cf\u2018+N3=0superscriptitalic-\u00cf\u20183subscript\u011f\ufffd\u2018\ufffd1superscriptitalic-\u00cf\u20182subscript\u011f\ufffd\u2018\ufffd2italic-\u00cf\u2018subscript\u011f\ufffd\u2018\ufffd30 start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT + italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_\u00cf\u2018 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_\u00cf\u2018 + italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0 be the characteristic equation of Jc\u00e2\ufffd\u00a2osubscript\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0153J_{co}italic_J start_POSTSUBSCRIPT italic_c italic_o end_POSTSUBSCRIPT. Then, N1=\u00e2\u02c6\u2019(u11+u22)subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u00a211subscript\u011f\ufffd\u2018\u00a222N_{1}=-(u_{11}+u_{22})italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = - ( italic_u start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT + italic_u start_POSTSUBSCRIPT 22 end_POSTSUBSCRIPT ), N2=\u00e2\u02c6\u2019u12\u00e2\ufffd\u00a2u21+u11\u00e2\ufffd\u00a2u22\u00e2\u02c6\u2019u23\u00e2\ufffd\u00a2u32subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\u00a212subscript\u011f\ufffd\u2018\u00a221subscript\u011f\ufffd\u2018\u00a211subscript\u011f\ufffd\u2018\u00a222subscript\u011f\ufffd\u2018\u00a223subscript\u011f\ufffd\u2018\u00a232N_{2}=-u_{12}u_{21}+u_{11}u_{22}-u_{23}u_{32}italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = - italic_u start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT italic_u start_POSTSUBSCRIPT 21 end_POSTSUBSCRIPT + italic_u start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT italic_u start_POSTSUBSCRIPT 22 end_POSTSUBSCRIPT - italic_u start_POSTSUBSCRIPT 23 end_POSTSUBSCRIPT italic_u start_POSTSUBSCRIPT 32 end_POSTSUBSCRIPT, and N3=u11\u00e2\ufffd\u00a2u23\u00e2\ufffd\u00a2u32subscript\u011f\ufffd\u2018\ufffd3subscript\u011f\ufffd\u2018\u00a211subscript\u011f\ufffd\u2018\u00a223subscript\u011f\ufffd\u2018\u00a232N_{3}=u_{11}u_{23}u_{32}italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = italic_u start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT italic_u start_POSTSUBSCRIPT 23 end_POSTSUBSCRIPT italic_u start_POSTSUBSCRIPT 32 end_POSTSUBSCRIPT. Thus, the coexisting equilibrium point Ec\u00e2\ufffd\u00a2(C,D,E)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b8E_{c}(C,D,E)italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( italic_C , italic_D , italic_E ) is locally stable if and only if Ni>0subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u20130N_{i}>0italic_N start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT > 0 and N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3>0subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd30N_{1}N_{2}-N_{3}>0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT > 0 for i=1,2,3, according to the Routh-Hurwitz criterion. Therefore, the proof. \u00e2\u02c6\ufffd The equilibrium points of both the ODE system (2) and the FODE system(3) remain unchanged. Therefore, the criterion for the existence of all equilibrium points in system (3) is identical to that of system (2). Thus, for the existence of the equilibrium points of the bio-system (3), one can refer to Subsection (6.1). So, in this subsection, we discuss the local stability conditions of the equilibrium points of the bio-system (3). The subsequent theorems discuss the local stability criteria of all equilibrium points. The vanishing equilibrium point Ev\u00e2\ufffd\u00a2(0,0,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a3000E_{v}(0,0,0)italic_E start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( 0 , 0 , 0 ) is locally stable if r>r1q\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\ufffdr> > divide start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG italic_q end_ARG. To find the local stability criterion of the vanishing equilibrium point Ev\u00e2\ufffd\u00a2(0,0,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a3000E_{v}(0,0,0)italic_E start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( 0 , 0 , 0 ), we have to compute the Jacobian matrix of the system (3) at Ev\u00e2\ufffd\u00a2(0,0,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a3000E_{v}(0,0,0)italic_E start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( 0 , 0 , 0 ) The diagonal elements of the Jacobian matrix Jv\u00e2\ufffd\u00a2asubscript\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\ufffdJ_{va}italic_J start_POSTSUBSCRIPT italic_v italic_a end_POSTSUBSCRIPT are the eigenvalues of Jv\u00e2\ufffd\u00a2asubscript\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\ufffdJ_{va}italic_J start_POSTSUBSCRIPT italic_v italic_a end_POSTSUBSCRIPT. The entries \u00e2\u02c6\u2019r\u00e2\ufffd\u00a2q+r1,\u00e2\u02c6\u2019d1,\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\u2018\u20181-rq+r_{1},-d_{1},- italic_r italic_q + italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , - italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , and \u00e2\u02c6\u2019d2subscript\u011f\ufffd\u2018\u20182-d_{2}- italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT are the eigenvalues of Jv\u00e2\ufffd\u00a2asubscript\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\ufffdJ_{va}italic_J start_POSTSUBSCRIPT italic_v italic_a end_POSTSUBSCRIPT. Now, utilising Lemma (4), we get the vanishing equilibrium point Ev\u00e2\ufffd\u00a2(0,0,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a3000E_{v}(0,0,0)italic_E start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( 0 , 0 , 0 ) is locally stable if r>r1q\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\ufffdr> > divide start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG italic_q end_ARG. Hence, the theorem. \u00e2\u02c6\ufffd The axial equilibrium point Ea\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019q\u00e2\ufffd\u00a2rr1,0,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffd1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u0178100E_{a}(1- start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( 1 - divide start_ARG italic_q italic_r end_ARG start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG , 0 , 0 ) is locally stable if the conditions ( r<r1q\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\ufffdr< < divide start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG italic_q end_ARG and ( r2<\u00e2\u02c6\u2019d1\u00e2\ufffd\u00a2r12\u00e2\u02c6\u2019\u00ce\u00b2\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2q2\u00e2\ufffd\u00a2r3+\u00cf\u20306subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u20181superscriptsubscript\u011f\ufffd\u2018\u017812\u011f\ufffd\u203a\u00bdsuperscript\u011f\ufffd\u2018\u01782superscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u0153\u201d6r_{2}< r^{2}q^{2}r_{3}+ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT < divide start_ARG - italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG - italic_\u00ce\u00b2 italic_r start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_q start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + italic_\u00cf\u2030 start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT end_ARG hold. The Jacobian matrix of the system (3) around Ea\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019q\u00e2\ufffd\u00a2rr1,0,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffd1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u0178100E_{a}(1- start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( 1 - divide start_ARG italic_q italic_r end_ARG start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG , 0 , 0 ) is as follows: Obviously, the diagonal elements \u00ce\u00bea,1=r\u00e2\ufffd\u00a2q\u00e2\u02c6\u2019r1subscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\ufffd1\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u01781 start_POSTSUBSCRIPT italic_a , 1 end_POSTSUBSCRIPT = italic_r italic_q - italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, \u00ce\u00bea,2=\u00e2\u02c6\u2019d1\u00e2\ufffd\u00a2r12+\u00ce\u00b2\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2q2\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r3\u00e2\u02c6\u2019r2\u00e2\ufffd\u00a2\u00cf\u20306r12subscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\u20181superscriptsubscript\u011f\ufffd\u2018\u017812\u011f\ufffd\u203a\u00bdsuperscript\u011f\ufffd\u2018\u01782superscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u0153\u201d6superscriptsubscript\u011f\ufffd\u2018\u017812 r^{2}q^{2}r_{2}r_{3}-r_{2} {1}^{2}}italic_\u00ce\u00be start_POSTSUBSCRIPT italic_a , 2 end_POSTSUBSCRIPT = divide start_ARG - italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_\u00ce\u00b2 italic_r start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_q start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT - italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_\u00cf\u2030 start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT end_ARG start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG, and \u00ce\u00bea,3=\u00e2\u02c6\u2019d2subscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\ufffd3subscript\u011f\ufffd\u2018\u20182 start_POSTSUBSCRIPT italic_a , 3 end_POSTSUBSCRIPT = - italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT are the eigenvalues of the Jacobian matrix Jv\u00e2\ufffd\u00a2asubscript\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\ufffdJ_{va}italic_J start_POSTSUBSCRIPT italic_v italic_a end_POSTSUBSCRIPT. Now, to study the local stability of the system (3) around the equilibrium point Easubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{a}italic_E start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT, we utilise Lemma (4). Here, |a\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2g\u00e2\ufffd\u00a2(\u00ce\u00bea,1)|=\u00cf\u20ac>\u00ce\u00b3\u00e2\ufffd\u00a2\u00cf\u20ac2\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u201dsubscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\ufffd1\u011f\ufffd\u0153\u2039\u011f\ufffd\u203a\u00be\u011f\ufffd\u0153\u20392|arg( italic_a italic_r italic_g ( italic_\u00ce\u00be start_POSTSUBSCRIPT italic_a , 1 end_POSTSUBSCRIPT ) | = italic_\u00cf\u20ac > divide start_ARG italic_\u00ce\u00b3 italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG if r<r1q\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\ufffdr< < divide start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG italic_q end_ARG, |a\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2g\u00e2\ufffd\u00a2(\u00ce\u00bea,2)|=\u00cf\u20ac>\u00ce\u00b3\u00e2\ufffd\u00a2\u00cf\u20ac2\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u201dsubscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\ufffd2\u011f\ufffd\u0153\u2039\u011f\ufffd\u203a\u00be\u011f\ufffd\u0153\u20392|arg( italic_a italic_r italic_g ( italic_\u00ce\u00be start_POSTSUBSCRIPT italic_a , 2 end_POSTSUBSCRIPT ) | = italic_\u00cf\u20ac > divide start_ARG italic_\u00ce\u00b3 italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG if r2<\u00e2\u02c6\u2019d1\u00e2\ufffd\u00a2r12\u00e2\u02c6\u2019\u00ce\u00b2\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2q2\u00e2\ufffd\u00a2r3+\u00cf\u20306subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u20181superscriptsubscript\u011f\ufffd\u2018\u017812\u011f\ufffd\u203a\u00bdsuperscript\u011f\ufffd\u2018\u01782superscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u0153\u201d6r_{2}< r^{2}q^{2}r_{3}+ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT < divide start_ARG - italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG - italic_\u00ce\u00b2 italic_r start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_q start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + italic_\u00cf\u2030 start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT end_ARG, and |arg\u00ce\u00bea,3)|=\u00cf\u20ac>\u00ce\u00b3\u00e2\ufffd\u00a2\u00cf\u20ac2|arg italic_a italic_r italic_g italic_\u00ce\u00be start_POSTSUBSCRIPT italic_a , 3 end_POSTSUBSCRIPT ) | = italic_\u00cf\u20ac > divide start_ARG italic_\u00ce\u00b3 italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG. Hence, the system (3) is locally asymptotically stable around the axial equilibrium point Easubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{a}italic_E start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT if the conditions ( r<r1q\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\ufffdr< < divide start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG italic_q end_ARG and ( r2<\u00e2\u02c6\u2019d1\u00e2\ufffd\u00a2r12\u00e2\u02c6\u2019\u00ce\u00b2\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2q2\u00e2\ufffd\u00a2r3+\u00cf\u20306subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u20181superscriptsubscript\u011f\ufffd\u2018\u017812\u011f\ufffd\u203a\u00bdsuperscript\u011f\ufffd\u2018\u01782superscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u0153\u201d6r_{2}< r^{2}q^{2}r_{3}+ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT < divide start_ARG - italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG - italic_\u00ce\u00b2 italic_r start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_q start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + italic_\u00cf\u2030 start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT end_ARG hold. \u00e2\u02c6\ufffd The system (3) shows local stability around Et\u00e2\ufffd\u00a2(A,B,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a1\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b50E_{t}(A,B,0)italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_A , italic_B , 0 ) is locally stable if the criteria ( t33<0subscript\u011f\ufffd\u2018\u00a1330t_{33}<0italic_t start_POSTSUBSCRIPT 33 end_POSTSUBSCRIPT < 0, ( t112+4\u00e2\ufffd\u00a2t12\u00e2\ufffd\u00a2t21<0superscriptsubscript\u011f\ufffd\u2018\u00a11124subscript\u011f\ufffd\u2018\u00a112subscript\u011f\ufffd\u2018\u00a1210t_{11}^{2}+4t_{12}t_{21}<0italic_t start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + 4 italic_t start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT 21 end_POSTSUBSCRIPT < 0, and ( t11<0subscript\u011f\ufffd\u2018\u00a1110t_{11}<0italic_t start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT < 0 hold. The Jacobian matrix of the system (3) around the top predator free equilibrium point Et\u00e2\ufffd\u00a2(A,B,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a1\u011f\ufffd\ufffd\u00b4\u011f\ufffd\ufffd\u00b50E_{t}(A,B,0)italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_A , italic_B , 0 ) is Jt\u00e2\ufffd\u00a2osubscript\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u0153J_{to}italic_J start_POSTSUBSCRIPT italic_t italic_o end_POSTSUBSCRIPT, already given in subsection (6.1). The characteristic equation of Jt\u00e2\ufffd\u00a2osubscript\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u0153J_{to}italic_J start_POSTSUBSCRIPT italic_t italic_o end_POSTSUBSCRIPT can be written as where C1=t11subscript\u011f\ufffd\ufffd\u00b61subscript\u011f\ufffd\u2018\u00a111C_{1}=t_{11}italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_t start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT and C2=\u00e2\u02c6\u2019t12\u00e2\ufffd\u00a2t21subscript\u011f\ufffd\ufffd\u00b62subscript\u011f\ufffd\u2018\u00a112subscript\u011f\ufffd\u2018\u00a121C_{2}=-t_{12}t_{21}italic_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = - italic_t start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT 21 end_POSTSUBSCRIPT. Let us consider the three eigenvalues of Jt\u00e2\ufffd\u00a2osubscript\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\u0153J_{to}italic_J start_POSTSUBSCRIPT italic_t italic_o end_POSTSUBSCRIPT: \u00ce\u00bet,1subscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\u00a11 start_POSTSUBSCRIPT italic_t , 1 end_POSTSUBSCRIPT, \u00ce\u00bet,2subscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\u00a12 start_POSTSUBSCRIPT italic_t , 2 end_POSTSUBSCRIPT, and \u00ce\u00bet,3subscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\u00a13 start_POSTSUBSCRIPT italic_t , 3 end_POSTSUBSCRIPT. Let the equation t33\u00e2\u02c6\u2019\u00ce\u00bdsubscript\u011f\ufffd\u2018\u00a133\u011f\ufffd\u0153\u02c6t_{33}- start_POSTSUBSCRIPT 33 end_POSTSUBSCRIPT - italic_\u00ce\u00bd give \u00ce\u00bet,1subscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\u00a11 start_POSTSUBSCRIPT italic_t , 1 end_POSTSUBSCRIPT, and from the equation \u00ce\u00bd2\u00e2\u02c6\u2019C1\u00e2\u02c6\u2014\u00e2\ufffd\u00a2\u00ce\u00bd+C2\u00e2\u02c6\u2014superscript\u011f\ufffd\u0153\u02c62superscriptsubscript\u011f\ufffd\ufffd\u00b61\u011f\ufffd\u0153\u02c6superscriptsubscript\u011f\ufffd\ufffd\u00b62 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - italic_C start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT italic_\u00ce\u00bd + italic_C start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u00e2\u02c6\u2014 end_POSTSUPERSCRIPT, we get \u00ce\u00bet,2subscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\u00a12 start_POSTSUBSCRIPT italic_t , 2 end_POSTSUBSCRIPT and \u00ce\u00bet,3subscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\u00a13 start_POSTSUBSCRIPT italic_t , 3 end_POSTSUBSCRIPT. Now, according to Lemma (4), the system (3) shows local stability around the equilibrium point Etsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a1E_{t}italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT if |a\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2g\u00e2\ufffd\u00a2(\u00ce\u00bet,1)|=\u00cf\u20ac>\u00ce\u00b3\u00e2\ufffd\u00a2\u00cf\u20ac2\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u201dsubscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\u00a11\u011f\ufffd\u0153\u2039\u011f\ufffd\u203a\u00be\u011f\ufffd\u0153\u20392|arg( italic_a italic_r italic_g ( italic_\u00ce\u00be start_POSTSUBSCRIPT italic_t , 1 end_POSTSUBSCRIPT ) | = italic_\u00cf\u20ac > divide start_ARG italic_\u00ce\u00b3 italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG, |a\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2g\u00e2\ufffd\u00a2(\u00ce\u00bet,2)|=\u00cf\u20ac>\u00ce\u00b3\u00e2\ufffd\u00a2\u00cf\u20ac2\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u201dsubscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\u00a12\u011f\ufffd\u0153\u2039\u011f\ufffd\u203a\u00be\u011f\ufffd\u0153\u20392|arg( italic_a italic_r italic_g ( italic_\u00ce\u00be start_POSTSUBSCRIPT italic_t , 2 end_POSTSUBSCRIPT ) | = italic_\u00cf\u20ac > divide start_ARG italic_\u00ce\u00b3 italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG, and |a\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2g\u00e2\ufffd\u00a2(\u00ce\u00bet,3)|=\u00cf\u20ac>\u00ce\u00b3\u00e2\ufffd\u00a2\u00cf\u20ac2\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u201dsubscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\u00a13\u011f\ufffd\u0153\u2039\u011f\ufffd\u203a\u00be\u011f\ufffd\u0153\u20392|arg( italic_a italic_r italic_g ( italic_\u00ce\u00be start_POSTSUBSCRIPT italic_t , 3 end_POSTSUBSCRIPT ) | = italic_\u00cf\u20ac > divide start_ARG italic_\u00ce\u00b3 italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG. If the conditions ( t33<0subscript\u011f\ufffd\u2018\u00a1330t_{33}<0italic_t start_POSTSUBSCRIPT 33 end_POSTSUBSCRIPT < 0, ( t112+4\u00e2\ufffd\u00a2t12\u00e2\ufffd\u00a2t21<0superscriptsubscript\u011f\ufffd\u2018\u00a11124subscript\u011f\ufffd\u2018\u00a112subscript\u011f\ufffd\u2018\u00a1210t_{11}^{2}+4t_{12}t_{21}<0italic_t start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + 4 italic_t start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT 21 end_POSTSUBSCRIPT < 0, and ( t11<0subscript\u011f\ufffd\u2018\u00a1110t_{11}<0italic_t start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT < 0 satisfies, then |a\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2g\u00e2\ufffd\u00a2(\u00ce\u00bet,1)|=\u00cf\u20ac>\u00ce\u00b3\u00e2\ufffd\u00a2\u00cf\u20ac2\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u201dsubscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\u00a11\u011f\ufffd\u0153\u2039\u011f\ufffd\u203a\u00be\u011f\ufffd\u0153\u20392|arg( italic_a italic_r italic_g ( italic_\u00ce\u00be start_POSTSUBSCRIPT italic_t , 1 end_POSTSUBSCRIPT ) | = italic_\u00cf\u20ac > divide start_ARG italic_\u00ce\u00b3 italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG, |a\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2g\u00e2\ufffd\u00a2(\u00ce\u00bet,2)|=\u00cf\u20ac>\u00ce\u00b3\u00e2\ufffd\u00a2\u00cf\u20ac2\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u201dsubscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\u00a12\u011f\ufffd\u0153\u2039\u011f\ufffd\u203a\u00be\u011f\ufffd\u0153\u20392|arg( italic_a italic_r italic_g ( italic_\u00ce\u00be start_POSTSUBSCRIPT italic_t , 2 end_POSTSUBSCRIPT ) | = italic_\u00cf\u20ac > divide start_ARG italic_\u00ce\u00b3 italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG, and |a\u00e2\ufffd\u00a2r\u00e2\ufffd\u00a2g\u00e2\ufffd\u00a2(\u00ce\u00bet,3)|=\u00cf\u20ac>\u00ce\u00b3\u00e2\ufffd\u00a2\u00cf\u20ac2\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u201dsubscript\u011f\ufffd\u0153\u2030\u011f\ufffd\u2018\u00a13\u011f\ufffd\u0153\u2039\u011f\ufffd\u203a\u00be\u011f\ufffd\u0153\u20392|arg( italic_a italic_r italic_g ( italic_\u00ce\u00be start_POSTSUBSCRIPT italic_t , 3 end_POSTSUBSCRIPT ) | = italic_\u00cf\u20ac > divide start_ARG italic_\u00ce\u00b3 italic_\u00cf\u20ac end_ARG start_ARG 2 end_ARG. Thus, the system (3) shows local stability around the equilibrium point Etsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a1E_{t}italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT if the criteria ( t33<0subscript\u011f\ufffd\u2018\u00a1330t_{33}<0italic_t start_POSTSUBSCRIPT 33 end_POSTSUBSCRIPT < 0, ( t112+4\u00e2\ufffd\u00a2t12\u00e2\ufffd\u00a2t21<0superscriptsubscript\u011f\ufffd\u2018\u00a11124subscript\u011f\ufffd\u2018\u00a112subscript\u011f\ufffd\u2018\u00a1210t_{11}^{2}+4t_{12}t_{21}<0italic_t start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + 4 italic_t start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT 21 end_POSTSUBSCRIPT < 0, and ( t11<0subscript\u011f\ufffd\u2018\u00a1110t_{11}<0italic_t start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT < 0 hold. Hence, the theorem. \u00e2\u02c6\ufffd If any of the criteria ( ( and ( specified in the proof are satisfied, the coexisting equilibrium point Ec\u00e2\ufffd\u00a2(C,D,E)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b8E_{c}(C,D,E)italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( italic_C , italic_D , italic_E ) is locally asymptotically stable. In order to determine the local stability conditions of the system (3) in the vicinity of the coexistence equilibrium point Ec\u00e2\ufffd\u00a2(C,D,E)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b8E_{c}(C,D,E)italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( italic_C , italic_D , italic_E ), it is necessary to calculate the Jacobian matrix of the system (3) around the coexistence equilibrium point Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. The Jacobian matrix of the system (3) around the coexistence equilibrium point Ec\u00e2\ufffd\u00a2(C,D,E)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b8E_{c}(C,D,E)italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( italic_C , italic_D , italic_E ) is denoted as Jc\u00e2\ufffd\u00a2osubscript\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0153J_{co}italic_J start_POSTSUBSCRIPT italic_c italic_o end_POSTSUBSCRIPT, as previously provided in subsection (6.1). Now, let us consider, \u00cf\u00b1=\u00cf\u20183+N1\u00e2\ufffd\u00a2\u00cf\u20182+N2\u00e2\ufffd\u00a2\u00cf\u2018+N3italic-\u00cf\u00b1superscriptitalic-\u00cf\u20183subscript\u011f\ufffd\u2018\ufffd1superscriptitalic-\u00cf\u20182subscript\u011f\ufffd\u2018\ufffd2italic-\u00cf\u2018subscript\u011f\ufffd\u2018\ufffd3 = italic_\u00cf\u2018 start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT + italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_\u00cf\u2018 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_\u00cf\u2018 + italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT. The establishment of local asymptotic stability for the equilibrium point Ec\u00e2\ufffd\u00a2(C,D,E)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b8E_{c}(C,D,E)italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( italic_C , italic_D , italic_E ) in the system (3) is contingent upon the satisfaction of any of the following conditions [54]: ( If \u00ce\u201d\u00e2\ufffd\u00a2(\u00cf\u00b1)>0\u00ce\u201ditalic-\u00cf\u00b10 ( italic_\u00cf\u00b1 ) > 0, N1>0subscript\u011f\ufffd\u2018\ufffd10N_{1}>0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT > 0, N3>0subscript\u011f\ufffd\u2018\ufffd30N_{3}>0italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT > 0, and N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3>0subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd30N_{1}N_{2}-N_{3}>0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT > 0. ( If \u00ce\u201d\u00e2\ufffd\u00a2(\u00cf\u00b1)<0\u00ce\u201ditalic-\u00cf\u00b10 ( italic_\u00cf\u00b1 ) < 0, then N1\u00e2\u2030\u00a50subscript\u011f\ufffd\u2018\ufffd10N_{1} 0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030\u00a5 0, N2\u00e2\u2030\u00a50subscript\u011f\ufffd\u2018\ufffd20N_{2} 0italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT \u00e2\u2030\u00a5 0, N3>0subscript\u011f\ufffd\u2018\ufffd30N_{3}>0italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT > 0, and \u00ce\u00b3<23\u011f\ufffd\u203a\u00be23 < divide start_ARG 2 end_ARG start_ARG 3 end_ARG. ( If \u00ce\u201d\u00e2\ufffd\u00a2(\u00cf\u00b1)<0\u00ce\u201ditalic-\u00cf\u00b10 ( italic_\u00cf\u00b1 ) < 0, N1>0subscript\u011f\ufffd\u2018\ufffd10N_{1}>0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT > 0, N2>0subscript\u011f\ufffd\u2018\ufffd20N_{2}>0italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT > 0, N1\u00e2\ufffd\u00a2N2=N3subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd3N_{1}N_{2}=N_{3}italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT, and \u00ce\u00b3\u00e2\u02c6\u02c6(0,1)\u011f\ufffd\u203a\u00be01 \u00e2\u02c6\u02c6 ( 0 , 1 ). Here, \u00ce\u201d\u00e2\ufffd\u00a2(\u00cf\u00b1)=18\u00e2\ufffd\u00a2N1\u00e2\ufffd\u00a2N2\u00e2\ufffd\u00a2N3+(N1\u00e2\ufffd\u00a2N2)2\u00e2\u02c6\u20194\u00e2\ufffd\u00a2(N1)2\u00e2\ufffd\u00a2N3\u00e2\u02c6\u20194\u00e2\ufffd\u00a2(N2)2\u00e2\u02c6\u201927\u00e2\ufffd\u00a2(N3)2\u00ce\u201ditalic-\u00cf\u00b118subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd3superscriptsubscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd224superscriptsubscript\u011f\ufffd\u2018\ufffd12subscript\u011f\ufffd\u2018\ufffd34superscriptsubscript\u011f\ufffd\u2018\ufffd2227superscriptsubscript\u011f\ufffd\u2018\ufffd32 {2}-27(N_{3})^{2}roman_\u00ce\u201d ( italic_\u00cf\u00b1 ) = 18 italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + ( italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - 4 ( italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT - 4 ( italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - 27 ( italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT. In a subsequent section, the numerical verification of the local stability of Ec\u00e2\ufffd\u00a2(C,D,E)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b8E_{c}(C,D,E)italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( italic_C , italic_D , italic_E ) will be conducted. \u00e2\u02c6\ufffd Bifurcation in ecology denotes a substantial modification in the configuration or conduct of an ecological system resulting from variations in factors. The bifurcation point refers to the precise instant when a system undergoes a change from one stable state to another, possibly leading to different population densities. Bifurcations can have substantial consequences for the management and conservation of ecosystems. Transcritical bifurcation is a phenomenon in dynamical systems when the stability of two equilibrium points, one stable and one unstable, switch as a parameter is changed. This phenomena is of great significance when it comes to comprehending diverse ecological and biological systems, as it can elucidate changes in population dynamics, species interactions, and ecosystem states. Theorems pertaining to this can be found below. The system (2) undergoes a transcritical bifurcation near the equilibrium point Easubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{a}italic_E start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT at the critical value r1subscript\u011f\ufffd\u2018\u01781r_{1}italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT=q\u00e2\ufffd\u00a2r=r1t\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178superscriptsubscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdqr=r_{1}^{tbp}italic_q italic_r = italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t italic_b italic_p end_POSTSUPERSCRIPT. The Jacobian matrix of the system (2) around Easubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{a}italic_E start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT is Ja\u00e2\ufffd\u00a2xsubscript\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5J_{ax}italic_J start_POSTSUBSCRIPT italic_a italic_x end_POSTSUBSCRIPT as mentioned in the previous section. Using r1=q\u00e2\ufffd\u00a2r=r1t\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2psubscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178superscriptsubscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdr_{1}=qr=r_{1}^{tbp}italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_q italic_r = italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t italic_b italic_p end_POSTSUPERSCRIPT, we get Now, we assume that the zero eigenvalues of (Ja\u00e2\ufffd\u00a2x)r1=r1t\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2psubscriptsubscript\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5subscript\u011f\ufffd\u2018\u01781superscriptsubscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd(J_{ax})_{r_{1}=r_{1}^{tbp}}( italic_J start_POSTSUBSCRIPT italic_a italic_x end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t italic_b italic_p end_POSTSUPERSCRIPT end_POSTSUBSCRIPT and (Ja\u00e2\ufffd\u00a2x)r1=r1t\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2ptsubscriptsuperscriptsubscript\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5\u011f\ufffd\u2018\u00a1subscript\u011f\ufffd\u2018\u01781superscriptsubscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd(J_{ax})^{t}_{r_{1}=r_{1}^{tbp}}( italic_J start_POSTSUBSCRIPT italic_a italic_x end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t italic_b italic_p end_POSTSUPERSCRIPT end_POSTSUBSCRIPT correspond to two eigenvectors, U1subscript\u011f\ufffd\u2018\u02c61U_{1}italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and U2subscript\u011f\ufffd\u2018\u02c62U_{2}italic_U start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, respectively. After some computation, we get U1=(u11,u12,u13)t=(1,0,0)tsubscript\u011f\ufffd\u2018\u02c61superscriptsubscript\u011f\ufffd\u2018\u00a211subscript\u011f\ufffd\u2018\u00a212subscript\u011f\ufffd\u2018\u00a213\u011f\ufffd\u2018\u00a1superscript100\u011f\ufffd\u2018\u00a1U_{1}=(u_{11},u_{12},u_{13})^{t}=(1,0,0)^{t}italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = ( italic_u start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT , italic_u start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT , italic_u start_POSTSUBSCRIPT 13 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT = ( 1 , 0 , 0 ) start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT and U2=(u21,u22,u23)t=(1,0,0)tsubscript\u011f\ufffd\u2018\u02c62superscriptsubscript\u011f\ufffd\u2018\u00a221subscript\u011f\ufffd\u2018\u00a222subscript\u011f\ufffd\u2018\u00a223\u011f\ufffd\u2018\u00a1superscript100\u011f\ufffd\u2018\u00a1U_{2}=(u_{21},u_{22},u_{23})^{t}=(1,0,0)^{t}italic_U start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = ( italic_u start_POSTSUBSCRIPT 21 end_POSTSUBSCRIPT , italic_u start_POSTSUBSCRIPT 22 end_POSTSUBSCRIPT , italic_u start_POSTSUBSCRIPT 23 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT = ( 1 , 0 , 0 ) start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT. Now, the theorem put forward by Sotomayor [55] is used to demonstrate the occurrence of a transcritical bifurcation at r1=q\u00e2\ufffd\u00a2r=r1t\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2psubscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178superscriptsubscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdr_{1}=qr=r_{1}^{tbp}italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_q italic_r = italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t italic_b italic_p end_POSTSUPERSCRIPT in the vicinity of Easubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{a}italic_E start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT. Outlined below are the prerequisites for transcritical bifurcation, as stated in Sotomayor\u00e2\u20ac\u2122s theorem [55]. Zr1\u00e2\ufffd\u00a2(Ea;r1t\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p)=[000],D\u00e2\ufffd\u00a2(Zr1\u00e2\ufffd\u00a2(E1;r1t\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p))\u00e2\ufffd\u00a2U1=[q\u00e2\ufffd\u00a2r00000000]\u00e2\ufffd\u00a2[100]=[q\u00e2\ufffd\u00a2r00],formulae-sequencesubscript\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdmatrix000\u011f\ufffd\ufffd\u00b7subscript\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\ufffd\u00b81superscriptsubscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u02c61matrix\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u017800000000matrix100matrix\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u017800Z_{r_{1}}(E_{a};r_{1}^{tbp})= 0 0 0&0&0 0&0&0 0 0 0 0 start_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_E start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ; italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t italic_b italic_p end_POSTSUPERSCRIPT ) = [ start_ARG start_ROW start_CELL 0 end_CELL end_ROW start_ROW start_CELL 0 end_CELL end_ROW start_ROW start_CELL 0 end_CELL end_ROW end_ARG ] , italic_D ( italic_Z start_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_E start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ; italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t italic_b italic_p end_POSTSUPERSCRIPT ) ) italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = [ start_ARG start_ROW start_CELL italic_q italic_r end_CELL start_CELL 0 end_CELL start_CELL 0 end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL 0 end_CELL start_CELL 0 end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL 0 end_CELL start_CELL 0 end_CELL end_ROW end_ARG ] [ start_ARG start_ROW start_CELL 1 end_CELL end_ROW start_ROW start_CELL 0 end_CELL end_ROW start_ROW start_CELL 0 end_CELL end_ROW end_ARG ] = [ start_ARG start_ROW start_CELL italic_q italic_r end_CELL end_ROW start_ROW start_CELL 0 end_CELL end_ROW start_ROW start_CELL 0 end_CELL end_ROW end_ARG ] , and D2\u00e2\ufffd\u00a2(Zr1\u00e2\ufffd\u00a2(E1;r1t\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p))\u00e2\ufffd\u00a2(U1,U1)=[\u00e2\u02c6\u20192\u00e2\ufffd\u00a2r1+2\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2\u00e2\u02c6\u20192\u00e2\ufffd\u00a2(\u00e2\u02c6\u20191+m1)\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2r30]superscript\u011f\ufffd\ufffd\u00b72subscript\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u01781subscript\u011f\ufffd\ufffd\u00b81superscriptsubscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\u02c61subscript\u011f\ufffd\u2018\u02c61matrix2subscript\u011f\ufffd\u2018\u0178121subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u0178221subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u01782subscript\u011f\ufffd\u2018\u017830D^{2}(Z_{r_{1}}(E_{1};r_{1}^{tbp}))(U_{1},U_{1})= _{1})r_{2} -2(-1+m_{1})r_{2}r_{3} 0 start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( italic_Z start_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_E start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ; italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t italic_b italic_p end_POSTSUPERSCRIPT ) ) ( italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) = [ start_ARG start_ROW start_CELL - 2 italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + 2 ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL - 2 ( - 1 + italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL 0 end_CELL end_ROW end_ARG ] . Therefore, Thus, the application of Sotomayor\u00e2\u20ac\u2122s theorem [55] proves the presence of a transcritical bifurcation around Easubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{a}italic_E start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT at r1subscript\u011f\ufffd\u2018\u01781r_{1}italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT=q\u00e2\ufffd\u00a2r=r1t\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178superscriptsubscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdqr=r_{1}^{tbp}italic_q italic_r = italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t italic_b italic_p end_POSTSUPERSCRIPT. In addition, there are additional parameters that can be utilised as bifurcation parameters. \u00e2\u02c6\ufffd The Hopf bifurcation is a well-known and extensively studied phenomenon in the field of dynamical systems. It has been observed in various domains, including ecological models, where it plays a crucial role in understanding the qualitative changes in system behaviour as a parameter is systematically varied. The comprehension of Hopf bifurcation in the field of ecology holds significant importance for ecologists, as it enables them to comprehend the inherent capacity for intricate, cyclical patterns in the dynamics of populations. The following theorem establishes the conditions for the existence of Hopf bifurcation in the system (2) around the interior equilibrium point Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. The necessary and sufficient criteria for the system (2) to experience a Hopf bifurcation at m1=m1h\u00e2\ufffd\u00a2bsubscript\u011f\ufffd\u2018\u01611superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffdm_{1}=m_{1}^{hb}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT are as follows: ( Ni\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b)>0subscript\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u2013superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd0N_{i}(m_{1}^{hb})>0italic_N start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT ) > 0, i=1,2,3 ( N1\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b)\u00e2\ufffd\u00a2N2\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b)=N3\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b)subscript\u011f\ufffd\u2018\ufffd1superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd2superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd3superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffdN_{1}(m_{1}^{hb})N_{2}(m_{1}^{hb})=N_{3}(m_{1}^{hb})italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT ) italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT ) = italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT ), ( start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT ) N2\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\ufffd2\u00e2\u20ac\u00b2N_{2}^{{}^{ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT(m1h\u00e2\ufffd\u00a2bsuperscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffdm_{1}^{hb}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT) +N2\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b)subscript\u011f\ufffd\u2018\ufffd2superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffdN_{2}(m_{1}^{hb})italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT ) N1\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\ufffd1\u00e2\u20ac\u00b2N_{1}^{{}^{ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT(m1h\u00e2\ufffd\u00a2bsuperscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffdm_{1}^{hb}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT) -N3\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\ufffd3\u00e2\u20ac\u00b2N_{3}^{{}^{ start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT(m1h\u00e2\ufffd\u00a2bsuperscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffdm_{1}^{hb}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT) \u00e2\u2030 0absent0 0\u00e2\u2030 0, j=1,2,3, here, N1subscript\u011f\ufffd\u2018\ufffd1N_{1}italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, N2subscript\u011f\ufffd\u2018\ufffd2N_{2}italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, and N3subscript\u011f\ufffd\u2018\ufffd3N_{3}italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT are already defined in the theorem (8). \u00ce\u00b41subscript\u011f\ufffd\u203a\u00bf1 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, \u00ce\u00b42subscript\u011f\ufffd\u203a\u00bf2 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, and \u00ce\u00b43subscript\u011f\ufffd\u203a\u00bf3 start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT are the roots of the characteristic equation of the Jacobian matrix Jc\u00e2\ufffd\u00a2osubscript\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0153J_{co}italic_J start_POSTSUBSCRIPT italic_c italic_o end_POSTSUBSCRIPT. Taking m1=m1h\u00e2\ufffd\u00a2bsubscript\u011f\ufffd\u2018\u01611superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffdm_{1}=m_{1}^{hb}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT, the characteristic equation of the Jacobian matrix Jc\u00e2\ufffd\u00a2osubscript\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0153J_{co}italic_J start_POSTSUBSCRIPT italic_c italic_o end_POSTSUBSCRIPT reduces to now, the roots of the equation (12) are \u00ce\u00b41=\u00e2\u02c6\u2019N1subscript\u011f\ufffd\u203a\u00bf1subscript\u011f\ufffd\u2018\ufffd1 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = - italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and \u00ce\u00b42,3=\u00c2\u00b1i\u00e2\ufffd\u00a2N2subscript\u011f\ufffd\u203a\u00bf23plus-or-minus\u011f\ufffd\u2018\u2013subscript\u011f\ufffd\u2018\ufffd2 i start_POSTSUBSCRIPT 2 , 3 end_POSTSUBSCRIPT = \u00c2\u00b1 italic_i square-root start_ARG italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG. Let us consider, the roots of the characteristic equation for m1\u00e2\u02c6\u02c6(m1h\u00e2\ufffd\u00a2b\u00e2\u02c6\u2019\u00cf\u00b5,m1h\u00e2\ufffd\u00a2b+\u00cf\u00b5)subscript\u011f\ufffd\u2018\u01611superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffditalic-\u00cf\u00b5superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffditalic-\u00cf\u00b5m_{1} start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u02c6\u02c6 ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT - italic_\u00cf\u00b5 , italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT + italic_\u00cf\u00b5 ), \u00cf\u00b5>0italic-\u00cf\u00b50 > 0 are Now, we need to confirm the transversality condition ( By substituting \u00ce\u00b42\u00e2\ufffd\u00a2(m1)=\u00ce\u00a61\u00e2\ufffd\u00a2(m1)+i\u00e2\ufffd\u00a2\u00ce\u00a62\u00e2\ufffd\u00a2(m1)subscript\u011f\ufffd\u203a\u00bf2subscript\u011f\ufffd\u2018\u01611subscript\u00ce\u00a61subscript\u011f\ufffd\u2018\u01611\u011f\ufffd\u2018\u2013subscript\u00ce\u00a62subscript\u011f\ufffd\u2018\u01611 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) = roman_\u00ce\u00a6 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) + italic_i roman_\u00ce\u00a6 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) into equation (11)11( ) and subsequently differentiating and separating the real and imaginary parts, we obtain where, P\u00e2\ufffd\u00a2(m1)=3\u00e2\ufffd\u00a2\u00ce\u00a612\u00e2\ufffd\u00a2(m1)\u00e2\u02c6\u20193\u00e2\ufffd\u00a2\u00ce\u00a622\u00e2\ufffd\u00a2(m1)+N2\u00e2\ufffd\u00a2(m1)+2\u00e2\ufffd\u00a2N1\u00e2\ufffd\u00a2(m1)\u00e2\ufffd\u00a2\u00ce\u00a61\u00e2\ufffd\u00a2(m1)\u011f\ufffd\u2018\u0192subscript\u011f\ufffd\u2018\u016113superscriptsubscript\u00ce\u00a612subscript\u011f\ufffd\u2018\u016113superscriptsubscript\u00ce\u00a622subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\u016112subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u01611subscript\u00ce\u00a61subscript\u011f\ufffd\u2018\u01611P(m_{1})=3 ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) = 3 roman_\u00ce\u00a6 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) - 3 roman_\u00ce\u00a6 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) + italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) + 2 italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) roman_\u00ce\u00a6 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) , Q\u00e2\ufffd\u00a2(m1)=6\u00e2\ufffd\u00a2\u00ce\u00a61\u00e2\ufffd\u00a2(m1)\u00e2\ufffd\u00a2\u00ce\u00a62\u00e2\ufffd\u00a2(m1)+2\u00e2\ufffd\u00a2N1\u00e2\ufffd\u00a2(m1)\u00e2\ufffd\u00a2\u00ce\u00a62\u00e2\ufffd\u00a2(m1)\u011f\ufffd\u2018\u201esubscript\u011f\ufffd\u2018\u016116subscript\u00ce\u00a61subscript\u011f\ufffd\u2018\u01611subscript\u00ce\u00a62subscript\u011f\ufffd\u2018\u016112subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\u01611subscript\u00ce\u00a62subscript\u011f\ufffd\u2018\u01611Q(m_{1})=6 ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) = 6 roman_\u00ce\u00a6 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) roman_\u00ce\u00a6 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) + 2 italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) roman_\u00ce\u00a6 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) , and R\u00e2\ufffd\u00a2(m1)=N1\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(m1)\u00e2\ufffd\u00a2\u00ce\u00a612\u00e2\ufffd\u00a2(m1)\u00e2\u02c6\u2019N1\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(m1)\u00e2\ufffd\u00a2\u00ce\u00a622\u00e2\ufffd\u00a2(m1)+N2\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(m1)\u00e2\ufffd\u00a2\u00ce\u00a61\u00e2\ufffd\u00a2(m1)+N3\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(m1)\u011f\ufffd\u2018\u2026subscript\u011f\ufffd\u2018\u01611superscriptsubscript\u011f\ufffd\u2018\ufffd1\u00e2\u20ac\u00b2subscript\u011f\ufffd\u2018\u01611superscriptsubscript\u00ce\u00a612subscript\u011f\ufffd\u2018\u01611superscriptsubscript\u011f\ufffd\u2018\ufffd1\u00e2\u20ac\u00b2subscript\u011f\ufffd\u2018\u01611superscriptsubscript\u00ce\u00a622subscript\u011f\ufffd\u2018\u01611superscriptsubscript\u011f\ufffd\u2018\ufffd2\u00e2\u20ac\u00b2subscript\u011f\ufffd\u2018\u01611subscript\u00ce\u00a61subscript\u011f\ufffd\u2018\u01611superscriptsubscript\u011f\ufffd\u2018\ufffd3\u00e2\u20ac\u00b2subscript\u011f\ufffd\u2018\u01611R(m_{1})=N_{1}^{{}^{ 1}) ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) = italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) roman_\u00ce\u00a6 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) - italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) roman_\u00ce\u00a6 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) + italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) roman_\u00ce\u00a6 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) + italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ), S\u00e2\ufffd\u00a2(m1)=N2\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(m1)\u00e2\ufffd\u00a2\u00ce\u00a62\u00e2\ufffd\u00a2(m1)+2\u00e2\ufffd\u00a2\u00ce\u00a61\u00e2\ufffd\u00a2(m1)\u00e2\ufffd\u00a2\u00ce\u00a62\u00e2\ufffd\u00a2(m1)\u011f\ufffd\u2018\u2020subscript\u011f\ufffd\u2018\u01611superscriptsubscript\u011f\ufffd\u2018\ufffd2\u00e2\u20ac\u00b2subscript\u011f\ufffd\u2018\u01611subscript\u00ce\u00a62subscript\u011f\ufffd\u2018\u016112subscript\u00ce\u00a61subscript\u011f\ufffd\u2018\u01611subscript\u00ce\u00a62subscript\u011f\ufffd\u2018\u01611S(m_{1})=N_{2}^{{}^{ {1})italic_S ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) = italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) roman_\u00ce\u00a6 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) + 2 roman_\u00ce\u00a6 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) roman_\u00ce\u00a6 start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ). Now, we get, P\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b)=\u00e2\u02c6\u20192\u00e2\ufffd\u00a2N2\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b)\u011f\ufffd\u2018\u0192superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd2superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffdP(m_{1}^{hb})=-2N_{2}(m_{1}^{hb})italic_P ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT ) = - 2 italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT ) , Q\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b)=2\u00e2\ufffd\u00a2N1\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b)\u00e2\ufffd\u00a2N2\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b)\u011f\ufffd\u2018\u201esuperscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd1superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd2superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffdQ(m_{1}^{hb})=2N_{1}(m_{1}^{hb}) ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT ) = 2 italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT ) square-root start_ARG italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT ) end_ARG , and R\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b)=N3\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b)\u00e2\u02c6\u2019N1\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b)\u00e2\ufffd\u00a2N2\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b)\u011f\ufffd\u2018\u2026superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\ufffd3\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\ufffd1\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd2superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffdR(m_{1}^{hb})=N_{3}^{{}^{ _{2}(m_{1}^{hb})italic_R ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT ) = italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT ) - italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT ) italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT ) , S\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b)=N2\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b)\u00e2\ufffd\u00a2N2\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b)\u011f\ufffd\u2018\u2020superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd2superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\ufffd2\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffdS(m_{1}^{hb})= ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT ) = square-root start_ARG italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT ) end_ARG italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT ). Therefore, the following equation is obtained Now, the transversality condition is met when N1\u00e2\u20ac\u00b2N2\u00e2\u02c6\u2019N3\u00e2\u20ac\u00b2+N1N2\u00e2\u2030 \u00e2\u20ac\u00b20N_{1}^{{}^{ 0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT + italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT \u00e2\u2030 0 and \u00ce\u00b41\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b)=\u00e2\u02c6\u2019N1\u00e2\u2030 0subscript\u011f\ufffd\u203a\u00bf1superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd10 0italic_\u00ce\u00b4 start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT ) = - italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \u00e2\u2030 0 hold true. This suggests that a Hopf bifurcation takes place at the equilibrium point Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT when the value of m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT reaches the critical value m1h\u00e2\ufffd\u00a2bsuperscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffdm_{1}^{hb}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT. Therefore, the theorem follows. \u00e2\u02c6\ufffd In the previous sections, we already established some analytical conclusions. In this section, we conduct a numerical investigation into the dynamics of the prey-predator systems (2) and (3) and substantiate our analytical conclusions by utilizing some hypothetical parameter values. The analytical results obtained in previous sections are further supported by the utilisation of numerous figures generated by the use of the Mathematica and MATLAB software packages. In this section, we employ numerical methods to confirm the local stability of the equilibrium points of the integer order system (2) and the fractional order system (3) discussed in the preceding sections. At first, we will examine the local stability criteria of the equilibrium points of the system specified in the equation (2). In order to achieve this objective, we will examine some theoretical values of parameters. To verify the local stability of the vanishing equilibrium point Evsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a3E_{v}italic_E start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT, we consider the parameter values: r1=0.46subscript\u011f\ufffd\u2018\u017810.46r_{1}=0.46italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.46, r2=0.32subscript\u011f\ufffd\u2018\u017820.32r_{2}=0.32italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.32, r3=0.5subscript\u011f\ufffd\u2018\u017830.5r_{3}=0.5italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.5, r4=0.002subscript\u011f\ufffd\u2018\u017840.002r_{4}=0.002italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 0.002, r5=0.38subscript\u011f\ufffd\u2018\u017850.38r_{5}=0.38italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 0.38, \u00ce\u00b2=4.047\u011f\ufffd\u203a\u00bd4.047 = 4.047, m1=0.72subscript\u011f\ufffd\u2018\u016110.72m_{1}=0.72italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.72, m2=0.17subscript\u011f\ufffd\u2018\u016120.17m_{2}=0.17italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.17, d1=0.096subscript\u011f\ufffd\u2018\u201810.096d_{1}=0.096italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.096, d2=0.279subscript\u011f\ufffd\u2018\u201820.279d_{2}=0.279italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.279, c1=3.33subscript\u011f\ufffd\u2018\ufffd13.33c_{1}=3.33italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 3.33, q=1.35\u011f\ufffd\u2018\ufffd1.35q=1.35italic_q = 1.35, and r=0.38\u011f\ufffd\u2018\u01780.38r=0.38italic_r = 0.38. The eigenvalues of the Jacobian matrix Jv\u00e2\ufffd\u00a2asubscript\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u2018\u00a3\u011f\ufffd\u2018\ufffdJ_{va}italic_J start_POSTSUBSCRIPT italic_v italic_a end_POSTSUBSCRIPT of the system (2) around the vanishing equilibrium point Evsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a3E_{v}italic_E start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT are \u00e2\u02c6\u20190.096<00.0960-0.096<0- 0.096 < 0, \u00e2\u02c6\u20190.279<00.2790-0.279<0- 0.279 < 0, and \u00e2\u02c6\u20190.053<00.0530-0.053<0- 0.053 < 0 for these parameter values. Therefore, the vanishing equilibrium point Evsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a3E_{v}italic_E start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT is locally asymptotically stable, as depicted in figure (3). In addition, the numerical conditions necessary for the local stability of the equilibrium point Evsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a3E_{v}italic_E start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT, as stated in theorem (5), are also met, with r1q=0.34<rsubscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\ufffd0.34\u011f\ufffd\u2018\u0178 start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG italic_q end_ARG = 0.34 < italic_r. By reducing the value of the parameter q\u011f\ufffd\u2018\ufffdqitalic_q i.e., considering the following parameter values: r1=0.46subscript\u011f\ufffd\u2018\u017810.46r_{1}=0.46italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.46, r2=0.32subscript\u011f\ufffd\u2018\u017820.32r_{2}=0.32italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.32, r3=0.5subscript\u011f\ufffd\u2018\u017830.5r_{3}=0.5italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.5, r4=0.002subscript\u011f\ufffd\u2018\u017840.002r_{4}=0.002italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 0.002, r5=0.38subscript\u011f\ufffd\u2018\u017850.38r_{5}=0.38italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 0.38, \u00ce\u00b2=4.047\u011f\ufffd\u203a\u00bd4.047 = 4.047, m1=0.72subscript\u011f\ufffd\u2018\u016110.72m_{1}=0.72italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.72, m2=0.17subscript\u011f\ufffd\u2018\u016120.17m_{2}=0.17italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.17, d1=0.096subscript\u011f\ufffd\u2018\u201810.096d_{1}=0.096italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.096, d2=0.279subscript\u011f\ufffd\u2018\u201820.279d_{2}=0.279italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.279, c1=3.33subscript\u011f\ufffd\u2018\ufffd13.33c_{1}=3.33italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 3.33, q=0.838\u011f\ufffd\u2018\ufffd0.838q=0.838italic_q = 0.838, and r=0.38\u011f\ufffd\u2018\u01780.38r=0.38italic_r = 0.38, we can establish the local stability of the axial equilibrium point Easubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{a}italic_E start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT. The eigenvalues of the Jacobian matrix Ja\u00e2\ufffd\u00a2xsubscript\u011f\ufffd\ufffd\u00bd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u00a5J_{ax}italic_J start_POSTSUBSCRIPT italic_a italic_x end_POSTSUBSCRIPT of the system (2) around the axial equilibrium point Easubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{a}italic_E start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT are -0.279, -0.141341, and -0.0651173. Since all of the eigenvalues are negative, the local stability of the axial equilibrium point is established. Furthermore, it meets all the numerical requirements stated in theorem (6). Figure (3) provides visual evidence of the local stability of the axial equilibrium point Easubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{a}italic_E start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT. On further reduction of the parameter q\u011f\ufffd\u2018\ufffdqitalic_q to q=0.019\u011f\ufffd\u2018\ufffd0.019q=0.019italic_q = 0.019 and keeping the other parameter values the same as previously mentioned, we obtain that M1=0.682878>0subscript\u011f\ufffd\u2018\u20ac10.6828780M_{1}=0.682878>0italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.682878 > 0, M2=0.140642>0subscript\u011f\ufffd\u2018\u20ac20.1406420M_{2}=0.140642>0italic_M start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.140642 > 0, M3=0.00780181>0subscript\u011f\ufffd\u2018\u20ac30.007801810M_{3}=0.00780181>0italic_M start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.00780181 > 0, and M1\u00e2\ufffd\u00a2M2\u00e2\u02c6\u2019M3=0.0882396>0subscript\u011f\ufffd\u2018\u20ac1subscript\u011f\ufffd\u2018\u20ac2subscript\u011f\ufffd\u2018\u20ac30.08823960M_{1}M_{2}-M_{3}=0.0882396>0italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_M start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_M start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.0882396 > 0. Based on the theorem (7), it can be inferred that the top predator free equilibrium point Etsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a1E_{t}italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is locally stable. The precise depiction can be found in figure (3). Now, in order to establish the local stability of the coexisting equilibrium point Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT, we examine the parameter values: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, \u00ce\u00b2=0.01\u011f\ufffd\u203a\u00bd0.01 = 0.01, m1=0.5subscript\u011f\ufffd\u2018\u016110.5m_{1}=0.5italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, m2=0.6subscript\u011f\ufffd\u2018\u016120.6m_{2}=0.6italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.6, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, q=0.5\u011f\ufffd\u2018\ufffd0.5q=0.5italic_q = 0.5, and r=0.01\u011f\ufffd\u2018\u01780.01r=0.01italic_r = 0.01. For these parameter values, we get the values N1=1.57033subscript\u011f\ufffd\u2018\ufffd11.57033N_{1}=1.57033italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1.57033, N2=0.0862411subscript\u011f\ufffd\u2018\ufffd20.0862411N_{2}=0.0862411italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.0862411, N3=0.0774249subscript\u011f\ufffd\u2018\ufffd30.0774249N_{3}=0.0774249italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.0774249, and N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3=0.0580017subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd30.0580017N_{1}N_{2}-N_{3}=0.0580017italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.0580017. Since N1subscript\u011f\ufffd\u2018\ufffd1N_{1}italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, N2subscript\u011f\ufffd\u2018\ufffd2N_{2}italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, N3subscript\u011f\ufffd\u2018\ufffd3N_{3}italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT, and N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd3N_{1}N_{2}-N_{3}italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT are all positive, it can be concluded that the coexisting equilibrium point Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT is locally stable based on theorem (8). Figure (3) perfectly illustrates the local stability of all the ecologically feasible equilibrium points, including the coexisting equilibrium point Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. In this section, we will perform numerical validation of the theoretical results concerning the local stability of the equilibrium points of the system (3) that have been outlined in the preceding sections. In order to validate the theorem numerically, we will examine the parameter values: r1=0.46subscript\u011f\ufffd\u2018\u017810.46r_{1}=0.46italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.46, r2=0.32subscript\u011f\ufffd\u2018\u017820.32r_{2}=0.32italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.32, r3=0.5subscript\u011f\ufffd\u2018\u017830.5r_{3}=0.5italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.5, r4=0.002subscript\u011f\ufffd\u2018\u017840.002r_{4}=0.002italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 0.002, r5=0.38subscript\u011f\ufffd\u2018\u017850.38r_{5}=0.38italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 0.38, \u00ce\u00b2=4.047\u011f\ufffd\u203a\u00bd4.047 = 4.047, m1=0.72subscript\u011f\ufffd\u2018\u016110.72m_{1}=0.72italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.72, m2=0.17subscript\u011f\ufffd\u2018\u016120.17m_{2}=0.17italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.17, d1=0.096subscript\u011f\ufffd\u2018\u201810.096d_{1}=0.096italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.096, d2=0.279subscript\u011f\ufffd\u2018\u201820.279d_{2}=0.279italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.279, c1=3.33subscript\u011f\ufffd\u2018\ufffd13.33c_{1}=3.33italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 3.33, q=1.35\u011f\ufffd\u2018\ufffd1.35q=1.35italic_q = 1.35, r=0.38\u011f\ufffd\u2018\u01780.38r=0.38italic_r = 0.38 and \u00ce\u00b1=0.98\u011f\ufffd\u203a\u00bc0.98 = 0.98. Given the parameter values, r>0.34=r1q\u011f\ufffd\u2018\u01780.34subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\ufffdr>0.34= > 0.34 = divide start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG italic_q end_ARG, i.e., the condition outlined in theorem (9) is satisfied, resulting in the local stability of Ev\u00e2\ufffd\u00a2(0,0,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a3000E_{v}(0,0,0)italic_E start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( 0 , 0 , 0 ). Figure (4(a)) illustrates this. Now, we will investigate a different set of parameter values: r1=0.46subscript\u011f\ufffd\u2018\u017810.46r_{1}=0.46italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.46, r2=0.32subscript\u011f\ufffd\u2018\u017820.32r_{2}=0.32italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.32, r3=0.5subscript\u011f\ufffd\u2018\u017830.5r_{3}=0.5italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.5, r4=0.002subscript\u011f\ufffd\u2018\u017840.002r_{4}=0.002italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 0.002, r5=0.38subscript\u011f\ufffd\u2018\u017850.38r_{5}=0.38italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 0.38, \u00ce\u00b2=4.047\u011f\ufffd\u203a\u00bd4.047 = 4.047, m1=0.72subscript\u011f\ufffd\u2018\u016110.72m_{1}=0.72italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.72, m2=0.17subscript\u011f\ufffd\u2018\u016120.17m_{2}=0.17italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.17, d1=0.096subscript\u011f\ufffd\u2018\u201810.096d_{1}=0.096italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.096, d2=0.279subscript\u011f\ufffd\u2018\u201820.279d_{2}=0.279italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.279, c1=3.33subscript\u011f\ufffd\u2018\ufffd13.33c_{1}=3.33italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 3.33, q=0.838\u011f\ufffd\u2018\ufffd0.838q=0.838italic_q = 0.838, r=0.38\u011f\ufffd\u2018\u01780.38r=0.38italic_r = 0.38 and \u00ce\u00b1=0.98\u011f\ufffd\u203a\u00bc0.98 = 0.98. With respect to the given parameter values, it can be concluded that all the conditions stated in theorem (10) are satisfied. Hence, Ea\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019q\u00e2\ufffd\u00a2rr1,0,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffd1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u0178100E_{a}(1- start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( 1 - divide start_ARG italic_q italic_r end_ARG start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG , 0 , 0 ) is locally stable. The local stability of Ea\u00e2\ufffd\u00a2(1\u00e2\u02c6\u2019q\u00e2\ufffd\u00a2rr1,0,0)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffd1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178subscript\u011f\ufffd\u2018\u0178100E_{a}(1- start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT ( 1 - divide start_ARG italic_q italic_r end_ARG start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG , 0 , 0 ) is illustrated properly in figure (4(b)). We set the parameter values as follows: r1=0.46subscript\u011f\ufffd\u2018\u017810.46r_{1}=0.46italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.46, r2=0.32subscript\u011f\ufffd\u2018\u017820.32r_{2}=0.32italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.32, r3=0.5subscript\u011f\ufffd\u2018\u017830.5r_{3}=0.5italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.5, r4=0.002subscript\u011f\ufffd\u2018\u017840.002r_{4}=0.002italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 0.002, r5=0.38subscript\u011f\ufffd\u2018\u017850.38r_{5}=0.38italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 0.38, \u00ce\u00b2=4.047\u011f\ufffd\u203a\u00bd4.047 = 4.047, m1=0.72subscript\u011f\ufffd\u2018\u016110.72m_{1}=0.72italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.72, m2=0.17subscript\u011f\ufffd\u2018\u016120.17m_{2}=0.17italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.17, d1=0.096subscript\u011f\ufffd\u2018\u201810.096d_{1}=0.096italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.096, d2=0.279subscript\u011f\ufffd\u2018\u201820.279d_{2}=0.279italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.279, c1=3.33subscript\u011f\ufffd\u2018\ufffd13.33c_{1}=3.33italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 3.33, q=0.019\u011f\ufffd\u2018\ufffd0.019q=0.019italic_q = 0.019, r=0.38\u011f\ufffd\u2018\u01780.38r=0.38italic_r = 0.38 and \u00ce\u00b1=0.98\u011f\ufffd\u203a\u00bc0.98 = 0.98. Since all the requirements stated in theorem (11) are satisfied, Etsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a1E_{t}italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is locally stable. Figure (4(c)) illustrates this accurately. In order to demonstrate the correctness of theorem (12), we utilise certain parameter values: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, \u00ce\u00b2=4.047\u011f\ufffd\u203a\u00bd4.047 = 4.047, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, m1=0.9471subscript\u011f\ufffd\u2018\u016110.9471m_{1}=0.9471italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.9471, m2=0.17subscript\u011f\ufffd\u2018\u016120.17m_{2}=0.17italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.17, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, q=0.5\u011f\ufffd\u2018\ufffd0.5q=0.5italic_q = 0.5, r=0.01\u011f\ufffd\u2018\u01780.01r=0.01italic_r = 0.01 and \u00ce\u00b1=0.98\u011f\ufffd\u203a\u00bc0.98 = 0.98. Given the above parameter values, we calculate the following values: \u00ce\u201d\u00e2\ufffd\u00a2(\u00cf\u00b1)=0.0024>0\u00ce\u201ditalic-\u00cf\u00b10.00240 ( italic_\u00cf\u00b1 ) = 0.0024 > 0, N1=1.98>0subscript\u011f\ufffd\u2018\ufffd11.980N_{1}=1.98>0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1.98 > 0, N3=0.00002>0subscript\u011f\ufffd\u2018\ufffd30.000020N_{3}=0.00002>0italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.00002 > 0, and N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3=0.05>0subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd30.050N_{1}N_{2}-N_{3}=0.05>0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.05 > 0. Therefore, all the conditions specified by theorem (12) are met. Thus, the local asymptotic stability of the fixed point Ec\u00e2\ufffd\u00a2(C,D,E)subscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffd\u011f\ufffd\ufffd\u00b6\u011f\ufffd\ufffd\u00b7\u011f\ufffd\ufffd\u00b8E_{c}(C,D,E)italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ( italic_C , italic_D , italic_E ) in the system (3) has been verified. This is clearly evident in figure (4(d)). Figure (3) provides a clear visual representation of the local stability of each of the equilibrium points, which are ecologically feasible in the system (2), including the coexisting equilibrium point Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. On the other hand, figure (4) provides an explicit graphical illustration of the local stability of all of the equilibrium points that are ecologically feasible for the system (3). From an ecological standpoint, it has been observed that when the rate at which a prey species reproduces naturally becomes lower than the rate at which it is harvested, the prey species is at risk of extinction. Consequently, both the predator species that depend on the prey also face extinction. This leads to the establishment of a stable equilibrium point where all three species vanish. In addition, in this scenario, the presence of the axial equilibrium point becomes unattainable, mirroring the natural occurrence where the intrinsic growth rate of the prey species falls below the harvesting rate, rendering survival impossible for the prey. Therefore, in order for the prey to survive, its growth rate must exceed its harvesting rate. Therefore, in the previously mentioned bio-systems (2) and (3), it is possible for all three species to become extinct under certain conditions. In certain situations, it is also possible for the predator species to face extinction while the prey species thrives. Interestingly, when the value of q\u011f\ufffd\u2018\ufffdqitalic_q is set to 0.0190.0190.0190.019 and other parameters are assigned values such as r1=0.46subscript\u011f\ufffd\u2018\u017810.46r_{1}=0.46italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.46, r2=0.32subscript\u011f\ufffd\u2018\u017820.32r_{2}=0.32italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.32, r3=0.5subscript\u011f\ufffd\u2018\u017830.5r_{3}=0.5italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.5, r4=0.002subscript\u011f\ufffd\u2018\u017840.002r_{4}=0.002italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 0.002, r5=0.38subscript\u011f\ufffd\u2018\u017850.38r_{5}=0.38italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 0.38, \u00ce\u00b2=4.047\u011f\ufffd\u203a\u00bd4.047 = 4.047, m1=0.72subscript\u011f\ufffd\u2018\u016110.72m_{1}=0.72italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.72, m2=0.17subscript\u011f\ufffd\u2018\u016120.17m_{2}=0.17italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.17, d1=0.096subscript\u011f\ufffd\u2018\u201810.096d_{1}=0.096italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.096, d2=0.279subscript\u011f\ufffd\u2018\u201820.279d_{2}=0.279italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.279, c1=3.33subscript\u011f\ufffd\u2018\ufffd13.33c_{1}=3.33italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 3.33, and r=0.38\u011f\ufffd\u2018\u01780.38r=0.38italic_r = 0.38, it is observed that only the top predator faces extinction, allowing the intermediate predator and the prey to persist within the system, regardless of the memory effect. By increasing the value of q\u011f\ufffd\u2018\ufffdqitalic_q to q=0.838\u011f\ufffd\u2018\ufffd0.838q=0.838italic_q = 0.838, both the top predator and the intermediate predator disappear, leaving only the prey species in the system. Furthermore, if the value of q\u011f\ufffd\u2018\ufffdqitalic_q is increased slightly to q=1.35\u011f\ufffd\u2018\ufffd1.35q=1.35italic_q = 1.35, all three species face extinction and the system under investigation collapses. From an ecological perspective, the population size of the prey diminishes as the amount being harvested rises. As a result, the food supply declines for the intermediate predators, which has an adverse effect on their growth rate. This, in turn, hinders the growth of the top predator because of the reduced availability of food that comes from intermediate predators. As a result, either species could become extinct inside the system due to the catchability coefficient (q\u011f\ufffd\u2018\ufffdqitalic_q). This makes the parameter q\u011f\ufffd\u2018\ufffdqitalic_q a very critical component of the system under consideration. In addition, it is noticed that, given some parametric settings, the coexistence of all three species within the system is conceivable. All the observations mentioned above are pertinent to both systems (2) and (3). Memory in predator-prey systems pertains to the capacity of organisms to recollect previous encounters and adapt their behaviour or strategy in accordance with those recollections. In the past, ecological models have primarily concentrated on immediate interactions wherein predators react to the present availability of prey and vice versa. However, the inclusion of memory in predator-prey models offers an additional level of richness and realism. Following that, we constructed the model (3) to investigate the impact of memory on the bio-system (2). The fractional order \u00ce\u00b1\u011f\ufffd\u203a\u00bc in the model (3) represents the degree of memory that is influencing the system under investigation. As the fractional order \u00ce\u00b1\u00e2\u2020\u20190\u00e2\u2020\u2019\u011f\ufffd\u203a\u00bc0 0italic_\u00ce\u00b1 \u00e2\u2020\u2019 0, the system demonstrates a greater level of memory. On the other hand, as the value of \u00ce\u00b1\u00e2\u2020\u20191\u00e2\u2020\u2019\u011f\ufffd\u203a\u00bc1 1italic_\u00ce\u00b1 \u00e2\u2020\u2019 1, the system becomes increasingly devoid of memory. Studies have shown that as the fractional order goes up, there is an accompanying reduction in retention of memory [56, 57, 58]. In order to have a deeper comprehension of the impact of memory on the system (3), we examine several scenarios by adjusting different parameter values. Figure (6) displays four distinct instances. In the first case, we discuss the situation in which the system (3) has a value of \u00ce\u00b1=1\u011f\ufffd\u203a\u00bc1 = 1 , which is equivalent to the system (2). The second instance involves considering the system (3) with the value of \u00ce\u00b1=0.98\u011f\ufffd\u203a\u00bc0.98 = 0.98. In the third scenario, the system (3) is analysed with a value of \u00ce\u00b1=0.9\u011f\ufffd\u203a\u00bc0.9 = 0.9, whereas in the fourth scenario, the system (3) is studied with a value of \u00ce\u00b1=0.85\u011f\ufffd\u203a\u00bc0.85 = 0.85. Figure (6) clearly demonstrates that when the order of the fractional derivative decreases, i.e., \u00ce\u00b1\u00e2\u2020\u20190\u00e2\u2020\u2019\u011f\ufffd\u203a\u00bc0 0italic_\u00ce\u00b1 \u00e2\u2020\u2019 0, the stability of the system under discussion improves. In figure (6(a)), we can clearly see highly concentrated fluctuations in the populations of the three species, whereas in figure (6(b)), the fluctuations gradually disappear after a certain amount of time. Furthermore, it can be observed from figures (6(c)) and (6(d)) that the scale of fluctuations diminishes as the fractional order reduces, inducing more stability within the system. Similarly, figure (7) illustrates that as the value of \u00ce\u00b1\u011f\ufffd\u203a\u00bc decreases from 1 to 0, the fluctuations within the system become stabilised, demonstrating the impact of memory on the system. In a similar way figure (8) illustrates that in the system (3) where the prey species and intermediate predators do not exhibit refuge behaviour against their predators, the instability of the system increases as the species\u00e2\u20ac\u2122 memory diminishes. The same conclusion may be deduced from figures (9) and (10). Figure (9) illustrates the impact of fading memory on the system (3) in the absence of any harvesting. Figure (10) illustrates the impact of memory on the system (3) in the absence of prey odour effect. Hence, based on the aforementioned figures, it has been noted that individuals who suffer from memory loss or a deterioration in their ability to recall prior events can have a negative impact on the stability of the corresponding system. In this part, we analyse the impact of the parameters related to the refuge triggered by the predator odour in the aforementioned system. At first, we analyse the effects of parameter m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT on the system (2). The figure (5(a)) provide a clear and visually appealing demonstration of the several bifurcations that occur when the parameter m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is altered. We accomplish this by assuming other parameter values like r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, \u00ce\u00b2=0.01\u011f\ufffd\u203a\u00bd0.01 = 0.01, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, m2=0.5subscript\u011f\ufffd\u2018\u016120.5m_{2}=0.5italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, q=0.5\u011f\ufffd\u2018\ufffd0.5q=0.5italic_q = 0.5, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, r=0.01\u011f\ufffd\u2018\u01780.01r=0.01italic_r = 0.01, only altering the parameter m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. If the value of parameter m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is below a threshold value of m1=0.4498=m1h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a21subscript\u011f\ufffd\u2018\u016110.4498superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd1m_{1}=0.4498=m_{1}^{hb1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.4498 = italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b 1 end_POSTSUPERSCRIPT, then the system (2) exhibits stability around the fixed point Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. Given the following set of parameter values, it can be readily confirmed numerically: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, \u00ce\u00b2=0.01\u011f\ufffd\u203a\u00bd0.01 = 0.01, m1=0.3subscript\u011f\ufffd\u2018\u016110.3m_{1}=0.3italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.3, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, m2=0.5subscript\u011f\ufffd\u2018\u016120.5m_{2}=0.5italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, q=0.5\u011f\ufffd\u2018\ufffd0.5q=0.5italic_q = 0.5, and r=0.01\u011f\ufffd\u2018\u01780.01r=0.01italic_r = 0.01. For this particular set of parameter values, we obtain the following results: N1=1.53>0subscript\u011f\ufffd\u2018\ufffd11.530N_{1}=1.53>0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1.53 > 0, N2=0.13>0subscript\u011f\ufffd\u2018\ufffd20.130N_{2}=0.13>0italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.13 > 0, N3=0.18>0subscript\u011f\ufffd\u2018\ufffd30.180N_{3}=0.18>0italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.18 > 0, and N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3=0.027>0subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd30.0270N_{1}N_{2}-N_{3}=0.027>0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.027 > 0. This means that all the requirements needed to achieve stability given in theorem (8) are satisfied. This confirms the stability of Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. This is shown in figure (11(a)). When the value of m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT reaches a certain threshold, known as the Hopf bifurcation point, the system described by equation (2) undergoes a significant shift in stability. Numerical verification of the existence of a Hopf bifurcation can also be accomplished by applying the theorem (14). Given the threshold value of m1=m1h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a21subscript\u011f\ufffd\u2018\u01611superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd1m_{1}=m_{1}^{hb1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b 1 end_POSTSUPERSCRIPT and keeping other parameter values unchanged, we find the following values: N1=1.6>0subscript\u011f\ufffd\u2018\ufffd11.60N_{1}=1.6>0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1.6 > 0, N2=0.07>0subscript\u011f\ufffd\u2018\ufffd20.070N_{2}=0.07>0italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.07 > 0, N3=0.12>0subscript\u011f\ufffd\u2018\ufffd30.120N_{3}=0.12>0italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.12 > 0, N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3=0subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd30N_{1}N_{2}-N_{3}=0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0, and N1\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a21)\u00e2\ufffd\u00a2N2\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a21)+N2\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a21)\u00e2\ufffd\u00a2N1\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a21)\u00e2\u02c6\u2019N3\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b)=\u00e2\u02c6\u20190.07\u00e2\u2030 0subscript\u011f\ufffd\u2018\ufffd1superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd1superscriptsubscript\u011f\ufffd\u2018\ufffd2\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd1superscriptsubscript\u011f\ufffd\u2018\ufffd1\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd1superscriptsubscript\u011f\ufffd\u2018\ufffd3\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd0.070N_{1}(m_{1}^{hb1})N_{2}^{{}^{ ^{ 0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b 1 end_POSTSUPERSCRIPT ) italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b 1 end_POSTSUPERSCRIPT ) + italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b 1 end_POSTSUPERSCRIPT ) italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b 1 end_POSTSUPERSCRIPT ) - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT ) = - 0.07 \u00e2\u2030 0. This confirms the existence of a Hopf bifurcation at m1=m1h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a21subscript\u011f\ufffd\u2018\u01611superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd1m_{1}=m_{1}^{hb1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b 1 end_POSTSUPERSCRIPT. Furthermore, if the value of m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is slightly elevated, the system (2) demonstrates instability. Assuming the value of m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is 0.50.50.50.5, while keeping all other parameter values the same, we find that N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3=\u00e2\u02c6\u20190.001<0subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd30.0010N_{1}N_{2}-N_{3}=-0.001<0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = - 0.001 < 0. This result corroborates the instability of the system near Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. This situation is shown visually in figure (11(b)). Another Hopf bifurcation occurs when the parameter m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is increased to m1=0.5295=m1h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a22subscript\u011f\ufffd\u2018\u016110.5295superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd2m_{1}=0.5295=m_{1}^{hb2}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5295 = italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b 2 end_POSTSUPERSCRIPT, resulting in a change in the stability of the system (2). When m1=0.5295=m1h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a22subscript\u011f\ufffd\u2018\u016110.5295superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd2m_{1}=0.5295=m_{1}^{hb2}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5295 = italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b 2 end_POSTSUPERSCRIPT and all other parameter values remain the same, all the conditions of theorem (14) are satisfied. This can be seen as N1=1.7>0subscript\u011f\ufffd\u2018\ufffd11.70N_{1}=1.7>0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1.7 > 0, N2=0.05>0subscript\u011f\ufffd\u2018\ufffd20.050N_{2}=0.05>0italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.05 > 0, N3=0.09>0subscript\u011f\ufffd\u2018\ufffd30.090N_{3}=0.09>0italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.09 > 0, N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3=0subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd30N_{1}N_{2}-N_{3}=0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0, and N1\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a21)\u00e2\ufffd\u00a2N2\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a21)+N2\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a21)\u00e2\ufffd\u00a2N1\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a21)\u00e2\u02c6\u2019N3\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(m1h\u00e2\ufffd\u00a2b)=0.07\u00e2\u2030 0subscript\u011f\ufffd\u2018\ufffd1superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd1superscriptsubscript\u011f\ufffd\u2018\ufffd2\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd1superscriptsubscript\u011f\ufffd\u2018\ufffd1\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd1superscriptsubscript\u011f\ufffd\u2018\ufffd3\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd0.070N_{1}(m_{1}^{hb1})N_{2}^{{}^{ ^{ 0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b 1 end_POSTSUPERSCRIPT ) italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b 1 end_POSTSUPERSCRIPT ) + italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b 1 end_POSTSUPERSCRIPT ) italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b 1 end_POSTSUPERSCRIPT ) - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b end_POSTSUPERSCRIPT ) = 0.07 \u00e2\u2030 0. This validates the presence of a second Hopf bifurcation at m1=0.5295=m1h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a22subscript\u011f\ufffd\u2018\u016110.5295superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd2m_{1}=0.5295=m_{1}^{hb2}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5295 = italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b 2 end_POSTSUPERSCRIPT. If the values of m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT exceed m1h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a22superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd2m_{1}^{hb2}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b 2 end_POSTSUPERSCRIPT, the system (2) demonstrates stability in the vicinity of the fixed point Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. Numerical confirmation can be obtained by evaluating the parameter values. For example, when m1=0.6>m1h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a22subscript\u011f\ufffd\u2018\u016110.6superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd2m_{1}=0.6>m_{1}^{hb2}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.6 > italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b 2 end_POSTSUPERSCRIPT and all other parameters are unaltered, we find that N1=1.75>0subscript\u011f\ufffd\u2018\ufffd11.750N_{1}=1.75>0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1.75 > 0, N2=0.04>0subscript\u011f\ufffd\u2018\ufffd20.040N_{2}=0.04>0italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.04 > 0, N3=0.06>0subscript\u011f\ufffd\u2018\ufffd30.060N_{3}=0.06>0italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.06 > 0, and N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3=0.01>0subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd30.010N_{1}N_{2}-N_{3}=0.01>0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.01 > 0. Figure (11(c)) depicts this same scenario. On the other hand, if we slightly increase the value of the parameter m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, an interesting phenomenon occurs. At a certain point, denoted as m1=0.73375185=m1t\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2psubscript\u011f\ufffd\u2018\u016110.73375185superscriptsubscript\u011f\ufffd\u2018\u01611\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdm_{1}=0.73375185=m_{1}^{tbp}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.73375185 = italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t italic_b italic_p end_POSTSUPERSCRIPT, a transcritical bifurcation occurs. This results in the system (2) being unstable around Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT, whereas the fixed point Easubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{a}italic_E start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT becomes stable. Numerically, when m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is equal to 0.8 and all other parameters remain unchanged, we obtain r<4=r1q\u011f\ufffd\u2018\u01784subscript\u011f\ufffd\u2018\u01781\u011f\ufffd\u2018\ufffdr<4= < 4 = divide start_ARG italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG italic_q end_ARG and r2=1<\u00e2\u02c6\u2019d1\u00e2\ufffd\u00a2r12\u00e2\u02c6\u2019\u00ce\u00b2\u00e2\ufffd\u00a2r2\u00e2\ufffd\u00a2q2\u00e2\ufffd\u00a2r3+\u00cf\u20306subscript\u011f\ufffd\u2018\u017821subscript\u011f\ufffd\u2018\u20181superscriptsubscript\u011f\ufffd\u2018\u017812\u011f\ufffd\u203a\u00bdsuperscript\u011f\ufffd\u2018\u01782superscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\u01783subscript\u011f\ufffd\u0153\u201d6r_{2}=1< r^{2}q^{2}r_{3}+ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1 < divide start_ARG - italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG - italic_\u00ce\u00b2 italic_r start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_q start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT + italic_\u00cf\u2030 start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT end_ARG. Additionally, we have N3=\u00e2\u02c6\u20190.03<0subscript\u011f\ufffd\u2018\ufffd30.030N_{3}=-0.03<0italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = - 0.03 < 0. Therefore, it is evident that Easubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{a}italic_E start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT is stable while Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT is unstable. The precise depiction of the particular scenario can be observed in figure (11(d)). Based on the preceding discussion, it is evident that the parameter m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT plays a significant role in the system (2). By looking at the situation from an an ecological standpoint, it has been observed that when the parameter m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is set to a very low value, the prey population tends to remain small. On the other hand, when the amount of prey refuge increases, it has a direct positive impact on the population of the prey species, resulting in increase in the prey population as well. As the parameter m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT increases, an interesting phenomenon occurs. At a certain value, fluctuations in the population of the three species are observed. These fluctuations are subsequently stabilised by the occurrence of another Hopf bifurcation at a slightly elevated value of the parameter m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. By increasing the parameter m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, a remarkable phenomenon known as a transcritical bifurcation occurs. This leads to an unstable coexistence equilibrium, making it impossible for all three populations to cohabit. Now, we will examine the significance of the parameter m2subscript\u011f\ufffd\u2018\u01612m_{2}italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT in the system (2). To do this, we set other parameters to values like r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, \u00ce\u00b2=0.01\u011f\ufffd\u203a\u00bd0.01 = 0.01, m1=0.5subscript\u011f\ufffd\u2018\u016110.5m_{1}=0.5italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, q=0.5\u011f\ufffd\u2018\ufffd0.5q=0.5italic_q = 0.5, r=0.01\u011f\ufffd\u2018\u01780.01r=0.01italic_r = 0.01, and change only m2subscript\u011f\ufffd\u2018\u01612m_{2}italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. Based on the information provided in figure (5(b)), it is clear that the parameter m2subscript\u011f\ufffd\u2018\u01612m_{2}italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT plays a significant role in the system (2). For all values of the parameter m2subscript\u011f\ufffd\u2018\u01612m_{2}italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT that are less than a threshold value m2=0.503528=m2h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2psubscript\u011f\ufffd\u2018\u016120.503528superscriptsubscript\u011f\ufffd\u2018\u01612\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdm_{2}=0.503528=m_{2}^{hbp}italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.503528 = italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT, and with all other parameter values remaining the same, the system (2) exhibits instability around the fixed point Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. More precisely, the system (2) exhibits oscillations in populations. For instance, when we set the parameter values as follows: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, \u00ce\u00b2=0.01\u011f\ufffd\u203a\u00bd0.01 = 0.01, m1=0.5subscript\u011f\ufffd\u2018\u016110.5m_{1}=0.5italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, m2=0.4subscript\u011f\ufffd\u2018\u016120.4m_{2}=0.4italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.4, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, q=0.5\u011f\ufffd\u2018\ufffd0.5q=0.5italic_q = 0.5, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, and r=0.01\u011f\ufffd\u2018\u01780.01r=0.01italic_r = 0.01, the expression N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd3N_{1}N_{2}-N_{3}italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT evaluates to -0.02, which is less than 0. This confirms the instability of Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. It is shown in figure (12(a)). The value m2=0.503528=m2h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2psubscript\u011f\ufffd\u2018\u016120.503528superscriptsubscript\u011f\ufffd\u2018\u01612\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdm_{2}=0.503528=m_{2}^{hbp}italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.503528 = italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT represents a Hopf bifurcation point, as it fulfils all the criteria stated in theorem (14). When m2=0.503528=m2h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2psubscript\u011f\ufffd\u2018\u016120.503528superscriptsubscript\u011f\ufffd\u2018\u01612\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdm_{2}=0.503528=m_{2}^{hbp}italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.503528 = italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT, we find that N2=0.065>0subscript\u011f\ufffd\u2018\ufffd20.0650N_{2}=0.065>0italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.065 > 0, N3=0.10>0subscript\u011f\ufffd\u2018\ufffd30.100N_{3}=0.10>0italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.10 > 0, N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3=0subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd30N_{1}N_{2}-N_{3}=0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0, and N1\u00e2\ufffd\u00a2(m2h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p)\u00e2\ufffd\u00a2N2\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(m2h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p)+N2\u00e2\ufffd\u00a2(m2h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p)\u00e2\ufffd\u00a2N1\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(m2h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p)\u00e2\u02c6\u2019N3\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(m2h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p)=0.02\u00e2\u2030 0subscript\u011f\ufffd\u2018\ufffd1superscriptsubscript\u011f\ufffd\u2018\u01612\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\ufffd2\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u01612\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd2superscriptsubscript\u011f\ufffd\u2018\u01612\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\ufffd1\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u01612\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\ufffd3\u00e2\u20ac\u00b2superscriptsubscript\u011f\ufffd\u2018\u01612\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd0.020N_{1}(m_{2}^{hbp})N_{2}^{{}^{ ^{ 0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT ) italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT ) + italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT ) italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT ) - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT ) = 0.02 \u00e2\u2030 0. Therefore, it is numerically confirmed that a Hopf bifurcation occurs at m2=0.503528=m2h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2psubscript\u011f\ufffd\u2018\u016120.503528superscriptsubscript\u011f\ufffd\u2018\u01612\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdm_{2}=0.503528=m_{2}^{hbp}italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.503528 = italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT. This Hopf bifurcation stabilizes the system until a transcritical bifurcation occurs, which alters its stability. This transcritical bifurcation occurs at m2=0.74958126=m2t\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2psubscript\u011f\ufffd\u2018\u016120.74958126superscriptsubscript\u011f\ufffd\u2018\u01612\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdm_{2}=0.74958126=m_{2}^{tbp}italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.74958126 = italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t italic_b italic_p end_POSTSUPERSCRIPT, along with other parameter values that remain unchanged. For example, when the parameter values are set as follows: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, \u00ce\u00b2=0.01\u011f\ufffd\u203a\u00bd0.01 = 0.01, m1=0.5subscript\u011f\ufffd\u2018\u016110.5m_{1}=0.5italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5, m2=0.6subscript\u011f\ufffd\u2018\u016120.6m_{2}=0.6italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.6, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, q=0.5\u011f\ufffd\u2018\ufffd0.5q=0.5italic_q = 0.5, and r=0.01\u011f\ufffd\u2018\u01780.01r=0.01italic_r = 0.01, the resulting values are N1=1.57>0subscript\u011f\ufffd\u2018\ufffd11.570N_{1}=1.57>0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1.57 > 0, N2=0.086>0subscript\u011f\ufffd\u2018\ufffd20.0860N_{2}=0.086>0italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.086 > 0, N3=0.077>0subscript\u011f\ufffd\u2018\ufffd30.0770N_{3}=0.077>0italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.077 > 0, and N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3=0.058>0subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd30.0580N_{1}N_{2}-N_{3}=0.058>0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.058 > 0. This confirms the stability of Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. This particular situation is illustrated in figure (12(b)). For a different set of parameter values, specifically r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, \u00ce\u00b2=0.01\u011f\ufffd\u203a\u00bd0.01 = 0.01, m1=0.5subscript\u011f\ufffd\u2018\u016110.5m_{1}=0.5italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, m2=0.8subscript\u011f\ufffd\u2018\u016120.8m_{2}=0.8italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.8, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, q=0.5\u011f\ufffd\u2018\ufffd0.5q=0.5italic_q = 0.5, and r=0.01\u011f\ufffd\u2018\u01780.01r=0.01italic_r = 0.01, it has been determined that N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd3N_{1}N_{2}-N_{3}italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT is equal to -9.39, which is less than 0. Moreover, all the conditions outlined in theorem (7) are also met, confirming the instability of Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT and the stability of Etsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a1E_{t}italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT. The precise depiction of the particular circumstance can be observed in figure (12(c)). When the intermediate predator seeks shelter from the top predator\u00e2\u20ac\u2122s predation pressure, the system (2) becomes more intricate and intriguing. It is evident that when the parameter m2subscript\u011f\ufffd\u2018\u01612m_{2}italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT is extremely low, oscillations in the population of all three species within the system occur. However, as this parameter increases, the fluctuations gradually decrease. Eventually, after reaching a certain value, these fluctuations stabilise due to the occurrence of a Hopf bifurcation. As the parameter m2subscript\u011f\ufffd\u2018\u01612m_{2}italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT increases, the population of the intermediate predator similarly increases. However, the population of prey continues to decline, a trend that can be rationalised from an ecological standpoint. When the parameter m2subscript\u011f\ufffd\u2018\u01612m_{2}italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT reaches a higher value, a transcritical bifurcation takes place, resulting in the inability of all three species to coexist within the system (2). This phenomenon can be readily understood from an ecological standpoint. When the intermediate predator strategically enhances its protection against predation by the top predator in response to the top predator\u00e2\u20ac\u2122s odour, thereby reducing its vulnerability to being hunted. Consequently, the predation pressure on the prey by the intermediate predator increases, leading to a substantial decline in the prey population. As a result, the coexistence of all three species within the system becomes extremely difficult. Some special cases: In this portion, we are going to explore three distinct specific situations that may arise in the system (2). In the first scenario, we focus on the situation where the prey is unable to detect the odour of the predator, that is, when a1=0subscript\u011f\ufffd\u2018\ufffd10a_{1}=0italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0, resulting in m1=mf\u00e2\ufffd\u00a2p\u00e2\ufffd\u00a2a1=0subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd10m_{1}=m_{fp}a_{1}=0italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_m start_POSTSUBSCRIPT italic_f italic_p end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0. Consequently, they are unpredictably attacked by camouflaged predators, leaving them little opportunity to respond or seek refuge. In the second scenario, we address a circumstance where the intermediate predator cannot sense the odour of their predator or whether the top predator conceals their odour, specifically when a2=0subscript\u011f\ufffd\u2018\ufffd20a_{2}=0italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0, leading to m2=ms\u00e2\ufffd\u00a2p\u00e2\ufffd\u00a2a2=0subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018 \u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd20m_{2}=m_{sp}a_{2}=0italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = italic_m start_POSTSUBSCRIPT italic_s italic_p end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0. In the third scenario, our attention is directed towards a situation in which the intermediate predator and the prey are unable to effectively utilise refuge to protect themselves from their predators for a variety of reasons, that is, when m1=0=m2subscript\u011f\ufffd\u2018\u016110subscript\u011f\ufffd\u2018\u01612m_{1}=0=m_{2}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0 = italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. Scenario 1: When the predator\u00e2\u20ac\u2122s odour is undetectable to the prey species, leading to a lack of refuge activity in prey (m1=0subscriptm10m_{1}=0italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0) In this situation, the prey species is unable to detect the odour of the intermediate predator, or the predator masks their odour, i.e., when a1=0subscript\u011f\ufffd\u2018\ufffd10a_{1}=0italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0, implying m1=mf\u00e2\ufffd\u00a2p\u00e2\ufffd\u00a2a1=0subscript\u011f\ufffd\u2018\u01611subscript\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd10m_{1}=m_{fp}a_{1}=0italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_m start_POSTSUBSCRIPT italic_f italic_p end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0. In an attempt to gain a better understanding of the situation when m1=0subscript\u011f\ufffd\u2018\u016110m_{1}=0italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0, we conducted a series of simulations and obtained a range of figures. Based on the figure (13), it has been determined that when the parameter m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is set to 0, along with the following values for the other parameters: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, \u00ce\u00b2=0.01\u011f\ufffd\u203a\u00bd0.01 = 0.01, m2=0.5subscript\u011f\ufffd\u2018\u016120.5m_{2}=0.5italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, q=0.5\u011f\ufffd\u2018\ufffd0.5q=0.5italic_q = 0.5, and r=0.01\u011f\ufffd\u2018\u01780.01r=0.01italic_r = 0.01, the system (2) exhibits stability around Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. This is indicated by the fact that all the values N1=1.32subscript\u011f\ufffd\u2018\ufffd11.32N_{1}=1.32italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1.32, N2=0.29subscript\u011f\ufffd\u2018\ufffd20.29N_{2}=0.29italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.29, N3=0.024subscript\u011f\ufffd\u2018\ufffd30.024N_{3}=0.024italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.024, and N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3=0.14subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd30.14N_{1}N_{2}-N_{3}=0.14italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.14 are positive. Figure (13(b)) demonstrates the time series of all three populations within the system (2). The figure was obtained using an initial value of (0.8,0.8,0.8). On the other hand, figure (13(a)) illustrates the phase portrait with three different initial conditions: (0.1,0.8,0.1), (0.1,0.1,0.1), and (0.8,0.8,0.8). From an ecological perspective, it can be inferred that if the prey species does not exhibit any refuge behaviour, then all three species can coexist within the system (2). In the natural world, it is quite common for predators to employ chemical camouflage to mask their odours, making it difficult for their prey to detect them [59, 60]. As an example, numerous insect species thrive within social insect colonies, preying on colony members by concealing their own odour. When the prey has no refuge from the predation pressure exerted by the intermediate predator, it becomes apparent that all three populations can persist, even though the prey population density remains very low. This is consistent with ecological reasoning, as when prey have no refuge from their predators, the predators may easily pursue them, leading to a potential decline in the prey population. It is intriguing to see that even without the presence of an appropriate refuge for prey, the system we are discussing can nonetheless achieve the coexistence of all three species. Scenario 2: When the top predator\u00e2\u20ac\u2122s odour induces no refuge in the intermediate predators, or when intermediate predators are unable to detect the odours of the top predator (m2=0subscriptm20m_{2}=0italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0) In this particular case, we are investigating a scenario in which the intermediate predator is incapable of perceiving the odour of the first predator, therefore leaving it defenceless against predation by the top predator. That is, when a2=0subscript\u011f\ufffd\u2018\ufffd20a_{2}=0italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0, which means m2=mf\u00e2\ufffd\u00a2p\u00e2\ufffd\u00a2a2=0subscript\u011f\ufffd\u2018\u01612subscript\u011f\ufffd\u2018\u0161\u011f\ufffd\u2018\u201c\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd20m_{2}=m_{fp}a_{2}=0italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = italic_m start_POSTSUBSCRIPT italic_f italic_p end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0. Alternatively, if the intermediate predator does have a refuge, the top predator is capable of overcoming it, resulting in m2=0subscript\u011f\ufffd\u2018\u016120m_{2}=0italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0. This phenomenon can occur in the natural world when certain predators conceal their scents in order to avoid detection by their prey. Additionally, some predators possess physical adaptations or exhibit specific behaviours that enable them to access or infiltrate shelters or hiding places [59, 60, 61]. In order to comprehend the situation where m2=0subscript\u011f\ufffd\u2018\u016120m_{2}=0italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0, we conducted multiple simulations, which resulted in diverse figures. We utilise the following parameter values: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, \u00ce\u00b2=0.01\u011f\ufffd\u203a\u00bd0.01 = 0.01, m1=0.5subscript\u011f\ufffd\u2018\u016110.5m_{1}=0.5italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5, m2=0subscript\u011f\ufffd\u2018\u016120m_{2}=0italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, q=0.5\u011f\ufffd\u2018\ufffd0.5q=0.5italic_q = 0.5, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, and r=0.01\u011f\ufffd\u2018\u01780.01r=0.01italic_r = 0.01, in order to generate figure (14). Figure (14(b)) depicts the temporal progression of the three populations in the system (2). The initial point (0.8,0.8,0.8) is used to generate figure (14(b)). In a similar way, figure (14(a)) illustrates the phase portrait of all three populations when m2=0subscript\u011f\ufffd\u2018\u016120m_{2}=0italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0. The starting point (0.8,0.8,0.8) is utilised to produce figure (14(a)). Based on the information presented in figure (14), it is apparent that the system (2) exhibits instability near Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT when the intermediate predator does not have any refuge against predation by the top predator. It is interesting to observe that the populations of all three species experience fluctuations when there is no refuge for the intermediate predator against the predation pressure from the top predator. Thus, all three species may persist within the system in the absence of the intermediate predator\u00e2\u20ac\u2122s refuge behaviour against the top predator\u00e2\u20ac\u2122s predation effort, but population levels for all species remain fluctuant. This affirms the significance of the parameter m2subscript\u011f\ufffd\u2018\u01612m_{2}italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT within the system (2). Scenario 3: When there is no refuge behaviour in both the prey species and the intermediate predator, i.e., when m1=0=m2subscriptm10subscriptm2m_{1}=0=m_{2}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0 = italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT occur simultaneously In the above paragraphs, we have already covered two unique situations. In one scenario, the prey is unable to detect the odours of the intermediate predators, which leads to them not utilising refuge. However, the intermediate predator is able to use refuge as a defence against the top predator, in response to the top predator\u00e2\u20ac\u2122s odour. In another scenario, prey seek refuge from intermediate predators, but the intermediate predators either do not utilise refuge or it proves ineffective against the top predator. This can be attributed to factors such as the intermediate predator\u00e2\u20ac\u2122s inability to detect the odour of the top predator or the top predator\u00e2\u20ac\u2122s ability to mask their odour (Scenario 2). In this part, we will explore a scenario where neither the prey nor the intermediate predators utilise refuge, or where refuge proves ineffective in protecting them from their respective predators (Scenario 3). In order to have a better understanding of this particular situation, we conducted several simulations with the following parameter values: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, \u00ce\u00b2=0.01\u011f\ufffd\u203a\u00bd0.01 = 0.01, m1=0subscript\u011f\ufffd\u2018\u016110m_{1}=0italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, m2=0subscript\u011f\ufffd\u2018\u016120m_{2}=0italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, q=0.5\u011f\ufffd\u2018\ufffd0.5q=0.5italic_q = 0.5, and r=0.01\u011f\ufffd\u2018\u01780.01r=0.01italic_r = 0.01. By utilising these specific parameter values, we have generated figures (15(a)) and (15(b)). The time series of all three populations when the parameters m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and m2subscript\u011f\ufffd\u2018\u01612m_{2}italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT are both equal to zero is depicted in figure (15(a)). Additionally, the phase portrait of all three populations within the system (2) is illustrated in figure (15(b)). The initial condition utilised for obtaining the aforementioned two figures is (0.8, 0.6, 0.8). It is clear that when m1=0=m2subscript\u011f\ufffd\u2018\u016110subscript\u011f\ufffd\u2018\u01612m_{1}=0=m_{2}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0 = italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, the system (2) exhibits instability around Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. Furthermore, the system (2) exhibits oscillations in the populations of the three species within the system when m1=0=m2subscript\u011f\ufffd\u2018\u016110subscript\u011f\ufffd\u2018\u01612m_{1}=0=m_{2}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0 = italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. In addition, the presence of a limit cycle may be observed in figure (15(b)). Hence, it may be inferred that the absence of the refuge phenomenon prevents a stable coexistence of all three species within the system. That is, in the absence of refuge behaviour in the prey species and the intermediate predator species in order to defend themselves from their predators, the populations of all three species consistently fluctuate. Thus, the importance of the refuge phenomenon within the system is firmly established. Within this section, we will examine the occurrence of the bubbling phenomenon within the system (2). Occasionally, a bifurcation diagram may exhibit a closed-loop configuration resembling a bubble like structure due to the emergence and vanishing of oscillations originating from two Hopf bifurcation points. This occurrence is commonly known as the bubbling phenomenon. Many researchers have acknowledged the occurrence of bubbling phenomena in predator-prey models[62, 63, 64, 65, 66, 67]. The system (2) exhibits the bubbling phenomenon when certain parameter values are fixed and only the parameter m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is altered. The fixed parameter values are: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, \u00ce\u00b2=0.01\u011f\ufffd\u203a\u00bd0.01 = 0.01, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, m2=0.5subscript\u011f\ufffd\u2018\u016120.5m_{2}=0.5italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, q=0.5\u011f\ufffd\u2018\ufffd0.5q=0.5italic_q = 0.5, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, r=0.01\u011f\ufffd\u2018\u01780.01r=0.01italic_r = 0.01. The emergence of a bubble of oscillations between two hopf bifurcation points, m1=0.4498=m1h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a21subscript\u011f\ufffd\u2018\u016110.4498superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd1m_{1}=0.4498=m_{1}^{hb1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.4498 = italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b 1 end_POSTSUPERSCRIPT and m1=0.5295=m1h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a22subscript\u011f\ufffd\u2018\u016110.5295superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd2m_{1}=0.5295=m_{1}^{hb2}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5295 = italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b 2 end_POSTSUPERSCRIPT, respectively, is properly illustrated in figures (5(a)) and (16). Following the initial Hopf bifurcation at m1=m1h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a21subscript\u011f\ufffd\u2018\u01611superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd1m_{1}=m_{1}^{hb1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b 1 end_POSTSUPERSCRIPT, there is a noticeable presence of oscillations in the populations of the three species. As the parameter m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT continues to rise, the amplitude of these oscillations steadily increases. However, after reaching a certain threshold, the amplitude begins to diminish and eventually stabilises at the second Hopf bifurcation at m1=m1h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a22subscript\u011f\ufffd\u2018\u01611superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd2m_{1}=m_{1}^{hb2}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b 2 end_POSTSUPERSCRIPT. Thereby, the significance of the parameter m1subscript\u011f\ufffd\u2018\u01611m_{1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT within the system (2) is further emphasised. The figure (5(a)) clearly illustrates the bubbling phenomenon in the x1\u00e2\u02c6\u2019m1subscript\u011f\ufffd\u2018\u00a51subscript\u011f\ufffd\u2018\u01611x_{1}-m_{1}italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT - italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT plane. On the other hand, figures (16(a)) and (16(b)) illustrate the presence of a fluctuation bubble resulting from the appearance of two Hopf bifurcations at m1=m1h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a21subscript\u011f\ufffd\u2018\u01611superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd1m_{1}=m_{1}^{hb1}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b 1 end_POSTSUPERSCRIPT and m1=m1h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a22subscript\u011f\ufffd\u2018\u01611superscriptsubscript\u011f\ufffd\u2018\u01611\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd2m_{1}=m_{1}^{hb2}italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_h italic_b 2 end_POSTSUPERSCRIPT on the x2\u00e2\u02c6\u2019m1subscript\u011f\ufffd\u2018\u00a52subscript\u011f\ufffd\u2018\u01611x_{2}-m_{1}italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and x3\u00e2\u02c6\u2019m1subscript\u011f\ufffd\u2018\u00a53subscript\u011f\ufffd\u2018\u01611x_{3}-m_{1}italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT - italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT planes, respectively. In the given system (1), the parameters associated with the odour of the intermediate predator and top predator are denoted as a1subscript\u011f\ufffd\u2018\ufffd1a_{1}italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and a2subscript\u011f\ufffd\u2018\ufffd2a_{2}italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, respectively. With the following parameter values set, the figure (17) is produced: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, \u00ce\u00b2=0.01\u011f\ufffd\u203a\u00bd0.01 = 0.01, m1=0.5subscript\u011f\ufffd\u2018\u016110.5m_{1}=0.5italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5, m2=0.6subscript\u011f\ufffd\u2018\u016120.6m_{2}=0.6italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.6, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, a2=1subscript\u011f\ufffd\u2018\ufffd21a_{2}=1italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, q=0.5\u011f\ufffd\u2018\ufffd0.5q=0.5italic_q = 0.5, r=0.01\u011f\ufffd\u2018\u01780.01r=0.01italic_r = 0.01, and continuously varying the parameter a1subscript\u011f\ufffd\u2018\ufffd1a_{1}italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. Based on the figure (17), it is evident that the parameter a1subscript\u011f\ufffd\u2018\ufffd1a_{1}italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT has a noticeable impact on the system (2). If the parameter a1<\u00e2\u02c6\u20193.024subscript\u011f\ufffd\u2018\ufffd13.024a_{1}<-3.024italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < - 3.024, the top predator within the system is at risk of extinction. This is shown in figures (17(a)) and (17(b)). This is because a transcritical bifurcation occurs at a1=\u00e2\u02c6\u20193.024subscript\u011f\ufffd\u2018\ufffd13.024a_{1}=-3.024italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = - 3.024. In ecological circumstance, this is not possible as the parameter a1subscript\u011f\ufffd\u2018\ufffd1a_{1}italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is always positive. However, when \u00e2\u02c6\u20193.024<a1<1.4483.024subscript\u011f\ufffd\u2018\ufffd11.448-3.024<a_{1}<1.448- 3.024 < italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT < 1.448, then it is observed that the prey, intermediate predator and the top predator, all coexist within the system (2). This is evident in figure (17(c)). Moreover, there is another transcritical bifurcation that occurs at a1=1.448subscript\u011f\ufffd\u2018\ufffd11.448a_{1}=1.448italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1.448. As a result, the system once again faces the extinction of the top predator. This is illustrated in figure (17(d)). On the other hand, there is another transcritical bifurcation that takes place at a1=1.503subscript\u011f\ufffd\u2018\ufffd11.503a_{1}=1.503italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1.503. This bifurcation results in the removal of predators, leaving only the prey species in the system, as seen in figure (17(e)). Thus, the parameter a1subscript\u011f\ufffd\u2018\ufffd1a_{1}italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is capable of causing transcritical bifurcations in the system (2). Consequently, the coexistence of all species in the system is highly dependent on the value of this parameter. Figure (18(a)) represents the coexistence equilibrium curve which is generated using some fixed parameter values and constantly changing the value of the parameter a2subscript\u011f\ufffd\u2018\ufffd2a_{2}italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. The fixed parameter values are: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, \u00ce\u00b2=0.01\u011f\ufffd\u203a\u00bd0.01 = 0.01, m1=0.5subscript\u011f\ufffd\u2018\u016110.5m_{1}=0.5italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5, m1=0.5subscript\u011f\ufffd\u2018\u016110.5m_{1}=0.5italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5, m2=0.6subscript\u011f\ufffd\u2018\u016120.6m_{2}=0.6italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.6, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, a1=1subscript\u011f\ufffd\u2018\ufffd11a_{1}=1italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, q=0.5\u011f\ufffd\u2018\ufffd0.5q=0.5italic_q = 0.5, and r=0.01\u011f\ufffd\u2018\u01780.01r=0.01italic_r = 0.01. Based on the information shown in figure (18(a)), it is clear that the parameter a2subscript\u011f\ufffd\u2018\ufffd2a_{2}italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT plays a significant role in the system (2). It has the ability to cause a Hopf bifurcation and a transcritical bifurcation within the system. When a2<0.839221subscript\u011f\ufffd\u2018\ufffd20.839221a_{2}<0.839221italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT < 0.8392211, all three populations within the system experiences fluctuations that are later stabilised by a hopf bifurcation occurring at a2=0.839221subscript\u011f\ufffd\u2018\ufffd20.839221a_{2}=0.839221italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.839221. This is illustrated in the figure (18(b)). Therefore, for a range of values between 0.8392210.8392210.8392210.839221 and 1.2493021.2493021.2493021.249302 for a2subscript\u011f\ufffd\u2018\ufffd2a_{2}italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, the system (2) exhibits the coexistence of all three species. The evidence is readily apparent in the figure (18(c)). Nevertheless, when a2>1.249302subscript\u011f\ufffd\u2018\ufffd21.249302a_{2}>1.249302italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT > 1.249302, the top predator disappears from the system, rendering coexistence unattainable as a transcritical bifurcation takes place at a2=1.249302subscript\u011f\ufffd\u2018\ufffd21.249302a_{2}=1.249302italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1.249302. This is depicted in the figure (18(d)). Thus, the significance of the role parameter a2subscript\u011f\ufffd\u2018\ufffd2a_{2}italic_a start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT in either facilitating or preventing coexistence is well established. In this part, we investigate the consequences resulting from the act of harvesting in the system (2). Initially, we will try to elucidate the significance of the catchability constant q\u011f\ufffd\u2018\ufffdqitalic_q in the system (2). To be able to accomplish this, we have conducted simulations involving several figures that pertain to the significance of the catchability constant q\u011f\ufffd\u2018\ufffdqitalic_q. Figure (5(c)) demonstrates that changes in the parameter q\u011f\ufffd\u2018\ufffdqitalic_q can lead to various forms of bifurcations. Figure (19) shows phase portraits at different values of the parameter q\u011f\ufffd\u2018\ufffdqitalic_q while keeping the other parameter values unchanged. The fixed parameter values are: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, \u00ce\u00b2=0.01\u011f\ufffd\u203a\u00bd0.01 = 0.01, m1=0.5subscript\u011f\ufffd\u2018\u016110.5m_{1}=0.5italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, m2=0.5subscript\u011f\ufffd\u2018\u016120.5m_{2}=0.5italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, and r=0.01\u011f\ufffd\u2018\u01780.01r=0.01italic_r = 0.01. From figure (5(c)), it is apparent that changing the parameter q\u011f\ufffd\u2018\ufffdqitalic_q leads to a Hopf bifurcation, which in turn affects the stability of the system (2). For the given parameter values, namely r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, \u00ce\u00b2=0.01\u011f\ufffd\u203a\u00bd0.01 = 0.01, m1=0.5subscript\u011f\ufffd\u2018\u016110.5m_{1}=0.5italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5, m2=0.5subscript\u011f\ufffd\u2018\u016120.5m_{2}=0.5italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, q=0.3\u011f\ufffd\u2018\ufffd0.3q=0.3italic_q = 0.3, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, and r=0.01\u011f\ufffd\u2018\u01780.01r=0.01italic_r = 0.01, when the value of q\u011f\ufffd\u2018\ufffdqitalic_q is less than a certain threshold q=1.04003=qh\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p\u011f\ufffd\u2018\ufffd1.04003superscript\u011f\ufffd\u2018\ufffd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdq=1.04003=q^{hbp}italic_q = 1.04003 = italic_q start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT, the system described by equation (2) exhibits instability around the point Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. We obtain the values: N1=1.68>0subscript\u011f\ufffd\u2018\ufffd11.680N_{1}=1.68>0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1.68 > 0, N2=0.064>0subscript\u011f\ufffd\u2018\ufffd20.0640N_{2}=0.064>0italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.064 > 0, N3=0.11>0subscript\u011f\ufffd\u2018\ufffd30.110N_{3}=0.11>0italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.11 > 0, and N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3=\u00e2\u02c6\u20190.0018<0subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd30.00180N_{1}N_{2}-N_{3}=-0.0018<0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = - 0.0018 < 0, confirming the instability of Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. Figure (19(a)) depicts the precise scenario. More precisely, the system (2) exhibits fluctuations in the populations of the three species. As a result of a Hopf bifurcation at q=1.04003=qh\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p\u011f\ufffd\u2018\ufffd1.04003superscript\u011f\ufffd\u2018\ufffd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdq=1.04003=q^{hbp}italic_q = 1.04003 = italic_q start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT, the stability of the system (2) changes and becomes stable for all parameter values q>qh\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p\u011f\ufffd\u2018\ufffdsuperscript\u011f\ufffd\u2018\ufffd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdq>q^{hbp}italic_q > italic_q start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT, while keeping all other parameter values unchanged. When the value of q\u011f\ufffd\u2018\ufffdqitalic_q is set to 1.04003=qh\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p1.04003superscript\u011f\ufffd\u2018\ufffd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd1.04003=q^{hbp}1.04003 = italic_q start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT, keeping all other parameters unchanged, we observe that N1=1.6>0subscript\u011f\ufffd\u2018\ufffd11.60N_{1}=1.6>0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1.6 > 0, N2=0.06>0subscript\u011f\ufffd\u2018\ufffd20.060N_{2}=0.06>0italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.06 > 0, N3=0.1>0subscript\u011f\ufffd\u2018\ufffd30.10N_{3}=0.1>0italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.1 > 0, N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3=0subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd30N_{1}N_{2}-N_{3}=0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0, and N1\u00e2\ufffd\u00a2(qh\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p)\u00e2\ufffd\u00a2N2\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(qh\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p)+N2\u00e2\ufffd\u00a2(qh\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p)\u00e2\ufffd\u00a2N1\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(qh\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p)\u00e2\u02c6\u2019N3\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(qh\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p)=0.002\u00e2\u2030 0subscript\u011f\ufffd\u2018\ufffd1superscript\u011f\ufffd\u2018\ufffd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\ufffd2\u00e2\u20ac\u00b2superscript\u011f\ufffd\u2018\ufffd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd2superscript\u011f\ufffd\u2018\ufffd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\ufffd1\u00e2\u20ac\u00b2superscript\u011f\ufffd\u2018\ufffd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\ufffd3\u00e2\u20ac\u00b2superscript\u011f\ufffd\u2018\ufffd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd0.0020N_{1}(q^{hbp})N_{2}^{{}^{ ^{hbp})-N_{3}^{{}^{ 0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_q start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT ) italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_q start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT ) + italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_q start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT ) italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_q start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT ) - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_q start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT ) = 0.002 \u00e2\u2030 0. These findings confirm the presence of a Hopf bifurcation. It can be seen that the system (2) exhibits stable characteristics for the parameter values: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, \u00ce\u00b2=0.01\u011f\ufffd\u203a\u00bd0.01 = 0.01, m1=0.5subscript\u011f\ufffd\u2018\u016110.5m_{1}=0.5italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5, m2=0.5subscript\u011f\ufffd\u2018\u016120.5m_{2}=0.5italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, q=2\u011f\ufffd\u2018\ufffd2q=2italic_q = 2, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, and r=0.01\u011f\ufffd\u2018\u01780.01r=0.01italic_r = 0.01, as depicted in figure (19(b)). Based on the given parameter values, it can be observed that N1=1.66>0subscript\u011f\ufffd\u2018\ufffd11.660N_{1}=1.66>0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1.66 > 0, N2=0.06>0subscript\u011f\ufffd\u2018\ufffd20.060N_{2}=0.06>0italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.06 > 0, N3=0.1>0subscript\u011f\ufffd\u2018\ufffd30.10N_{3}=0.1>0italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.1 > 0, and N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3=0.002>0subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd30.0020N_{1}N_{2}-N_{3}=0.002>0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.002 > 0. These results provide evidence for the stability of Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. This discussion provides us with compelling evidence that highlights the significance of the parameter q\u011f\ufffd\u2018\ufffdqitalic_q throughout the system (2). From the preceding discussions, it is evident that when the catchability constant q\u011f\ufffd\u2018\ufffdqitalic_q is extremely low, meaning that the likelihood of capturing prey through harvesting efforts is small, the stable coexistence of all three populations becomes challenging. This is due to fluctuations in the populations of all three species within the system (2). This implies that coexistence is feasible in this scenario, albeit the population continues to fluctuate. As the likelihood of capturing prey, represented by the catchability constant q\u011f\ufffd\u2018\ufffdqitalic_q, grows, a stable coexistence of all three species becomes possible due to the emergence of a Hopf bifurcation. This indicates that for the three species in the system to coexist, a high catchability constant q\u011f\ufffd\u2018\ufffdqitalic_q is required. Although a higher catchability constant q\u011f\ufffd\u2018\ufffdqitalic_q can lead to a reduction in the prey population over time in the long-term dynamics. Thus, the catchability constant q\u011f\ufffd\u2018\ufffdqitalic_q plays a crucial role within the system. Now, we will shift our attention to the significance of the parameter r\u011f\ufffd\u2018\u0178ritalic_r in the system (2). In order to gain a deeper comprehension of the influence of this parameter on the system, we conduct simulations using various values of the parameter r\u011f\ufffd\u2018\u0178ritalic_r. In order to produce the figure (5(d)), we need to change the parameter r\u011f\ufffd\u2018\u0178ritalic_r and employ the following parameter values: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, \u00ce\u00b2=0.01\u011f\ufffd\u203a\u00bd0.01 = 0.01, m1=0.5subscript\u011f\ufffd\u2018\u016110.5m_{1}=0.5italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, m2=0.5subscript\u011f\ufffd\u2018\u016120.5m_{2}=0.5italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, q=0.5\u011f\ufffd\u2018\ufffd0.5q=0.5italic_q = 0.5. This figure elegantly depicts the manifestation of several bifurcations as the parameter r\u011f\ufffd\u2018\u0178ritalic_r undergoes modifications. In order to obtain figure (20(a)), we utilise the following parameter values: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, \u00ce\u00b2=0.01\u011f\ufffd\u203a\u00bd0.01 = 0.01, m1=0.5subscript\u011f\ufffd\u2018\u016110.5m_{1}=0.5italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5, m2=0.5subscript\u011f\ufffd\u2018\u016120.5m_{2}=0.5italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, q=0.5\u011f\ufffd\u2018\ufffd0.5q=0.5italic_q = 0.5, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, and r=0.015\u011f\ufffd\u2018\u01780.015r=0.015italic_r = 0.015. Alternatively, in order to simulate figure (20(b)), we employ the following parameter values: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, \u00ce\u00b2=0.01\u011f\ufffd\u203a\u00bd0.01 = 0.01, m1=0.5subscript\u011f\ufffd\u2018\u016110.5m_{1}=0.5italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5, m2=0.5subscript\u011f\ufffd\u2018\u016120.5m_{2}=0.5italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, q=0.5\u011f\ufffd\u2018\ufffd0.5q=0.5italic_q = 0.5, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, and r=0.04\u011f\ufffd\u2018\u01780.04r=0.04italic_r = 0.04. Based on the information provided in figure (5(d)), it can be inferred that if the parameter r\u011f\ufffd\u2018\u0178ritalic_r is smaller than r=0.0208005=rh\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p\u011f\ufffd\u2018\u01780.0208005superscript\u011f\ufffd\u2018\u0178\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdr=0.0208005=r^{hbp}italic_r = 0.0208005 = italic_r start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT, the system (2) exhibits instability in the vicinity of Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. When the parameter values are set to r=0.015\u011f\ufffd\u2018\u01780.015r=0.015italic_r = 0.015, while keeping all other parameter values unchanged, we find that N1=1.67>0subscript\u011f\ufffd\u2018\ufffd11.670N_{1}=1.67>0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1.67 > 0, N2=0.064>0subscript\u011f\ufffd\u2018\ufffd20.0640N_{2}=0.064>0italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.064 > 0, N3=0.10>0subscript\u011f\ufffd\u2018\ufffd30.100N_{3}=0.10>0italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.10 > 0, and N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3=\u00e2\u02c6\u20190.0007<0subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd30.00070N_{1}N_{2}-N_{3}=-0.0007<0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = - 0.0007 < 0. This confirms the instability of Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. This is accurately illustrated in figure (20(a)). A Hopf bifurcation occurs at the value of r\u011f\ufffd\u2018\u0178ritalic_r equal to r=0.0208005=rh\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p\u011f\ufffd\u2018\u01780.0208005superscript\u011f\ufffd\u2018\u0178\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdr=0.0208005=r^{hbp}italic_r = 0.0208005 = italic_r start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT. This is evident as all the criteria specified in theorem (14) are met for these parameter values. More precisely, we have N1=1.6>0subscript\u011f\ufffd\u2018\ufffd11.60N_{1}=1.6>0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1.6 > 0, N2=0.06>0subscript\u011f\ufffd\u2018\ufffd20.060N_{2}=0.06>0italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.06 > 0, N3=0.1>0subscript\u011f\ufffd\u2018\ufffd30.10N_{3}=0.1>0italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.1 > 0, N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3=0subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd30N_{1}N_{2}-N_{3}=0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0, and N1\u00e2\ufffd\u00a2(qh\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p)\u00e2\ufffd\u00a2N2\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(qh\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p)+N2\u00e2\ufffd\u00a2(qh\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p)\u00e2\ufffd\u00a2N1\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(qh\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p)\u00e2\u02c6\u2019N3\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(qh\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p)=0.125\u00e2\u2030 0subscript\u011f\ufffd\u2018\ufffd1superscript\u011f\ufffd\u2018\ufffd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\ufffd2\u00e2\u20ac\u00b2superscript\u011f\ufffd\u2018\ufffd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd2superscript\u011f\ufffd\u2018\ufffd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\ufffd1\u00e2\u20ac\u00b2superscript\u011f\ufffd\u2018\ufffd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\ufffd3\u00e2\u20ac\u00b2superscript\u011f\ufffd\u2018\ufffd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd0.1250N_{1}(q^{hbp})N_{2}^{{}^{ ^{hbp})-N_{3}^{{}^{ 0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_q start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT ) italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_q start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT ) + italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_q start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT ) italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_q start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT ) - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_q start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT ) = 0.125 \u00e2\u2030 0. The system (2) exhibits stability around Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT for all values of the parameter rt\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p>r>rh\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2psuperscript\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\u0178superscript\u011f\ufffd\u2018\u0178\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdr^{tbp}>r>r^{hbp}italic_r start_POSTSUPERSCRIPT italic_t italic_b italic_p end_POSTSUPERSCRIPT > italic_r > italic_r start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT. It can be established numerically through the use of the following parameter values: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, \u00ce\u00b2=0.01\u011f\ufffd\u203a\u00bd0.01 = 0.01, m1=0.5subscript\u011f\ufffd\u2018\u016110.5m_{1}=0.5italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5, m2=0.5subscript\u011f\ufffd\u2018\u016120.5m_{2}=0.5italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, q=0.5\u011f\ufffd\u2018\ufffd0.5q=0.5italic_q = 0.5, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, and r=0.04\u011f\ufffd\u2018\u01780.04r=0.04italic_r = 0.04. At these parameter values, N1=1.6>0subscript\u011f\ufffd\u2018\ufffd11.60N_{1}=1.6>0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1.6 > 0, N2=0.06>0subscript\u011f\ufffd\u2018\ufffd20.060N_{2}=0.06>0italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.06 > 0, N3=0.1>0subscript\u011f\ufffd\u2018\ufffd30.10N_{3}=0.1>0italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.1 > 0, and N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3=0.002>0subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd30.0020N_{1}N_{2}-N_{3}=0.002>0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.002 > 0. This substantiates the stability of Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT in accordance with theorem (8). This is accurately demonstrated in figure (20(b)). A transcritical bifurcation occurs when the value of r\u011f\ufffd\u2018\u0178ritalic_r reaches r=1.5074136=rt\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p\u011f\ufffd\u2018\u01781.5074136superscript\u011f\ufffd\u2018\u0178\u011f\ufffd\u2018\u00a1\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdr=1.5074136=r^{tbp}italic_r = 1.5074136 = italic_r start_POSTSUPERSCRIPT italic_t italic_b italic_p end_POSTSUPERSCRIPT, causing a shift in the stability of the system (2) and making it unstable. In order to have a better understanding of this exact situation, we use parameter values: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, \u00ce\u00b2=0.01\u011f\ufffd\u203a\u00bd0.01 = 0.01, m1=0.5subscript\u011f\ufffd\u2018\u016110.5m_{1}=0.5italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5, m2=0.5subscript\u011f\ufffd\u2018\u016120.5m_{2}=0.5italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, q=0.5\u011f\ufffd\u2018\ufffd0.5q=0.5italic_q = 0.5, and r=1.6\u011f\ufffd\u2018\u01781.6r=1.6italic_r = 1.6. At these parameter values, we notice that N3subscript\u011f\ufffd\u2018\ufffd3N_{3}italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT is equal to -0.01, which is less than 0. This demonstrates the instability of Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT as per theorem (8). Furthermore, for these specific parameter values, all the conditions outlined in theorem (7) are met, indicating the stability of Etsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a1E_{t}italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT. This is precisely shown in figure (20(c)). The level of harvesting effort plays a crucial role in predator-prey systems, as it has far-reaching effects on both the target species and the overall ecosystem. Efficiently managing the harvesting effort is crucial for maintaining the population\u00e2\u20ac\u2122s long-term sustainability. The preceding calculations show that as the amount of harvesting effort increases, the prey population decreases, which is consistent with biological principles. In addition, it has been observed that when the level of harvesting effort is low, the populations of all three species exhibit fluctuations. When the level of harvesting effort is increased, the system becomes stable, allowing for the coexistence of all three populations. This is the result of the manifestation of a Hopf bifurcation. Interestingly, when the level of harvesting effort is further increased, the coexistence of all species becomes unattainable, and the top predator becomes extinct. Some special cases: In this part, we delve into certain unique scenarios that often arise related to the harvesting of prey species within natural settings. In the first scenario, our focus is on a case where the catchability coefficient (q)\u011f\ufffd\u2018\ufffd(q)( italic_q ) is insignificant, even with normal harvesting effort. In the second scenario, we consider a situation where the harvesting effort (r)\u011f\ufffd\u2018\u0178(r)( italic_r ) is minimal, while the catchability coefficient (q)\u011f\ufffd\u2018\ufffd(q)( italic_q ) remains within normal levels. In the third scenario, there is a situation where both the harvesting effort (r)\u011f\ufffd\u2018\u0178(r)( italic_r ) and the catchability coefficient (q)\u011f\ufffd\u2018\ufffd(q)( italic_q ) are negligible at the same time. Scenario 1: When the catchability coefficient (q)q(q)( italic_q ) is negligible, even with normal harvesting effort This scenario represents that despite considerable exertion in the process of harvesting, no individuals from the population are being harvested. This indicates the presence of some sort of obstacle impeding the successful capture of prey, despite considerable exertion. It is essential to identify and tackle the underlying causes, which can be technological, behavioural, environmental, or related to population absence, in order to effectively manage and implement sustainable harvesting procedures. In order to have a clearer understanding of this specific situation, we employ certain parameter values to simulate this exact scenario. The parameter values are as follows: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, \u00ce\u00b2=0.01\u011f\ufffd\u203a\u00bd0.01 = 0.01, m1=0.5subscript\u011f\ufffd\u2018\u016110.5m_{1}=0.5italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5, m2=0.5subscript\u011f\ufffd\u2018\u016120.5m_{2}=0.5italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, q=0\u011f\ufffd\u2018\ufffd0q=0italic_q = 0, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, and r=0.01\u011f\ufffd\u2018\u01780.01r=0.01italic_r = 0.01. By utilising these specific parameter values, we have generated figure (21). The time series of all three populations at q=0\u011f\ufffd\u2018\ufffd0q=0italic_q = 0 is depicted in figure (21(a)). The phase portrait depicting the dynamics of the three populations is illustrated in figure (21(b)). Both the figures (21(a)) and (21(b)) are generated using the initial value (0.8,0.6,0.8). When the catchability coefficient is insignificant, the stable cohabitation of the three species is not possible, even with the standard harvesting effort. This is clearly shown in figure (21), where fluctuations in the populations of the three species occur within the system (2) when q=0\u011f\ufffd\u2018\ufffd0q=0italic_q = 0. Moreover, the occurrence of a limit cycle can also be seen in figure (21(b)). Looking at it from an ecological standpoint, it becomes evident that when the catchability coefficient is negligible, meaning that only a few prey are harvested even with consistent harvesting efforts, it results in population fluctuations among the three species. Thus, to promote a harmonious coexistence among all species in the system (2), it is essential to maintain a substantial level of harvesting output. Thus, the catchability coefficient (q)\u011f\ufffd\u2018\ufffd(q)( italic_q ) plays a crucial role in maintaining the coexistence of all three species in the system. Scenario 2: When the harvesting effort (r)r(r)( italic_r ) is minimal, while the catchability coefficient (q)q(q)( italic_q ) remains within normal levels In this scenario, only a small amount of effort invested in harvesting results in a significantly large number of catches, suggesting a high catchability coefficient. This scenario can occur in an ecological setting. For example, in a small region where prey are densely populated and are easily affected by the harvesting technique used, minimal effort could lead to a significant increase in the number of prey caught. Utilising highly effective harvesting equipment or technology can result in a significant increase in the rate of catching preys, while requiring minimal work. For instance, sophisticated nets, traps, or fishing methods that are very efficient in capturing the desired species. Gaining comprehension of these circumstances can aid in formulating more effective harvesting tactics and management protocols. In order to simulate this exact scenario, the following values of the parameters are used: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, \u00ce\u00b2=0.01\u011f\ufffd\u203a\u00bd0.01 = 0.01, m1=0.5subscript\u011f\ufffd\u2018\u016110.5m_{1}=0.5italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, m2=0.5subscript\u011f\ufffd\u2018\u016120.5m_{2}=0.5italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, q=0.5\u011f\ufffd\u2018\ufffd0.5q=0.5italic_q = 0.5, and r=0.001\u011f\ufffd\u2018\u01780.001r=0.001italic_r = 0.001. Based on the given parameter values, figure (22) has been generated. From this figure, it is understandable the manner in which the system\u00e2\u20ac\u2122s long-term dynamics are affected by the harvesting effort (r)\u011f\ufffd\u2018\u0178(r)( italic_r ). When the harvesting effort is kept to a minimum, fluctuations among the populations of the three species within the system (2) are observed. This makes it extremely challenging for the three species to stably coexist in such circumstances. Increasing the harvesting effort enhances the stability of coexistence, among the three species. That is why it is a crucial parameter within the system (2). Figures (22(a)) and (22(b)) show the phase portrait and time series, respectively, illustrating the dynamics of all three populations under minimal harvesting effort. Scenario 3: When there is a situation where both the harvesting effort (r)r(r)( italic_r ) and the catchability coefficient (q)q(q)( italic_q ) are negligible at the same time In this situation, it can be deduced that there is no allocation of resources or efforts towards harvesting the prey, resulting in the absence of any individuals being captured. Without any harvesting effort, there would be no catch. This scenario is simple and straightforward, as the lack of effort results in no interaction with the prey population. This scenario could arise in designated conservation areas where the act of harvesting is strictly forbidden, resulting in no attempts being made to harvest prey. It can also happen in situations where there is no desire or requirement for capturing the prey, resulting in little effort and inability to capture them. We utilise the following parameter values to gain a deeper understanding of this particular scenario: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, \u00ce\u00b2=0.01\u011f\ufffd\u203a\u00bd0.01 = 0.01, m1=0.5subscript\u011f\ufffd\u2018\u016110.5m_{1}=0.5italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, m2=0.5subscript\u011f\ufffd\u2018\u016120.5m_{2}=0.5italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, q=0\u011f\ufffd\u2018\ufffd0q=0italic_q = 0, and r=0\u011f\ufffd\u2018\u01780r=0italic_r = 0. By utilising these specific parameter settings, we have conducted a series of simulations and acquired diverse figures. Figures (23(a)) and (23(b)) depict the phase portrait and time series, respectively, of the three populations in the system (2) in the absence of harvesting. These results demonstrate that achieving steady coexistence in the above described system is extremely difficult without harvesting. Population fluctuations are observable in all three species in the system (2) when harvesting is not taking place. Therefore, the significance of harvesting in this system is explicitly established. Within this part, we explore the impact of prey odour on the system (2). The parameter \u00ce\u00b2\u011f\ufffd\u203a\u00bd in this system reflects the coefficient that quantifies the impact of prey odour. Figure (5(e)) vividly demonstrates the significance of the parameter \u00ce\u00b2\u011f\ufffd\u203a\u00bd Figure (5(e)) is obtained using the following parameter values: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, \u00ce\u00b2=0.5\u011f\ufffd\u203a\u00bd0.5 = 0.5, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, m1=0.5subscript\u011f\ufffd\u2018\u016110.5m_{1}=0.5italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5, m2=0.5subscript\u011f\ufffd\u2018\u016120.5m_{2}=0.5italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, q=0.5\u011f\ufffd\u2018\ufffd0.5q=0.5italic_q = 0.5, and r=0.01\u011f\ufffd\u2018\u01780.01r=0.01italic_r = 0.01. Based on figure (5(e)), it is apparent that the parameter \u00ce\u00b2\u011f\ufffd\u203a\u00bd significantly contributes to the stability of the system (2). Fluctuations in the populations of the three species within the system can be detected when the parameter value \u00ce\u00b2<0.020337=\u00ce\u00b2h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p\u011f\ufffd\u203a\u00bd0.020337superscript\u011f\ufffd\u203a\u00bd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd < 0.020337 = italic_\u00ce\u00b2 start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT. As an example, we will examine the parameter values: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, \u00ce\u00b2=0.015<\u00ce\u00b2h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p\u011f\ufffd\u203a\u00bd0.015superscript\u011f\ufffd\u203a\u00bd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd = 0.015 < italic_\u00ce\u00b2 start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT, m1=0.5subscript\u011f\ufffd\u2018\u016110.5m_{1}=0.5italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5, m2=0.5subscript\u011f\ufffd\u2018\u016120.5m_{2}=0.5italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, q=0.5\u011f\ufffd\u2018\ufffd0.5q=0.5italic_q = 0.5, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, and r=0.01\u011f\ufffd\u2018\u01780.01r=0.01italic_r = 0.01. Given this parameter configuration, we get the values N1=1.6>0subscript\u011f\ufffd\u2018\ufffd11.60N_{1}=1.6>0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1.6 > 0, N2=0.06>0subscript\u011f\ufffd\u2018\ufffd20.060N_{2}=0.06>0italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.06 > 0, N3=0.1>0subscript\u011f\ufffd\u2018\ufffd30.10N_{3}=0.1>0italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.1 > 0, and N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3=\u00e2\u02c6\u20190.0007<0subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd30.00070N_{1}N_{2}-N_{3}=-0.0007<0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = - 0.0007 < 0. Therefore, this verifies the instability of Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. This is readily apparent in figure (24(a)). A Hopf bifurcation occurs at \u00ce\u00b2=0.020337=\u00ce\u00b2h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p\u011f\ufffd\u203a\u00bd0.020337superscript\u011f\ufffd\u203a\u00bd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd = 0.020337 = italic_\u00ce\u00b2 start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT, leading to the stabilisation of the system. Given the parameter values: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, \u00ce\u00b2=\u00ce\u00b2h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p\u011f\ufffd\u203a\u00bdsuperscript\u011f\ufffd\u203a\u00bd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd = italic_\u00ce\u00b2 start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT, m1=0.5subscript\u011f\ufffd\u2018\u016110.5m_{1}=0.5italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5, m2=0.5subscript\u011f\ufffd\u2018\u016120.5m_{2}=0.5italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, q=0.5\u011f\ufffd\u2018\ufffd0.5q=0.5italic_q = 0.5, and r=0.01\u011f\ufffd\u2018\u01780.01r=0.01italic_r = 0.01, we find that N1=1.6>0subscript\u011f\ufffd\u2018\ufffd11.60N_{1}=1.6>0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1.6 > 0, N2=0.06>0subscript\u011f\ufffd\u2018\ufffd20.060N_{2}=0.06>0italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.06 > 0, N3=0.1>0subscript\u011f\ufffd\u2018\ufffd30.10N_{3}=0.1>0italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.1 > 0, N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3=0subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd30N_{1}N_{2}-N_{3}=0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0, and N1\u00e2\ufffd\u00a2(qh\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p)\u00e2\ufffd\u00a2N2\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(qh\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p)+N2\u00e2\ufffd\u00a2(qh\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p)\u00e2\ufffd\u00a2N1\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(qh\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p)\u00e2\u02c6\u2019N3\u00e2\u20ac\u00b2\u00e2\ufffd\u00a2(qh\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p)=0.133\u00e2\u2030 0subscript\u011f\ufffd\u2018\ufffd1superscript\u011f\ufffd\u2018\ufffd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\ufffd2\u00e2\u20ac\u00b2superscript\u011f\ufffd\u2018\ufffd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsubscript\u011f\ufffd\u2018\ufffd2superscript\u011f\ufffd\u2018\ufffd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\ufffd1\u00e2\u20ac\u00b2superscript\u011f\ufffd\u2018\ufffd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffdsuperscriptsubscript\u011f\ufffd\u2018\ufffd3\u00e2\u20ac\u00b2superscript\u011f\ufffd\u2018\ufffd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd0.1330N_{1}(q^{hbp})N_{2}^{{}^{ ^{hbp})-N_{3}^{{}^{ 0italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_q start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT ) italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_q start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT ) + italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_q start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT ) italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_q start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT ) - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT \u00e2\u20ac\u00b2 end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_q start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT ) = 0.133 \u00e2\u2030 0. Therefore, all the requirements outlined in theorem (14) for the existence of Hopf bifurcation are met, resulting in a Hopf bifurcation at \u00ce\u00b2=\u00ce\u00b2h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p\u011f\ufffd\u203a\u00bdsuperscript\u011f\ufffd\u203a\u00bd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd = italic_\u00ce\u00b2 start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT. When the parameter value \u00ce\u00b2\u011f\ufffd\u203a\u00bd is set to \u00ce\u00b2=0.04>\u00ce\u00b2h\u00e2\ufffd\u00a2b\u00e2\ufffd\u00a2p\u011f\ufffd\u203a\u00bd0.04superscript\u011f\ufffd\u203a\u00bd\u00e2\u201e\ufffd\u011f\ufffd\u2018\ufffd\u011f\ufffd\u2018\ufffd = 0.04 > italic_\u00ce\u00b2 start_POSTSUPERSCRIPT italic_h italic_b italic_p end_POSTSUPERSCRIPT, and all other parameter values remaining unchanged, we have the following results: N1=1.6subscript\u011f\ufffd\u2018\ufffd11.6N_{1}=1.6italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1.6, N2=0.07subscript\u011f\ufffd\u2018\ufffd20.07N_{2}=0.07italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.07, N3=0.1subscript\u011f\ufffd\u2018\ufffd30.1N_{3}=0.1italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.1, and N1\u00e2\ufffd\u00a2N2\u00e2\u02c6\u2019N3=0.002subscript\u011f\ufffd\u2018\ufffd1subscript\u011f\ufffd\u2018\ufffd2subscript\u011f\ufffd\u2018\ufffd30.002N_{1}N_{2}-N_{3}=0.002italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_N start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 0.002. All of these values are greater than zero. Therefore, based on theorem (8), the system (2) displays stability near Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT given the specified parameter values. This specific situation is depicted in figure (24(b)). Based on the previous discussion, it readily apparent that when the coefficient of prey odour effect increases, the intermediate predator becomes more attracted to the prey due to the odour released by the prey. As a result, the population of prey species decreases due to an increase in the encounter rate between the intermediate predator and prey, leading to a higher predation rate. This is precisely what happens within the system (2) as evident from figure (5(e)). Interestingly, it has been noted that a minimal amount of prey odour effect renders the stable coexistence of all three species within the system unattainable, resulting in oscillations in the populations of the three species. However, when the intensity of the prey odour is significantly enhanced, a Hopf bifurcation occurs, resulting in the long-term coexistence of all three populations within the system (2). Therefore, it has been discovered that the influence of prey odour aids in fostering a state of lasting cohabitation within this particular system. Special case: When the effect of prey odour is negligible, i.e., \u00ce\u00b2=0\u00ce\u00b20 = 0 In this portion, we aim to examine the scenario in which the influence of prey odour becomes insignificant within the system (2), specifically when \u00ce\u00b2=0\u011f\ufffd\u203a\u00bd0 = 0. In this scenario, the predator is unable to utilise scent as a means of locating its prey, hence the impact of prey odour in predation becomes negligible. In order to comprehend the scenario in which \u00ce\u00b2=0\u011f\ufffd\u203a\u00bd0 = 0, we conducted many simulations utilising specific parameter values: r1=2subscript\u011f\ufffd\u2018\u017812r_{1}=2italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 2, r5=1subscript\u011f\ufffd\u2018\u017851r_{5}=1italic_r start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT = 1, \u00ce\u00b2=0\u011f\ufffd\u203a\u00bd0 = 0, m1=0.5subscript\u011f\ufffd\u2018\u016110.5m_{1}=0.5italic_m start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.5, m2=0.5subscript\u011f\ufffd\u2018\u016120.5m_{2}=0.5italic_m start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, d1=0.25subscript\u011f\ufffd\u2018\u201810.25d_{1}=0.25italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.25, d2=0.5subscript\u011f\ufffd\u2018\u201820.5d_{2}=0.5italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.5, r2=1subscript\u011f\ufffd\u2018\u017821r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, r3=1subscript\u011f\ufffd\u2018\u017831r_{3}=1italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT = 1, c1=1subscript\u011f\ufffd\u2018\ufffd11c_{1}=1italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1, r4=3subscript\u011f\ufffd\u2018\u017843r_{4}=3italic_r start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT = 3, q=0.5\u011f\ufffd\u2018\ufffd0.5q=0.5italic_q = 0.5, and r=0.01\u011f\ufffd\u2018\u01780.01r=0.01italic_r = 0.01. We have produced two figures illustrating the circumstance where \u00ce\u00b2=0\u011f\ufffd\u203a\u00bd0 = 0. These are figures (25(a)) and (25(b)). Both of these figures are produced using the initial value of (0.8, 0.6, 0.8). Figures (25(a)) and (25(b)) illustrate the time series and phase portrait of the three populations species within the system (2), respectively. Looking at the aforementioned two figures, it is clear that the populations of the three species experience oscillations when there is no influence of prey odour in the system, specifically when \u00ce\u00b2=0\u011f\ufffd\u203a\u00bd0 = 0. To be more precise, the system (2) exhibits instability in the vicinity of Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. On top of that, figure (25(b)) clearly displays the presence of a limit cycle. In terms of ecology, the absence of the prey odour effect in the system makes it difficult for all three species to cohabit in a stable manner over a long period of time. This phenomenon, where the impact of prey odour becomes negligible within the system, is frequently seen in nature. As mentioned before, it has been discovered that predator species frequently mask their scents to avoid being detected by prey, enabling them to launch surprise attacks. Similarly, it has been observed that many prey species use similar tactics to evade detection by predators. Some prey species have been observed using the scent of other non-prey species as a way to conceal their own odour and avoid being detected by predators [68, 69, 70, 71]. For example, some caterpillars of the butterflies (Biston robustum) and (Mechanitis polymnia) have shown the remarkable ability to imitate the scent of the plants they eat and live on. This clever strategy helps them avoid being detected by predatory ants [69, 71]. The limpet species (Notoacmea palacea) employs chemical mimicry to decrease the likelihood of being preyed upon by matching the organisms it feeds on and resides with [68, 71]. Based on the numerical evidence provided, it appears that when the impact of prey odour on predators becomes too little, oscillations in the populations of all three species emerge. This ultimately leads to an unstable state of coexistence in the long term. Once the parameter \u00ce\u00b2\u011f\ufffd\u203a\u00bd surpasses a specific non-zero value, the coexistence of all species becomes stable. This suggests that the intermediate predator\u00e2\u20ac\u2122s level of attraction to the prey, caused by the prey\u00e2\u20ac\u2122s odour, plays a crucial role in the coexistence of the three species within the system under investigation. Our study delves into a model that investigates the intricate dynamics of a odour-mediated three species food chain. This model incorporates a commonly observed phenomenon, notably the influence of odour. It incorporates predator odour-induced prey refuge and prey harvesting. The model equations are formulated in two different types: one employing ordinary differential equations and the other utilising Caputo fractional-order differential equations to incorporate the memory effect. The paper explores the fundamental prerequisites, such as the existence, non-negativity, and uniqueness of the solutions of the system. The model\u00e2\u20ac\u2122s biologically plausible equilibrium states are established. All ecologically feasible equilibrium points are analysed in terms of their local stability. The article extensively covers the phenomenon of bifurcation, with a particular focus on the occurrence of Hopf bifurcations. An analysis has been conducted to compare the two systems, ODE (2) and FDE (3). We perform numerical simulations with biologically attainable parameters to illustrate the behaviour of the system close to the equilibrium points. It is found that our system can attain a maximum four equilibrium states: the vanishing equilibrium point Evsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a3E_{v}italic_E start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT, the axial equilibrium point Easubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{a}italic_E start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT, the top predator free equilibrium point Etsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a1E_{t}italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT, and the coexisting equilibrium point Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT. From an ecological standpoint, the vanishing equilibrium point Evsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a3E_{v}italic_E start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT represents the state in which all three species in the bio-system become extinct and the system breaks down. The axial equilibrium point Easubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{a}italic_E start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT represents the situation in which the two predators vanish, leaving only the prey species. The top predator free equilibrium point Etsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a1E_{t}italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT indicates the state in which only the top predator becomes extinct. The coexisting equilibrium point Ecsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{c}italic_E start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT reflects the scenario in which all three species coexist in the system. Based on our research findings, it can be inferred that if the rate of harvesting exceeds the growth rate of the prey species, the system will ultimately reach the vanishing equilibrium point, resulting in the extinction of all three species and the collapse of the system. The local stability of the vanishing equilibrium point Evsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a3E_{v}italic_E start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT precludes the possibility of the existence of the axial equilibrium point Easubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\ufffdE_{a}italic_E start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT and the top predator free equilibrium point Etsubscript\u011f\ufffd\ufffd\u00b8\u011f\ufffd\u2018\u00a1E_{t}italic_E start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT. Ecologically, reaching the vanishing equilibrium point refers to the instant at which all species in our system become extinct. At this point, there is no possibility of any growth in the species unless we reintroduce them, which is biologically true. The local stability of both the axial and top predator free equilibrium points negates the local stability of the vanishing equilibrium scores. From a biological perspective, this means that when the bio-system reaches a state where either just the prey survives in the system or the top predator becomes extinct from the system, the system has no way to collapse. In other words, all three species cannot become extinct simultaneously, as evidenced from our model. Upon satisfying certain parametric conditions, our discussed bio-system can achieve the coexistence equilibrium point. From an ecological point of view, it is evident that the coexistence of all three species is feasible within this system. Existing literature has already established that when prey species detect the presence of a nearby predator through olfactory cues, they become vigilant and employ various anti-predator strategies to minimise encounters. One effective strategy is for prey species to seek refuge in order to prevent predators from reaching them. In this study, we examine the consequences of refuge behaviour exhibited by prey and intermediate predators in response to their respective predators\u00e2\u20ac\u2122 odour. The prey\u00e2\u20ac\u2122s refuge behaviour towards the intermediate predator has been discovered to have a significant impact on the system. This parameter has the potential to trigger two Hopf bifurcations in the system, resulting in oscillations in the populations of the three species and giving birth to the intriguing bubbling phenomenon. Moreover, this parameter has the power to trigger a transcritical bifurcation in the system, altering the stability of the equilibrium points. Remarkably, it has been seen that when prey species seek refuge at a high rate, it can lead to the extinction of predators, making coexistence impossible. Moreover, the influence of the intermediate predator\u00e2\u20ac\u2122s odour on the dynamics of the system is established. This impact is readily apparent, as the parameter related to the intermediate predator\u00e2\u20ac\u2122s odour can trigger numerous transcritical bifurcations in the system. It has been discovered that it has a substantial influence on facilitating the coexistence of all three species in the system. Similarly, the refuge behaviour of the intermediate predator against the top predator also plays a crucial role in the long-term dynamics of the system. This parameter can additionally trigger oscillations in the system by inducing a Hopf bifurcation. Interestingly, an increase in this parameter may contribute to an overall reduction in the size of the prey population. Thus, the act of seeking refuge performed by individuals to avoid being preyed upon can have a significant impact on the long-term dynamics of the system. Additionally, it has been observed that the parameter associated with the odour of the top predator can trigger both a Hopf bifurcation and a transcritical bifurcation in the system. When the concentration of the top predator\u00e2\u20ac\u2122s odour is insignificant, no refuge is observed among the population of intermediate predators. However, even under such a scenario, it is still conceivable for the three species to coexist. Though fluctuations in the populations of all three species have been noted in this scenario. The study reveals that prey harvesting parameters have the potential to induce both Hopf bifurcation and transcritical bifurcations in the system, thus highlighting the significance of these parameters in the system. When the rate of successfully capturing prey through harvesting activities is low, it becomes challenging for all three species to maintain a stable coexistence. Furthermore, it is evident that for the three species in the system to coexist, a substantial catchability constant q\u011f\ufffd\u2018\ufffdqitalic_q is required, despite the fact that a greater catchability constant q\u011f\ufffd\u2018\ufffdqitalic_q can lead to a reduction in the prey population in the long-term dynamics. Additionally, it has been noted that an increase in the level of harvesting effort leads to a drop in the prey population, aligning with established biological principles. Surprisingly, when the intensity of the harvesting effort reaches an exceedingly high value, it becomes impossible for all species to cohabit, and the top predator faces the risk of extinction. It has been found that the level of attraction of the intermediate predator to the prey, influenced by the prey\u00e2\u20ac\u2122s odour, is a critical factor in the coexistence of the three species in the system. It is intriguing that the absence of the prey odour effect in the system poses a challenge for all three species to live together, leading to fluctuations in their populations. However, with a significant increase in the strength of the prey odour\u00e2\u20ac\u2122s effect, a Hopf bifurcation arises, leading to the sustained coexistence of all three populations in the system. In addition, as the impact of prey odour becomes stronger, the intermediate predator becomes more drawn to the prey, leading to a decrease in the population of the prey species due to an increase in the rate of encounters between the intermediate predator and the prey. This ultimately results in an elevated predation rate. The effect of memory on the system is also studied using a Caputo-type fractional-order derivative of order \u00ce\u00b1\u011f\ufffd\u203a\u00bc into the modelling of the system. It is observed that as the order of the fractional derivative decreases, the system under consideration becomes more and more stable. From an ecological perspective, it is possible to infer that in this system, as an individual\u00e2\u20ac\u2122s memory retention ability diminishes, they become unable to recall their previous experiences pertaining to their early life history. As a result, their consciousness of their immediate surroundings drops, leading to the instabilities and fluctuating cohabitation of the three species within the system. Therefore, it can be concluded that the memory of the individuals in this system is crucial for promoting the stability of the cohabitation of the three species within the system. Furthermore, this model can be broadened to include the relationship between a species\u00e2\u20ac\u2122 odour and its rate of harvesting. In this study, we have found, through a literature survey, a substantial body of ecological studies indicating the correlation between the odour of a species and its harvesting rate, although this aspect is not addressed in this document. This opens avenues for further investigation. Data Availability Statement No data of any source has been used in this study.",
        "keywords": ""
    }
]